{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392ad7b-3e05-4af1-80ca-cf56b3c2c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Union\n",
    "\n",
    "def engineer_features(df, expected_num_cols=None, expected_cat_cols=None):\n",
    "    df_engi = df.copy()\n",
    "    df_engi_temp = df_engi.fillna(0)\n",
    "    df_engi[\"TotalPastDue\"] = (\n",
    "        df_engi_temp[\"NumberOfTime30-59DaysPastDueNotWorse\"]\n",
    "        + df_engi_temp[\"NumberOfTimes90DaysLate\"]\n",
    "        + df_engi_temp[\"NumberOfTime60-89DaysPastDueNotWorse\"]\n",
    "    )\n",
    "    df_engi[\"HasDelinquencyBinary\"] = (df_engi[\"TotalPastDue\"] > 0).astype(int)\n",
    "    df_engi[\"MajorDelinquencyBinary\"] = (\n",
    "        (df_engi_temp[\"NumberOfTimes90DaysLate\"] > 0)\n",
    "        | (df_engi_temp[\"NumberOfTime60-89DaysPastDueNotWorse\"] > 0)\n",
    "    ).astype(int)\n",
    "    df_engi[\"IsHighUtilizationBinary\"] = (df_engi_temp[\"RevolvingUtilizationOfUnsecuredLines\"] > 0.67).astype(int)\n",
    "    age_notna = df_engi[\"age\"].notna()\n",
    "    df_engi.loc[age_notna, \"AgeBin\"] = pd.cut(\n",
    "        df_engi.loc[age_notna, \"age\"],\n",
    "        bins=[0, 25, 35, 45, 55, 65, 75, 85, 100],\n",
    "        labels=[\n",
    "            \"Age_0_25\", \"Age_25_35\", \"Age_35_45\", \"Age_45_55\",\n",
    "            \"Age_55_65\", \"Age_65_75\", \"Age_75_85\", \"Age_85_100\"\n",
    "        ],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    def credit_mix(row):\n",
    "        if pd.isna(row[\"NumberRealEstateLoansOrLines\"]) or pd.isna(row[\"NumberOfOpenCreditLinesAndLoans\"]):\n",
    "            return np.nan\n",
    "        if row[\"NumberRealEstateLoansOrLines\"] == 0 and row[\"NumberOfOpenCreditLinesAndLoans\"] == 0:\n",
    "            return \"NoCredit\"\n",
    "        elif row[\"NumberRealEstateLoansOrLines\"] > 0 and row[\"NumberOfOpenCreditLinesAndLoans\"] == 0:\n",
    "            return \"RealEstateOnly\"\n",
    "        elif row[\"NumberRealEstateLoansOrLines\"] == 0 and row[\"NumberOfOpenCreditLinesAndLoans\"] > 0:\n",
    "            return \"OtherCreditOnly\"\n",
    "        else:\n",
    "            return \"MixedCredit\"\n",
    "    df_engi[\"CreditMix\"] = df_engi.apply(credit_mix, axis=1)\n",
    "    df_engi[\"IsCreditMixRisky\"] = df_engi[\"CreditMix\"].ne(\"MixedCredit\").astype(int)\n",
    "    df_engi[\"HasDebtRatioHigh\"] = (df_engi_temp[\"DebtRatio\"] > 0.67).astype(int)\n",
    "    df_engi[\"Has90DaysLate\"] = (df_engi_temp[\"NumberOfTimes90DaysLate\"] > 0).astype(int)\n",
    "    df_engi[\"HasAnyLate\"] = (\n",
    "        df_engi_temp[\"NumberOfTimes90DaysLate\"]\n",
    "        + df_engi_temp[\"NumberOfTime30-59DaysPastDueNotWorse\"]\n",
    "        + df_engi_temp[\"NumberOfTime60-89DaysPastDueNotWorse\"]\n",
    "        > 0\n",
    "    ).astype(int)\n",
    "    df_engi[\"HasMultipleLate\"] = (\n",
    "        df_engi_temp[\"NumberOfTimes90DaysLate\"]\n",
    "        + df_engi_temp[\"NumberOfTime30-59DaysPastDueNotWorse\"]\n",
    "        + df_engi_temp[\"NumberOfTime60-89DaysPastDueNotWorse\"]\n",
    "        >= 2\n",
    "    ).astype(int)\n",
    "    df_engi[\"HasHighOpenCreditLines\"] = (df_engi_temp[\"NumberOfOpenCreditLinesAndLoans\"] > 8).astype(int)\n",
    "    df_engi[\"HasHighDebtLoad\"] = (\n",
    "        (df_engi_temp[\"DebtRatio\"] > 0.5) & (df_engi_temp[\"RevolvingUtilizationOfUnsecuredLines\"] > 0.67)\n",
    "    ).astype(int)\n",
    "    df_engi[\"DebtToIncomeRatio\"] = df_engi_temp[\"DebtRatio\"] / (df_engi_temp[\"MonthlyIncome\"] + 1e-3)\n",
    "    for col in [\"MonthlyIncome\", \"NumberOfDependents\"]:\n",
    "        df_engi[f\"{col}_was_missing\"] = df[col].isna().astype(int)\n",
    "    return df_engi\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(cat_dim, emb_dim) for cat_dim, emb_dim in zip(cat_dims, emb_dims)])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.out = nn.Linear(64, 1)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        x_cat_emb = torch.cat([emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "        x_num = self.bn_num(x_num)\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "        x_main = self.main(x)\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "        x_combined = x_main + x_skip\n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "num_imputer = joblib.load(\"num_imputer.pkl\")\n",
    "cat_imputer = joblib.load(\"cat_imputer.pkl\")\n",
    "robust_scaler = joblib.load(\"robust_scaler.pkl\")\n",
    "std_scaler = joblib.load(\"std_scaler.pkl\")\n",
    "cat_maps = joblib.load(\"cat_maps.pkl\")\n",
    "cat_col_order = joblib.load(\"cat_col_order.pkl\")\n",
    "num_col_order = joblib.load(\"num_col_order.pkl\")\n",
    "skewed_col_order = joblib.load(\"skewed_col_order.pkl\")\n",
    "threshold = joblib.load(\"threshold.pkl\")\n",
    "rare_maps = joblib.load(\"rare_maps.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cat_dims = [len(cat_maps[c]) for c in cat_col_order]\n",
    "emb_dims = [min(50, (len(cat_maps[c]) + 1) // 2) for c in cat_col_order]\n",
    "\n",
    "model = NN(num_numeric=len(num_col_order), cat_dims=cat_dims, emb_dims=emb_dims)\n",
    "model.load_state_dict(torch.load(\"cr_weights.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "app = FastAPI(title=\"Credit Risk Prediction API\")\n",
    "\n",
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    data: Dict[str, Union[str, float, int, None]]\n",
    "\n",
    "def preprocess_input(df: pd.DataFrame):\n",
    "    df_num_raw = df[num_col_order].copy()\n",
    "    df_num_imputed = pd.DataFrame(num_imputer.transform(df_num_raw), columns=num_col_order)\n",
    "    df_num_scaled = pd.DataFrame(index=df.index)\n",
    "    if skewed_col_order:\n",
    "        df_num_scaled[skewed_col_order] = robust_scaler.transform(df_num_imputed[skewed_col_order])\n",
    "    normal_col_order = [c for c in num_col_order if c not in skewed_col_order]\n",
    "    if normal_col_order:\n",
    "        df_num_scaled[normal_col_order] = std_scaler.transform(df_num_imputed[normal_col_order])\n",
    "    x_num_tensor = torch.tensor(df_num_scaled.values, dtype=torch.float32).to(device)\n",
    "    df_cat = df[cat_col_order].copy().astype(str)\n",
    "    for col, rare_cats in rare_maps.items():\n",
    "        if col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].apply(lambda x: x if x not in rare_cats else 'Other')\n",
    "    df_cat = df_cat.fillna(\"Other\")\n",
    "    for col in cat_col_order:\n",
    "        df_cat[col] = df_cat[col].map(cat_maps[col]).fillna(0).astype(int)\n",
    "    x_cat_tensor = torch.tensor(df_cat.values, dtype=torch.int64).to(device)\n",
    "    return x_num_tensor, x_cat_tensor\n",
    "\n",
    "def predict(df: pd.DataFrame, threshold=threshold):\n",
    "    df = engineer_features(df, expected_num_cols=num_col_order, expected_cat_cols=cat_col_order)\n",
    "    x_num, x_cat = preprocess_input(df)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6abb69-4c93-441d-a9bd-83918041f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvicorn main:app --host 127.0.0.1 --port 8001\n",
    "# pip install -r requirements.txt\n",
    "# python3 -m http.server\n",
    "# pm2 start \"uvicorn main:app --host 127.0.0.1 --port 8001\" --name \"my-fastapi-app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b47d0-c755-4ffe-a296-e25ee8ff4110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
