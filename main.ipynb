{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392ad7b-3e05-4af1-80ca-cf56b3c2c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Union\n",
    "\n",
    "\n",
    "def engineer_features(df):\n",
    "\n",
    "    df_engi = df.copy()\n",
    "\n",
    "    df_engi[\"TotalPastDue\"] = (\n",
    "        df_engi[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0) +\n",
    "        df_engi[\"NumberOfTimes90DaysLate\"].fillna(0) +\n",
    "        df_engi[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0)\n",
    "    )\n",
    "    \n",
    "    df_engi[\"HasDelinquencyBinary\"] = (df_engi[\"TotalPastDue\"] > 0).astype(int)\n",
    "    \n",
    "    df_engi[\"MajorDelinquencyBinary\"] = (\n",
    "        (df_engi[\"NumberOfTimes90DaysLate\"].fillna(0) > 0) |\n",
    "        (df_engi[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0) > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_engi[\"IsHighUtilizationBinary\"] = (\n",
    "        df_engi[\"RevolvingUtilizationOfUnsecuredLines\"] > 0.67\n",
    "    ).astype(float).fillna(np.nan).astype(\"Int64\") \n",
    "    \n",
    "    df_engi['age'] = pd.to_numeric(df_engi['age'], errors='coerce')\n",
    "\n",
    "    df_engi[\"AgeBin\"] = pd.cut(\n",
    "        df_engi[\"age\"],\n",
    "        bins=[0, 25, 35, 45, 55, 65, 75, 85, 100],\n",
    "        labels=[\n",
    "            \"Age_0_25\", \"Age_25_35\", \"Age_35_45\", \"Age_45_55\",\n",
    "            \"Age_55_65\", \"Age_65_75\", \"Age_75_85\", \"Age_85_100\"\n",
    "        ],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    def credit_mix_no_impute(row):\n",
    "        real_estate = row[\"NumberRealEstateLoansOrLines\"]\n",
    "        open_credit = row[\"NumberOfOpenCreditLinesAndLoans\"]\n",
    "        if pd.isna(real_estate) or pd.isna(open_credit):\n",
    "            return np.nan \n",
    "        elif real_estate == 0 and open_credit == 0:\n",
    "            return \"NoCredit\"\n",
    "        elif real_estate > 0 and open_credit == 0:\n",
    "            return \"RealEstateOnly\"\n",
    "        elif real_estate == 0 and open_credit > 0:\n",
    "            return \"OtherCreditOnly\"\n",
    "        else:\n",
    "            return \"MixedCredit\"\n",
    "\n",
    "    df_engi[\"CreditMix\"] = df_engi.apply(credit_mix_no_impute, axis=1)\n",
    "\n",
    "    df_engi[\"IsCreditMixRisky\"] = df_engi[\"CreditMix\"].ne(\"MixedCredit\").astype(float).fillna(np.nan).astype(\"Int64\")\n",
    "    \n",
    "    df_engi[\"HasDebtRatioHigh\"] = (df_engi[\"DebtRatio\"] > 0.67).astype(float).fillna(np.nan).astype(\"Int64\")\n",
    "    \n",
    "    df_engi[\"Has90DaysLate\"] = (df_engi[\"NumberOfTimes90DaysLate\"].fillna(0) > 0).astype(int)\n",
    "  \n",
    "    df_engi[\"HasAnyLate\"] = (df_engi[\"TotalPastDue\"] > 0).astype(int)\n",
    "    \n",
    "    df_engi[\"HasMultipleLate\"] = (df_engi[\"TotalPastDue\"] >= 2).astype(int)\n",
    "    \n",
    "    df_engi[\"HasHighOpenCreditLines\"] = (df_engi[\"NumberOfOpenCreditLinesAndLoans\"] > 8).astype(float).fillna(np.nan).astype(\"Int64\")\n",
    "    \n",
    "    df_engi[\"HasHighDebtLoad\"] = (\n",
    "        (df_engi[\"DebtRatio\"] > 0.5) & \n",
    "        (df_engi[\"RevolvingUtilizationOfUnsecuredLines\"] > 0.67)\n",
    "    ).astype(float).fillna(np.nan).astype(\"Int64\")\n",
    "\n",
    "    df_engi[\"DebtToIncomeRatio\"] = df_engi[\"DebtRatio\"] / (df_engi[\"MonthlyIncome\"] + 1e-3)\n",
    "    \n",
    "    return df_engi\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(cat_dim, emb_dim) for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.out = nn.Linear(64, 1)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        x_cat_emb = torch.cat([emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "        x_num = self.bn_num(x_num)\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "        x_main = self.main(x)\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "        x_combined = x_main + x_skip\n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model_b = xgb.XGBClassifier()\n",
    "model_b.load_model(\"cr_b.json\")\n",
    "num_imputer = joblib.load(\"num_imputer.pkl\")\n",
    "cat_imputer = joblib.load(\"cat_imputer.pkl\")\n",
    "robust_scaler = joblib.load(\"robust_scaler.pkl\")\n",
    "std_scaler = joblib.load(\"std_scaler.pkl\")\n",
    "cat_maps = joblib.load(\"cat_maps.pkl\")\n",
    "cat_col_order = joblib.load(\"cat_col_order.pkl\")\n",
    "num_col_order = joblib.load(\"num_col_order.pkl\")\n",
    "skewed_col_order = joblib.load(\"skewed_col_order.pkl\")\n",
    "threshold_a = joblib.load(\"threshold_a.pkl\")\n",
    "threshold_b = joblib.load(\"threshold_b.pkl\")\n",
    "rare_maps = joblib.load(\"rare_maps.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cat_dims = [len(cat_maps[c]) for c in cat_col_order]\n",
    "emb_dims = [min(50, (len(cat_maps[c]) + 1) // 2) for c in cat_col_order]\n",
    "\n",
    "model = NN(num_numeric=len(num_col_order), cat_dims=cat_dims, emb_dims=emb_dims)\n",
    "\n",
    "weights_path = \"cr_weights.pth\"\n",
    "loaded_weights = torch.load(weights_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(loaded_weights)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "app = FastAPI(title=\"Credit Risk Prediction API\")\n",
    "\n",
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    data: Dict[str, Union[str, float, int, None]]\n",
    "\n",
    "def preprocess(df: pd.DataFrame, add_was_imputed: bool = False):\n",
    "\n",
    "    df_engi = engineer_features(df)\n",
    "    \n",
    "    if add_was_imputed:\n",
    "        for col in df_engi.columns:\n",
    "            df_engi[f\"Was{col}Imputed\"] = df_engi[col].isna().astype(int)\n",
    "    \n",
    "    df_num_raw = df_engi[num_col_order].copy()\n",
    "    df_num_imputed = pd.DataFrame(num_imputer.transform(df_num_raw), columns=num_col_order)\n",
    "    \n",
    "    df_num_scaled = pd.DataFrame(index=df_engi.index)\n",
    "    if skewed_col_order:\n",
    "        df_num_scaled[skewed_col_order] = robust_scaler.transform(df_num_imputed[skewed_col_order])\n",
    "    normal_col_order = [c for c in num_col_order if c not in skewed_col_order]\n",
    "    if normal_col_order:\n",
    "        df_num_scaled[normal_col_order] = std_scaler.transform(df_num_imputed[normal_col_order])\n",
    "    \n",
    "    df_cat = df_engi[cat_col_order].copy().astype('category')  \n",
    "    for col, rare_cats in rare_maps.items():\n",
    "        if col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].cat.add_categories('Other')\n",
    "            df_cat[col] = df_cat[col].where(~df_cat[col].isin(rare_cats), 'Other')\n",
    "    \n",
    "    for col in df_cat.columns:\n",
    "        df_cat[col] = df_cat[col].cat.add_categories('Unknown')\n",
    "        df_cat[col] = df_cat[col].fillna('Unknown')\n",
    "    \n",
    "    for col in cat_col_order:\n",
    "        df_cat[col] = df_cat[col].map(cat_maps[col])\n",
    "        unknown_code = cat_maps[col].get('Unknown', None)\n",
    "        other_code = cat_maps[col].get('Other', 0)\n",
    "        if unknown_code is not None:\n",
    "            df_cat[col] = df_cat[col].fillna(unknown_code)\n",
    "        else:\n",
    "            df_cat[col] = df_cat[col].fillna(other_code)\n",
    "        df_cat[col] = df_cat[col].astype(int)\n",
    "\n",
    "    if add_was_imputed:\n",
    "        df_final = pd.concat([df_num_scaled, df_cat], axis=1)\n",
    "        was_imputed_cols = [c for c in df_engi.columns if c.startswith(\"Was\")]\n",
    "        df_final = pd.concat([df_final, df_engi[was_imputed_cols]], axis=1)\n",
    "        df_final = df_final.astype(np.float32)\n",
    "        trained_features = model_b.get_booster().feature_names\n",
    "        df_final = df_final.reindex(columns=trained_features, fill_value=0.0)\n",
    "        return df_final\n",
    "    else:\n",
    "        x_num_tensor = torch.tensor(df_num_scaled.values, dtype=torch.float32).to(device)\n",
    "        x_cat_tensor = torch.tensor(df_cat.values, dtype=torch.int64).to(device)\n",
    "        return x_num_tensor, x_cat_tensor\n",
    "\n",
    "def predict_nn(df: pd.DataFrame, threshold=threshold_a):\n",
    "    x_num, x_cat = preprocess(df, add_was_imputed=False)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_nn\")\n",
    "def predict_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_nn(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}\n",
    "    \n",
    "\n",
    "def predict_xgb(df: pd.DataFrame, threshold=threshold_b):\n",
    "    df = preprocess(df, add_was_imputed=True)\n",
    "    probs = model_b.predict_proba(df)[:, 1]\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_xgb\")\n",
    "def predict_xgb_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_xgb(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6abb69-4c93-441d-a9bd-83918041f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvicorn main:app --host 127.0.0.1 --port 8001\n",
    "# pip install -r requirements.txt\n",
    "# python3 -m http.server\n",
    "# pm2 start venv/bin/python --name \"fastapi-app\" -- -m uvicorn main:app --host 127.0.0.1 --port 8001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b47d0-c755-4ffe-a296-e25ee8ff4110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
