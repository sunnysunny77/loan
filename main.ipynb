{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6392ad7b-3e05-4af1-80ca-cf56b3c2c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Union\n",
    "\n",
    "def engineer_features(df):\n",
    "    df_e = df.copy()\n",
    "\n",
    "    # Fill all missing values with 0 for safety\n",
    "    df_e = df_e.fillna(0)\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    expected_cols = [\n",
    "        \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "        \"RevolvingUtilizationOfUnsecuredLines\", \"DebtRatio\", \"MonthlyIncome\", \"NumberOfOpenCreditLinesAndLoans\",\n",
    "        \"age\", \"NumberOfDependents\"\n",
    "    ]\n",
    "    for col in expected_cols:\n",
    "        if col not in df_e.columns:\n",
    "            df_e[col] = 0\n",
    "\n",
    "    TotalPastDue = (\n",
    "        df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"]\n",
    "        + df_e[\"NumberOfTimes90DaysLate\"]\n",
    "        + df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"]\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationOfUnsecuredLines = np.log1p(df_e[\"RevolvingUtilizationOfUnsecuredLines\"])\n",
    "\n",
    "    df_e[\"MajorDelinquencyBinary\"] = (\n",
    "        (df_e[\"NumberOfTimes90DaysLate\"] > 0) |\n",
    "        (df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"] > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"HasDelinquencies\"] = (TotalPastDue > 0).astype(int)\n",
    "    df_e[\"NormalizedUtilization\"] = np.sqrt(RevolvingUtilizationOfUnsecuredLines)\n",
    "    df_e[\"DelinquencyInteraction\"] = TotalPastDue * RevolvingUtilizationOfUnsecuredLines\n",
    "    df_e[\"UtilizationPerAge\"] = RevolvingUtilizationOfUnsecuredLines / (df_e[\"age\"].replace(0, np.nan))\n",
    "    df_e[\"LatePaymentsPerAge\"] = TotalPastDue / (df_e[\"age\"].replace(0, np.nan))\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / (df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan))\n",
    "    df_e[\"TotalPastDue_Squared\"] = TotalPastDue ** 2\n",
    "    df_e[\"90DaysLate_Squared\"] = df_e[\"NumberOfTimes90DaysLate\"] ** 2\n",
    "    df_e[\"LogDebtRatio\"] = np.log1p(df_e[\"DebtRatio\"])\n",
    "    df_e[\"LogMonthlyIncome\"] = np.log1p(df_e[\"MonthlyIncome\"])\n",
    "    df_e[\"IncomePerCreditLine\"] = df_e[\"LogMonthlyIncome\"] / (df_e[\"NumberOfOpenCreditLinesAndLoans\"] + 1)\n",
    "    df_e[\"DebtToIncome\"] = df_e[\"LogDebtRatio\"] * df_e[\"LogMonthlyIncome\"]\n",
    "\n",
    "    df_e[\"AgeRisk\"] = np.where(df_e[\"age\"] < 25, 1,\n",
    "                       np.where(df_e[\"age\"] < 35, 0.8,\n",
    "                       np.where(df_e[\"age\"] < 50, 0.6, 0.4)))\n",
    "\n",
    "    utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    df_e[\"UtilizationBucket\"] = pd.cut(RevolvingUtilizationOfUnsecuredLines, bins=utilization_bins, labels=utilization_labels)\n",
    "\n",
    "    late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    df_e[\"LatePaymentBucket\"] = pd.cut(TotalPastDue, bins=late_bins, labels=late_labels)\n",
    "\n",
    "    df_e = df_e.drop([\n",
    "        \"RevolvingUtilizationOfUnsecuredLines\", \"NumberOfTimes90DaysLate\", \"NumberRealEstateLoansOrLines\",\n",
    "        \"DebtRatio\", \"MonthlyIncome\", \"NumberOfOpenCreditLinesAndLoans\",\n",
    "        \"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "        \"age\", \"NumberOfDependents\", \"LogMonthlyIncome\", \"LogDebtRatio\"\n",
    "    ], axis=1, errors='ignore')\n",
    "\n",
    "    return df_e\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(cat_dim, emb_dim) for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.out = nn.Linear(64, 1)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        x_cat_emb = torch.cat([emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "        x_num = self.bn_num(x_num)\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "        x_main = self.main(x)\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "        x_combined = x_main + x_skip\n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model_b = xgb.XGBClassifier()\n",
    "model_b.load_model(\"cr_b.json\")\n",
    "num_imputer = joblib.load(\"num_imputer.pkl\")\n",
    "cat_imputer = joblib.load(\"cat_imputer.pkl\")\n",
    "robust_scaler = joblib.load(\"robust_scaler.pkl\")\n",
    "std_scaler = joblib.load(\"std_scaler.pkl\")\n",
    "cat_maps = joblib.load(\"cat_maps.pkl\")\n",
    "cat_col_order = joblib.load(\"cat_col_order.pkl\")\n",
    "num_col_order = joblib.load(\"num_col_order.pkl\")\n",
    "skewed_col_order = joblib.load(\"skewed_col_order.pkl\")\n",
    "threshold_a = joblib.load(\"threshold_a.pkl\")\n",
    "threshold_b = joblib.load(\"threshold_b.pkl\")\n",
    "rare_maps = joblib.load(\"rare_maps.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cat_dims = [len(cat_maps[c]) for c in cat_col_order]\n",
    "emb_dims = [min(50, (len(cat_maps[c]) + 1) // 2) for c in cat_col_order]\n",
    "\n",
    "model = NN(num_numeric=len(num_col_order), cat_dims=cat_dims, emb_dims=emb_dims)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights_path = \"cr_weights.pth\"\n",
    "loaded_weights = torch.load(weights_path, map_location=device) \n",
    "model.load_state_dict(loaded_weights)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "app = FastAPI(title=\"Credit Risk Prediction API\")\n",
    "\n",
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    data: Dict[str, Union[str, float, int, None]]\n",
    "\n",
    "def preprocess(df: pd.DataFrame, add_was_imputed: bool = False):\n",
    "\n",
    "    df_engi = engineer_features(df)\n",
    "\n",
    "    if add_was_imputed:\n",
    "        for col in df_engi.columns:\n",
    "            df_engi[f\"Was{col}Imputed\"] = df_engi[col].isna().astype(int)\n",
    "\n",
    "    df_num_raw = df_engi[num_col_order].copy()\n",
    "    df_num_imputed = pd.DataFrame(num_imputer.transform(df_num_raw), columns=num_col_order)\n",
    "\n",
    "    df_num_scaled = pd.DataFrame(index=df_engi.index)\n",
    "    if skewed_col_order:\n",
    "        df_num_scaled[skewed_col_order] = robust_scaler.transform(df_num_imputed[skewed_col_order])\n",
    "    normal_col_order = [c for c in num_col_order if c not in skewed_col_order]\n",
    "    if normal_col_order:\n",
    "        df_num_scaled[normal_col_order] = std_scaler.transform(df_num_imputed[normal_col_order])\n",
    "\n",
    "    df_cat = df_engi[cat_col_order].copy().astype('category')  \n",
    "    for col, rare_cats in rare_maps.items():\n",
    "        if col in df_cat.columns:\n",
    "            df_cat[col] = df_cat[col].cat.add_categories('Other')\n",
    "            df_cat[col] = df_cat[col].where(~df_cat[col].isin(rare_cats), 'Other')\n",
    "\n",
    "    for col in df_cat.columns:\n",
    "        df_cat[col] = df_cat[col].cat.add_categories('Unknown')\n",
    "        df_cat[col] = df_cat[col].fillna('Unknown')\n",
    "\n",
    "    for col in cat_col_order:\n",
    "        df_cat[col] = df_cat[col].map(cat_maps[col])\n",
    "        unknown_code = cat_maps[col].get('Unknown', None)\n",
    "        other_code = cat_maps[col].get('Other', 0)\n",
    "        if unknown_code is not None:\n",
    "            df_cat[col] = df_cat[col].fillna(unknown_code)\n",
    "        else:\n",
    "            df_cat[col] = df_cat[col].fillna(other_code)\n",
    "        df_cat[col] = df_cat[col].astype(int)\n",
    "\n",
    "    if add_was_imputed:\n",
    "        df_final = pd.concat([df_num_scaled, df_cat], axis=1)\n",
    "        was_imputed_cols = [c for c in df_engi.columns if c.startswith(\"Was\")]\n",
    "        df_final = pd.concat([df_final, df_engi[was_imputed_cols]], axis=1)\n",
    "        df_final = df_final.astype(np.float32)\n",
    "        trained_features = model_b.get_booster().feature_names\n",
    "        df_final = df_final.reindex(columns=trained_features, fill_value=0.0)\n",
    "        return df_final\n",
    "    else:\n",
    "        x_num_tensor = torch.tensor(df_num_scaled.values, dtype=torch.float32).to(device)\n",
    "        x_cat_tensor = torch.tensor(df_cat.values, dtype=torch.int64).to(device)\n",
    "        return x_num_tensor, x_cat_tensor\n",
    "\n",
    "def predict_nn(df: pd.DataFrame, threshold=threshold_a):\n",
    "    x_num, x_cat = preprocess(df, add_was_imputed=False)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_nn\")\n",
    "def predict_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_nn(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}\n",
    "\n",
    "\n",
    "def predict_xgb(df: pd.DataFrame, threshold=threshold_b):\n",
    "    df = preprocess(df, add_was_imputed=True)\n",
    "    probs = model_b.predict_proba(df)[:, 1]\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_xgb\")\n",
    "def predict_xgb_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_xgb(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6abb69-4c93-441d-a9bd-83918041f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvicorn main:app --host 127.0.0.1 --port 8001\n",
    "# pip install -r requirements.txt\n",
    "# python3 -m http.server\n",
    "# pm2 start venv/bin/python --name \"fastapi-app\" -- -m uvicorn main:app --host 127.0.0.1 --port 8001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b47d0-c755-4ffe-a296-e25ee8ff4110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cdfca-51bf-45b6-ad55-4eec00eb1c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861c565-eb87-4afe-89e4-4ec130d31f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
