{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    TotalPastDueCapped = TotalPastDue.clip(upper=10)\n",
    "\n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLog / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = RevolvingUtilizationCappedLog\n",
    "    df_e[\"TotalPastDueCapped\"] = TotalPastDueCapped\n",
    "    \n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationCappedLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationCapped, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"TotalPastDueCapped\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"scale_pos_weight\": sum(y_train==0)/sum(y_train==1),\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 4,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in X_train.columns}\n",
    "\n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "\n",
    "    final_features = list(set(top_features + cat_cols))\n",
    "\n",
    "    dropped_features = [f for f in df_temp.columns if f not in final_features]\n",
    "\n",
    "    print(f\"Kept {len(final_features)} features (including categorical columns)\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[final_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    \n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    \n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 609 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyBucket                         0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasAnyDelinquency                         0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                    1043            1.09\n",
      "LatePaymentsPerCreditLine              1043            1.09\n",
      "RevolvingUtilizationCappedLog          6831            7.15\n",
      "TotalPastDueCapped                        0            0.00\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      6831            7.15\n",
      "UtilizationPerCreditLine               7874            8.24\n",
      "UtilizationTimesDelinquency            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 29 rare categories: ['Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'Very High_ModerateLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very High_FrequentLate', 'Low_ModerateLate', 'nan_FewLate', 'Very Low_ModerateLate', 'High_FrequentLate', 'Very High_ChronicLate', 'nan_ModerateLate', 'Moderate_FrequentLate', 'Extreme_NoLate', 'Low_FrequentLate', 'High_ChronicLate', 'Very Low_FrequentLate', 'Extreme_ModerateLate', 'Moderate_ChronicLate', 'nan_FrequentLate', 'Extreme_FewLate', 'Extreme_FrequentLate', 'Low_ChronicLate', 'nan_ChronicLate', 'Extreme_ChronicLate', 'Very Low_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 14 features (including categorical columns)\n",
      "Dropped 0 features\n",
      "                          Feature  Importance\n",
      "0       LatePaymentsPerCreditLine  843.328247\n",
      "1                DelinquencyScore  449.028839\n",
      "2     UtilizationTimesDelinquency  336.475403\n",
      "3               DelinquencyBucket  211.412292\n",
      "4     UtilizationBucketLateBucket  181.459122\n",
      "5              TotalPastDueCapped  169.305695\n",
      "6               UtilizationPerAge  120.161751\n",
      "7             HasMajorDelinquency   96.044540\n",
      "8   RevolvingUtilizationCappedLog   72.250793\n",
      "9             DebtToIncomeAgeRisk   47.982803\n",
      "10            IncomePerCreditLine   37.936604\n",
      "11                HighAgeRiskFlag   31.727243\n",
      "12       UtilizationPerCreditLine   31.542318\n",
      "13              HasAnyDelinquency    6.560921\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2908 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92598, 28)\n",
      "Total rows: 92598\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076097</td>\n",
       "      <td>0.300314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.388191</td>\n",
       "      <td>0.309645</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.281012</td>\n",
       "      <td>0.771726</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681580</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>0.268645</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>0.216556</td>\n",
       "      <td>0.633069</td>\n",
       "      <td>-0.440434</td>\n",
       "      <td>-0.320875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673260</td>\n",
       "      <td>4.139011</td>\n",
       "      <td>1.117564</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.321183</td>\n",
       "      <td>2.143377</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.399441</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.575909</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.497662</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>-0.228439</td>\n",
       "      <td>-0.089933</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15842</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.093738</td>\n",
       "      <td>0.364758</td>\n",
       "      <td>True</td>\n",
       "      <td>HasAnyDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>1.608289</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.422533</td>\n",
       "      <td>0.028949</td>\n",
       "      <td>0.586787</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.268737</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.209562</td>\n",
       "      <td>1.775414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.241138</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82039</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>2.314940</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.309695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707668</td>\n",
       "      <td>39.419312</td>\n",
       "      <td>4.650212</td>\n",
       "      <td>0.177593</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205091</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.460809</td>\n",
       "      <td>0.311074</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationTimesDelinquency (0.74), TotalPastDueCapped (0.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.924108</td>\n",
       "      <td>0.362474</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDueCapped</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>1.097088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.180515</td>\n",
       "      <td>0.399287</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.86), HasAnyDelinquency (0.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.683308</td>\n",
       "      <td>2.492097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.231471</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDueCapped (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.816249</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.622637</td>\n",
       "      <td>0.053309</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.777148</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasRevolvingUtilizationCappedLogImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerAgeImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.777148</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHighAgeRiskFlagImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationTimesDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerAgeImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>0.236548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.724540</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95), WasUtilizationTimesDelinquencyImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasTotalPastDueCappedImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyScoreImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dtype  non_null  missing  \\\n",
       "LatePaymentsPerCreditLine                float64     92598        0   \n",
       "UtilizationPerAge                        float64     92598        0   \n",
       "RevolvingUtilizationCappedLog            float64     92598        0   \n",
       "IncomePerCreditLine                      float64     92598        0   \n",
       "HighAgeRiskFlag                          float64     92598        0   \n",
       "UtilizationTimesDelinquency              float64     92598        0   \n",
       "DebtToIncomeAgeRisk                      float64     92598        0   \n",
       "UtilizationBucketLateBucket                 int8     92598        0   \n",
       "UtilizationPerCreditLine                 float64     92598        0   \n",
       "HasAnyDelinquency                        float64     92598        0   \n",
       "HasMajorDelinquency                      float64     92598        0   \n",
       "TotalPastDueCapped                       float64     92598        0   \n",
       "DelinquencyScore                         float64     92598        0   \n",
       "DelinquencyBucket                           int8     92598        0   \n",
       "WasLatePaymentsPerCreditLineImputed        int64     92598        0   \n",
       "WasUtilizationPerAgeImputed                int64     92598        0   \n",
       "WasRevolvingUtilizationCappedLogImputed    int64     92598        0   \n",
       "WasIncomePerCreditLineImputed              int64     92598        0   \n",
       "WasHighAgeRiskFlagImputed                  int64     92598        0   \n",
       "WasUtilizationTimesDelinquencyImputed      int64     92598        0   \n",
       "WasDebtToIncomeAgeRiskImputed              int64     92598        0   \n",
       "WasUtilizationPerCreditLineImputed         int64     92598        0   \n",
       "WasHasAnyDelinquencyImputed                int64     92598        0   \n",
       "WasHasMajorDelinquencyImputed              int64     92598        0   \n",
       "WasTotalPastDueCappedImputed               int64     92598        0   \n",
       "WasDelinquencyScoreImputed                 int64     92598        0   \n",
       "WasUtilizationBucketLateBucketImputed      int64     92598        0   \n",
       "WasDelinquencyBucketImputed                int64     92598        0   \n",
       "\n",
       "                                         missing_%  unique      mean  \\\n",
       "LatePaymentsPerCreditLine                      0.0     201  0.076097   \n",
       "UtilizationPerAge                              0.0   82305  0.281012   \n",
       "RevolvingUtilizationCappedLog                  0.0   80850  0.216556   \n",
       "IncomePerCreditLine                            0.0   26180  0.321183   \n",
       "HighAgeRiskFlag                                0.0       2 -0.001075   \n",
       "UtilizationTimesDelinquency                    0.0   15842  0.001908   \n",
       "DebtToIncomeAgeRisk                            0.0   72746  0.268932   \n",
       "UtilizationBucketLateBucket                    0.0       7  3.209562   \n",
       "UtilizationPerCreditLine                       0.0   82039  0.726617   \n",
       "HasAnyDelinquency                              0.0       2  0.205091   \n",
       "HasMajorDelinquency                            0.0       2  0.087302   \n",
       "TotalPastDueCapped                             0.0      11  0.409426   \n",
       "DelinquencyScore                               0.0      38  0.683308   \n",
       "DelinquencyBucket                              0.0       4  1.816249   \n",
       "WasLatePaymentsPerCreditLineImputed            0.0       2  0.006015   \n",
       "WasUtilizationPerAgeImputed                    0.0       2  0.053478   \n",
       "WasRevolvingUtilizationCappedLogImputed        0.0       2  0.053478   \n",
       "WasIncomePerCreditLineImputed                  0.0       2  0.006015   \n",
       "WasHighAgeRiskFlagImputed                      0.0       1  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed          0.0       2  0.053478   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.0       1  0.000000   \n",
       "WasUtilizationPerCreditLineImputed             0.0       2  0.059494   \n",
       "WasHasAnyDelinquencyImputed                    0.0       1  0.000000   \n",
       "WasHasMajorDelinquencyImputed                  0.0       1  0.000000   \n",
       "WasTotalPastDueCappedImputed                   0.0       1  0.000000   \n",
       "WasDelinquencyScoreImputed                     0.0       1  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.0       1  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.0       1  0.000000   \n",
       "\n",
       "                                              std       min       25%  \\\n",
       "LatePaymentsPerCreditLine                0.300314  0.000000  0.000000   \n",
       "UtilizationPerAge                        0.771726 -0.416697 -0.314413   \n",
       "RevolvingUtilizationCappedLog            0.633069 -0.440434 -0.320875   \n",
       "IncomePerCreditLine                      2.143377 -0.712727 -0.399441   \n",
       "HighAgeRiskFlag                          1.000129 -1.121933 -1.121933   \n",
       "UtilizationTimesDelinquency              0.005049  0.000000  0.000000   \n",
       "DebtToIncomeAgeRisk                      1.608289 -0.444698 -0.422533   \n",
       "UtilizationBucketLateBucket              1.775414  0.000000  2.000000   \n",
       "UtilizationPerCreditLine                 2.314940 -0.439705 -0.309695   \n",
       "HasAnyDelinquency                        0.403770  0.000000  0.000000   \n",
       "HasMajorDelinquency                      0.282279  0.000000  0.000000   \n",
       "TotalPastDueCapped                       1.097088  0.000000  0.000000   \n",
       "DelinquencyScore                         2.492097  0.000000  0.000000   \n",
       "DelinquencyBucket                        0.657420  0.000000  2.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.077325  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed              0.224987  0.000000  0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.224987  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed            0.077325  0.000000  0.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.224987  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000  0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.236548  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000  0.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000  0.000000   \n",
       "WasTotalPastDueCappedImputed             0.000000  0.000000  0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000  0.000000   \n",
       "\n",
       "                                              50%       75%         max  \\\n",
       "LatePaymentsPerCreditLine                0.000000  0.000000   30.000000   \n",
       "UtilizationPerAge                        0.000000  0.681580    8.241714   \n",
       "RevolvingUtilizationCappedLog            0.000000  0.673260    4.139011   \n",
       "IncomePerCreditLine                      0.014545  0.575909  279.287273   \n",
       "HighAgeRiskFlag                          0.891319  0.891319    0.891319   \n",
       "UtilizationTimesDelinquency              0.000000  0.000000    0.071670   \n",
       "DebtToIncomeAgeRisk                      0.028949  0.586787  230.122301   \n",
       "UtilizationBucketLateBucket              3.000000  5.000000    6.000000   \n",
       "UtilizationPerCreditLine                 0.000000  0.707668   39.419312   \n",
       "HasAnyDelinquency                        0.000000  0.000000    1.000000   \n",
       "HasMajorDelinquency                      0.000000  0.000000    1.000000   \n",
       "TotalPastDueCapped                       0.000000  0.000000   10.000000   \n",
       "DelinquencyScore                         0.000000  0.000000   60.000000   \n",
       "DelinquencyBucket                        2.000000  2.000000    3.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerAgeImputed              0.000000  0.000000    1.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.000000  0.000000    1.000000   \n",
       "WasIncomePerCreditLineImputed            0.000000  0.000000    1.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000    0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.000000  0.000000    1.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000    0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.000000  0.000000    1.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000    0.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000    0.000000   \n",
       "WasTotalPastDueCappedImputed             0.000000  0.000000    0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000    0.000000   \n",
       "\n",
       "                                              skew  corr_with_target  \\\n",
       "LatePaymentsPerCreditLine                18.388191          0.309645   \n",
       "UtilizationPerAge                         1.678331          0.268645   \n",
       "RevolvingUtilizationCappedLog             1.117564          0.271133   \n",
       "IncomePerCreditLine                      51.497662          0.003751   \n",
       "HighAgeRiskFlag                          -0.228439         -0.089933   \n",
       "UtilizationTimesDelinquency               3.093738          0.364758   \n",
       "DebtToIncomeAgeRisk                      66.268737          0.031882   \n",
       "UtilizationBucketLateBucket              -0.241138         -0.057175   \n",
       "UtilizationPerCreditLine                  4.650212          0.177593   \n",
       "HasAnyDelinquency                         1.460809          0.311074   \n",
       "HasMajorDelinquency                       2.924108          0.362474   \n",
       "TotalPastDueCapped                        4.180515          0.399287   \n",
       "DelinquencyScore                         11.231471          0.361854   \n",
       "DelinquencyBucket                        -1.622637          0.053309   \n",
       "WasLatePaymentsPerCreditLineImputed      12.777148          0.070744   \n",
       "WasUtilizationPerAgeImputed               3.969398         -0.026322   \n",
       "WasRevolvingUtilizationCappedLogImputed   3.969398         -0.026322   \n",
       "WasIncomePerCreditLineImputed            12.777148          0.070744   \n",
       "WasHighAgeRiskFlagImputed                 0.000000               NaN   \n",
       "WasUtilizationTimesDelinquencyImputed     3.969398         -0.026322   \n",
       "WasDebtToIncomeAgeRiskImputed             0.000000               NaN   \n",
       "WasUtilizationPerCreditLineImputed        3.724540         -0.001910   \n",
       "WasHasAnyDelinquencyImputed               0.000000               NaN   \n",
       "WasHasMajorDelinquencyImputed             0.000000               NaN   \n",
       "WasTotalPastDueCappedImputed              0.000000               NaN   \n",
       "WasDelinquencyScoreImputed                0.000000               NaN   \n",
       "WasUtilizationBucketLateBucketImputed     0.000000               NaN   \n",
       "WasDelinquencyBucketImputed               0.000000               NaN   \n",
       "\n",
       "                                         high_corr_flag  \\\n",
       "LatePaymentsPerCreditLine                         False   \n",
       "UtilizationPerAge                                  True   \n",
       "RevolvingUtilizationCappedLog                      True   \n",
       "IncomePerCreditLine                               False   \n",
       "HighAgeRiskFlag                                   False   \n",
       "UtilizationTimesDelinquency                        True   \n",
       "DebtToIncomeAgeRisk                               False   \n",
       "UtilizationBucketLateBucket                       False   \n",
       "UtilizationPerCreditLine                          False   \n",
       "HasAnyDelinquency                                  True   \n",
       "HasMajorDelinquency                               False   \n",
       "TotalPastDueCapped                                 True   \n",
       "DelinquencyScore                                   True   \n",
       "DelinquencyBucket                                 False   \n",
       "WasLatePaymentsPerCreditLineImputed                True   \n",
       "WasUtilizationPerAgeImputed                        True   \n",
       "WasRevolvingUtilizationCappedLogImputed            True   \n",
       "WasIncomePerCreditLineImputed                      True   \n",
       "WasHighAgeRiskFlagImputed                         False   \n",
       "WasUtilizationTimesDelinquencyImputed              True   \n",
       "WasDebtToIncomeAgeRiskImputed                     False   \n",
       "WasUtilizationPerCreditLineImputed                 True   \n",
       "WasHasAnyDelinquencyImputed                       False   \n",
       "WasHasMajorDelinquencyImputed                     False   \n",
       "WasTotalPastDueCappedImputed                      False   \n",
       "WasDelinquencyScoreImputed                        False   \n",
       "WasUtilizationBucketLateBucketImputed             False   \n",
       "WasDelinquencyBucketImputed                       False   \n",
       "\n",
       "                                                                                                                                                                  high_corr_with  \n",
       "LatePaymentsPerCreditLine                                                                                                                                                         \n",
       "UtilizationPerAge                                                                                                                           RevolvingUtilizationCappedLog (0.92)  \n",
       "RevolvingUtilizationCappedLog                                                                                                                           UtilizationPerAge (0.92)  \n",
       "IncomePerCreditLine                                                                                                                                                               \n",
       "HighAgeRiskFlag                                                                                                                                                                   \n",
       "UtilizationTimesDelinquency                                                                                                                             HasAnyDelinquency (0.74)  \n",
       "DebtToIncomeAgeRisk                                                                                                                                                               \n",
       "UtilizationBucketLateBucket                                                                                                                                                       \n",
       "UtilizationPerCreditLine                                                                                                                                                          \n",
       "HasAnyDelinquency                                                                                                  UtilizationTimesDelinquency (0.74), TotalPastDueCapped (0.73)  \n",
       "HasMajorDelinquency                                                                                                                                                               \n",
       "TotalPastDueCapped                                                                                                             DelinquencyScore (0.86), HasAnyDelinquency (0.73)  \n",
       "DelinquencyScore                                                                                                                                       TotalPastDueCapped (0.86)  \n",
       "DelinquencyBucket                                                                                                                                                                 \n",
       "WasLatePaymentsPerCreditLineImputed                                                                                                         WasIncomePerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerAgeImputed              WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasRevolvingUtilizationCappedLogImputed              WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerAgeImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasIncomePerCreditLineImputed                                                                                                         WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasHighAgeRiskFlagImputed                                                                                                                                                         \n",
       "WasUtilizationTimesDelinquencyImputed              WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerAgeImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                                                     \n",
       "WasUtilizationPerCreditLineImputed              WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95), WasUtilizationTimesDelinquencyImputed (0.95)  \n",
       "WasHasAnyDelinquencyImputed                                                                                                                                                       \n",
       "WasHasMajorDelinquencyImputed                                                                                                                                                     \n",
       "WasTotalPastDueCappedImputed                                                                                                                                                      \n",
       "WasDelinquencyScoreImputed                                                                                                                                                        \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                                                             \n",
       "WasDelinquencyBucketImputed                                                                                                                                                       "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasDelinquencyBucketImputed\",\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasHasAnyDelinquencyImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasIncomePerCreditLineImputed\",\n",
    "    \"WasLatePaymentsPerCreditLineImputed\",\n",
    "    \"WasRevolvingUtilizationCappedLogImputed\",\n",
    "    \"WasTotalPastDueCappedImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "    \"WasUtilizationPerAgeImputed\",\n",
    "    \"WasUtilizationPerCreditLineImputed\",\n",
    "    \"WasUtilizationTimesDelinquencyImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# NN\n",
    "X_train_flags_nn = X_train[X_train_flags]\n",
    "X_val_flags_nn = X_val[X_val_flags]\n",
    "X_test_flags_nn = X_test[X_test_flags]\n",
    "\n",
    "X_train_nn_encoded = pd.get_dummies(X_train, columns=cat_col_order)\n",
    "X_val_nn_encoded = pd.get_dummies(X_val, columns=cat_col_order)\n",
    "X_test_nn_encoded = pd.get_dummies(X_test, columns=cat_col_order)\n",
    "\n",
    "X_val_nn_encoded = X_val_nn_encoded.reindex(columns=X_train_nn_encoded.columns)\n",
    "X_test_nn_encoded = X_test_nn_encoded.reindex(columns=X_train_nn_encoded.columns)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_nn_encoded, X_train[num_col_order], X_train_flags_nn], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_nn_encoded, X_val[num_col_order], X_val_flags_nn], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_nn_encoded, X_test[num_col_order], X_test_flags_nn], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([92598, 35])\n",
      "Class weights: {np.int64(0): np.float64(0.5355209586379198), np.int64(1): np.float64(7.538098339303159)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92598, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 53703\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model = NN(X_train_tensor.shape[1]).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.027410 | Train AUC: 0.8210 | Val loss: 0.025221 | Val AUC: 0.8485\n",
      "Epoch 2/75 | Train loss: 0.024835 | Train AUC: 0.8483 | Val loss: 0.025075 | Val AUC: 0.8507\n",
      "Epoch 3/75 | Train loss: 0.024708 | Train AUC: 0.8508 | Val loss: 0.024623 | Val AUC: 0.8532\n",
      "Epoch 4/75 | Train loss: 0.024590 | Train AUC: 0.8521 | Val loss: 0.025036 | Val AUC: 0.8525\n",
      "Epoch 5/75 | Train loss: 0.024561 | Train AUC: 0.8533 | Val loss: 0.025303 | Val AUC: 0.8509\n",
      "Epoch 6/75 | Train loss: 0.024502 | Train AUC: 0.8530 | Val loss: 0.024895 | Val AUC: 0.8553\n",
      "Epoch 7/75 | Train loss: 0.024399 | Train AUC: 0.8550 | Val loss: 0.024988 | Val AUC: 0.8483\n",
      "Epoch 8/75 | Train loss: 0.024454 | Train AUC: 0.8537 | Val loss: 0.024739 | Val AUC: 0.8528\n",
      "Epoch 9/75 | Train loss: 0.024458 | Train AUC: 0.8550 | Val loss: 0.024617 | Val AUC: 0.8557\n",
      "Epoch 10/75 | Train loss: 0.024410 | Train AUC: 0.8550 | Val loss: 0.024868 | Val AUC: 0.8551\n",
      "Epoch 11/75 | Train loss: 0.024278 | Train AUC: 0.8567 | Val loss: 0.025090 | Val AUC: 0.8541\n",
      "Epoch 12/75 | Train loss: 0.024357 | Train AUC: 0.8559 | Val loss: 0.025052 | Val AUC: 0.8547\n",
      "Epoch 13/75 | Train loss: 0.024285 | Train AUC: 0.8571 | Val loss: 0.024806 | Val AUC: 0.8546\n",
      "Epoch 14/75 | Train loss: 0.024261 | Train AUC: 0.8573 | Val loss: 0.024823 | Val AUC: 0.8552\n",
      "Epoch 15/75 | Train loss: 0.024307 | Train AUC: 0.8565 | Val loss: 0.024915 | Val AUC: 0.8522\n",
      "Epoch 16/75 | Train loss: 0.024160 | Train AUC: 0.8588 | Val loss: 0.024787 | Val AUC: 0.8546\n",
      "Epoch 17/75 | Train loss: 0.024171 | Train AUC: 0.8584 | Val loss: 0.024630 | Val AUC: 0.8550\n",
      "Epoch 18/75 | Train loss: 0.024080 | Train AUC: 0.8595 | Val loss: 0.024858 | Val AUC: 0.8552\n",
      "Epoch 19/75 | Train loss: 0.024093 | Train AUC: 0.8594 | Val loss: 0.024713 | Val AUC: 0.8559\n",
      "Epoch 20/75 | Train loss: 0.024080 | Train AUC: 0.8595 | Val loss: 0.024547 | Val AUC: 0.8568\n",
      "Epoch 21/75 | Train loss: 0.024145 | Train AUC: 0.8589 | Val loss: 0.024680 | Val AUC: 0.8565\n",
      "Epoch 22/75 | Train loss: 0.024150 | Train AUC: 0.8588 | Val loss: 0.024781 | Val AUC: 0.8558\n",
      "Epoch 23/75 | Train loss: 0.024108 | Train AUC: 0.8592 | Val loss: 0.024602 | Val AUC: 0.8555\n",
      "Epoch 24/75 | Train loss: 0.024091 | Train AUC: 0.8598 | Val loss: 0.024667 | Val AUC: 0.8560\n",
      "Epoch 25/75 | Train loss: 0.024085 | Train AUC: 0.8603 | Val loss: 0.024616 | Val AUC: 0.8557\n",
      "Epoch 26/75 | Train loss: 0.024051 | Train AUC: 0.8601 | Val loss: 0.024505 | Val AUC: 0.8558\n",
      "Epoch 27/75 | Train loss: 0.024024 | Train AUC: 0.8607 | Val loss: 0.024795 | Val AUC: 0.8555\n",
      "Epoch 28/75 | Train loss: 0.023967 | Train AUC: 0.8614 | Val loss: 0.024596 | Val AUC: 0.8563\n",
      "Epoch 29/75 | Train loss: 0.023917 | Train AUC: 0.8621 | Val loss: 0.024650 | Val AUC: 0.8572\n",
      "Epoch 30/75 | Train loss: 0.023973 | Train AUC: 0.8611 | Val loss: 0.024633 | Val AUC: 0.8533\n",
      "Epoch 31/75 | Train loss: 0.023994 | Train AUC: 0.8611 | Val loss: 0.024993 | Val AUC: 0.8548\n",
      "Epoch 32/75 | Train loss: 0.023974 | Train AUC: 0.8612 | Val loss: 0.024520 | Val AUC: 0.8561\n",
      "Epoch 33/75 | Train loss: 0.023963 | Train AUC: 0.8612 | Val loss: 0.024648 | Val AUC: 0.8548\n",
      "Epoch 34/75 | Train loss: 0.023955 | Train AUC: 0.8618 | Val loss: 0.024579 | Val AUC: 0.8558\n",
      "Epoch 35/75 | Train loss: 0.023919 | Train AUC: 0.8623 | Val loss: 0.024535 | Val AUC: 0.8569\n",
      "Epoch 36/75 | Train loss: 0.023936 | Train AUC: 0.8618 | Val loss: 0.024692 | Val AUC: 0.8556\n",
      "Epoch 37/75 | Train loss: 0.023868 | Train AUC: 0.8629 | Val loss: 0.024883 | Val AUC: 0.8548\n",
      "Epoch 38/75 | Train loss: 0.023925 | Train AUC: 0.8619 | Val loss: 0.024757 | Val AUC: 0.8534\n",
      "Epoch 39/75 | Train loss: 0.023921 | Train AUC: 0.8622 | Val loss: 0.024711 | Val AUC: 0.8524\n",
      "Epoch 40/75 | Train loss: 0.023869 | Train AUC: 0.8630 | Val loss: 0.024518 | Val AUC: 0.8572\n",
      "Epoch 41/75 | Train loss: 0.023912 | Train AUC: 0.8619 | Val loss: 0.024561 | Val AUC: 0.8547\n",
      "Epoch 42/75 | Train loss: 0.023899 | Train AUC: 0.8627 | Val loss: 0.024773 | Val AUC: 0.8523\n",
      "Epoch 43/75 | Train loss: 0.023851 | Train AUC: 0.8631 | Val loss: 0.024587 | Val AUC: 0.8560\n",
      "Epoch 44/75 | Train loss: 0.023872 | Train AUC: 0.8627 | Val loss: 0.024498 | Val AUC: 0.8568\n",
      "Epoch 45/75 | Train loss: 0.023870 | Train AUC: 0.8628 | Val loss: 0.024472 | Val AUC: 0.8576\n",
      "Epoch 46/75 | Train loss: 0.023814 | Train AUC: 0.8638 | Val loss: 0.024488 | Val AUC: 0.8572\n",
      "Epoch 47/75 | Train loss: 0.023928 | Train AUC: 0.8618 | Val loss: 0.024494 | Val AUC: 0.8577\n",
      "Epoch 48/75 | Train loss: 0.023906 | Train AUC: 0.8624 | Val loss: 0.024666 | Val AUC: 0.8544\n",
      "Epoch 49/75 | Train loss: 0.023905 | Train AUC: 0.8621 | Val loss: 0.024586 | Val AUC: 0.8560\n",
      "Epoch 50/75 | Train loss: 0.023885 | Train AUC: 0.8626 | Val loss: 0.024648 | Val AUC: 0.8553\n",
      "Epoch 51/75 | Train loss: 0.023876 | Train AUC: 0.8628 | Val loss: 0.024480 | Val AUC: 0.8577\n",
      "Epoch 52/75 | Train loss: 0.023905 | Train AUC: 0.8624 | Val loss: 0.024575 | Val AUC: 0.8571\n",
      "Epoch 53/75 | Train loss: 0.023849 | Train AUC: 0.8631 | Val loss: 0.024693 | Val AUC: 0.8536\n",
      "Epoch 54/75 | Train loss: 0.023820 | Train AUC: 0.8636 | Val loss: 0.024645 | Val AUC: 0.8543\n",
      "Epoch 55/75 | Train loss: 0.023808 | Train AUC: 0.8638 | Val loss: 0.024446 | Val AUC: 0.8567\n",
      "Epoch 56/75 | Train loss: 0.023831 | Train AUC: 0.8633 | Val loss: 0.024652 | Val AUC: 0.8555\n",
      "Epoch 57/75 | Train loss: 0.023807 | Train AUC: 0.8637 | Val loss: 0.024538 | Val AUC: 0.8554\n",
      "Epoch 58/75 | Train loss: 0.023849 | Train AUC: 0.8628 | Val loss: 0.024557 | Val AUC: 0.8556\n",
      "Epoch 59/75 | Train loss: 0.023815 | Train AUC: 0.8634 | Val loss: 0.024476 | Val AUC: 0.8576\n",
      "Epoch 60/75 | Train loss: 0.023773 | Train AUC: 0.8643 | Val loss: 0.024498 | Val AUC: 0.8578\n",
      "Epoch 61/75 | Train loss: 0.023832 | Train AUC: 0.8636 | Val loss: 0.024451 | Val AUC: 0.8576\n",
      "Epoch 62/75 | Train loss: 0.023849 | Train AUC: 0.8628 | Val loss: 0.024663 | Val AUC: 0.8547\n",
      "Epoch 63/75 | Train loss: 0.023844 | Train AUC: 0.8632 | Val loss: 0.024742 | Val AUC: 0.8531\n",
      "Epoch 64/75 | Train loss: 0.023841 | Train AUC: 0.8634 | Val loss: 0.024683 | Val AUC: 0.8545\n",
      "Epoch 65/75 | Train loss: 0.023788 | Train AUC: 0.8643 | Val loss: 0.024521 | Val AUC: 0.8553\n",
      "Epoch 66/75 | Train loss: 0.023814 | Train AUC: 0.8637 | Val loss: 0.024464 | Val AUC: 0.8578\n",
      "Epoch 67/75 | Train loss: 0.023808 | Train AUC: 0.8639 | Val loss: 0.024485 | Val AUC: 0.8566\n",
      "Epoch 68/75 | Train loss: 0.023819 | Train AUC: 0.8638 | Val loss: 0.024656 | Val AUC: 0.8559\n",
      "Epoch 69/75 | Train loss: 0.023830 | Train AUC: 0.8635 | Val loss: 0.024465 | Val AUC: 0.8566\n",
      "Epoch 70/75 | Train loss: 0.023772 | Train AUC: 0.8644 | Val loss: 0.024569 | Val AUC: 0.8563\n",
      "Epoch 71/75 | Train loss: 0.023834 | Train AUC: 0.8635 | Val loss: 0.024732 | Val AUC: 0.8521\n",
      "Epoch 72/75 | Train loss: 0.023850 | Train AUC: 0.8630 | Val loss: 0.024528 | Val AUC: 0.8575\n",
      "Early stopping at epoch 73\n",
      "Run 1 best Val AUC: 0.8578\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.024134 | Train AUC: 0.8591 | Val loss: 0.024679 | Val AUC: 0.8542\n",
      "Epoch 2/75 | Train loss: 0.024070 | Train AUC: 0.8600 | Val loss: 0.024697 | Val AUC: 0.8518\n",
      "Epoch 3/75 | Train loss: 0.024160 | Train AUC: 0.8589 | Val loss: 0.025058 | Val AUC: 0.8535\n",
      "Epoch 4/75 | Train loss: 0.024203 | Train AUC: 0.8576 | Val loss: 0.024837 | Val AUC: 0.8500\n",
      "Epoch 5/75 | Train loss: 0.024172 | Train AUC: 0.8586 | Val loss: 0.024614 | Val AUC: 0.8537\n",
      "Epoch 6/75 | Train loss: 0.024171 | Train AUC: 0.8586 | Val loss: 0.024636 | Val AUC: 0.8555\n",
      "Epoch 7/75 | Train loss: 0.024120 | Train AUC: 0.8591 | Val loss: 0.024935 | Val AUC: 0.8515\n",
      "Epoch 8/75 | Train loss: 0.024062 | Train AUC: 0.8601 | Val loss: 0.024668 | Val AUC: 0.8554\n",
      "Epoch 9/75 | Train loss: 0.024167 | Train AUC: 0.8590 | Val loss: 0.024790 | Val AUC: 0.8542\n",
      "Epoch 10/75 | Train loss: 0.024138 | Train AUC: 0.8588 | Val loss: 0.024711 | Val AUC: 0.8531\n",
      "Epoch 11/75 | Train loss: 0.024108 | Train AUC: 0.8592 | Val loss: 0.024460 | Val AUC: 0.8563\n",
      "Epoch 12/75 | Train loss: 0.024142 | Train AUC: 0.8590 | Val loss: 0.024739 | Val AUC: 0.8572\n",
      "Epoch 13/75 | Train loss: 0.024112 | Train AUC: 0.8594 | Val loss: 0.024685 | Val AUC: 0.8547\n",
      "Epoch 14/75 | Train loss: 0.024133 | Train AUC: 0.8592 | Val loss: 0.024728 | Val AUC: 0.8559\n",
      "Epoch 15/75 | Train loss: 0.024106 | Train AUC: 0.8597 | Val loss: 0.024692 | Val AUC: 0.8555\n",
      "Epoch 16/75 | Train loss: 0.024124 | Train AUC: 0.8591 | Val loss: 0.024756 | Val AUC: 0.8539\n",
      "Epoch 17/75 | Train loss: 0.024073 | Train AUC: 0.8601 | Val loss: 0.024773 | Val AUC: 0.8512\n",
      "Epoch 18/75 | Train loss: 0.024073 | Train AUC: 0.8600 | Val loss: 0.024907 | Val AUC: 0.8536\n",
      "Epoch 19/75 | Train loss: 0.023979 | Train AUC: 0.8612 | Val loss: 0.024577 | Val AUC: 0.8574\n",
      "Epoch 20/75 | Train loss: 0.023999 | Train AUC: 0.8611 | Val loss: 0.024550 | Val AUC: 0.8550\n",
      "Epoch 21/75 | Train loss: 0.023955 | Train AUC: 0.8621 | Val loss: 0.024483 | Val AUC: 0.8564\n",
      "Epoch 22/75 | Train loss: 0.023921 | Train AUC: 0.8625 | Val loss: 0.024653 | Val AUC: 0.8556\n",
      "Epoch 23/75 | Train loss: 0.023924 | Train AUC: 0.8620 | Val loss: 0.024813 | Val AUC: 0.8552\n",
      "Epoch 24/75 | Train loss: 0.023974 | Train AUC: 0.8615 | Val loss: 0.024490 | Val AUC: 0.8568\n",
      "Epoch 25/75 | Train loss: 0.023933 | Train AUC: 0.8618 | Val loss: 0.024589 | Val AUC: 0.8552\n",
      "Epoch 26/75 | Train loss: 0.023861 | Train AUC: 0.8631 | Val loss: 0.024457 | Val AUC: 0.8565\n",
      "Epoch 27/75 | Train loss: 0.023831 | Train AUC: 0.8636 | Val loss: 0.024693 | Val AUC: 0.8567\n",
      "Epoch 28/75 | Train loss: 0.023862 | Train AUC: 0.8632 | Val loss: 0.024543 | Val AUC: 0.8565\n",
      "Epoch 29/75 | Train loss: 0.023890 | Train AUC: 0.8624 | Val loss: 0.024609 | Val AUC: 0.8547\n",
      "Epoch 30/75 | Train loss: 0.023901 | Train AUC: 0.8620 | Val loss: 0.024460 | Val AUC: 0.8564\n",
      "Epoch 31/75 | Train loss: 0.023795 | Train AUC: 0.8637 | Val loss: 0.024857 | Val AUC: 0.8524\n",
      "Early stopping at epoch 32\n",
      "Run 2 best Val AUC: 0.8574\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8578)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3426468074321747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.84      0.90     27868\n",
      "   Defaulted       0.24      0.71      0.36      1978\n",
      "\n",
      "    accuracy                           0.83     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.83      0.87     29846\n",
      "\n",
      "Accuracy: 83.08%\n",
      "ROC AUC: 0.859\n",
      "TP=1409, FP=4480, TN=23388, FN=569\n",
      "Accuracy for class 'Repaid': 83.92%\n",
      "Accuracy for class 'Defaulted': 71.23%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, 0.70)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "best_param = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": sum(y_train==0)/sum(y_train==1),\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_alpha\": 1,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84573\n",
      "[1]\tvalidation_0-auc:0.84657\n",
      "[2]\tvalidation_0-auc:0.84769\n",
      "[3]\tvalidation_0-auc:0.84743\n",
      "[4]\tvalidation_0-auc:0.84812\n",
      "[5]\tvalidation_0-auc:0.84957\n",
      "[6]\tvalidation_0-auc:0.84983\n",
      "[7]\tvalidation_0-auc:0.85018\n",
      "[8]\tvalidation_0-auc:0.85025\n",
      "[9]\tvalidation_0-auc:0.85072\n",
      "[10]\tvalidation_0-auc:0.85074\n",
      "[11]\tvalidation_0-auc:0.85058\n",
      "[12]\tvalidation_0-auc:0.85073\n",
      "[13]\tvalidation_0-auc:0.85078\n",
      "[14]\tvalidation_0-auc:0.85077\n",
      "[15]\tvalidation_0-auc:0.85081\n",
      "[16]\tvalidation_0-auc:0.85077\n",
      "[17]\tvalidation_0-auc:0.85056\n",
      "[18]\tvalidation_0-auc:0.85080\n",
      "[19]\tvalidation_0-auc:0.85077\n",
      "[20]\tvalidation_0-auc:0.85075\n",
      "[21]\tvalidation_0-auc:0.85071\n",
      "[22]\tvalidation_0-auc:0.85095\n",
      "[23]\tvalidation_0-auc:0.85113\n",
      "[24]\tvalidation_0-auc:0.85104\n",
      "[25]\tvalidation_0-auc:0.85118\n",
      "[26]\tvalidation_0-auc:0.85126\n",
      "[27]\tvalidation_0-auc:0.85137\n",
      "[28]\tvalidation_0-auc:0.85140\n",
      "[29]\tvalidation_0-auc:0.85129\n",
      "[30]\tvalidation_0-auc:0.85126\n",
      "[31]\tvalidation_0-auc:0.85122\n",
      "[32]\tvalidation_0-auc:0.85118\n",
      "[33]\tvalidation_0-auc:0.85125\n",
      "[34]\tvalidation_0-auc:0.85119\n",
      "[35]\tvalidation_0-auc:0.85136\n",
      "[36]\tvalidation_0-auc:0.85160\n",
      "[37]\tvalidation_0-auc:0.85175\n",
      "[38]\tvalidation_0-auc:0.85188\n",
      "[39]\tvalidation_0-auc:0.85192\n",
      "[40]\tvalidation_0-auc:0.85247\n",
      "[41]\tvalidation_0-auc:0.85251\n",
      "[42]\tvalidation_0-auc:0.85262\n",
      "[43]\tvalidation_0-auc:0.85280\n",
      "[44]\tvalidation_0-auc:0.85279\n",
      "[45]\tvalidation_0-auc:0.85267\n",
      "[46]\tvalidation_0-auc:0.85258\n",
      "[47]\tvalidation_0-auc:0.85260\n",
      "[48]\tvalidation_0-auc:0.85252\n",
      "[49]\tvalidation_0-auc:0.85258\n",
      "[50]\tvalidation_0-auc:0.85264\n",
      "[51]\tvalidation_0-auc:0.85270\n",
      "[52]\tvalidation_0-auc:0.85278\n",
      "[53]\tvalidation_0-auc:0.85280\n",
      "[54]\tvalidation_0-auc:0.85285\n",
      "[55]\tvalidation_0-auc:0.85290\n",
      "[56]\tvalidation_0-auc:0.85288\n",
      "[57]\tvalidation_0-auc:0.85310\n",
      "[58]\tvalidation_0-auc:0.85310\n",
      "[59]\tvalidation_0-auc:0.85313\n",
      "[60]\tvalidation_0-auc:0.85323\n",
      "[61]\tvalidation_0-auc:0.85329\n",
      "[62]\tvalidation_0-auc:0.85340\n",
      "[63]\tvalidation_0-auc:0.85341\n",
      "[64]\tvalidation_0-auc:0.85347\n",
      "[65]\tvalidation_0-auc:0.85350\n",
      "[66]\tvalidation_0-auc:0.85350\n",
      "[67]\tvalidation_0-auc:0.85369\n",
      "[68]\tvalidation_0-auc:0.85374\n",
      "[69]\tvalidation_0-auc:0.85380\n",
      "[70]\tvalidation_0-auc:0.85380\n",
      "[71]\tvalidation_0-auc:0.85380\n",
      "[72]\tvalidation_0-auc:0.85381\n",
      "[73]\tvalidation_0-auc:0.85387\n",
      "[74]\tvalidation_0-auc:0.85384\n",
      "[75]\tvalidation_0-auc:0.85392\n",
      "[76]\tvalidation_0-auc:0.85389\n",
      "[77]\tvalidation_0-auc:0.85397\n",
      "[78]\tvalidation_0-auc:0.85394\n",
      "[79]\tvalidation_0-auc:0.85400\n",
      "[80]\tvalidation_0-auc:0.85384\n",
      "[81]\tvalidation_0-auc:0.85380\n",
      "[82]\tvalidation_0-auc:0.85381\n",
      "[83]\tvalidation_0-auc:0.85386\n",
      "[84]\tvalidation_0-auc:0.85397\n",
      "[85]\tvalidation_0-auc:0.85410\n",
      "[86]\tvalidation_0-auc:0.85406\n",
      "[87]\tvalidation_0-auc:0.85427\n",
      "[88]\tvalidation_0-auc:0.85429\n",
      "[89]\tvalidation_0-auc:0.85435\n",
      "[90]\tvalidation_0-auc:0.85440\n",
      "[91]\tvalidation_0-auc:0.85446\n",
      "[92]\tvalidation_0-auc:0.85447\n",
      "[93]\tvalidation_0-auc:0.85448\n",
      "[94]\tvalidation_0-auc:0.85453\n",
      "[95]\tvalidation_0-auc:0.85451\n",
      "[96]\tvalidation_0-auc:0.85462\n",
      "[97]\tvalidation_0-auc:0.85466\n",
      "[98]\tvalidation_0-auc:0.85469\n",
      "[99]\tvalidation_0-auc:0.85461\n",
      "[100]\tvalidation_0-auc:0.85467\n",
      "[101]\tvalidation_0-auc:0.85471\n",
      "[102]\tvalidation_0-auc:0.85476\n",
      "[103]\tvalidation_0-auc:0.85476\n",
      "[104]\tvalidation_0-auc:0.85474\n",
      "[105]\tvalidation_0-auc:0.85481\n",
      "[106]\tvalidation_0-auc:0.85485\n",
      "[107]\tvalidation_0-auc:0.85493\n",
      "[108]\tvalidation_0-auc:0.85494\n",
      "[109]\tvalidation_0-auc:0.85492\n",
      "[110]\tvalidation_0-auc:0.85492\n",
      "[111]\tvalidation_0-auc:0.85495\n",
      "[112]\tvalidation_0-auc:0.85498\n",
      "[113]\tvalidation_0-auc:0.85493\n",
      "[114]\tvalidation_0-auc:0.85500\n",
      "[115]\tvalidation_0-auc:0.85494\n",
      "[116]\tvalidation_0-auc:0.85499\n",
      "[117]\tvalidation_0-auc:0.85507\n",
      "[118]\tvalidation_0-auc:0.85512\n",
      "[119]\tvalidation_0-auc:0.85521\n",
      "[120]\tvalidation_0-auc:0.85524\n",
      "[121]\tvalidation_0-auc:0.85526\n",
      "[122]\tvalidation_0-auc:0.85525\n",
      "[123]\tvalidation_0-auc:0.85526\n",
      "[124]\tvalidation_0-auc:0.85527\n",
      "[125]\tvalidation_0-auc:0.85526\n",
      "[126]\tvalidation_0-auc:0.85532\n",
      "[127]\tvalidation_0-auc:0.85536\n",
      "[128]\tvalidation_0-auc:0.85540\n",
      "[129]\tvalidation_0-auc:0.85542\n",
      "[130]\tvalidation_0-auc:0.85542\n",
      "[131]\tvalidation_0-auc:0.85543\n",
      "[132]\tvalidation_0-auc:0.85542\n",
      "[133]\tvalidation_0-auc:0.85551\n",
      "[134]\tvalidation_0-auc:0.85558\n",
      "[135]\tvalidation_0-auc:0.85556\n",
      "[136]\tvalidation_0-auc:0.85557\n",
      "[137]\tvalidation_0-auc:0.85562\n",
      "[138]\tvalidation_0-auc:0.85568\n",
      "[139]\tvalidation_0-auc:0.85573\n",
      "[140]\tvalidation_0-auc:0.85577\n",
      "[141]\tvalidation_0-auc:0.85584\n",
      "[142]\tvalidation_0-auc:0.85590\n",
      "[143]\tvalidation_0-auc:0.85597\n",
      "[144]\tvalidation_0-auc:0.85598\n",
      "[145]\tvalidation_0-auc:0.85594\n",
      "[146]\tvalidation_0-auc:0.85598\n",
      "[147]\tvalidation_0-auc:0.85607\n",
      "[148]\tvalidation_0-auc:0.85607\n",
      "[149]\tvalidation_0-auc:0.85609\n",
      "[150]\tvalidation_0-auc:0.85606\n",
      "[151]\tvalidation_0-auc:0.85609\n",
      "[152]\tvalidation_0-auc:0.85613\n",
      "[153]\tvalidation_0-auc:0.85617\n",
      "[154]\tvalidation_0-auc:0.85619\n",
      "[155]\tvalidation_0-auc:0.85625\n",
      "[156]\tvalidation_0-auc:0.85628\n",
      "[157]\tvalidation_0-auc:0.85632\n",
      "[158]\tvalidation_0-auc:0.85634\n",
      "[159]\tvalidation_0-auc:0.85639\n",
      "[160]\tvalidation_0-auc:0.85638\n",
      "[161]\tvalidation_0-auc:0.85647\n",
      "[162]\tvalidation_0-auc:0.85647\n",
      "[163]\tvalidation_0-auc:0.85648\n",
      "[164]\tvalidation_0-auc:0.85650\n",
      "[165]\tvalidation_0-auc:0.85652\n",
      "[166]\tvalidation_0-auc:0.85655\n",
      "[167]\tvalidation_0-auc:0.85653\n",
      "[168]\tvalidation_0-auc:0.85654\n",
      "[169]\tvalidation_0-auc:0.85659\n",
      "[170]\tvalidation_0-auc:0.85663\n",
      "[171]\tvalidation_0-auc:0.85665\n",
      "[172]\tvalidation_0-auc:0.85665\n",
      "[173]\tvalidation_0-auc:0.85670\n",
      "[174]\tvalidation_0-auc:0.85671\n",
      "[175]\tvalidation_0-auc:0.85675\n",
      "[176]\tvalidation_0-auc:0.85677\n",
      "[177]\tvalidation_0-auc:0.85677\n",
      "[178]\tvalidation_0-auc:0.85680\n",
      "[179]\tvalidation_0-auc:0.85683\n",
      "[180]\tvalidation_0-auc:0.85687\n",
      "[181]\tvalidation_0-auc:0.85689\n",
      "[182]\tvalidation_0-auc:0.85689\n",
      "[183]\tvalidation_0-auc:0.85694\n",
      "[184]\tvalidation_0-auc:0.85693\n",
      "[185]\tvalidation_0-auc:0.85696\n",
      "[186]\tvalidation_0-auc:0.85697\n",
      "[187]\tvalidation_0-auc:0.85698\n",
      "[188]\tvalidation_0-auc:0.85699\n",
      "[189]\tvalidation_0-auc:0.85698\n",
      "[190]\tvalidation_0-auc:0.85700\n",
      "[191]\tvalidation_0-auc:0.85701\n",
      "[192]\tvalidation_0-auc:0.85702\n",
      "[193]\tvalidation_0-auc:0.85703\n",
      "[194]\tvalidation_0-auc:0.85704\n",
      "[195]\tvalidation_0-auc:0.85707\n",
      "[196]\tvalidation_0-auc:0.85706\n",
      "[197]\tvalidation_0-auc:0.85707\n",
      "[198]\tvalidation_0-auc:0.85710\n",
      "[199]\tvalidation_0-auc:0.85711\n",
      "[200]\tvalidation_0-auc:0.85713\n",
      "[201]\tvalidation_0-auc:0.85715\n",
      "[202]\tvalidation_0-auc:0.85715\n",
      "[203]\tvalidation_0-auc:0.85718\n",
      "[204]\tvalidation_0-auc:0.85720\n",
      "[205]\tvalidation_0-auc:0.85722\n",
      "[206]\tvalidation_0-auc:0.85725\n",
      "[207]\tvalidation_0-auc:0.85724\n",
      "[208]\tvalidation_0-auc:0.85722\n",
      "[209]\tvalidation_0-auc:0.85724\n",
      "[210]\tvalidation_0-auc:0.85724\n",
      "[211]\tvalidation_0-auc:0.85729\n",
      "[212]\tvalidation_0-auc:0.85729\n",
      "[213]\tvalidation_0-auc:0.85729\n",
      "[214]\tvalidation_0-auc:0.85732\n",
      "[215]\tvalidation_0-auc:0.85736\n",
      "[216]\tvalidation_0-auc:0.85737\n",
      "[217]\tvalidation_0-auc:0.85737\n",
      "[218]\tvalidation_0-auc:0.85739\n",
      "[219]\tvalidation_0-auc:0.85743\n",
      "[220]\tvalidation_0-auc:0.85744\n",
      "[221]\tvalidation_0-auc:0.85745\n",
      "[222]\tvalidation_0-auc:0.85748\n",
      "[223]\tvalidation_0-auc:0.85750\n",
      "[224]\tvalidation_0-auc:0.85750\n",
      "[225]\tvalidation_0-auc:0.85748\n",
      "[226]\tvalidation_0-auc:0.85750\n",
      "[227]\tvalidation_0-auc:0.85752\n",
      "[228]\tvalidation_0-auc:0.85753\n",
      "[229]\tvalidation_0-auc:0.85756\n",
      "[230]\tvalidation_0-auc:0.85759\n",
      "[231]\tvalidation_0-auc:0.85759\n",
      "[232]\tvalidation_0-auc:0.85760\n",
      "[233]\tvalidation_0-auc:0.85759\n",
      "[234]\tvalidation_0-auc:0.85759\n",
      "[235]\tvalidation_0-auc:0.85758\n",
      "[236]\tvalidation_0-auc:0.85758\n",
      "[237]\tvalidation_0-auc:0.85760\n",
      "[238]\tvalidation_0-auc:0.85761\n",
      "[239]\tvalidation_0-auc:0.85762\n",
      "[240]\tvalidation_0-auc:0.85764\n",
      "[241]\tvalidation_0-auc:0.85765\n",
      "[242]\tvalidation_0-auc:0.85765\n",
      "[243]\tvalidation_0-auc:0.85766\n",
      "[244]\tvalidation_0-auc:0.85767\n",
      "[245]\tvalidation_0-auc:0.85766\n",
      "[246]\tvalidation_0-auc:0.85766\n",
      "[247]\tvalidation_0-auc:0.85767\n",
      "[248]\tvalidation_0-auc:0.85764\n",
      "[249]\tvalidation_0-auc:0.85766\n",
      "[250]\tvalidation_0-auc:0.85765\n",
      "[251]\tvalidation_0-auc:0.85766\n",
      "[252]\tvalidation_0-auc:0.85766\n",
      "[253]\tvalidation_0-auc:0.85771\n",
      "[254]\tvalidation_0-auc:0.85770\n",
      "[255]\tvalidation_0-auc:0.85769\n",
      "[256]\tvalidation_0-auc:0.85770\n",
      "[257]\tvalidation_0-auc:0.85773\n",
      "[258]\tvalidation_0-auc:0.85775\n",
      "[259]\tvalidation_0-auc:0.85775\n",
      "[260]\tvalidation_0-auc:0.85775\n",
      "[261]\tvalidation_0-auc:0.85776\n",
      "[262]\tvalidation_0-auc:0.85774\n",
      "[263]\tvalidation_0-auc:0.85774\n",
      "[264]\tvalidation_0-auc:0.85774\n",
      "[265]\tvalidation_0-auc:0.85775\n",
      "[266]\tvalidation_0-auc:0.85774\n",
      "[267]\tvalidation_0-auc:0.85773\n",
      "[268]\tvalidation_0-auc:0.85773\n",
      "[269]\tvalidation_0-auc:0.85776\n",
      "[270]\tvalidation_0-auc:0.85775\n",
      "[271]\tvalidation_0-auc:0.85774\n",
      "[272]\tvalidation_0-auc:0.85778\n",
      "[273]\tvalidation_0-auc:0.85779\n",
      "[274]\tvalidation_0-auc:0.85781\n",
      "[275]\tvalidation_0-auc:0.85781\n",
      "[276]\tvalidation_0-auc:0.85781\n",
      "[277]\tvalidation_0-auc:0.85780\n",
      "[278]\tvalidation_0-auc:0.85780\n",
      "[279]\tvalidation_0-auc:0.85781\n",
      "[280]\tvalidation_0-auc:0.85781\n",
      "[281]\tvalidation_0-auc:0.85783\n",
      "[282]\tvalidation_0-auc:0.85784\n",
      "[283]\tvalidation_0-auc:0.85784\n",
      "[284]\tvalidation_0-auc:0.85785\n",
      "[285]\tvalidation_0-auc:0.85786\n",
      "[286]\tvalidation_0-auc:0.85785\n",
      "[287]\tvalidation_0-auc:0.85786\n",
      "[288]\tvalidation_0-auc:0.85783\n",
      "[289]\tvalidation_0-auc:0.85783\n",
      "[290]\tvalidation_0-auc:0.85784\n",
      "[291]\tvalidation_0-auc:0.85784\n",
      "[292]\tvalidation_0-auc:0.85784\n",
      "[293]\tvalidation_0-auc:0.85788\n",
      "[294]\tvalidation_0-auc:0.85787\n",
      "[295]\tvalidation_0-auc:0.85787\n",
      "[296]\tvalidation_0-auc:0.85787\n",
      "[297]\tvalidation_0-auc:0.85788\n",
      "[298]\tvalidation_0-auc:0.85789\n",
      "[299]\tvalidation_0-auc:0.85792\n",
      "[300]\tvalidation_0-auc:0.85793\n",
      "[301]\tvalidation_0-auc:0.85794\n",
      "[302]\tvalidation_0-auc:0.85795\n",
      "[303]\tvalidation_0-auc:0.85796\n",
      "[304]\tvalidation_0-auc:0.85798\n",
      "[305]\tvalidation_0-auc:0.85798\n",
      "[306]\tvalidation_0-auc:0.85799\n",
      "[307]\tvalidation_0-auc:0.85799\n",
      "[308]\tvalidation_0-auc:0.85800\n",
      "[309]\tvalidation_0-auc:0.85799\n",
      "[310]\tvalidation_0-auc:0.85800\n",
      "[311]\tvalidation_0-auc:0.85802\n",
      "[312]\tvalidation_0-auc:0.85802\n",
      "[313]\tvalidation_0-auc:0.85801\n",
      "[314]\tvalidation_0-auc:0.85801\n",
      "[315]\tvalidation_0-auc:0.85800\n",
      "[316]\tvalidation_0-auc:0.85799\n",
      "[317]\tvalidation_0-auc:0.85800\n",
      "[318]\tvalidation_0-auc:0.85799\n",
      "[319]\tvalidation_0-auc:0.85802\n",
      "[320]\tvalidation_0-auc:0.85801\n",
      "[321]\tvalidation_0-auc:0.85801\n",
      "[322]\tvalidation_0-auc:0.85803\n",
      "[323]\tvalidation_0-auc:0.85803\n",
      "[324]\tvalidation_0-auc:0.85803\n",
      "[325]\tvalidation_0-auc:0.85804\n",
      "[326]\tvalidation_0-auc:0.85802\n",
      "[327]\tvalidation_0-auc:0.85801\n",
      "[328]\tvalidation_0-auc:0.85803\n",
      "[329]\tvalidation_0-auc:0.85802\n",
      "[330]\tvalidation_0-auc:0.85802\n",
      "[331]\tvalidation_0-auc:0.85802\n",
      "[332]\tvalidation_0-auc:0.85801\n",
      "[333]\tvalidation_0-auc:0.85799\n",
      "[334]\tvalidation_0-auc:0.85798\n",
      "[335]\tvalidation_0-auc:0.85797\n",
      "[336]\tvalidation_0-auc:0.85797\n",
      "[337]\tvalidation_0-auc:0.85797\n",
      "[338]\tvalidation_0-auc:0.85798\n",
      "[339]\tvalidation_0-auc:0.85799\n",
      "[340]\tvalidation_0-auc:0.85799\n",
      "[341]\tvalidation_0-auc:0.85799\n",
      "[342]\tvalidation_0-auc:0.85800\n",
      "[343]\tvalidation_0-auc:0.85801\n",
      "[344]\tvalidation_0-auc:0.85802\n",
      "[345]\tvalidation_0-auc:0.85800\n",
      "[346]\tvalidation_0-auc:0.85800\n",
      "[347]\tvalidation_0-auc:0.85800\n",
      "[348]\tvalidation_0-auc:0.85801\n",
      "[349]\tvalidation_0-auc:0.85800\n",
      "[350]\tvalidation_0-auc:0.85799\n",
      "[351]\tvalidation_0-auc:0.85800\n",
      "[352]\tvalidation_0-auc:0.85802\n",
      "[353]\tvalidation_0-auc:0.85802\n",
      "[354]\tvalidation_0-auc:0.85801\n",
      "[355]\tvalidation_0-auc:0.85802\n",
      "[356]\tvalidation_0-auc:0.85802\n",
      "[357]\tvalidation_0-auc:0.85803\n",
      "[358]\tvalidation_0-auc:0.85803\n",
      "[359]\tvalidation_0-auc:0.85805\n",
      "[360]\tvalidation_0-auc:0.85804\n",
      "[361]\tvalidation_0-auc:0.85802\n",
      "[362]\tvalidation_0-auc:0.85803\n",
      "[363]\tvalidation_0-auc:0.85801\n",
      "[364]\tvalidation_0-auc:0.85802\n",
      "[365]\tvalidation_0-auc:0.85802\n",
      "[366]\tvalidation_0-auc:0.85802\n",
      "[367]\tvalidation_0-auc:0.85802\n",
      "[368]\tvalidation_0-auc:0.85801\n",
      "[369]\tvalidation_0-auc:0.85800\n",
      "[370]\tvalidation_0-auc:0.85799\n",
      "[371]\tvalidation_0-auc:0.85800\n",
      "[372]\tvalidation_0-auc:0.85800\n",
      "[373]\tvalidation_0-auc:0.85800\n",
      "[374]\tvalidation_0-auc:0.85800\n",
      "[375]\tvalidation_0-auc:0.85799\n",
      "[376]\tvalidation_0-auc:0.85798\n",
      "[377]\tvalidation_0-auc:0.85798\n",
      "[378]\tvalidation_0-auc:0.85795\n",
      "[379]\tvalidation_0-auc:0.85793\n",
      "[380]\tvalidation_0-auc:0.85793\n",
      "[381]\tvalidation_0-auc:0.85793\n",
      "[382]\tvalidation_0-auc:0.85794\n",
      "[383]\tvalidation_0-auc:0.85796\n",
      "[384]\tvalidation_0-auc:0.85797\n",
      "[385]\tvalidation_0-auc:0.85794\n",
      "[386]\tvalidation_0-auc:0.85793\n",
      "[387]\tvalidation_0-auc:0.85795\n",
      "[388]\tvalidation_0-auc:0.85795\n",
      "[389]\tvalidation_0-auc:0.85795\n",
      "[390]\tvalidation_0-auc:0.85796\n",
      "[391]\tvalidation_0-auc:0.85796\n",
      "[392]\tvalidation_0-auc:0.85796\n",
      "[393]\tvalidation_0-auc:0.85796\n",
      "[394]\tvalidation_0-auc:0.85795\n",
      "[395]\tvalidation_0-auc:0.85796\n",
      "[396]\tvalidation_0-auc:0.85797\n",
      "[397]\tvalidation_0-auc:0.85797\n",
      "[398]\tvalidation_0-auc:0.85797\n",
      "[399]\tvalidation_0-auc:0.85798\n",
      "[400]\tvalidation_0-auc:0.85798\n",
      "[401]\tvalidation_0-auc:0.85797\n",
      "[402]\tvalidation_0-auc:0.85795\n",
      "[403]\tvalidation_0-auc:0.85795\n",
      "[404]\tvalidation_0-auc:0.85795\n",
      "[405]\tvalidation_0-auc:0.85793\n",
      "[406]\tvalidation_0-auc:0.85793\n",
      "[407]\tvalidation_0-auc:0.85794\n",
      "[408]\tvalidation_0-auc:0.85794\n",
      "[409]\tvalidation_0-auc:0.85794\n",
      "[410]\tvalidation_0-auc:0.85793\n",
      "[411]\tvalidation_0-auc:0.85792\n",
      "[412]\tvalidation_0-auc:0.85791\n",
      "[413]\tvalidation_0-auc:0.85792\n",
      "[414]\tvalidation_0-auc:0.85792\n",
      "[415]\tvalidation_0-auc:0.85794\n",
      "[416]\tvalidation_0-auc:0.85793\n",
      "[417]\tvalidation_0-auc:0.85790\n",
      "[418]\tvalidation_0-auc:0.85789\n",
      "[419]\tvalidation_0-auc:0.85787\n",
      "[420]\tvalidation_0-auc:0.85787\n",
      "[421]\tvalidation_0-auc:0.85788\n",
      "[422]\tvalidation_0-auc:0.85786\n",
      "[423]\tvalidation_0-auc:0.85785\n",
      "[424]\tvalidation_0-auc:0.85784\n",
      "[425]\tvalidation_0-auc:0.85784\n",
      "[426]\tvalidation_0-auc:0.85785\n",
      "[427]\tvalidation_0-auc:0.85784\n",
      "[428]\tvalidation_0-auc:0.85784\n",
      "[429]\tvalidation_0-auc:0.85783\n",
      "[430]\tvalidation_0-auc:0.85783\n",
      "[431]\tvalidation_0-auc:0.85783\n",
      "[432]\tvalidation_0-auc:0.85782\n",
      "[433]\tvalidation_0-auc:0.85783\n",
      "[434]\tvalidation_0-auc:0.85782\n",
      "[435]\tvalidation_0-auc:0.85783\n",
      "[436]\tvalidation_0-auc:0.85782\n",
      "[437]\tvalidation_0-auc:0.85783\n",
      "[438]\tvalidation_0-auc:0.85781\n",
      "[439]\tvalidation_0-auc:0.85781\n",
      "[440]\tvalidation_0-auc:0.85780\n",
      "[441]\tvalidation_0-auc:0.85780\n",
      "[442]\tvalidation_0-auc:0.85779\n",
      "[443]\tvalidation_0-auc:0.85781\n",
      "[444]\tvalidation_0-auc:0.85779\n",
      "[445]\tvalidation_0-auc:0.85779\n",
      "[446]\tvalidation_0-auc:0.85778\n",
      "[447]\tvalidation_0-auc:0.85779\n",
      "[448]\tvalidation_0-auc:0.85778\n",
      "[449]\tvalidation_0-auc:0.85775\n",
      "[450]\tvalidation_0-auc:0.85776\n",
      "[451]\tvalidation_0-auc:0.85777\n",
      "[452]\tvalidation_0-auc:0.85777\n",
      "[453]\tvalidation_0-auc:0.85778\n",
      "[454]\tvalidation_0-auc:0.85777\n",
      "[455]\tvalidation_0-auc:0.85777\n",
      "[456]\tvalidation_0-auc:0.85777\n",
      "[457]\tvalidation_0-auc:0.85777\n",
      "[458]\tvalidation_0-auc:0.85777\n",
      "[459]\tvalidation_0-auc:0.85778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.85, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.85</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auc&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.02</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.076196678606317)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.85</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.85, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              feature_weights=None, gamma=1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5532964468002319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.72      0.35      1978\n",
      "\n",
      "    accuracy                           0.83     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.83      0.86     29846\n",
      "\n",
      "Accuracy: 82.57%\n",
      "ROC AUC: 0.859\n",
      "TP=1424, FP=4647, TN=23221, FN=554\n",
      "Accuracy for class 'Repaid': 83.32%\n",
      "Accuracy for class 'Defaulted': 71.99%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, 0.72)\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Feature   Importance\n",
      "0               HasAnyDelinquency  9510.608398\n",
      "1               DelinquencyBucket  2416.239258\n",
      "2              TotalPastDueCapped  1750.670654\n",
      "3                DelinquencyScore   887.870361\n",
      "4     UtilizationTimesDelinquency   537.402100\n",
      "5     UtilizationBucketLateBucket   370.240204\n",
      "6               UtilizationPerAge   323.701935\n",
      "7   RevolvingUtilizationCappedLog   135.808762\n",
      "8             DebtToIncomeAgeRisk    78.961166\n",
      "9             HasMajorDelinquency    74.126953\n",
      "10            IncomePerCreditLine    58.123276\n",
      "11       UtilizationPerCreditLine    43.318695\n",
      "12      LatePaymentsPerCreditLine    42.630283\n",
      "13                HighAgeRiskFlag    40.883766\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4f9d1f895544f38049cbc473f0705c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "1                              UtilizationPerAge       0.017166\n",
      "8                              HasAnyDelinquency       0.011502\n",
      "17   UtilizationBucketLateBucket_Very Low_NoLate       0.011368\n",
      "2                  RevolvingUtilizationCappedLog       0.008158\n",
      "24                             UtilizationPerAge       0.006629\n",
      "29                           DebtToIncomeAgeRisk       0.006502\n",
      "26                           IncomePerCreditLine       0.004828\n",
      "13        UtilizationBucketLateBucket_Low_NoLate       0.003602\n",
      "9                            HasMajorDelinquency       0.003029\n",
      "3                            IncomePerCreditLine       0.002776\n",
      "21                        DelinquencyBucket_None       0.002244\n",
      "14   UtilizationBucketLateBucket_Moderate_NoLate       0.002224\n",
      "33                            TotalPastDueCapped       0.002064\n",
      "22                       DelinquencyBucket_Other       0.002059\n",
      "19                         DelinquencyBucket_Few       0.001931\n",
      "11                              DelinquencyScore       0.001868\n",
      "18        UtilizationBucketLateBucket_nan_NoLate       0.001121\n",
      "7                       UtilizationPerCreditLine       0.001093\n",
      "6                            DebtToIncomeAgeRisk       0.000980\n",
      "4                                HighAgeRiskFlag       0.000732\n",
      "31                             HasAnyDelinquency       0.000652\n",
      "20                    DelinquencyBucket_Moderate       0.000461\n",
      "5                    UtilizationTimesDelinquency       0.000460\n",
      "30                      UtilizationPerCreditLine       0.000421\n",
      "16  UtilizationBucketLateBucket_Very High_NoLate       0.000362\n",
      "0                      LatePaymentsPerCreditLine       0.000307\n",
      "23                     LatePaymentsPerCreditLine       0.000261\n",
      "12       UtilizationBucketLateBucket_High_NoLate       0.000227\n",
      "32                           HasMajorDelinquency       0.000158\n",
      "27                               HighAgeRiskFlag       0.000154\n",
      "25                 RevolvingUtilizationCappedLog       0.000020\n",
      "15             UtilizationBucketLateBucket_Other       0.000009\n",
      "10                            TotalPastDueCapped       0.000000\n",
      "28                   UtilizationTimesDelinquency       0.000000\n",
      "34                              DelinquencyScore       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Shap\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "\n",
    "def shap_ohe(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    model_cpu.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "\n",
    "background = shap.sample(X_train_nn_full.astype('float32').values, 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_nn_full.astype('float32').values[:500])\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_xgb.columns.tolist(), \"xgb_col_order.pkl\")\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
