{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "        \n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    imputed_flags = [col for col in numeric_cols if col.startswith(\"Was\") or col.endswith(\"Imputed\")]\n",
    "    regular_numeric_cols = [col for col in numeric_cols if col not in imputed_flags]\n",
    "\n",
    "    df_num = df_copy[regular_numeric_cols].copy()\n",
    "    \n",
    "    df_num.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    print(f\"Dataset shape: {df_num.shape}\")\n",
    "    print(f\"Total rows: {len(df_num)}\")\n",
    "    print(f\"Total duplicate rows: {df_num.duplicated().sum()}\")\n",
    "\n",
    "    desc = df_num.describe().T\n",
    "    desc[\"skew\"] = df_num.skew()\n",
    "    \n",
    "    desc[\"dtype\"] = df_copy[desc.index].dtypes\n",
    "    desc[\"non_null\"] = df_copy[desc.index].notna().sum()\n",
    "    desc[\"missing\"] = df_copy[desc.index].isna().sum()\n",
    "    desc[\"missing_%\"] = (df_copy[desc.index].isna().mean() * 100).round(2)\n",
    "    desc[\"unique\"] = df_copy[desc.index].nunique()\n",
    "    \n",
    "    if y is not None:\n",
    "        df_num['target'] = y\n",
    "        desc[\"corr_with_target\"] = df_num.corr()['target'].drop('target')\n",
    "    \n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "       \n",
    "    corr_pairs = (\n",
    "        corr_matrix\n",
    "        .where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "      \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "     \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    high_corr_flags = []\n",
    "    high_corr_with = []\n",
    "    \n",
    "    for col in desc.index:\n",
    "        if col in corr_map:\n",
    "            high_corr_flags.append(True)\n",
    "            high_corr_with.append(\", \".join(corr_map[col]))\n",
    "        else:\n",
    "            high_corr_flags.append(False)\n",
    "            high_corr_with.append(\"\")\n",
    "    \n",
    "    desc[\"high_corr_flag\"] = high_corr_flags\n",
    "    desc[\"high_corr_with\"] = high_corr_with\n",
    "    \n",
    "    return desc.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(X, y, n_high=100, n_low=10):\n",
    "    \n",
    "    X_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "    \n",
    "    numeric_cols = X_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    X_copy[numeric_cols] = X_copy[numeric_cols].fillna(0)\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X_copy, y_copy)\n",
    "    y_pred_proba = hgb.predict_proba(X_copy)[:, 1]\n",
    "\n",
    "    df_combined = X_copy.copy()\n",
    "    df_combined[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_combined[\"__target__\"] = y_copy.values\n",
    "\n",
    "    df_sorted = df_combined.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    X_filtered = df_filtered.drop(columns=[\"__pred_proba__\", \"__target__\"])\n",
    "    y_filtered = df_filtered[\"__target__\"]\n",
    "\n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    \n",
    "    TotalPastDueCapped = TotalPastDue.clip(upper=10)\n",
    "    \n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationFilled = RevolvingUtilizationCapped.fillna(0.0)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationFilled).replace(0, np.nan)\n",
    "        \n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * df_e[\"MonthlyIncome\"]\n",
    "    \n",
    "    IncomePerCreditLine = df_e[\"MonthlyIncome\"] / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLog / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDueCapped > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = RevolvingUtilizationCappedLog\n",
    "\n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"DelinquencyDensity\"] = TotalPastDue / AgeSafe\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationCappedLog / CreditLinesSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "           \n",
    "    df_e[\"PaymentStress\"] = df_e[\"DebtRatio\"] * RevolvingUtilizationFilled\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "    \n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationFilled, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"DelinquencyScore\",\n",
    "        \"DelinquencyDensity\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"PaymentStress\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    best_param = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"scale_pos_weight\": sum(y_train == 0) / sum(y_train == 1),\n",
    "        \"learning_rate\": 0.012,        \n",
    "        \"n_estimators\": 2000,          \n",
    "        \"max_depth\": 6,              \n",
    "        \"min_child_weight\": 8,         \n",
    "        \"gamma\": 0.5,                 \n",
    "        \"subsample\": 0.85,             \n",
    "        \"colsample_bytree\": 0.85,     \n",
    "        \"reg_alpha\": 3,               \n",
    "        \"reg_lambda\": 6,               \n",
    "        \"max_bin\": 1024,              \n",
    "        \"booster\": \"gbtree\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",    \n",
    "        \"device\": \"cuda\",\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": X_train.columns,\n",
    "        \"Importance\": mean_abs_shap\n",
    "    }).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "\n",
    "    final_features = list(set(top_features + cat_cols))\n",
    "\n",
    "    dropped_features = [f for f in df_temp.columns if f not in final_features]\n",
    "\n",
    "    print(f\"Kept {len(final_features)} features (including categorical columns)\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[final_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    \n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    \n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>120269.0</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>146076.0</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count         mean           std  \\\n",
       "MonthlyIncome                         120269.0  6670.221237  14384.674215   \n",
       "NumberOfDependents                    146076.0     0.757222      1.115086   \n",
       "age                                   150000.0    52.295207     14.771866   \n",
       "RevolvingUtilizationOfUnsecuredLines  150000.0     6.048438    249.755371   \n",
       "DebtRatio                             150000.0   353.005076   2037.818523   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  150000.0     0.421033      4.192781   \n",
       "NumberOfOpenCreditLinesAndLoans       150000.0     8.452760      5.145951   \n",
       "NumberOfTimes90DaysLate               150000.0     0.265973      4.169304   \n",
       "NumberRealEstateLoansOrLines          150000.0     1.018240      1.129771   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  150000.0     0.240387      4.155179   \n",
       "\n",
       "                                      min          25%          50%  \\\n",
       "MonthlyIncome                         0.0  3400.000000  5400.000000   \n",
       "NumberOfDependents                    0.0     0.000000     0.000000   \n",
       "age                                   0.0    41.000000    52.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines  0.0     0.029867     0.154181   \n",
       "DebtRatio                             0.0     0.175074     0.366508   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans       0.0     5.000000     8.000000   \n",
       "NumberOfTimes90DaysLate               0.0     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines          0.0     0.000000     1.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "\n",
       "                                              75%        max        skew  \\\n",
       "MonthlyIncome                         8249.000000  3008750.0  114.040318   \n",
       "NumberOfDependents                       1.000000       20.0    1.588242   \n",
       "age                                     63.000000      109.0    0.188995   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.559046    50708.0   97.631574   \n",
       "DebtRatio                                0.868254   329664.0   95.157793   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000       98.0   22.597108   \n",
       "NumberOfOpenCreditLinesAndLoans         11.000000       58.0    1.215314   \n",
       "NumberOfTimes90DaysLate                  0.000000       98.0   23.087345   \n",
       "NumberRealEstateLoansOrLines             2.000000       54.0    3.482484   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000       98.0   23.331743   \n",
       "\n",
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique  corr_with_target  \\\n",
       "MonthlyIncome                          13594         -0.019746   \n",
       "NumberOfDependents                        13          0.046048   \n",
       "age                                       86         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728         -0.001802   \n",
       "DebtRatio                             114194         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans           58         -0.029669   \n",
       "NumberOfTimes90DaysLate                   19          0.117175   \n",
       "NumberRealEstateLoansOrLines              28         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>1.202670e+05</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>146074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066841</td>\n",
       "      <td>6.048512</td>\n",
       "      <td>52.295557</td>\n",
       "      <td>0.421032</td>\n",
       "      <td>353.009780</td>\n",
       "      <td>6.645265e+03</td>\n",
       "      <td>8.452766</td>\n",
       "      <td>0.265977</td>\n",
       "      <td>1.018234</td>\n",
       "      <td>0.240390</td>\n",
       "      <td>0.757198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249747</td>\n",
       "      <td>249.757035</td>\n",
       "      <td>14.771347</td>\n",
       "      <td>4.192809</td>\n",
       "      <td>2037.831702</td>\n",
       "      <td>1.148842e+04</td>\n",
       "      <td>5.145980</td>\n",
       "      <td>4.169331</td>\n",
       "      <td>1.129776</td>\n",
       "      <td>4.155207</td>\n",
       "      <td>1.115074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029869</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>3.400000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>5.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559044</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868260</td>\n",
       "      <td>8.249000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149998.000000                         149998.000000  149998.000000   \n",
       "mean           0.066841                              6.048512      52.295557   \n",
       "std            0.249747                            249.757035      14.771347   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.029869      41.000000   \n",
       "50%            0.000000                              0.154181      52.000000   \n",
       "75%            0.000000                              0.559044      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                         149998.000000  149998.000000   1.202670e+05   \n",
       "mean                               0.421032     353.009780   6.645265e+03   \n",
       "std                                4.192809    2037.831702   1.148842e+04   \n",
       "min                                0.000000       0.000000   0.000000e+00   \n",
       "25%                                0.000000       0.175074   3.400000e+03   \n",
       "50%                                0.000000       0.366508   5.400000e+03   \n",
       "75%                                0.000000       0.868260   8.249000e+03   \n",
       "max                               98.000000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149998.000000            149998.000000   \n",
       "mean                          8.452766                 0.265977   \n",
       "std                           5.145980                 4.169331   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149998.000000                         149998.000000   \n",
       "mean                       1.018234                              0.240390   \n",
       "std                        1.129776                              4.155207   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       146074.000000  \n",
       "mean             0.757198  \n",
       "std              1.115074  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling Manual\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139972\n",
      "1     10026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_train)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Outlier Handling \n",
    "X_train_cut, y_train_cut = outlier_handling(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_cut, y_train_cut, test_size=0.2, stratify=y_train_cut, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "026bc2c6-c772-4a73-9cbf-5e29c2b410e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 451 duplicates\n",
      "Dropped: 45 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)\n",
    "X_val, y_val = check_and_drop_duplicates(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95419 features\n",
      "Engineered cols: ['DelinquencyScore', 'DelinquencyDensity', 'HasMajorDelinquency', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'PaymentStress', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2bd0425-dbbf-491a-aee0-b602edf86033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2141 duplicates\n"
     ]
    }
   ],
   "source": [
    "df_e, y_train = check_and_drop_duplicates(df_e, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyDensity                        0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                     692            0.74\n",
      "LatePaymentsPerCreditLine               692            0.74\n",
      "PaymentStress                             0            0.00\n",
      "RevolvingUtilizationCappedLog          4952            5.31\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      4952            5.31\n",
      "UtilizationPerCreditLine               5644            6.05\n",
      "UtilizationTimesDelinquency            4952            5.31\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           30           0.03\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'UtilizationBucketLateBucket': collapsed 25 rare categories: ['Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'Very High_ModerateLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very High_FrequentLate', 'Very Low_ModerateLate', 'Low_ModerateLate', 'High_FrequentLate', 'Very High_ChronicLate', 'Moderate_FrequentLate', 'Extreme_NoLate', 'Very Low_FrequentLate', 'Low_FrequentLate', 'High_ChronicLate', 'Extreme_ModerateLate', 'Extreme_FrequentLate', 'Moderate_ChronicLate', 'Extreme_FewLate', 'Very Low_ChronicLate', 'Low_ChronicLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2da8189b-60a9-4cc7-a082-1a56c327dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 13 features (including categorical columns)\n",
      "Dropped 0 features\n",
      "                          Feature  Importance\n",
      "0               UtilizationPerAge    0.610352\n",
      "1       LatePaymentsPerCreditLine    0.449736\n",
      "2                DelinquencyScore    0.316338\n",
      "3   RevolvingUtilizationCappedLog    0.294214\n",
      "4             IncomePerCreditLine    0.228368\n",
      "5        UtilizationPerCreditLine    0.177873\n",
      "6             DebtToIncomeAgeRisk    0.163105\n",
      "7     UtilizationTimesDelinquency    0.159490\n",
      "8                   PaymentStress    0.145672\n",
      "9              DelinquencyDensity    0.144463\n",
      "10    UtilizationBucketLateBucket    0.050002\n",
      "11            HasMajorDelinquency    0.049367\n",
      "12                HighAgeRiskFlag    0.022870\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n",
      "['LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyDensity', 'UtilizationPerCreditLine', 'PaymentStress', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog', 'DelinquencyScore', 'HasMajorDelinquency', 'UtilizationPerAge', 'UtilizationTimesDelinquency']\n",
      "['UtilizationBucketLateBucket']\n",
      "{'UtilizationBucketLateBucket': {'Very Low_NoLate': 0, 'Low_NoLate': 1, 'Moderate_NoLate': 2, 'High_NoLate': 3, 'Other': 4, 'Very High_NoLate': 5}}\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")\n",
    "print(num_col_order)\n",
    "print(cat_col_order)\n",
    "print(cat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23923 features\n",
      "Engineered cols: ['DelinquencyScore', 'DelinquencyDensity', 'HasMajorDelinquency', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'PaymentStress', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 30000 features\n",
      "Engineered cols: ['DelinquencyScore', 'DelinquencyDensity', 'HasMajorDelinquency', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'PaymentStress', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (93278, 13)\n",
      "Total rows: 93278\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>7.674226e-02</td>\n",
       "      <td>0.302173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>17.861586</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192</td>\n",
       "      <td>0.293777</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>3.102119e-01</td>\n",
       "      <td>2.335493</td>\n",
       "      <td>-0.750774</td>\n",
       "      <td>-0.434985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565015</td>\n",
       "      <td>288.722910</td>\n",
       "      <td>58.772174</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26044</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>2.372536e-01</td>\n",
       "      <td>1.472134</td>\n",
       "      <td>-0.463910</td>\n",
       "      <td>-0.445721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554279</td>\n",
       "      <td>228.592559</td>\n",
       "      <td>67.005507</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72788</td>\n",
       "      <td>0.037938</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyDensity</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>9.492553e-03</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>14.211243</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474</td>\n",
       "      <td>0.330339</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>7.406146e-01</td>\n",
       "      <td>2.324695</td>\n",
       "      <td>-0.426464</td>\n",
       "      <td>-0.299282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700718</td>\n",
       "      <td>37.858252</td>\n",
       "      <td>4.441822</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82003</td>\n",
       "      <td>0.161567</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaymentStress</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>2.848564e+02</td>\n",
       "      <td>1968.873569</td>\n",
       "      <td>-0.214825</td>\n",
       "      <td>-0.192144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807856</td>\n",
       "      <td>271006.935090</td>\n",
       "      <td>49.680027</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86994</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>3.166502e+00</td>\n",
       "      <td>1.712756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.336996</td>\n",
       "      <td>int8</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.054283</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>-7.861233e-17</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-1.117425</td>\n",
       "      <td>-1.117425</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>0.894915</td>\n",
       "      <td>-0.222513</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.092288</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>2.240582e-01</td>\n",
       "      <td>0.626909</td>\n",
       "      <td>-0.431209</td>\n",
       "      <td>-0.311038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688962</td>\n",
       "      <td>4.071430</td>\n",
       "      <td>1.074615</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80873</td>\n",
       "      <td>0.263038</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>6.799031e-01</td>\n",
       "      <td>2.479221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.343651</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.348857</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyDensity (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>8.752332e-02</td>\n",
       "      <td>0.282602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.919198</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.353128</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>2.895178e-01</td>\n",
       "      <td>0.770289</td>\n",
       "      <td>-0.409952</td>\n",
       "      <td>-0.306232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693768</td>\n",
       "      <td>8.130976</td>\n",
       "      <td>1.660911</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82266</td>\n",
       "      <td>0.259937</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>93278.0</td>\n",
       "      <td>1.929952e-03</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.090812</td>\n",
       "      <td>float64</td>\n",
       "      <td>93278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15917</td>\n",
       "      <td>0.360803</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count          mean          std       min  \\\n",
       "LatePaymentsPerCreditLine      93278.0  7.674226e-02     0.302173  0.000000   \n",
       "IncomePerCreditLine            93278.0  3.102119e-01     2.335493 -0.750774   \n",
       "DebtToIncomeAgeRisk            93278.0  2.372536e-01     1.472134 -0.463910   \n",
       "DelinquencyDensity             93278.0  9.492553e-03     0.032358  0.000000   \n",
       "UtilizationPerCreditLine       93278.0  7.406146e-01     2.324695 -0.426464   \n",
       "PaymentStress                  93278.0  2.848564e+02  1968.873569 -0.214825   \n",
       "UtilizationBucketLateBucket    93278.0  3.166502e+00     1.712756  0.000000   \n",
       "HighAgeRiskFlag                93278.0 -7.861233e-17     1.000005 -1.117425   \n",
       "RevolvingUtilizationCappedLog  93278.0  2.240582e-01     0.626909 -0.431209   \n",
       "DelinquencyScore               93278.0  6.799031e-01     2.479221  0.000000   \n",
       "HasMajorDelinquency            93278.0  8.752332e-02     0.282602  0.000000   \n",
       "UtilizationPerAge              93278.0  2.895178e-01     0.770289 -0.409952   \n",
       "UtilizationTimesDelinquency    93278.0  1.929952e-03     0.005096  0.000000   \n",
       "\n",
       "                                    25%       50%       75%            max  \\\n",
       "LatePaymentsPerCreditLine      0.000000  0.000000  0.000000      30.000000   \n",
       "IncomePerCreditLine           -0.434985  0.000000  0.565015     288.722910   \n",
       "DebtToIncomeAgeRisk           -0.445721  0.000000  0.554279     228.592559   \n",
       "DelinquencyDensity             0.000000  0.000000  0.000000       1.428571   \n",
       "UtilizationPerCreditLine      -0.299282  0.000000  0.700718      37.858252   \n",
       "PaymentStress                 -0.192144  0.000000  0.807856  271006.935090   \n",
       "UtilizationBucketLateBucket    2.000000  3.000000  5.000000       5.000000   \n",
       "HighAgeRiskFlag               -1.117425  0.894915  0.894915       0.894915   \n",
       "RevolvingUtilizationCappedLog -0.311038  0.000000  0.688962       4.071430   \n",
       "DelinquencyScore               0.000000  0.000000  0.000000      60.000000   \n",
       "HasMajorDelinquency            0.000000  0.000000  0.000000       1.000000   \n",
       "UtilizationPerAge             -0.306232  0.000000  0.693768       8.130976   \n",
       "UtilizationTimesDelinquency    0.000000  0.000000  0.000000       0.071670   \n",
       "\n",
       "                                    skew    dtype  non_null  missing  \\\n",
       "LatePaymentsPerCreditLine      17.861586  float64     93278        0   \n",
       "IncomePerCreditLine            58.772174  float64     93278        0   \n",
       "DebtToIncomeAgeRisk            67.005507  float64     93278        0   \n",
       "DelinquencyDensity             14.211243  float64     93278        0   \n",
       "UtilizationPerCreditLine        4.441822  float64     93278        0   \n",
       "PaymentStress                  49.680027  float64     93278        0   \n",
       "UtilizationBucketLateBucket    -0.336996     int8     93278        0   \n",
       "HighAgeRiskFlag                -0.222513  float64     93278        0   \n",
       "RevolvingUtilizationCappedLog   1.074615  float64     93278        0   \n",
       "DelinquencyScore               11.343651  float64     93278        0   \n",
       "HasMajorDelinquency             2.919198  float64     93278        0   \n",
       "UtilizationPerAge               1.660911  float64     93278        0   \n",
       "UtilizationTimesDelinquency     3.090812  float64     93278        0   \n",
       "\n",
       "                               missing_%  unique  corr_with_target  \\\n",
       "LatePaymentsPerCreditLine            0.0     192          0.293777   \n",
       "IncomePerCreditLine                  0.0   26044          0.001486   \n",
       "DebtToIncomeAgeRisk                  0.0   72788          0.037938   \n",
       "DelinquencyDensity                   0.0     474          0.330339   \n",
       "UtilizationPerCreditLine             0.0   82003          0.161567   \n",
       "PaymentStress                        0.0   86994          0.031168   \n",
       "UtilizationBucketLateBucket          0.0       6         -0.054283   \n",
       "HighAgeRiskFlag                      0.0       2         -0.092288   \n",
       "RevolvingUtilizationCappedLog        0.0   80873          0.263038   \n",
       "DelinquencyScore                     0.0      37          0.348857   \n",
       "HasMajorDelinquency                  0.0       2          0.353128   \n",
       "UtilizationPerAge                    0.0   82266          0.259937   \n",
       "UtilizationTimesDelinquency          0.0   15917          0.360803   \n",
       "\n",
       "                               high_corr_flag  \\\n",
       "LatePaymentsPerCreditLine               False   \n",
       "IncomePerCreditLine                     False   \n",
       "DebtToIncomeAgeRisk                     False   \n",
       "DelinquencyDensity                       True   \n",
       "UtilizationPerCreditLine                False   \n",
       "PaymentStress                           False   \n",
       "UtilizationBucketLateBucket             False   \n",
       "HighAgeRiskFlag                         False   \n",
       "RevolvingUtilizationCappedLog            True   \n",
       "DelinquencyScore                         True   \n",
       "HasMajorDelinquency                     False   \n",
       "UtilizationPerAge                        True   \n",
       "UtilizationTimesDelinquency             False   \n",
       "\n",
       "                                                     high_corr_with  \n",
       "LatePaymentsPerCreditLine                                            \n",
       "IncomePerCreditLine                                                  \n",
       "DebtToIncomeAgeRisk                                                  \n",
       "DelinquencyDensity                          DelinquencyScore (0.92)  \n",
       "UtilizationPerCreditLine                                             \n",
       "PaymentStress                                                        \n",
       "UtilizationBucketLateBucket                                          \n",
       "HighAgeRiskFlag                                                      \n",
       "RevolvingUtilizationCappedLog              UtilizationPerAge (0.92)  \n",
       "DelinquencyScore                          DelinquencyDensity (0.92)  \n",
       "HasMajorDelinquency                                                  \n",
       "UtilizationPerAge              RevolvingUtilizationCappedLog (0.92)  \n",
       "UtilizationTimesDelinquency                                          "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WasLatePaymentsPerCreditLineImputed', 'WasUtilizationPerCreditLineImputed', 'WasUtilizationPerAgeImputed']\n"
     ]
    }
   ],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasUtilizationTimesDelinquencyImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasRevolvingUtilizationCappedLogImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "    \"WasPaymentStressImputed\",\n",
    "    \"WasIncomePerCreditLineImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasDelinquencyDensityImputed\",\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep\n",
    "print(X_train_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Flags\n",
    "X_train_flags = X_train[X_train_flags]\n",
    "X_val_flags = X_val[X_val_flags]\n",
    "X_test_flags = X_test[X_test_flags]\n",
    "\n",
    "# NN\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_col_order])\n",
    "X_val_cat = encoder.transform(X_val[cat_col_order])\n",
    "X_test_cat = encoder.transform(X_test[cat_col_order])\n",
    "\n",
    "cat_feature_names = encoder.get_feature_names_out(cat_col_order)\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "X_val_cat_df = pd.DataFrame(X_val_cat, columns=cat_feature_names, index=X_val.index)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat, columns=cat_feature_names, index=X_test.index)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_cat_df, X_train[num_col_order], X_train_flags], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_cat_df, X_val[num_col_order], X_val_flags], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_cat_df, X_test[num_col_order], X_test_flags], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([93278, 21])\n",
      "Class weights: {np.int64(0): np.float64(0.5355203178284783), np.int64(1): np.float64(7.538225311136253)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 93278, Val: 23923, Test: 30000\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=21, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=21, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 49195\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model = NN(X_train_tensor.shape[1]).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.030661 | Train AUC: 0.7894 | Val loss: 0.025874 | Val AUC: 0.8428\n",
      "Epoch 2/75 | Train loss: 0.025604 | Train AUC: 0.8372 | Val loss: 0.024906 | Val AUC: 0.8507\n",
      "Epoch 3/75 | Train loss: 0.025018 | Train AUC: 0.8452 | Val loss: 0.025099 | Val AUC: 0.8489\n",
      "Epoch 4/75 | Train loss: 0.024912 | Train AUC: 0.8472 | Val loss: 0.025150 | Val AUC: 0.8515\n",
      "Epoch 5/75 | Train loss: 0.024817 | Train AUC: 0.8484 | Val loss: 0.025396 | Val AUC: 0.8510\n",
      "Epoch 6/75 | Train loss: 0.024772 | Train AUC: 0.8490 | Val loss: 0.025453 | Val AUC: 0.8523\n",
      "Epoch 7/75 | Train loss: 0.024722 | Train AUC: 0.8503 | Val loss: 0.025874 | Val AUC: 0.8504\n",
      "Epoch 8/75 | Train loss: 0.024648 | Train AUC: 0.8510 | Val loss: 0.025081 | Val AUC: 0.8521\n",
      "Epoch 9/75 | Train loss: 0.024628 | Train AUC: 0.8516 | Val loss: 0.025342 | Val AUC: 0.8524\n",
      "Epoch 10/75 | Train loss: 0.024575 | Train AUC: 0.8526 | Val loss: 0.024811 | Val AUC: 0.8522\n",
      "Epoch 11/75 | Train loss: 0.024563 | Train AUC: 0.8527 | Val loss: 0.025264 | Val AUC: 0.8512\n",
      "Epoch 12/75 | Train loss: 0.024552 | Train AUC: 0.8525 | Val loss: 0.025203 | Val AUC: 0.8520\n",
      "Epoch 13/75 | Train loss: 0.024405 | Train AUC: 0.8550 | Val loss: 0.025029 | Val AUC: 0.8544\n",
      "Epoch 14/75 | Train loss: 0.024411 | Train AUC: 0.8548 | Val loss: 0.025088 | Val AUC: 0.8530\n",
      "Epoch 15/75 | Train loss: 0.024374 | Train AUC: 0.8555 | Val loss: 0.025547 | Val AUC: 0.8534\n",
      "Epoch 16/75 | Train loss: 0.024352 | Train AUC: 0.8561 | Val loss: 0.025190 | Val AUC: 0.8521\n",
      "Epoch 17/75 | Train loss: 0.024401 | Train AUC: 0.8549 | Val loss: 0.024823 | Val AUC: 0.8544\n",
      "Epoch 18/75 | Train loss: 0.024378 | Train AUC: 0.8557 | Val loss: 0.024813 | Val AUC: 0.8541\n",
      "Epoch 19/75 | Train loss: 0.024368 | Train AUC: 0.8555 | Val loss: 0.024932 | Val AUC: 0.8509\n",
      "Epoch 20/75 | Train loss: 0.024341 | Train AUC: 0.8560 | Val loss: 0.024591 | Val AUC: 0.8541\n",
      "Epoch 21/75 | Train loss: 0.024314 | Train AUC: 0.8563 | Val loss: 0.024622 | Val AUC: 0.8544\n",
      "Epoch 22/75 | Train loss: 0.024257 | Train AUC: 0.8574 | Val loss: 0.024683 | Val AUC: 0.8539\n",
      "Epoch 23/75 | Train loss: 0.024237 | Train AUC: 0.8577 | Val loss: 0.025098 | Val AUC: 0.8544\n",
      "Epoch 24/75 | Train loss: 0.024333 | Train AUC: 0.8559 | Val loss: 0.024920 | Val AUC: 0.8540\n",
      "Epoch 25/75 | Train loss: 0.024257 | Train AUC: 0.8573 | Val loss: 0.024622 | Val AUC: 0.8546\n",
      "Epoch 26/75 | Train loss: 0.024301 | Train AUC: 0.8567 | Val loss: 0.024951 | Val AUC: 0.8549\n",
      "Epoch 27/75 | Train loss: 0.024205 | Train AUC: 0.8581 | Val loss: 0.024772 | Val AUC: 0.8543\n",
      "Epoch 28/75 | Train loss: 0.024234 | Train AUC: 0.8578 | Val loss: 0.024935 | Val AUC: 0.8533\n",
      "Epoch 29/75 | Train loss: 0.024235 | Train AUC: 0.8578 | Val loss: 0.024540 | Val AUC: 0.8546\n",
      "Epoch 30/75 | Train loss: 0.024288 | Train AUC: 0.8568 | Val loss: 0.024778 | Val AUC: 0.8528\n",
      "Epoch 31/75 | Train loss: 0.024210 | Train AUC: 0.8582 | Val loss: 0.024763 | Val AUC: 0.8536\n",
      "Epoch 32/75 | Train loss: 0.024267 | Train AUC: 0.8573 | Val loss: 0.024850 | Val AUC: 0.8528\n",
      "Epoch 33/75 | Train loss: 0.024216 | Train AUC: 0.8575 | Val loss: 0.024976 | Val AUC: 0.8536\n",
      "Epoch 34/75 | Train loss: 0.024227 | Train AUC: 0.8579 | Val loss: 0.024802 | Val AUC: 0.8525\n",
      "Epoch 35/75 | Train loss: 0.024218 | Train AUC: 0.8580 | Val loss: 0.024607 | Val AUC: 0.8540\n",
      "Epoch 36/75 | Train loss: 0.024190 | Train AUC: 0.8582 | Val loss: 0.024897 | Val AUC: 0.8546\n",
      "Epoch 37/75 | Train loss: 0.024222 | Train AUC: 0.8579 | Val loss: 0.024706 | Val AUC: 0.8551\n",
      "Epoch 38/75 | Train loss: 0.024184 | Train AUC: 0.8583 | Val loss: 0.024712 | Val AUC: 0.8537\n",
      "Epoch 39/75 | Train loss: 0.024135 | Train AUC: 0.8592 | Val loss: 0.024869 | Val AUC: 0.8537\n",
      "Epoch 40/75 | Train loss: 0.024171 | Train AUC: 0.8589 | Val loss: 0.024740 | Val AUC: 0.8527\n",
      "Epoch 41/75 | Train loss: 0.024142 | Train AUC: 0.8591 | Val loss: 0.024675 | Val AUC: 0.8546\n",
      "Epoch 42/75 | Train loss: 0.024224 | Train AUC: 0.8579 | Val loss: 0.024581 | Val AUC: 0.8545\n",
      "Epoch 43/75 | Train loss: 0.024213 | Train AUC: 0.8580 | Val loss: 0.024819 | Val AUC: 0.8542\n",
      "Epoch 44/75 | Train loss: 0.024234 | Train AUC: 0.8576 | Val loss: 0.024698 | Val AUC: 0.8551\n",
      "Epoch 45/75 | Train loss: 0.024192 | Train AUC: 0.8584 | Val loss: 0.024811 | Val AUC: 0.8552\n",
      "Epoch 46/75 | Train loss: 0.024158 | Train AUC: 0.8589 | Val loss: 0.024788 | Val AUC: 0.8549\n",
      "Epoch 47/75 | Train loss: 0.024151 | Train AUC: 0.8590 | Val loss: 0.024823 | Val AUC: 0.8516\n",
      "Epoch 48/75 | Train loss: 0.024186 | Train AUC: 0.8584 | Val loss: 0.024979 | Val AUC: 0.8533\n",
      "Epoch 49/75 | Train loss: 0.024128 | Train AUC: 0.8589 | Val loss: 0.024686 | Val AUC: 0.8545\n",
      "Epoch 50/75 | Train loss: 0.024136 | Train AUC: 0.8590 | Val loss: 0.024631 | Val AUC: 0.8546\n",
      "Epoch 51/75 | Train loss: 0.024110 | Train AUC: 0.8599 | Val loss: 0.024810 | Val AUC: 0.8550\n",
      "Epoch 52/75 | Train loss: 0.024137 | Train AUC: 0.8591 | Val loss: 0.024931 | Val AUC: 0.8548\n",
      "Epoch 53/75 | Train loss: 0.024122 | Train AUC: 0.8595 | Val loss: 0.024717 | Val AUC: 0.8552\n",
      "Epoch 54/75 | Train loss: 0.024155 | Train AUC: 0.8586 | Val loss: 0.024612 | Val AUC: 0.8550\n",
      "Epoch 55/75 | Train loss: 0.024177 | Train AUC: 0.8587 | Val loss: 0.024604 | Val AUC: 0.8547\n",
      "Epoch 56/75 | Train loss: 0.024130 | Train AUC: 0.8594 | Val loss: 0.024573 | Val AUC: 0.8548\n",
      "Epoch 57/75 | Train loss: 0.024107 | Train AUC: 0.8598 | Val loss: 0.024835 | Val AUC: 0.8510\n",
      "Epoch 58/75 | Train loss: 0.024114 | Train AUC: 0.8596 | Val loss: 0.024962 | Val AUC: 0.8543\n",
      "Epoch 59/75 | Train loss: 0.024166 | Train AUC: 0.8585 | Val loss: 0.024753 | Val AUC: 0.8550\n",
      "Epoch 60/75 | Train loss: 0.024165 | Train AUC: 0.8583 | Val loss: 0.025057 | Val AUC: 0.8510\n",
      "Epoch 61/75 | Train loss: 0.024169 | Train AUC: 0.8588 | Val loss: 0.024764 | Val AUC: 0.8527\n",
      "Epoch 62/75 | Train loss: 0.024136 | Train AUC: 0.8593 | Val loss: 0.024568 | Val AUC: 0.8541\n",
      "Epoch 63/75 | Train loss: 0.024119 | Train AUC: 0.8597 | Val loss: 0.024740 | Val AUC: 0.8548\n",
      "Epoch 64/75 | Train loss: 0.024098 | Train AUC: 0.8598 | Val loss: 0.024746 | Val AUC: 0.8535\n",
      "Epoch 65/75 | Train loss: 0.024101 | Train AUC: 0.8600 | Val loss: 0.024617 | Val AUC: 0.8537\n",
      "Early stopping at epoch 66\n",
      "Run 1 best Val AUC: 0.8552\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.024368 | Train AUC: 0.8553 | Val loss: 0.024865 | Val AUC: 0.8510\n",
      "Epoch 2/75 | Train loss: 0.024376 | Train AUC: 0.8553 | Val loss: 0.024678 | Val AUC: 0.8536\n",
      "Epoch 3/75 | Train loss: 0.024398 | Train AUC: 0.8553 | Val loss: 0.024744 | Val AUC: 0.8530\n",
      "Epoch 4/75 | Train loss: 0.024382 | Train AUC: 0.8557 | Val loss: 0.025102 | Val AUC: 0.8472\n",
      "Epoch 5/75 | Train loss: 0.024388 | Train AUC: 0.8556 | Val loss: 0.024941 | Val AUC: 0.8528\n",
      "Epoch 6/75 | Train loss: 0.024364 | Train AUC: 0.8557 | Val loss: 0.025712 | Val AUC: 0.8525\n",
      "Epoch 7/75 | Train loss: 0.024378 | Train AUC: 0.8557 | Val loss: 0.024743 | Val AUC: 0.8515\n",
      "Epoch 8/75 | Train loss: 0.024325 | Train AUC: 0.8564 | Val loss: 0.024709 | Val AUC: 0.8510\n",
      "Epoch 9/75 | Train loss: 0.024242 | Train AUC: 0.8577 | Val loss: 0.024634 | Val AUC: 0.8551\n",
      "Epoch 10/75 | Train loss: 0.024232 | Train AUC: 0.8577 | Val loss: 0.024499 | Val AUC: 0.8540\n",
      "Epoch 11/75 | Train loss: 0.024287 | Train AUC: 0.8571 | Val loss: 0.024650 | Val AUC: 0.8544\n",
      "Epoch 12/75 | Train loss: 0.024225 | Train AUC: 0.8582 | Val loss: 0.024559 | Val AUC: 0.8550\n",
      "Epoch 13/75 | Train loss: 0.024190 | Train AUC: 0.8583 | Val loss: 0.024681 | Val AUC: 0.8548\n",
      "Epoch 14/75 | Train loss: 0.024250 | Train AUC: 0.8577 | Val loss: 0.024595 | Val AUC: 0.8540\n",
      "Epoch 15/75 | Train loss: 0.024152 | Train AUC: 0.8591 | Val loss: 0.024557 | Val AUC: 0.8552\n",
      "Epoch 16/75 | Train loss: 0.024129 | Train AUC: 0.8593 | Val loss: 0.024555 | Val AUC: 0.8554\n",
      "Epoch 17/75 | Train loss: 0.024158 | Train AUC: 0.8589 | Val loss: 0.024696 | Val AUC: 0.8544\n",
      "Epoch 18/75 | Train loss: 0.024189 | Train AUC: 0.8588 | Val loss: 0.024464 | Val AUC: 0.8549\n",
      "Epoch 19/75 | Train loss: 0.024132 | Train AUC: 0.8591 | Val loss: 0.024555 | Val AUC: 0.8546\n",
      "Epoch 20/75 | Train loss: 0.024142 | Train AUC: 0.8590 | Val loss: 0.024605 | Val AUC: 0.8546\n",
      "Epoch 21/75 | Train loss: 0.024161 | Train AUC: 0.8589 | Val loss: 0.024543 | Val AUC: 0.8552\n",
      "Epoch 22/75 | Train loss: 0.024167 | Train AUC: 0.8587 | Val loss: 0.024503 | Val AUC: 0.8541\n",
      "Epoch 23/75 | Train loss: 0.024098 | Train AUC: 0.8599 | Val loss: 0.024544 | Val AUC: 0.8549\n",
      "Epoch 24/75 | Train loss: 0.024080 | Train AUC: 0.8603 | Val loss: 0.024713 | Val AUC: 0.8540\n",
      "Epoch 25/75 | Train loss: 0.024089 | Train AUC: 0.8599 | Val loss: 0.024565 | Val AUC: 0.8546\n",
      "Epoch 26/75 | Train loss: 0.024045 | Train AUC: 0.8610 | Val loss: 0.024610 | Val AUC: 0.8552\n",
      "Epoch 27/75 | Train loss: 0.024091 | Train AUC: 0.8603 | Val loss: 0.024757 | Val AUC: 0.8544\n",
      "Epoch 28/75 | Train loss: 0.024166 | Train AUC: 0.8588 | Val loss: 0.024670 | Val AUC: 0.8526\n",
      "Early stopping at epoch 29\n",
      "Run 2 best Val AUC: 0.8554\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8554)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3420815169811249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.85      0.91     27995\n",
      "   Defaulted       0.26      0.71      0.38      2005\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.84      0.88     30000\n",
      "\n",
      "Accuracy: 84.44%\n",
      "ROC AUC: 0.869\n",
      "TP=1427, FP=4090, TN=23905, FN=578\n",
      "Accuracy for class 'Repaid': 85.39%\n",
      "Accuracy for class 'Defaulted': 71.17%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, 0.70)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running model 1/10 with params: {'subsample': 0.9, 'reg_lambda': 6, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.75}\n",
      "[INFO] Running model 2/10 with params: {'subsample': 0.9, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9}\n",
      "[INFO] Running model 3/10 with params: {'subsample': 0.75, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.9}\n",
      "[INFO] Running model 4/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.9}\n",
      "[INFO] Running model 5/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 1.0, 'colsample_bytree': 0.85}\n",
      "[INFO] Running model 6/10 with params: {'subsample': 0.9, 'reg_lambda': 6, 'reg_alpha': 3, 'min_child_weight': 4, 'max_depth': 6, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.85}\n",
      "[INFO] Running model 7/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 3, 'min_child_weight': 8, 'max_depth': 5, 'learning_rate': 0.012, 'gamma': 0.5, 'colsample_bytree': 0.9}\n",
      "[INFO] Running model 8/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 1, 'min_child_weight': 6, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 1.0, 'colsample_bytree': 0.9}\n",
      "[INFO] Running model 9/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.75}\n",
      "[INFO] Running model 10/10 with params: {'subsample': 0.75, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.9}\n",
      "Best AUC: 0.855758180129041\n",
      "Best params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 1.0, 'colsample_bytree': 0.85}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"learning_rate\": [0.008, 0.01, 0.012],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"min_child_weight\": [4, 6, 8],\n",
    "    \"gamma\": [0.0, 0.5, 1.0],\n",
    "    \"subsample\": [0.75, 0.85, 0.9],\n",
    "    \"colsample_bytree\": [0.75, 0.85, 0.9],\n",
    "    \"reg_alpha\": [1, 3, 5],\n",
    "    \"reg_lambda\": [4, 6, 8],\n",
    "}\n",
    "\n",
    "n_iter = 10  \n",
    "sampler = ParameterSampler(param_dist, n_iter=n_iter, random_state=42)\n",
    "\n",
    "best_auc, best_params = 0.0, None\n",
    "\n",
    "for i, params in enumerate(sampler, start=1):\n",
    "    print(f\"[INFO] Running model {i}/{len(sampler)} with params: {params}\")\n",
    "\n",
    "    model_b = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),\n",
    "        n_estimators=800,\n",
    "        max_bin=1024,\n",
    "        booster=\"gbtree\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        early_stopping_rounds=100,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    model_b.fit(\n",
    "        X_train_xgb, y_train,\n",
    "        eval_set=[(X_val_xgb, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if model_b.best_score > best_auc:\n",
    "        best_auc, best_params = model_b.best_score, params\n",
    "\n",
    "print(\"Best AUC:\", best_auc)\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5608208775520325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.86      0.91     27995\n",
      "   Defaulted       0.27      0.71      0.39      2005\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.85      0.88     30000\n",
      "\n",
      "Accuracy: 84.93%\n",
      "ROC AUC: 0.869\n",
      "TP=1424, FP=3941, TN=24054, FN=581\n",
      "Accuracy for class 'Repaid': 85.92%\n",
      "Accuracy for class 'Defaulted': 71.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "dtest = xgb.DMatrix(X_test_xgb)\n",
    "y_probs = model_b.get_booster().predict(dtest) \n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, 0.71)\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                Feature  Importance\n",
      "0           UtilizationBucketLateBucket    0.695242\n",
      "1                     UtilizationPerAge    0.309190\n",
      "2                      DelinquencyScore    0.297416\n",
      "3           UtilizationTimesDelinquency    0.138738\n",
      "4                   IncomePerCreditLine    0.137874\n",
      "5         RevolvingUtilizationCappedLog    0.122133\n",
      "6                    DelinquencyDensity    0.117504\n",
      "7                   DebtToIncomeAgeRisk    0.108334\n",
      "8              UtilizationPerCreditLine    0.065265\n",
      "9                         PaymentStress    0.060212\n",
      "10                  HasMajorDelinquency    0.032008\n",
      "11            LatePaymentsPerCreditLine    0.022787\n",
      "12                      HighAgeRiskFlag    0.019077\n",
      "13   WasUtilizationPerCreditLineImputed    0.000685\n",
      "14          WasUtilizationPerAgeImputed    0.000199\n",
      "15  WasLatePaymentsPerCreditLineImputed    0.000003\n"
     ]
    }
   ],
   "source": [
    "# Shap xgb\n",
    "explainer = shap.TreeExplainer(model_b)\n",
    "shap_values = explainer.shap_values(X_train_xgb)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_xgb.columns,\n",
    "    \"Importance\": mean_abs_shap\n",
    "}).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c489fed174dfb85d99d13c3e37542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "0                              UtilizationPerAge       0.020205\n",
      "1                  RevolvingUtilizationCappedLog       0.013021\n",
      "2                            HasMajorDelinquency       0.008555\n",
      "3                            IncomePerCreditLine       0.008139\n",
      "4    UtilizationBucketLateBucket_Very Low_NoLate       0.007718\n",
      "5              UtilizationBucketLateBucket_Other       0.006545\n",
      "6                             DelinquencyDensity       0.005438\n",
      "7                            DebtToIncomeAgeRisk       0.004937\n",
      "8                               DelinquencyScore       0.003968\n",
      "9         UtilizationBucketLateBucket_Low_NoLate       0.002870\n",
      "10                               HighAgeRiskFlag       0.002453\n",
      "11                      UtilizationPerCreditLine       0.002002\n",
      "12                     LatePaymentsPerCreditLine       0.001901\n",
      "13   UtilizationBucketLateBucket_Moderate_NoLate       0.001536\n",
      "14                   UtilizationTimesDelinquency       0.001533\n",
      "15                                 PaymentStress       0.000963\n",
      "16  UtilizationBucketLateBucket_Very High_NoLate       0.000580\n",
      "17       UtilizationBucketLateBucket_High_NoLate       0.000261\n",
      "18            WasUtilizationPerCreditLineImputed       0.000157\n",
      "19                   WasUtilizationPerAgeImputed       0.000112\n",
      "20           WasLatePaymentsPerCreditLineImputed       0.000032\n"
     ]
    }
   ],
   "source": [
    "# Shap NN\n",
    "model_gpu = copy.deepcopy(model).to(device)\n",
    "model_gpu.eval()\n",
    "\n",
    "def shap_ohe_gpu(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        logits = model_gpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "background = shap.sample(X_train_tensor.cpu().numpy(), 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe_gpu, background)\n",
    "shap_values = explainer.shap_values(X_val_tensor[:500].cpu().numpy())\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_xgb.columns.tolist(), \"xgb_col_order.pkl\")\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfb507-cce9-4894-b873-e5e1f5d657ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
