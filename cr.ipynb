{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationOfUnsecuredLinesCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationOfUnsecuredLines = np.log1p(RevolvingUtilizationOfUnsecuredLinesCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "    \n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = RevolvingUtilizationOfUnsecuredLines / AgeSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "    df_e[\"AgeRisk\"] = AgeRisk\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationOfUnsecuredLines, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"AgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10, random_state=42, bias_mode=None):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "    \n",
    "    minority_class = 1 if pos_count < neg_count else 0\n",
    "    majority_class = 0 if minority_class == 1 else 1\n",
    "\n",
    "    if bias_mode is False:\n",
    "        scale_pos_weight = neg_count / max(1, pos_count)\n",
    "        print(\"Biasing toward minority class\")\n",
    "    elif bias_mode is True:\n",
    "        scale_pos_weight = pos_count / max(1, neg_count)\n",
    "        print(\"Biasing toward majority class\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Using normal class weights\")\n",
    "        \n",
    "    tuned_params = {\n",
    "        'subsample': 0.9, \n",
    "        'reg_lambda': 0.5, \n",
    "        'reg_alpha': 0.1, \n",
    "        'min_child_weight': 7, \n",
    "        'max_depth': 5, \n",
    "        'learning_rate': 0.01, \n",
    "        'gamma': 0.2, \n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=800,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        **tuned_params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "    \n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    numeric_feats = [f for f in feature_cols if f not in cat_cols]\n",
    "    top_numeric = importance_df[importance_df[\"Feature\"].isin(numeric_feats)][\"Feature\"].head(n_to_keep).tolist()\n",
    "    kept_features = top_numeric + cat_cols\n",
    "    dropped_features = [f for f in numeric_feats if f not in top_numeric]\n",
    "\n",
    "    print(f\"Kept {len(kept_features)} select features (including all {len(cat_cols)} categorical)\")\n",
    "    print(f\"Dropped:{len(dropped_features)} numeric select features cols\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols:{dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[kept_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None, drop_target_na=False, show_info=True):\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    target_cleaned = None\n",
    "    \n",
    "    total_duplicates = df_cleaned.duplicated().sum()\n",
    "    if total_duplicates > 0:\n",
    "        df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "        if show_info:\n",
    "            print(f\"Dropped {total_duplicates} duplicate rows. Remaining: {len(df_cleaned)}\")\n",
    "    \n",
    "    if target is not None:\n",
    "        target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "        if drop_target_na:\n",
    "            mask = target_cleaned.notna()\n",
    "            dropped = len(target_cleaned) - mask.sum()\n",
    "            if dropped > 0 and show_info:\n",
    "                print(f\"Dropped {dropped} rows with missing target values\")\n",
    "            df_cleaned = df_cleaned.loc[mask].reset_index(drop=True)\n",
    "            target_cleaned = target_cleaned.loc[mask].reset_index(drop=True)\n",
    "        else:\n",
    "            target_cleaned = target_cleaned.reset_index(drop=True)\n",
    "        return df_cleaned, target_cleaned\n",
    "    else:\n",
    "        return df_cleaned\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def fast_fbeta_scores(y_true, y_probs, thresholds, beta=2, return_details=False):\n",
    "\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FP = (preds & (y_true[:, None] == 0)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "    f_beta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall + 1e-8)\n",
    "\n",
    "    if return_details:\n",
    "        return f_beta, precision, recall\n",
    "    return f_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 609 duplicate rows. Remaining: 149391\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'AgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             MissingCount  MissingPercent\n",
      "AgeRisk                                 0            0.00\n",
      "DebtToIncomeAgeRisk                     0            0.00\n",
      "DelinquencyBucket                       0            0.00\n",
      "DelinquencyScore                        0            0.00\n",
      "HasAnyDelinquency                       0            0.00\n",
      "HasMajorDelinquency                     0            0.00\n",
      "IncomePerCreditLine                  1043            1.09\n",
      "LatePaymentsPerCreditLine            1043            1.09\n",
      "UtilizationBucketLateBucket             0            0.00\n",
      "UtilizationPerAge                    6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 30 rare categories: ['Moderate_FewLate', 'High_FewLate', 'Very Low_FewLate', 'Low_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'High_FrequentLate', 'Low_ModerateLate', 'Very Low_ModerateLate', 'nan_FewLate', 'Moderate_FrequentLate', 'High_ChronicLate', 'nan_ModerateLate', 'Low_FrequentLate', 'Extreme_NoLate', 'Moderate_ChronicLate', 'Very Low_FrequentLate', 'Very High_ModerateLate', 'nan_FrequentLate', 'Very High_NoLate', 'Very High_FrequentLate', 'Very High_FewLate', 'Low_ChronicLate', 'Very High_ChronicLate', 'nan_ChronicLate', 'Extreme_FewLate', 'Very Low_ChronicLate', 'Extreme_ModerateLate', 'Extreme_FrequentLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normal class weights\n",
      "Kept 10 select features (including all 2 categorical)\n",
      "Dropped:0 numeric select features cols\n",
      "                       Feature  Importance\n",
      "0             DelinquencyScore  191.750351\n",
      "1            HasAnyDelinquency  127.972359\n",
      "2  UtilizationBucketLateBucket   40.661636\n",
      "3          HasMajorDelinquency   37.174274\n",
      "4    LatePaymentsPerCreditLine   27.704081\n",
      "5            DelinquencyBucket   24.136913\n",
      "6            UtilizationPerAge   20.652411\n",
      "7          DebtToIncomeAgeRisk    6.114011\n",
      "8          IncomePerCreditLine    5.109613\n",
      "9                      AgeRisk    4.852194\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14, bias_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'AgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'AgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3213 duplicate rows. Remaining: 92293\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92293, 20)\n",
      "Total rows: 92293\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>2.495604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.217984</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205823</td>\n",
       "      <td>0.404304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.455260</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087558</td>\n",
       "      <td>0.282653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.918428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>0.300755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.364952</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.276903</td>\n",
       "      <td>0.768358</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.315081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671427</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.679275</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.271290</td>\n",
       "      <td>1.610420</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.420286</td>\n",
       "      <td>0.031907</td>\n",
       "      <td>0.589293</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.220030</td>\n",
       "      <td>-0.001893</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.324979</td>\n",
       "      <td>2.146190</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.394545</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.581127</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.460337</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.579762</td>\n",
       "      <td>0.734112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.016414</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.815457</td>\n",
       "      <td>0.658607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.617601</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.690648</td>\n",
       "      <td>1.412039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.390001</td>\n",
       "      <td>-0.007608</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyScoreImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.077313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.779086</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054002</td>\n",
       "      <td>0.226023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.946574</td>\n",
       "      <td>-0.006431</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.077313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.779086</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         dtype  non_null  missing  missing_%  \\\n",
       "DelinquencyScore                       float64     92293        0        0.0   \n",
       "HasAnyDelinquency                      float64     92293        0        0.0   \n",
       "HasMajorDelinquency                    float64     92293        0        0.0   \n",
       "LatePaymentsPerCreditLine              float64     92293        0        0.0   \n",
       "UtilizationPerAge                      float64     92293        0        0.0   \n",
       "DebtToIncomeAgeRisk                    float64     92293        0        0.0   \n",
       "IncomePerCreditLine                    float64     92293        0        0.0   \n",
       "AgeRisk                                float64     92293        0        0.0   \n",
       "DelinquencyBucket                         int8     92293        0        0.0   \n",
       "UtilizationBucketLateBucket               int8     92293        0        0.0   \n",
       "WasDelinquencyScoreImputed               int64     92293        0        0.0   \n",
       "WasHasAnyDelinquencyImputed              int64     92293        0        0.0   \n",
       "WasHasMajorDelinquencyImputed            int64     92293        0        0.0   \n",
       "WasLatePaymentsPerCreditLineImputed      int64     92293        0        0.0   \n",
       "WasUtilizationPerAgeImputed              int64     92293        0        0.0   \n",
       "WasDebtToIncomeAgeRiskImputed            int64     92293        0        0.0   \n",
       "WasIncomePerCreditLineImputed            int64     92293        0        0.0   \n",
       "WasAgeRiskImputed                        int64     92293        0        0.0   \n",
       "WasDelinquencyBucketImputed              int64     92293        0        0.0   \n",
       "WasUtilizationBucketLateBucketImputed    int64     92293        0        0.0   \n",
       "\n",
       "                                       unique      mean       std       min  \\\n",
       "DelinquencyScore                           38  0.685415  2.495604  0.000000   \n",
       "HasAnyDelinquency                           2  0.205823  0.404304  0.000000   \n",
       "HasMajorDelinquency                         2  0.087558  0.282653  0.000000   \n",
       "LatePaymentsPerCreditLine                 201  0.076351  0.300755  0.000000   \n",
       "UtilizationPerAge                       82305  0.276903  0.768358 -0.416697   \n",
       "DebtToIncomeAgeRisk                     72746  0.271290  1.610420 -0.444698   \n",
       "IncomePerCreditLine                     26180  0.324979  2.146190 -0.712727   \n",
       "AgeRisk                                     4  0.579762  0.734112  0.000000   \n",
       "DelinquencyBucket                           4  1.815457  0.658607  0.000000   \n",
       "UtilizationBucketLateBucket                 6  2.690648  1.412039  0.000000   \n",
       "WasDelinquencyScoreImputed                  1  0.000000  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed                 1  0.000000  0.000000  0.000000   \n",
       "WasHasMajorDelinquencyImputed               1  0.000000  0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed         2  0.006013  0.077313  0.000000   \n",
       "WasUtilizationPerAgeImputed                 2  0.054002  0.226023  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed               1  0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed               2  0.006013  0.077313  0.000000   \n",
       "WasAgeRiskImputed                           1  0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed                 1  0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed       1  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                            25%       50%       75%  \\\n",
       "DelinquencyScore                       0.000000  0.000000  0.000000   \n",
       "HasAnyDelinquency                      0.000000  0.000000  0.000000   \n",
       "HasMajorDelinquency                    0.000000  0.000000  0.000000   \n",
       "LatePaymentsPerCreditLine              0.000000  0.000000  0.000000   \n",
       "UtilizationPerAge                     -0.315081  0.000000  0.671427   \n",
       "DebtToIncomeAgeRisk                   -0.420286  0.031907  0.589293   \n",
       "IncomePerCreditLine                   -0.394545  0.017945  0.581127   \n",
       "AgeRisk                                0.000000  0.000000  1.000000   \n",
       "DelinquencyBucket                      2.000000  2.000000  2.000000   \n",
       "UtilizationBucketLateBucket            1.000000  3.000000  4.000000   \n",
       "WasDelinquencyScoreImputed             0.000000  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed            0.000000  0.000000  0.000000   \n",
       "WasHasMajorDelinquencyImputed          0.000000  0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed    0.000000  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed            0.000000  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed          0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed          0.000000  0.000000  0.000000   \n",
       "WasAgeRiskImputed                      0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed            0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                              max       skew  \\\n",
       "DelinquencyScore                        60.000000  11.217984   \n",
       "HasAnyDelinquency                        1.000000   1.455260   \n",
       "HasMajorDelinquency                      1.000000   2.918428   \n",
       "LatePaymentsPerCreditLine               30.000000  18.364952   \n",
       "UtilizationPerAge                        8.241714   1.679275   \n",
       "DebtToIncomeAgeRisk                    230.122301  66.220030   \n",
       "IncomePerCreditLine                    279.287273  51.460337   \n",
       "AgeRisk                                  3.000000   1.016414   \n",
       "DelinquencyBucket                        3.000000  -1.617601   \n",
       "UtilizationBucketLateBucket              5.000000  -0.390001   \n",
       "WasDelinquencyScoreImputed               0.000000   0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000   0.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000   0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      1.000000  12.779086   \n",
       "WasUtilizationPerAgeImputed              1.000000   3.946574   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000   0.000000   \n",
       "WasIncomePerCreditLineImputed            1.000000  12.779086   \n",
       "WasAgeRiskImputed                        0.000000   0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000   0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000   0.000000   \n",
       "\n",
       "                                       corr_with_target  high_corr_flag  \\\n",
       "DelinquencyScore                               0.000600           False   \n",
       "HasAnyDelinquency                              0.000600           False   \n",
       "HasMajorDelinquency                                 NaN           False   \n",
       "LatePaymentsPerCreditLine                      0.000219           False   \n",
       "UtilizationPerAge                             -0.000117           False   \n",
       "DebtToIncomeAgeRisk                           -0.001893           False   \n",
       "IncomePerCreditLine                           -0.003929           False   \n",
       "AgeRisk                                        0.001934           False   \n",
       "DelinquencyBucket                             -0.000600           False   \n",
       "UtilizationBucketLateBucket                   -0.007608           False   \n",
       "WasDelinquencyScoreImputed                          NaN           False   \n",
       "WasHasAnyDelinquencyImputed                         NaN           False   \n",
       "WasHasMajorDelinquencyImputed                       NaN           False   \n",
       "WasLatePaymentsPerCreditLineImputed           -0.003527            True   \n",
       "WasUtilizationPerAgeImputed                   -0.006431           False   \n",
       "WasDebtToIncomeAgeRiskImputed                       NaN           False   \n",
       "WasIncomePerCreditLineImputed                 -0.003527            True   \n",
       "WasAgeRiskImputed                                   NaN           False   \n",
       "WasDelinquencyBucketImputed                         NaN           False   \n",
       "WasUtilizationBucketLateBucketImputed               NaN           False   \n",
       "\n",
       "                                                                   high_corr_with  \n",
       "DelinquencyScore                                                                   \n",
       "HasAnyDelinquency                                                                  \n",
       "HasMajorDelinquency                                                                \n",
       "LatePaymentsPerCreditLine                                                          \n",
       "UtilizationPerAge                                                                  \n",
       "DebtToIncomeAgeRisk                                                                \n",
       "IncomePerCreditLine                                                                \n",
       "AgeRisk                                                                            \n",
       "DelinquencyBucket                                                                  \n",
       "UtilizationBucketLateBucket                                                        \n",
       "WasDelinquencyScoreImputed                                                         \n",
       "WasHasAnyDelinquencyImputed                                                        \n",
       "WasHasMajorDelinquencyImputed                                                      \n",
       "WasLatePaymentsPerCreditLineImputed          WasIncomePerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerAgeImputed                                                        \n",
       "WasDebtToIncomeAgeRiskImputed                                                      \n",
       "WasIncomePerCreditLineImputed          WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasAgeRiskImputed                                                                  \n",
       "WasDelinquencyBucketImputed                                                        \n",
       "WasUtilizationBucketLateBucketImputed                                              "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols \n",
    "zero_importance_cols = [\n",
    "    \"WasHasAnyDelinquencyImputed\", \n",
    "    \"WasUtilizationPerAgeImputed\", \n",
    "    \"WasHasMajorDelinquencyImputed\", \n",
    "    \"WasDebtToIncomeAgeRiskImputed\", \n",
    "    \"WasDelinquencyBucketImputed\", \n",
    "    \"WasUtilizationBucketLateBucketImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val   = X_val.drop(columns=zero_importance_cols)\n",
    "X_test  = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags   = flags_to_keep\n",
    "X_test_flags  = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 and int64\n",
    "X_train_num = X_train[num_col_order + X_train_flags].astype('float32').values\n",
    "X_val_num   = X_val[num_col_order + X_val_flags].astype('float32').values\n",
    "X_test_num  = X_test[num_col_order + X_test_flags].astype('float32').values\n",
    "\n",
    "X_train_cat = X_train[cat_col_order].astype('int64').values\n",
    "X_val_cat   = X_val[cat_col_order].astype('int64').values\n",
    "X_test_cat  = X_test[cat_col_order].astype('int64').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric input shape: torch.Size([92293, 12])\n",
      "Categorical input shape: torch.Size([92293, 2])\n",
      "Class weights: {np.int64(0): np.float64(0.5355721133201026), np.int64(1): np.float64(7.527977161500815)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_train_num_tensor = torch.tensor(X_train_num)\n",
    "X_val_num_tensor = torch.tensor(X_val_num)\n",
    "X_test_num_tensor = torch.tensor(X_test_num)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat)\n",
    "X_val_cat_tensor = torch.tensor(X_val_cat)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "print(\"Numeric input shape:\", X_train_num_tensor.shape)\n",
    "print(\"Categorical input shape:\", X_train_cat_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92293, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num, x_cat, y):\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor)\n",
    "val_ds = TabularDataset(X_val_num_tensor, X_val_cat_tensor, y_val_tensor)\n",
    "test_ds = TabularDataset(X_test_num_tensor, X_test_cat_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(6, 3)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bn_num): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=17, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (cat_skip): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 48435\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim)\n",
    "            for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)\n",
    "        ])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "    \n",
    "        x_cat_emb = torch.cat([\n",
    "            emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)\n",
    "        ], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "\n",
    "        x_num = self.bn_num(x_num)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "cat_dims = [len(cat_maps[col]) for col in cat_col_order]\n",
    "emb_dims = [min(50, (cat_dim + 1) // 2) for cat_dim in cat_dims]\n",
    "\n",
    "model = NN(X_train_num.shape[1], cat_dims, emb_dims).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.049955 | Train AUC: 0.8294 | Val loss: 0.047948 | Val AUC: 0.8525\n",
      "Epoch 2/75 | Train loss: 0.047412 | Train AUC: 0.8474 | Val loss: 0.049059 | Val AUC: 0.8491\n",
      "Epoch 3/75 | Train loss: 0.047231 | Train AUC: 0.8491 | Val loss: 0.048248 | Val AUC: 0.8433\n",
      "Epoch 4/75 | Train loss: 0.046908 | Train AUC: 0.8509 | Val loss: 0.048140 | Val AUC: 0.8523\n",
      "Epoch 5/75 | Train loss: 0.046822 | Train AUC: 0.8522 | Val loss: 0.048042 | Val AUC: 0.8520\n",
      "Epoch 6/75 | Train loss: 0.046827 | Train AUC: 0.8520 | Val loss: 0.048781 | Val AUC: 0.8465\n",
      "Epoch 7/75 | Train loss: 0.046684 | Train AUC: 0.8536 | Val loss: 0.049433 | Val AUC: 0.8533\n",
      "Epoch 8/75 | Train loss: 0.046552 | Train AUC: 0.8546 | Val loss: 0.047607 | Val AUC: 0.8512\n",
      "Epoch 9/75 | Train loss: 0.046473 | Train AUC: 0.8556 | Val loss: 0.047643 | Val AUC: 0.8530\n",
      "Epoch 10/75 | Train loss: 0.046518 | Train AUC: 0.8548 | Val loss: 0.047486 | Val AUC: 0.8547\n",
      "Epoch 11/75 | Train loss: 0.046492 | Train AUC: 0.8551 | Val loss: 0.047257 | Val AUC: 0.8545\n",
      "Epoch 12/75 | Train loss: 0.046487 | Train AUC: 0.8545 | Val loss: 0.047444 | Val AUC: 0.8526\n",
      "Epoch 13/75 | Train loss: 0.046418 | Train AUC: 0.8551 | Val loss: 0.047784 | Val AUC: 0.8496\n",
      "Epoch 14/75 | Train loss: 0.046318 | Train AUC: 0.8562 | Val loss: 0.047973 | Val AUC: 0.8504\n",
      "Epoch 15/75 | Train loss: 0.046229 | Train AUC: 0.8570 | Val loss: 0.047996 | Val AUC: 0.8531\n",
      "Epoch 16/75 | Train loss: 0.046164 | Train AUC: 0.8576 | Val loss: 0.048460 | Val AUC: 0.8540\n",
      "Epoch 17/75 | Train loss: 0.046017 | Train AUC: 0.8594 | Val loss: 0.047253 | Val AUC: 0.8556\n",
      "Epoch 18/75 | Train loss: 0.046120 | Train AUC: 0.8585 | Val loss: 0.047133 | Val AUC: 0.8550\n",
      "Epoch 19/75 | Train loss: 0.046038 | Train AUC: 0.8587 | Val loss: 0.047118 | Val AUC: 0.8551\n",
      "Epoch 20/75 | Train loss: 0.046142 | Train AUC: 0.8574 | Val loss: 0.046878 | Val AUC: 0.8561\n",
      "Epoch 21/75 | Train loss: 0.046057 | Train AUC: 0.8586 | Val loss: 0.047682 | Val AUC: 0.8483\n",
      "Epoch 22/75 | Train loss: 0.046032 | Train AUC: 0.8589 | Val loss: 0.047709 | Val AUC: 0.8554\n",
      "Epoch 23/75 | Train loss: 0.045907 | Train AUC: 0.8598 | Val loss: 0.047248 | Val AUC: 0.8540\n",
      "Epoch 24/75 | Train loss: 0.046036 | Train AUC: 0.8586 | Val loss: 0.048502 | Val AUC: 0.8515\n",
      "Epoch 25/75 | Train loss: 0.045929 | Train AUC: 0.8594 | Val loss: 0.047538 | Val AUC: 0.8535\n",
      "Epoch 26/75 | Train loss: 0.045957 | Train AUC: 0.8596 | Val loss: 0.047065 | Val AUC: 0.8529\n",
      "Epoch 27/75 | Train loss: 0.045934 | Train AUC: 0.8591 | Val loss: 0.047168 | Val AUC: 0.8529\n",
      "Epoch 28/75 | Train loss: 0.045708 | Train AUC: 0.8615 | Val loss: 0.047815 | Val AUC: 0.8503\n",
      "Epoch 29/75 | Train loss: 0.045758 | Train AUC: 0.8608 | Val loss: 0.047795 | Val AUC: 0.8517\n",
      "Epoch 30/75 | Train loss: 0.045779 | Train AUC: 0.8607 | Val loss: 0.047196 | Val AUC: 0.8540\n",
      "Epoch 31/75 | Train loss: 0.045734 | Train AUC: 0.8612 | Val loss: 0.047207 | Val AUC: 0.8526\n",
      "Epoch 32/75 | Train loss: 0.045744 | Train AUC: 0.8611 | Val loss: 0.046840 | Val AUC: 0.8565\n",
      "Epoch 33/75 | Train loss: 0.045721 | Train AUC: 0.8608 | Val loss: 0.047506 | Val AUC: 0.8527\n",
      "Epoch 34/75 | Train loss: 0.045708 | Train AUC: 0.8616 | Val loss: 0.047216 | Val AUC: 0.8539\n",
      "Epoch 35/75 | Train loss: 0.045740 | Train AUC: 0.8609 | Val loss: 0.046991 | Val AUC: 0.8536\n",
      "Epoch 36/75 | Train loss: 0.045633 | Train AUC: 0.8620 | Val loss: 0.047024 | Val AUC: 0.8544\n",
      "Epoch 37/75 | Train loss: 0.045729 | Train AUC: 0.8611 | Val loss: 0.047098 | Val AUC: 0.8542\n",
      "Epoch 38/75 | Train loss: 0.045722 | Train AUC: 0.8610 | Val loss: 0.047239 | Val AUC: 0.8523\n",
      "Epoch 39/75 | Train loss: 0.045730 | Train AUC: 0.8610 | Val loss: 0.047161 | Val AUC: 0.8532\n",
      "Epoch 40/75 | Train loss: 0.045730 | Train AUC: 0.8609 | Val loss: 0.047117 | Val AUC: 0.8531\n",
      "Epoch 41/75 | Train loss: 0.045516 | Train AUC: 0.8630 | Val loss: 0.047277 | Val AUC: 0.8511\n",
      "Epoch 42/75 | Train loss: 0.045628 | Train AUC: 0.8625 | Val loss: 0.046911 | Val AUC: 0.8542\n",
      "Epoch 43/75 | Train loss: 0.045641 | Train AUC: 0.8615 | Val loss: 0.047312 | Val AUC: 0.8533\n",
      "Epoch 44/75 | Train loss: 0.045686 | Train AUC: 0.8615 | Val loss: 0.046937 | Val AUC: 0.8558\n",
      "Early stopping at epoch 45\n",
      "Run 1 best Val AUC: 0.8565\n",
      "\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.045935 | Train AUC: 0.8596 | Val loss: 0.047965 | Val AUC: 0.8555\n",
      "Epoch 2/75 | Train loss: 0.046143 | Train AUC: 0.8578 | Val loss: 0.047592 | Val AUC: 0.8521\n",
      "Epoch 3/75 | Train loss: 0.046039 | Train AUC: 0.8580 | Val loss: 0.047598 | Val AUC: 0.8489\n",
      "Epoch 4/75 | Train loss: 0.046049 | Train AUC: 0.8585 | Val loss: 0.047437 | Val AUC: 0.8532\n",
      "Epoch 5/75 | Train loss: 0.046029 | Train AUC: 0.8592 | Val loss: 0.047115 | Val AUC: 0.8540\n",
      "Epoch 6/75 | Train loss: 0.046094 | Train AUC: 0.8576 | Val loss: 0.047459 | Val AUC: 0.8526\n",
      "Epoch 7/75 | Train loss: 0.046028 | Train AUC: 0.8589 | Val loss: 0.047120 | Val AUC: 0.8539\n",
      "Epoch 8/75 | Train loss: 0.045814 | Train AUC: 0.8604 | Val loss: 0.047174 | Val AUC: 0.8535\n",
      "Epoch 9/75 | Train loss: 0.045730 | Train AUC: 0.8609 | Val loss: 0.047267 | Val AUC: 0.8535\n",
      "Epoch 10/75 | Train loss: 0.045824 | Train AUC: 0.8606 | Val loss: 0.047043 | Val AUC: 0.8520\n",
      "Epoch 11/75 | Train loss: 0.045644 | Train AUC: 0.8616 | Val loss: 0.047123 | Val AUC: 0.8560\n",
      "Epoch 12/75 | Train loss: 0.045734 | Train AUC: 0.8608 | Val loss: 0.047031 | Val AUC: 0.8560\n",
      "Epoch 13/75 | Train loss: 0.045642 | Train AUC: 0.8619 | Val loss: 0.047458 | Val AUC: 0.8510\n",
      "Epoch 14/75 | Train loss: 0.045730 | Train AUC: 0.8610 | Val loss: 0.047367 | Val AUC: 0.8547\n",
      "Epoch 15/75 | Train loss: 0.045732 | Train AUC: 0.8611 | Val loss: 0.047322 | Val AUC: 0.8531\n",
      "Epoch 16/75 | Train loss: 0.045692 | Train AUC: 0.8612 | Val loss: 0.047248 | Val AUC: 0.8533\n",
      "Epoch 17/75 | Train loss: 0.045749 | Train AUC: 0.8610 | Val loss: 0.046938 | Val AUC: 0.8551\n",
      "Epoch 18/75 | Train loss: 0.045738 | Train AUC: 0.8610 | Val loss: 0.047096 | Val AUC: 0.8522\n",
      "Epoch 19/75 | Train loss: 0.045478 | Train AUC: 0.8631 | Val loss: 0.047523 | Val AUC: 0.8523\n",
      "Epoch 20/75 | Train loss: 0.045569 | Train AUC: 0.8623 | Val loss: 0.046883 | Val AUC: 0.8525\n",
      "Epoch 21/75 | Train loss: 0.045553 | Train AUC: 0.8626 | Val loss: 0.047008 | Val AUC: 0.8522\n",
      "Epoch 22/75 | Train loss: 0.045496 | Train AUC: 0.8630 | Val loss: 0.046782 | Val AUC: 0.8544\n",
      "Epoch 23/75 | Train loss: 0.045574 | Train AUC: 0.8623 | Val loss: 0.047303 | Val AUC: 0.8525\n",
      "Epoch 24/75 | Train loss: 0.045595 | Train AUC: 0.8619 | Val loss: 0.046917 | Val AUC: 0.8533\n",
      "Early stopping at epoch 25\n",
      "Run 2 best Val AUC: 0.8560\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8565)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_num, x_cat, yb in train_loader:\n",
    "            x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_num, x_cat)  \n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_num.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_num, x_cat, yb in val_loader:\n",
    "                x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "                logits = model(x_num, x_cat)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_num.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "\n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.28167942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.81      0.89     27868\n",
      "   Defaulted       0.22      0.76      0.34      1978\n",
      "\n",
      "    accuracy                           0.80     29846\n",
      "   macro avg       0.60      0.78      0.61     29846\n",
      "weighted avg       0.93      0.80      0.85     29846\n",
      "\n",
      "Accuracy: 80.43%\n",
      "ROC AUC: 0.859\n",
      "TP=1498, FP=5361, TN=22507, FN=480\n",
      "Accuracy for class 'Repaid': 80.76%\n",
      "Accuracy for class 'Defaulted': 75.73%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in val_loader:  \n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_val, y_val_probs, thresholds, beta=2.3)\n",
    "best_thresh_a = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdba09d8-8307-4ade-b197-9eb639de9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.11190864600326, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.11190864600326, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.11190864600326, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.05595432300163, subsample=0.6; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.05595432300163, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.05595432300163, subsample=0.6; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.13988580750408, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.13988580750408, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.13988580750408, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.11190864600326, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.11190864600326, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.11190864600326, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.05595432300163, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.167862969004894, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.167862969004894, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.11190864600326, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.05595432300163, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.083931484502447, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.13988580750408, subsample=0.9; total time=   0.6s\n",
      "Best params: {'subsample': 0.9, 'scale_pos_weight': np.float64(14.05595432300163), 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84229\n",
      "[1]\tvalidation_0-auc:0.84898\n",
      "[2]\tvalidation_0-auc:0.85050\n",
      "[3]\tvalidation_0-auc:0.85075\n",
      "[4]\tvalidation_0-auc:0.85116\n",
      "[5]\tvalidation_0-auc:0.85110\n",
      "[6]\tvalidation_0-auc:0.85089\n",
      "[7]\tvalidation_0-auc:0.85101\n",
      "[8]\tvalidation_0-auc:0.85110\n",
      "[9]\tvalidation_0-auc:0.85133\n",
      "[10]\tvalidation_0-auc:0.85162\n",
      "[11]\tvalidation_0-auc:0.85210\n",
      "[12]\tvalidation_0-auc:0.85224\n",
      "[13]\tvalidation_0-auc:0.85200\n",
      "[14]\tvalidation_0-auc:0.85202\n",
      "[15]\tvalidation_0-auc:0.85192\n",
      "[16]\tvalidation_0-auc:0.85212\n",
      "[17]\tvalidation_0-auc:0.85213\n",
      "[18]\tvalidation_0-auc:0.85216\n",
      "[19]\tvalidation_0-auc:0.85221\n",
      "[20]\tvalidation_0-auc:0.85221\n",
      "[21]\tvalidation_0-auc:0.85235\n",
      "[22]\tvalidation_0-auc:0.85249\n",
      "[23]\tvalidation_0-auc:0.85253\n",
      "[24]\tvalidation_0-auc:0.85248\n",
      "[25]\tvalidation_0-auc:0.85237\n",
      "[26]\tvalidation_0-auc:0.85255\n",
      "[27]\tvalidation_0-auc:0.85261\n",
      "[28]\tvalidation_0-auc:0.85230\n",
      "[29]\tvalidation_0-auc:0.85237\n",
      "[30]\tvalidation_0-auc:0.85228\n",
      "[31]\tvalidation_0-auc:0.85220\n",
      "[32]\tvalidation_0-auc:0.85230\n",
      "[33]\tvalidation_0-auc:0.85238\n",
      "[34]\tvalidation_0-auc:0.85230\n",
      "[35]\tvalidation_0-auc:0.85235\n",
      "[36]\tvalidation_0-auc:0.85235\n",
      "[37]\tvalidation_0-auc:0.85237\n",
      "[38]\tvalidation_0-auc:0.85230\n",
      "[39]\tvalidation_0-auc:0.85239\n",
      "[40]\tvalidation_0-auc:0.85236\n",
      "[41]\tvalidation_0-auc:0.85237\n",
      "[42]\tvalidation_0-auc:0.85260\n",
      "[43]\tvalidation_0-auc:0.85262\n",
      "[44]\tvalidation_0-auc:0.85267\n",
      "[45]\tvalidation_0-auc:0.85272\n",
      "[46]\tvalidation_0-auc:0.85278\n",
      "[47]\tvalidation_0-auc:0.85274\n",
      "[48]\tvalidation_0-auc:0.85275\n",
      "[49]\tvalidation_0-auc:0.85274\n",
      "[50]\tvalidation_0-auc:0.85278\n",
      "[51]\tvalidation_0-auc:0.85287\n",
      "[52]\tvalidation_0-auc:0.85287\n",
      "[53]\tvalidation_0-auc:0.85288\n",
      "[54]\tvalidation_0-auc:0.85287\n",
      "[55]\tvalidation_0-auc:0.85285\n",
      "[56]\tvalidation_0-auc:0.85285\n",
      "[57]\tvalidation_0-auc:0.85287\n",
      "[58]\tvalidation_0-auc:0.85290\n",
      "[59]\tvalidation_0-auc:0.85292\n",
      "[60]\tvalidation_0-auc:0.85291\n",
      "[61]\tvalidation_0-auc:0.85292\n",
      "[62]\tvalidation_0-auc:0.85294\n",
      "[63]\tvalidation_0-auc:0.85294\n",
      "[64]\tvalidation_0-auc:0.85299\n",
      "[65]\tvalidation_0-auc:0.85299\n",
      "[66]\tvalidation_0-auc:0.85304\n",
      "[67]\tvalidation_0-auc:0.85298\n",
      "[68]\tvalidation_0-auc:0.85292\n",
      "[69]\tvalidation_0-auc:0.85291\n",
      "[70]\tvalidation_0-auc:0.85291\n",
      "[71]\tvalidation_0-auc:0.85291\n",
      "[72]\tvalidation_0-auc:0.85294\n",
      "[73]\tvalidation_0-auc:0.85293\n",
      "[74]\tvalidation_0-auc:0.85293\n",
      "[75]\tvalidation_0-auc:0.85292\n",
      "[76]\tvalidation_0-auc:0.85293\n",
      "[77]\tvalidation_0-auc:0.85296\n",
      "[78]\tvalidation_0-auc:0.85294\n",
      "[79]\tvalidation_0-auc:0.85302\n",
      "[80]\tvalidation_0-auc:0.85300\n",
      "[81]\tvalidation_0-auc:0.85296\n",
      "[82]\tvalidation_0-auc:0.85294\n",
      "[83]\tvalidation_0-auc:0.85302\n",
      "[84]\tvalidation_0-auc:0.85301\n",
      "[85]\tvalidation_0-auc:0.85302\n",
      "[86]\tvalidation_0-auc:0.85300\n",
      "[87]\tvalidation_0-auc:0.85299\n",
      "[88]\tvalidation_0-auc:0.85305\n",
      "[89]\tvalidation_0-auc:0.85303\n",
      "[90]\tvalidation_0-auc:0.85303\n",
      "[91]\tvalidation_0-auc:0.85305\n",
      "[92]\tvalidation_0-auc:0.85307\n",
      "[93]\tvalidation_0-auc:0.85312\n",
      "[94]\tvalidation_0-auc:0.85310\n",
      "[95]\tvalidation_0-auc:0.85311\n",
      "[96]\tvalidation_0-auc:0.85310\n",
      "[97]\tvalidation_0-auc:0.85309\n",
      "[98]\tvalidation_0-auc:0.85307\n",
      "[99]\tvalidation_0-auc:0.85311\n",
      "[100]\tvalidation_0-auc:0.85309\n",
      "[101]\tvalidation_0-auc:0.85316\n",
      "[102]\tvalidation_0-auc:0.85318\n",
      "[103]\tvalidation_0-auc:0.85321\n",
      "[104]\tvalidation_0-auc:0.85330\n",
      "[105]\tvalidation_0-auc:0.85331\n",
      "[106]\tvalidation_0-auc:0.85334\n",
      "[107]\tvalidation_0-auc:0.85330\n",
      "[108]\tvalidation_0-auc:0.85332\n",
      "[109]\tvalidation_0-auc:0.85329\n",
      "[110]\tvalidation_0-auc:0.85332\n",
      "[111]\tvalidation_0-auc:0.85332\n",
      "[112]\tvalidation_0-auc:0.85334\n",
      "[113]\tvalidation_0-auc:0.85334\n",
      "[114]\tvalidation_0-auc:0.85336\n",
      "[115]\tvalidation_0-auc:0.85337\n",
      "[116]\tvalidation_0-auc:0.85341\n",
      "[117]\tvalidation_0-auc:0.85341\n",
      "[118]\tvalidation_0-auc:0.85335\n",
      "[119]\tvalidation_0-auc:0.85333\n",
      "[120]\tvalidation_0-auc:0.85330\n",
      "[121]\tvalidation_0-auc:0.85331\n",
      "[122]\tvalidation_0-auc:0.85330\n",
      "[123]\tvalidation_0-auc:0.85329\n",
      "[124]\tvalidation_0-auc:0.85328\n",
      "[125]\tvalidation_0-auc:0.85333\n",
      "[126]\tvalidation_0-auc:0.85335\n",
      "[127]\tvalidation_0-auc:0.85347\n",
      "[128]\tvalidation_0-auc:0.85345\n",
      "[129]\tvalidation_0-auc:0.85343\n",
      "[130]\tvalidation_0-auc:0.85344\n",
      "[131]\tvalidation_0-auc:0.85343\n",
      "[132]\tvalidation_0-auc:0.85347\n",
      "[133]\tvalidation_0-auc:0.85348\n",
      "[134]\tvalidation_0-auc:0.85350\n",
      "[135]\tvalidation_0-auc:0.85347\n",
      "[136]\tvalidation_0-auc:0.85354\n",
      "[137]\tvalidation_0-auc:0.85355\n",
      "[138]\tvalidation_0-auc:0.85359\n",
      "[139]\tvalidation_0-auc:0.85361\n",
      "[140]\tvalidation_0-auc:0.85361\n",
      "[141]\tvalidation_0-auc:0.85362\n",
      "[142]\tvalidation_0-auc:0.85363\n",
      "[143]\tvalidation_0-auc:0.85357\n",
      "[144]\tvalidation_0-auc:0.85357\n",
      "[145]\tvalidation_0-auc:0.85364\n",
      "[146]\tvalidation_0-auc:0.85364\n",
      "[147]\tvalidation_0-auc:0.85369\n",
      "[148]\tvalidation_0-auc:0.85372\n",
      "[149]\tvalidation_0-auc:0.85376\n",
      "[150]\tvalidation_0-auc:0.85378\n",
      "[151]\tvalidation_0-auc:0.85381\n",
      "[152]\tvalidation_0-auc:0.85380\n",
      "[153]\tvalidation_0-auc:0.85380\n",
      "[154]\tvalidation_0-auc:0.85382\n",
      "[155]\tvalidation_0-auc:0.85385\n",
      "[156]\tvalidation_0-auc:0.85387\n",
      "[157]\tvalidation_0-auc:0.85389\n",
      "[158]\tvalidation_0-auc:0.85388\n",
      "[159]\tvalidation_0-auc:0.85391\n",
      "[160]\tvalidation_0-auc:0.85396\n",
      "[161]\tvalidation_0-auc:0.85398\n",
      "[162]\tvalidation_0-auc:0.85400\n",
      "[163]\tvalidation_0-auc:0.85402\n",
      "[164]\tvalidation_0-auc:0.85405\n",
      "[165]\tvalidation_0-auc:0.85408\n",
      "[166]\tvalidation_0-auc:0.85411\n",
      "[167]\tvalidation_0-auc:0.85410\n",
      "[168]\tvalidation_0-auc:0.85412\n",
      "[169]\tvalidation_0-auc:0.85415\n",
      "[170]\tvalidation_0-auc:0.85416\n",
      "[171]\tvalidation_0-auc:0.85424\n",
      "[172]\tvalidation_0-auc:0.85425\n",
      "[173]\tvalidation_0-auc:0.85425\n",
      "[174]\tvalidation_0-auc:0.85428\n",
      "[175]\tvalidation_0-auc:0.85425\n",
      "[176]\tvalidation_0-auc:0.85424\n",
      "[177]\tvalidation_0-auc:0.85422\n",
      "[178]\tvalidation_0-auc:0.85424\n",
      "[179]\tvalidation_0-auc:0.85427\n",
      "[180]\tvalidation_0-auc:0.85430\n",
      "[181]\tvalidation_0-auc:0.85437\n",
      "[182]\tvalidation_0-auc:0.85437\n",
      "[183]\tvalidation_0-auc:0.85438\n",
      "[184]\tvalidation_0-auc:0.85438\n",
      "[185]\tvalidation_0-auc:0.85437\n",
      "[186]\tvalidation_0-auc:0.85439\n",
      "[187]\tvalidation_0-auc:0.85441\n",
      "[188]\tvalidation_0-auc:0.85441\n",
      "[189]\tvalidation_0-auc:0.85443\n",
      "[190]\tvalidation_0-auc:0.85444\n",
      "[191]\tvalidation_0-auc:0.85445\n",
      "[192]\tvalidation_0-auc:0.85450\n",
      "[193]\tvalidation_0-auc:0.85449\n",
      "[194]\tvalidation_0-auc:0.85450\n",
      "[195]\tvalidation_0-auc:0.85451\n",
      "[196]\tvalidation_0-auc:0.85450\n",
      "[197]\tvalidation_0-auc:0.85452\n",
      "[198]\tvalidation_0-auc:0.85454\n",
      "[199]\tvalidation_0-auc:0.85456\n",
      "[200]\tvalidation_0-auc:0.85457\n",
      "[201]\tvalidation_0-auc:0.85458\n",
      "[202]\tvalidation_0-auc:0.85459\n",
      "[203]\tvalidation_0-auc:0.85463\n",
      "[204]\tvalidation_0-auc:0.85465\n",
      "[205]\tvalidation_0-auc:0.85465\n",
      "[206]\tvalidation_0-auc:0.85466\n",
      "[207]\tvalidation_0-auc:0.85466\n",
      "[208]\tvalidation_0-auc:0.85468\n",
      "[209]\tvalidation_0-auc:0.85471\n",
      "[210]\tvalidation_0-auc:0.85474\n",
      "[211]\tvalidation_0-auc:0.85475\n",
      "[212]\tvalidation_0-auc:0.85475\n",
      "[213]\tvalidation_0-auc:0.85475\n",
      "[214]\tvalidation_0-auc:0.85477\n",
      "[215]\tvalidation_0-auc:0.85476\n",
      "[216]\tvalidation_0-auc:0.85475\n",
      "[217]\tvalidation_0-auc:0.85477\n",
      "[218]\tvalidation_0-auc:0.85477\n",
      "[219]\tvalidation_0-auc:0.85477\n",
      "[220]\tvalidation_0-auc:0.85477\n",
      "[221]\tvalidation_0-auc:0.85478\n",
      "[222]\tvalidation_0-auc:0.85480\n",
      "[223]\tvalidation_0-auc:0.85483\n",
      "[224]\tvalidation_0-auc:0.85485\n",
      "[225]\tvalidation_0-auc:0.85484\n",
      "[226]\tvalidation_0-auc:0.85486\n",
      "[227]\tvalidation_0-auc:0.85487\n",
      "[228]\tvalidation_0-auc:0.85487\n",
      "[229]\tvalidation_0-auc:0.85489\n",
      "[230]\tvalidation_0-auc:0.85489\n",
      "[231]\tvalidation_0-auc:0.85490\n",
      "[232]\tvalidation_0-auc:0.85488\n",
      "[233]\tvalidation_0-auc:0.85486\n",
      "[234]\tvalidation_0-auc:0.85486\n",
      "[235]\tvalidation_0-auc:0.85488\n",
      "[236]\tvalidation_0-auc:0.85489\n",
      "[237]\tvalidation_0-auc:0.85489\n",
      "[238]\tvalidation_0-auc:0.85492\n",
      "[239]\tvalidation_0-auc:0.85492\n",
      "[240]\tvalidation_0-auc:0.85494\n",
      "[241]\tvalidation_0-auc:0.85495\n",
      "[242]\tvalidation_0-auc:0.85497\n",
      "[243]\tvalidation_0-auc:0.85498\n",
      "[244]\tvalidation_0-auc:0.85501\n",
      "[245]\tvalidation_0-auc:0.85503\n",
      "[246]\tvalidation_0-auc:0.85503\n",
      "[247]\tvalidation_0-auc:0.85502\n",
      "[248]\tvalidation_0-auc:0.85504\n",
      "[249]\tvalidation_0-auc:0.85506\n",
      "[250]\tvalidation_0-auc:0.85506\n",
      "[251]\tvalidation_0-auc:0.85505\n",
      "[252]\tvalidation_0-auc:0.85506\n",
      "[253]\tvalidation_0-auc:0.85507\n",
      "[254]\tvalidation_0-auc:0.85511\n",
      "[255]\tvalidation_0-auc:0.85511\n",
      "[256]\tvalidation_0-auc:0.85512\n",
      "[257]\tvalidation_0-auc:0.85513\n",
      "[258]\tvalidation_0-auc:0.85514\n",
      "[259]\tvalidation_0-auc:0.85513\n",
      "[260]\tvalidation_0-auc:0.85513\n",
      "[261]\tvalidation_0-auc:0.85513\n",
      "[262]\tvalidation_0-auc:0.85516\n",
      "[263]\tvalidation_0-auc:0.85517\n",
      "[264]\tvalidation_0-auc:0.85517\n",
      "[265]\tvalidation_0-auc:0.85518\n",
      "[266]\tvalidation_0-auc:0.85518\n",
      "[267]\tvalidation_0-auc:0.85518\n",
      "[268]\tvalidation_0-auc:0.85518\n",
      "[269]\tvalidation_0-auc:0.85520\n",
      "[270]\tvalidation_0-auc:0.85521\n",
      "[271]\tvalidation_0-auc:0.85521\n",
      "[272]\tvalidation_0-auc:0.85524\n",
      "[273]\tvalidation_0-auc:0.85523\n",
      "[274]\tvalidation_0-auc:0.85523\n",
      "[275]\tvalidation_0-auc:0.85523\n",
      "[276]\tvalidation_0-auc:0.85524\n",
      "[277]\tvalidation_0-auc:0.85524\n",
      "[278]\tvalidation_0-auc:0.85527\n",
      "[279]\tvalidation_0-auc:0.85528\n",
      "[280]\tvalidation_0-auc:0.85530\n",
      "[281]\tvalidation_0-auc:0.85529\n",
      "[282]\tvalidation_0-auc:0.85530\n",
      "[283]\tvalidation_0-auc:0.85529\n",
      "[284]\tvalidation_0-auc:0.85530\n",
      "[285]\tvalidation_0-auc:0.85531\n",
      "[286]\tvalidation_0-auc:0.85529\n",
      "[287]\tvalidation_0-auc:0.85531\n",
      "[288]\tvalidation_0-auc:0.85531\n",
      "[289]\tvalidation_0-auc:0.85531\n",
      "[290]\tvalidation_0-auc:0.85533\n",
      "[291]\tvalidation_0-auc:0.85534\n",
      "[292]\tvalidation_0-auc:0.85535\n",
      "[293]\tvalidation_0-auc:0.85534\n",
      "[294]\tvalidation_0-auc:0.85534\n",
      "[295]\tvalidation_0-auc:0.85535\n",
      "[296]\tvalidation_0-auc:0.85539\n",
      "[297]\tvalidation_0-auc:0.85539\n",
      "[298]\tvalidation_0-auc:0.85541\n",
      "[299]\tvalidation_0-auc:0.85542\n",
      "[300]\tvalidation_0-auc:0.85542\n",
      "[301]\tvalidation_0-auc:0.85543\n",
      "[302]\tvalidation_0-auc:0.85543\n",
      "[303]\tvalidation_0-auc:0.85542\n",
      "[304]\tvalidation_0-auc:0.85544\n",
      "[305]\tvalidation_0-auc:0.85544\n",
      "[306]\tvalidation_0-auc:0.85545\n",
      "[307]\tvalidation_0-auc:0.85546\n",
      "[308]\tvalidation_0-auc:0.85546\n",
      "[309]\tvalidation_0-auc:0.85545\n",
      "[310]\tvalidation_0-auc:0.85546\n",
      "[311]\tvalidation_0-auc:0.85546\n",
      "[312]\tvalidation_0-auc:0.85545\n",
      "[313]\tvalidation_0-auc:0.85545\n",
      "[314]\tvalidation_0-auc:0.85545\n",
      "[315]\tvalidation_0-auc:0.85547\n",
      "[316]\tvalidation_0-auc:0.85547\n",
      "[317]\tvalidation_0-auc:0.85550\n",
      "[318]\tvalidation_0-auc:0.85553\n",
      "[319]\tvalidation_0-auc:0.85553\n",
      "[320]\tvalidation_0-auc:0.85552\n",
      "[321]\tvalidation_0-auc:0.85553\n",
      "[322]\tvalidation_0-auc:0.85551\n",
      "[323]\tvalidation_0-auc:0.85550\n",
      "[324]\tvalidation_0-auc:0.85551\n",
      "[325]\tvalidation_0-auc:0.85552\n",
      "[326]\tvalidation_0-auc:0.85553\n",
      "[327]\tvalidation_0-auc:0.85553\n",
      "[328]\tvalidation_0-auc:0.85554\n",
      "[329]\tvalidation_0-auc:0.85553\n",
      "[330]\tvalidation_0-auc:0.85554\n",
      "[331]\tvalidation_0-auc:0.85554\n",
      "[332]\tvalidation_0-auc:0.85554\n",
      "[333]\tvalidation_0-auc:0.85557\n",
      "[334]\tvalidation_0-auc:0.85558\n",
      "[335]\tvalidation_0-auc:0.85559\n",
      "[336]\tvalidation_0-auc:0.85560\n",
      "[337]\tvalidation_0-auc:0.85560\n",
      "[338]\tvalidation_0-auc:0.85559\n",
      "[339]\tvalidation_0-auc:0.85560\n",
      "[340]\tvalidation_0-auc:0.85561\n",
      "[341]\tvalidation_0-auc:0.85561\n",
      "[342]\tvalidation_0-auc:0.85561\n",
      "[343]\tvalidation_0-auc:0.85561\n",
      "[344]\tvalidation_0-auc:0.85562\n",
      "[345]\tvalidation_0-auc:0.85561\n",
      "[346]\tvalidation_0-auc:0.85562\n",
      "[347]\tvalidation_0-auc:0.85563\n",
      "[348]\tvalidation_0-auc:0.85564\n",
      "[349]\tvalidation_0-auc:0.85565\n",
      "[350]\tvalidation_0-auc:0.85565\n",
      "[351]\tvalidation_0-auc:0.85566\n",
      "[352]\tvalidation_0-auc:0.85565\n",
      "[353]\tvalidation_0-auc:0.85563\n",
      "[354]\tvalidation_0-auc:0.85563\n",
      "[355]\tvalidation_0-auc:0.85563\n",
      "[356]\tvalidation_0-auc:0.85563\n",
      "[357]\tvalidation_0-auc:0.85561\n",
      "[358]\tvalidation_0-auc:0.85560\n",
      "[359]\tvalidation_0-auc:0.85560\n",
      "[360]\tvalidation_0-auc:0.85559\n",
      "[361]\tvalidation_0-auc:0.85558\n",
      "[362]\tvalidation_0-auc:0.85560\n",
      "[363]\tvalidation_0-auc:0.85559\n",
      "[364]\tvalidation_0-auc:0.85559\n",
      "[365]\tvalidation_0-auc:0.85559\n",
      "[366]\tvalidation_0-auc:0.85560\n",
      "[367]\tvalidation_0-auc:0.85562\n",
      "[368]\tvalidation_0-auc:0.85561\n",
      "[369]\tvalidation_0-auc:0.85562\n",
      "[370]\tvalidation_0-auc:0.85563\n",
      "[371]\tvalidation_0-auc:0.85563\n",
      "[372]\tvalidation_0-auc:0.85564\n",
      "[373]\tvalidation_0-auc:0.85565\n",
      "[374]\tvalidation_0-auc:0.85565\n",
      "[375]\tvalidation_0-auc:0.85565\n",
      "[376]\tvalidation_0-auc:0.85564\n",
      "[377]\tvalidation_0-auc:0.85565\n",
      "[378]\tvalidation_0-auc:0.85566\n",
      "[379]\tvalidation_0-auc:0.85567\n",
      "[380]\tvalidation_0-auc:0.85568\n",
      "[381]\tvalidation_0-auc:0.85568\n",
      "[382]\tvalidation_0-auc:0.85567\n",
      "[383]\tvalidation_0-auc:0.85566\n",
      "[384]\tvalidation_0-auc:0.85567\n",
      "[385]\tvalidation_0-auc:0.85567\n",
      "[386]\tvalidation_0-auc:0.85568\n",
      "[387]\tvalidation_0-auc:0.85568\n",
      "[388]\tvalidation_0-auc:0.85571\n",
      "[389]\tvalidation_0-auc:0.85573\n",
      "[390]\tvalidation_0-auc:0.85572\n",
      "[391]\tvalidation_0-auc:0.85573\n",
      "[392]\tvalidation_0-auc:0.85573\n",
      "[393]\tvalidation_0-auc:0.85573\n",
      "[394]\tvalidation_0-auc:0.85574\n",
      "[395]\tvalidation_0-auc:0.85574\n",
      "[396]\tvalidation_0-auc:0.85574\n",
      "[397]\tvalidation_0-auc:0.85572\n",
      "[398]\tvalidation_0-auc:0.85572\n",
      "[399]\tvalidation_0-auc:0.85572\n",
      "[400]\tvalidation_0-auc:0.85571\n",
      "[401]\tvalidation_0-auc:0.85571\n",
      "[402]\tvalidation_0-auc:0.85572\n",
      "[403]\tvalidation_0-auc:0.85575\n",
      "[404]\tvalidation_0-auc:0.85574\n",
      "[405]\tvalidation_0-auc:0.85573\n",
      "[406]\tvalidation_0-auc:0.85573\n",
      "[407]\tvalidation_0-auc:0.85573\n",
      "[408]\tvalidation_0-auc:0.85574\n",
      "[409]\tvalidation_0-auc:0.85574\n",
      "[410]\tvalidation_0-auc:0.85575\n",
      "[411]\tvalidation_0-auc:0.85575\n",
      "[412]\tvalidation_0-auc:0.85573\n",
      "[413]\tvalidation_0-auc:0.85573\n",
      "[414]\tvalidation_0-auc:0.85574\n",
      "[415]\tvalidation_0-auc:0.85575\n",
      "[416]\tvalidation_0-auc:0.85576\n",
      "[417]\tvalidation_0-auc:0.85573\n",
      "[418]\tvalidation_0-auc:0.85571\n",
      "[419]\tvalidation_0-auc:0.85568\n",
      "[420]\tvalidation_0-auc:0.85566\n",
      "[421]\tvalidation_0-auc:0.85567\n",
      "[422]\tvalidation_0-auc:0.85566\n",
      "[423]\tvalidation_0-auc:0.85567\n",
      "[424]\tvalidation_0-auc:0.85567\n",
      "[425]\tvalidation_0-auc:0.85567\n",
      "[426]\tvalidation_0-auc:0.85566\n",
      "[427]\tvalidation_0-auc:0.85565\n",
      "[428]\tvalidation_0-auc:0.85564\n",
      "[429]\tvalidation_0-auc:0.85564\n",
      "[430]\tvalidation_0-auc:0.85564\n",
      "[431]\tvalidation_0-auc:0.85565\n",
      "[432]\tvalidation_0-auc:0.85564\n",
      "[433]\tvalidation_0-auc:0.85564\n",
      "[434]\tvalidation_0-auc:0.85565\n",
      "[435]\tvalidation_0-auc:0.85565\n",
      "[436]\tvalidation_0-auc:0.85567\n",
      "[437]\tvalidation_0-auc:0.85567\n",
      "[438]\tvalidation_0-auc:0.85567\n",
      "[439]\tvalidation_0-auc:0.85567\n",
      "[440]\tvalidation_0-auc:0.85567\n",
      "[441]\tvalidation_0-auc:0.85567\n",
      "[442]\tvalidation_0-auc:0.85567\n",
      "[443]\tvalidation_0-auc:0.85568\n",
      "[444]\tvalidation_0-auc:0.85568\n",
      "[445]\tvalidation_0-auc:0.85567\n",
      "[446]\tvalidation_0-auc:0.85566\n",
      "[447]\tvalidation_0-auc:0.85566\n",
      "[448]\tvalidation_0-auc:0.85566\n",
      "[449]\tvalidation_0-auc:0.85567\n",
      "[450]\tvalidation_0-auc:0.85566\n",
      "[451]\tvalidation_0-auc:0.85567\n",
      "[452]\tvalidation_0-auc:0.85566\n",
      "[453]\tvalidation_0-auc:0.85565\n",
      "[454]\tvalidation_0-auc:0.85564\n",
      "[455]\tvalidation_0-auc:0.85565\n",
      "[456]\tvalidation_0-auc:0.85565\n",
      "[457]\tvalidation_0-auc:0.85566\n",
      "[458]\tvalidation_0-auc:0.85565\n",
      "[459]\tvalidation_0-auc:0.85566\n",
      "[460]\tvalidation_0-auc:0.85565\n",
      "[461]\tvalidation_0-auc:0.85565\n",
      "[462]\tvalidation_0-auc:0.85565\n",
      "[463]\tvalidation_0-auc:0.85568\n",
      "[464]\tvalidation_0-auc:0.85568\n",
      "[465]\tvalidation_0-auc:0.85567\n",
      "[466]\tvalidation_0-auc:0.85567\n",
      "[467]\tvalidation_0-auc:0.85567\n",
      "[468]\tvalidation_0-auc:0.85566\n",
      "[469]\tvalidation_0-auc:0.85566\n",
      "[470]\tvalidation_0-auc:0.85567\n",
      "[471]\tvalidation_0-auc:0.85568\n",
      "[472]\tvalidation_0-auc:0.85567\n",
      "[473]\tvalidation_0-auc:0.85565\n",
      "[474]\tvalidation_0-auc:0.85564\n",
      "[475]\tvalidation_0-auc:0.85564\n",
      "[476]\tvalidation_0-auc:0.85564\n",
      "[477]\tvalidation_0-auc:0.85563\n",
      "[478]\tvalidation_0-auc:0.85563\n",
      "[479]\tvalidation_0-auc:0.85562\n",
      "[480]\tvalidation_0-auc:0.85562\n",
      "[481]\tvalidation_0-auc:0.85562\n",
      "[482]\tvalidation_0-auc:0.85561\n",
      "[483]\tvalidation_0-auc:0.85562\n",
      "[484]\tvalidation_0-auc:0.85563\n",
      "[485]\tvalidation_0-auc:0.85563\n",
      "[486]\tvalidation_0-auc:0.85565\n",
      "[487]\tvalidation_0-auc:0.85565\n",
      "[488]\tvalidation_0-auc:0.85564\n",
      "[489]\tvalidation_0-auc:0.85564\n",
      "[490]\tvalidation_0-auc:0.85563\n",
      "[491]\tvalidation_0-auc:0.85562\n",
      "[492]\tvalidation_0-auc:0.85564\n",
      "[493]\tvalidation_0-auc:0.85564\n",
      "[494]\tvalidation_0-auc:0.85563\n",
      "[495]\tvalidation_0-auc:0.85563\n",
      "[496]\tvalidation_0-auc:0.85563\n",
      "[497]\tvalidation_0-auc:0.85563\n",
      "[498]\tvalidation_0-auc:0.85562\n",
      "[499]\tvalidation_0-auc:0.85561\n",
      "[500]\tvalidation_0-auc:0.85561\n",
      "[501]\tvalidation_0-auc:0.85561\n",
      "[502]\tvalidation_0-auc:0.85560\n",
      "[503]\tvalidation_0-auc:0.85560\n",
      "[504]\tvalidation_0-auc:0.85561\n",
      "[505]\tvalidation_0-auc:0.85562\n",
      "[506]\tvalidation_0-auc:0.85560\n",
      "[507]\tvalidation_0-auc:0.85560\n",
      "[508]\tvalidation_0-auc:0.85559\n",
      "[509]\tvalidation_0-auc:0.85560\n",
      "[510]\tvalidation_0-auc:0.85560\n",
      "[511]\tvalidation_0-auc:0.85559\n",
      "[512]\tvalidation_0-auc:0.85560\n",
      "[513]\tvalidation_0-auc:0.85562\n",
      "[514]\tvalidation_0-auc:0.85562\n",
      "[515]\tvalidation_0-auc:0.85562\n",
      "[516]\tvalidation_0-auc:0.85561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.05595432300163)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.5139487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.80      0.88     27868\n",
      "   Defaulted       0.21      0.76      0.33      1978\n",
      "\n",
      "    accuracy                           0.80     29846\n",
      "   macro avg       0.60      0.78      0.61     29846\n",
      "weighted avg       0.93      0.80      0.84     29846\n",
      "\n",
      "Accuracy: 79.82%\n",
      "ROC AUC: 0.857\n",
      "TP=1500, FP=5545, TN=22323, FN=478\n",
      "Accuracy for class 'Repaid': 80.10%\n",
      "Accuracy for class 'Defaulted': 75.83%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_test, y_probs, thresholds, beta=2.6)\n",
    "best_thresh_b = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Feature   Importance\n",
      "0                     DelinquencyBucket  2885.546631\n",
      "1                     HasAnyDelinquency  2848.300537\n",
      "2                      DelinquencyScore  1286.996460\n",
      "3           UtilizationBucketLateBucket   398.085663\n",
      "4                     UtilizationPerAge   223.421066\n",
      "5                   DebtToIncomeAgeRisk    59.941853\n",
      "6                   HasMajorDelinquency    57.907116\n",
      "7                   IncomePerCreditLine    45.574932\n",
      "8             LatePaymentsPerCreditLine    39.242130\n",
      "9                               AgeRisk    35.709614\n",
      "10  WasLatePaymentsPerCreditLineImputed    10.699715\n",
      "11        WasIncomePerCreditLineImputed     9.961766\n",
      "12           WasDelinquencyScoreImputed     0.000000\n",
      "13                    WasAgeRiskImputed     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85476d4b21c4c939f4dfb56ada710de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                feature  mean_abs_shap\n",
      "4                     UtilizationPerAge       0.037822\n",
      "1                     HasAnyDelinquency       0.020648\n",
      "6                   IncomePerCreditLine       0.013806\n",
      "5                   DebtToIncomeAgeRisk       0.011878\n",
      "2                   HasMajorDelinquency       0.009322\n",
      "13                    WasAgeRiskImputed       0.009134\n",
      "0                      DelinquencyScore       0.008646\n",
      "12        WasIncomePerCreditLineImputed       0.003701\n",
      "3             LatePaymentsPerCreditLine       0.003427\n",
      "7                               AgeRisk       0.002723\n",
      "9           UtilizationBucketLateBucket       0.000100\n",
      "10           WasDelinquencyScoreImputed       0.000082\n",
      "8                     DelinquencyBucket       0.000000\n",
      "11  WasLatePaymentsPerCreditLineImputed       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance NN\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "model_cpu.eval()\n",
    "\n",
    "def shap_cpu(X):\n",
    "    \"\"\"Wrapper that splits combined input into numeric & categorical parts before feeding to model.\"\"\"\n",
    "    n_num = X_train_num_tensor.shape[1]\n",
    "    n_cat = X_train_cat_tensor.shape[1]\n",
    "\n",
    "    X_num = X[:, :n_num].astype(np.float32)\n",
    "    X_cat = X[:, n_num:n_num + n_cat].astype(np.int64)\n",
    "\n",
    "    X_num_tensor = torch.tensor(X_num, dtype=torch.float32)\n",
    "    X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_num_tensor, X_cat_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "X_train_combined = np.hstack([\n",
    "    X_train_num_tensor.numpy(),\n",
    "    X_train_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_val_num_tensor.numpy(),\n",
    "    X_val_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "background = shap.sample(X_train_combined, 100, random_state=42)\n",
    "X_val_sample = X_val_combined[:500]\n",
    "\n",
    "explainer = shap.KernelExplainer(shap_cpu, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "\n",
    "feature_names = (\n",
    "    list(num_col_order) +\n",
    "    list(cat_col_order) +\n",
    "    list(X_train_flags)\n",
    ")\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
