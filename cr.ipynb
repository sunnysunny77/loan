{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    df_e[\"age\"] = pd.to_numeric(df_e[\"age\"], errors='coerce')\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationOfUnsecuredLinesCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationOfUnsecuredLines = np.log1p(RevolvingUtilizationOfUnsecuredLinesCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"TotalPastDue_Squared\"] = TotalPastDue ** 2\n",
    "    df_e[\"NormalizedUtilization\"] = np.sqrt(RevolvingUtilizationOfUnsecuredLines)\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "    df_e[\"SevereDelinquency\"] = (\n",
    "        (NumberOfTimes90DaysLate > 0) &\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = RevolvingUtilizationOfUnsecuredLines / AgeSafe\n",
    "    df_e[\"LatePaymentsPerAge\"] = TotalPastDue / AgeSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "\n",
    "    df_e[\"90DaysLate_Squared\"] = NumberOfTimes90DaysLate ** 2\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"IncomePerCreditLineHasDelinquencies\"] = IncomePerCreditLine * HasAnyDelinquency\n",
    "    df_e[\"DebtToIncome\"] = DebtToIncome\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    Age_bins = [0, 25, 50, 120]\n",
    "    Age_labels = [\"Young\", \"Mid\", \"Senior\"]\n",
    "    df_e[\"AgeBucket\"] = pd.cut(AgeSafe, bins=Age_bins, labels=Age_labels)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    df_e[\"UtilizationBucket\"] = pd.cut(RevolvingUtilizationOfUnsecuredLines, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    df_e[\"LatePaymentBucket\"] = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        df_e[\"UtilizationBucket\"].astype(str) + \"_\" + df_e[\"LatePaymentBucket\"].astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"TotalPastDue_Squared\",\n",
    "        \"NormalizedUtilization\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"SevereDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"90DaysLate_Squared\",\n",
    "        \"IncomePerCreditLineHasDelinquencies\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncome\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"AgeBucket\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucket\",\n",
    "        \"LatePaymentBucket\",\n",
    "        \"UtilizationBucketLateBucket\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10, random_state=42, bias_mode=None):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "    \n",
    "    minority_class = 1 if pos_count < neg_count else 0\n",
    "    majority_class = 0 if minority_class == 1 else 1\n",
    "\n",
    "    if bias_mode is False:\n",
    "        scale_pos_weight = neg_count / max(1, pos_count)\n",
    "        print(\"Biasing toward minority class\")\n",
    "    elif bias_mode is True:\n",
    "        scale_pos_weight = pos_count / max(1, neg_count)\n",
    "        print(\"Biasing toward majority class\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Using normal class weights\")\n",
    "        \n",
    "    tuned_params = {\n",
    "        'subsample': 0.9, \n",
    "        'reg_lambda': 0.5, \n",
    "        'reg_alpha': 0.1, \n",
    "        'min_child_weight': 7, \n",
    "        'max_depth': 5, \n",
    "        'learning_rate': 0.01, \n",
    "        'gamma': 0.2, \n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=800,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        **tuned_params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "    \n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    numeric_feats = [f for f in feature_cols if f not in cat_cols]\n",
    "    top_numeric = importance_df[importance_df[\"Feature\"].isin(numeric_feats)][\"Feature\"].head(n_to_keep).tolist()\n",
    "    kept_features = top_numeric + cat_cols\n",
    "    dropped_features = [f for f in numeric_feats if f not in top_numeric]\n",
    "\n",
    "    print(f\"Kept {len(kept_features)} select features (including all {len(cat_cols)} categorical)\")\n",
    "    print(f\"Dropped:{len(dropped_features)} numeric select features cols\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols:{dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[kept_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None, drop_target_na=False, show_info=True):\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    target_cleaned = None\n",
    "    \n",
    "    total_duplicates = df_cleaned.duplicated().sum()\n",
    "    if total_duplicates > 0:\n",
    "        df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "        if show_info:\n",
    "            print(f\"Dropped {total_duplicates} duplicate rows. Remaining: {len(df_cleaned)}\")\n",
    "    \n",
    "    if target is not None:\n",
    "        target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "        if drop_target_na:\n",
    "            mask = target_cleaned.notna()\n",
    "            dropped = len(target_cleaned) - mask.sum()\n",
    "            if dropped > 0 and show_info:\n",
    "                print(f\"Dropped {dropped} rows with missing target values\")\n",
    "            df_cleaned = df_cleaned.loc[mask].reset_index(drop=True)\n",
    "            target_cleaned = target_cleaned.loc[mask].reset_index(drop=True)\n",
    "        else:\n",
    "            target_cleaned = target_cleaned.reset_index(drop=True)\n",
    "        return df_cleaned, target_cleaned\n",
    "    else:\n",
    "        return df_cleaned\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def fast_fbeta_scores(y_true, y_probs, thresholds, beta=2, return_details=False):\n",
    "\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FP = (preds & (y_true[:, None] == 0)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "    f_beta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall + 1e-8)\n",
    "\n",
    "    if return_details:\n",
    "        return f_beta, precision, recall\n",
    "    return f_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 609 duplicate rows. Remaining: 149391\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     MissingCount  MissingPercent\n",
      "90DaysLate_Squared                              0            0.00\n",
      "AgeBucket                                       0            0.00\n",
      "DebtToIncome                                    0            0.00\n",
      "DebtToIncomeAgeRisk                             0            0.00\n",
      "DelinquencyBucket                               0            0.00\n",
      "HasAnyDelinquency                               0            0.00\n",
      "HasMajorDelinquency                             0            0.00\n",
      "IncomePerCreditLine                          1043            1.09\n",
      "IncomePerCreditLineHasDelinquencies          1043            1.09\n",
      "LatePaymentBucket                               0            0.00\n",
      "LatePaymentsPerAge                              0            0.00\n",
      "LatePaymentsPerCreditLine                    1043            1.09\n",
      "NormalizedUtilization                        6831            7.15\n",
      "SevereDelinquency                               0            0.00\n",
      "TotalPastDue_Squared                            0            0.00\n",
      "UtilizationBucket                            6831            7.15\n",
      "UtilizationBucketLateBucket                     0            0.00\n",
      "UtilizationPerAge                            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "UtilizationBucket                      6           0.01\n",
      "DelinquencyBucket                      5           0.01\n",
      "LatePaymentBucket                      5           0.01\n",
      "AgeBucket                              3           0.00\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'AgeBucket': collapsed 1 rare categories: ['Young']\n",
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucket': collapsed 2 rare categories: ['Very High', 'Extreme']\n",
      "Column 'LatePaymentBucket': collapsed 2 rare categories: ['FrequentLate', 'ChronicLate']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 30 rare categories: ['Moderate_FewLate', 'High_FewLate', 'Very Low_FewLate', 'Low_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'High_FrequentLate', 'Low_ModerateLate', 'Very Low_ModerateLate', 'nan_FewLate', 'Moderate_FrequentLate', 'High_ChronicLate', 'nan_ModerateLate', 'Low_FrequentLate', 'Extreme_NoLate', 'Moderate_ChronicLate', 'Very Low_FrequentLate', 'Very High_ModerateLate', 'nan_FrequentLate', 'Very High_NoLate', 'Very High_FrequentLate', 'Very High_FewLate', 'Low_ChronicLate', 'Very High_ChronicLate', 'nan_ChronicLate', 'Extreme_FewLate', 'Very Low_ChronicLate', 'Extreme_ModerateLate', 'Extreme_FrequentLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normal class weights\n",
      "Kept 18 select features (including all 5 categorical)\n",
      "Dropped:0 numeric select features cols\n",
      "                                Feature  Importance\n",
      "0                   HasMajorDelinquency  399.656158\n",
      "1                     DelinquencyBucket  179.330734\n",
      "2                    LatePaymentsPerAge   99.352119\n",
      "3                     HasAnyDelinquency   86.910057\n",
      "4           UtilizationBucketLateBucket   62.711529\n",
      "5             LatePaymentsPerCreditLine   61.038666\n",
      "6                  TotalPastDue_Squared   25.083838\n",
      "7                 NormalizedUtilization   21.311892\n",
      "8                     UtilizationPerAge   18.475431\n",
      "9                     UtilizationBucket   13.193119\n",
      "10                   90DaysLate_Squared   12.552547\n",
      "11                    SevereDelinquency    7.909042\n",
      "12                  DebtToIncomeAgeRisk    6.769241\n",
      "13                         DebtToIncome    6.441879\n",
      "14  IncomePerCreditLineHasDelinquencies    6.216121\n",
      "15                  IncomePerCreditLine    5.876752\n",
      "16                    LatePaymentBucket    5.220783\n",
      "17                            AgeBucket    4.831497\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14, bias_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3144 duplicate rows. Remaining: 92362\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92362, 36)\n",
      "Total rows: 92362\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087709</td>\n",
       "      <td>0.282873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.915086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>476</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>13.845509</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue_Squared (0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.206470</td>\n",
       "      <td>0.404774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.450370</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>True</td>\n",
       "      <td>LatePaymentBucket (-0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076485</td>\n",
       "      <td>0.300731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.355663</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDue_Squared</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.898865</td>\n",
       "      <td>23.365551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>35.382023</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>True</td>\n",
       "      <td>90DaysLate_Squared (0.83), LatePaymentsPerAge (0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalizedUtilization</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>-0.020675</td>\n",
       "      <td>0.998718</td>\n",
       "      <td>-1.733326</td>\n",
       "      <td>-0.894044</td>\n",
       "      <td>-0.108104</td>\n",
       "      <td>0.845259</td>\n",
       "      <td>3.534759</td>\n",
       "      <td>0.258662</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.88), UtilizationBucket (-0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.276778</td>\n",
       "      <td>0.768165</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670842</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.680048</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>True</td>\n",
       "      <td>NormalizedUtilization (0.88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90DaysLate_Squared</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.283829</td>\n",
       "      <td>3.314985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.931588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue_Squared (0.83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SevereDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>0.131907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.312712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.270759</td>\n",
       "      <td>1.609936</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.420889</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.588833</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.231184</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>True</td>\n",
       "      <td>DebtToIncome (0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71469</td>\n",
       "      <td>0.260203</td>\n",
       "      <td>1.613489</td>\n",
       "      <td>-0.448192</td>\n",
       "      <td>-0.423783</td>\n",
       "      <td>0.033638</td>\n",
       "      <td>0.583821</td>\n",
       "      <td>191.043159</td>\n",
       "      <td>59.285196</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>True</td>\n",
       "      <td>DebtToIncomeAgeRisk (0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLineHasDelinquencies</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7961</td>\n",
       "      <td>165.474257</td>\n",
       "      <td>1057.539313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000.000000</td>\n",
       "      <td>120.937250</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.324203</td>\n",
       "      <td>2.145664</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.394545</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.579388</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.460893</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.080488</td>\n",
       "      <td>0.987869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.161482</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.814350</td>\n",
       "      <td>0.659846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.613501</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>True</td>\n",
       "      <td>LatePaymentBucket (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.360289</td>\n",
       "      <td>1.551426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.149179</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationBucketLateBucket (0.82), NormalizedUtilization (-0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.731177</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.653581</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyBucket (0.86), HasAnyDelinquency (-0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.690771</td>\n",
       "      <td>1.411436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.390698</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationBucket (0.82)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.760557</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00), WasIncomePerCreditLineHasDelinquenciesImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasTotalPastDue_SquaredImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasNormalizedUtilizationImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.227306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.918554</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasUtilizationBucketImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.227306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.918554</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>True</td>\n",
       "      <td>WasNormalizedUtilizationImputed (1.00), WasUtilizationBucketImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Was90DaysLate_SquaredImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasSevereDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineHasDelinquenciesImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.760557</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00), WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.760557</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00), WasIncomePerCreditLineHasDelinquenciesImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasAgeBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.227306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.918554</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>True</td>\n",
       "      <td>WasNormalizedUtilizationImputed (1.00), WasUtilizationPerAgeImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dtype  non_null  missing  \\\n",
       "HasMajorDelinquency                            float64     92362        0   \n",
       "LatePaymentsPerAge                             float64     92362        0   \n",
       "HasAnyDelinquency                              float64     92362        0   \n",
       "LatePaymentsPerCreditLine                      float64     92362        0   \n",
       "TotalPastDue_Squared                           float64     92362        0   \n",
       "NormalizedUtilization                          float64     92362        0   \n",
       "UtilizationPerAge                              float64     92362        0   \n",
       "90DaysLate_Squared                             float64     92362        0   \n",
       "SevereDelinquency                              float64     92362        0   \n",
       "DebtToIncomeAgeRisk                            float64     92362        0   \n",
       "DebtToIncome                                   float64     92362        0   \n",
       "IncomePerCreditLineHasDelinquencies            float64     92362        0   \n",
       "IncomePerCreditLine                            float64     92362        0   \n",
       "AgeBucket                                         int8     92362        0   \n",
       "DelinquencyBucket                                 int8     92362        0   \n",
       "UtilizationBucket                                 int8     92362        0   \n",
       "LatePaymentBucket                                 int8     92362        0   \n",
       "UtilizationBucketLateBucket                       int8     92362        0   \n",
       "WasHasMajorDelinquencyImputed                    int64     92362        0   \n",
       "WasLatePaymentsPerAgeImputed                     int64     92362        0   \n",
       "WasHasAnyDelinquencyImputed                      int64     92362        0   \n",
       "WasLatePaymentsPerCreditLineImputed              int64     92362        0   \n",
       "WasTotalPastDue_SquaredImputed                   int64     92362        0   \n",
       "WasNormalizedUtilizationImputed                  int64     92362        0   \n",
       "WasUtilizationPerAgeImputed                      int64     92362        0   \n",
       "Was90DaysLate_SquaredImputed                     int64     92362        0   \n",
       "WasSevereDelinquencyImputed                      int64     92362        0   \n",
       "WasDebtToIncomeAgeRiskImputed                    int64     92362        0   \n",
       "WasDebtToIncomeImputed                           int64     92362        0   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed    int64     92362        0   \n",
       "WasIncomePerCreditLineImputed                    int64     92362        0   \n",
       "WasAgeBucketImputed                              int64     92362        0   \n",
       "WasDelinquencyBucketImputed                      int64     92362        0   \n",
       "WasUtilizationBucketImputed                      int64     92362        0   \n",
       "WasLatePaymentBucketImputed                      int64     92362        0   \n",
       "WasUtilizationBucketLateBucketImputed            int64     92362        0   \n",
       "\n",
       "                                               missing_%  unique        mean  \\\n",
       "HasMajorDelinquency                                  0.0       2    0.087709   \n",
       "LatePaymentsPerAge                                   0.0     476    0.009541   \n",
       "HasAnyDelinquency                                    0.0       2    0.206470   \n",
       "LatePaymentsPerCreditLine                            0.0     201    0.076485   \n",
       "TotalPastDue_Squared                                 0.0      19    1.898865   \n",
       "NormalizedUtilization                                0.0   80850   -0.020675   \n",
       "UtilizationPerAge                                    0.0   82305    0.276778   \n",
       "90DaysLate_Squared                                   0.0      11    0.283829   \n",
       "SevereDelinquency                                    0.0       2    0.017713   \n",
       "DebtToIncomeAgeRisk                                  0.0   72746    0.270759   \n",
       "DebtToIncome                                         0.0   71469    0.260203   \n",
       "IncomePerCreditLineHasDelinquencies                  0.0    7961  165.474257   \n",
       "IncomePerCreditLine                                  0.0   26180    0.324203   \n",
       "AgeBucket                                            0.0       3    1.080488   \n",
       "DelinquencyBucket                                    0.0       4    1.814350   \n",
       "UtilizationBucket                                    0.0       5    2.360289   \n",
       "LatePaymentBucket                                    0.0       4    1.731177   \n",
       "UtilizationBucketLateBucket                          0.0       6    2.690771   \n",
       "WasHasMajorDelinquencyImputed                        0.0       1    0.000000   \n",
       "WasLatePaymentsPerAgeImputed                         0.0       1    0.000000   \n",
       "WasHasAnyDelinquencyImputed                          0.0       1    0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed                  0.0       2    0.006031   \n",
       "WasTotalPastDue_SquaredImputed                       0.0       1    0.000000   \n",
       "WasNormalizedUtilizationImputed                      0.0       2    0.054655   \n",
       "WasUtilizationPerAgeImputed                          0.0       2    0.054655   \n",
       "Was90DaysLate_SquaredImputed                         0.0       1    0.000000   \n",
       "WasSevereDelinquencyImputed                          0.0       1    0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                        0.0       1    0.000000   \n",
       "WasDebtToIncomeImputed                               0.0       1    0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed        0.0       2    0.006031   \n",
       "WasIncomePerCreditLineImputed                        0.0       2    0.006031   \n",
       "WasAgeBucketImputed                                  0.0       1    0.000000   \n",
       "WasDelinquencyBucketImputed                          0.0       1    0.000000   \n",
       "WasUtilizationBucketImputed                          0.0       2    0.054655   \n",
       "WasLatePaymentBucketImputed                          0.0       1    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed                0.0       1    0.000000   \n",
       "\n",
       "                                                       std       min  \\\n",
       "HasMajorDelinquency                               0.282873  0.000000   \n",
       "LatePaymentsPerAge                                0.032292  0.000000   \n",
       "HasAnyDelinquency                                 0.404774  0.000000   \n",
       "LatePaymentsPerCreditLine                         0.300731  0.000000   \n",
       "TotalPastDue_Squared                             23.365551  0.000000   \n",
       "NormalizedUtilization                             0.998718 -1.733326   \n",
       "UtilizationPerAge                                 0.768165 -0.416697   \n",
       "90DaysLate_Squared                                3.314985  0.000000   \n",
       "SevereDelinquency                                 0.131907  0.000000   \n",
       "DebtToIncomeAgeRisk                               1.609936 -0.444698   \n",
       "DebtToIncome                                      1.613489 -0.448192   \n",
       "IncomePerCreditLineHasDelinquencies            1057.539313  0.000000   \n",
       "IncomePerCreditLine                               2.145664 -0.712727   \n",
       "AgeBucket                                         0.987869  0.000000   \n",
       "DelinquencyBucket                                 0.659846  0.000000   \n",
       "UtilizationBucket                                 1.551426  0.000000   \n",
       "LatePaymentBucket                                 0.698215  0.000000   \n",
       "UtilizationBucketLateBucket                       1.411436  0.000000   \n",
       "WasHasMajorDelinquencyImputed                     0.000000  0.000000   \n",
       "WasLatePaymentsPerAgeImputed                      0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed                       0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed               0.077423  0.000000   \n",
       "WasTotalPastDue_SquaredImputed                    0.000000  0.000000   \n",
       "WasNormalizedUtilizationImputed                   0.227306  0.000000   \n",
       "WasUtilizationPerAgeImputed                       0.227306  0.000000   \n",
       "Was90DaysLate_SquaredImputed                      0.000000  0.000000   \n",
       "WasSevereDelinquencyImputed                       0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                     0.000000  0.000000   \n",
       "WasDebtToIncomeImputed                            0.000000  0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed     0.077423  0.000000   \n",
       "WasIncomePerCreditLineImputed                     0.077423  0.000000   \n",
       "WasAgeBucketImputed                               0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed                       0.000000  0.000000   \n",
       "WasUtilizationBucketImputed                       0.227306  0.000000   \n",
       "WasLatePaymentBucketImputed                       0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed             0.000000  0.000000   \n",
       "\n",
       "                                                    25%       50%       75%  \\\n",
       "HasMajorDelinquency                            0.000000  0.000000  0.000000   \n",
       "LatePaymentsPerAge                             0.000000  0.000000  0.000000   \n",
       "HasAnyDelinquency                              0.000000  0.000000  0.000000   \n",
       "LatePaymentsPerCreditLine                      0.000000  0.000000  0.000000   \n",
       "TotalPastDue_Squared                           0.000000  0.000000  0.000000   \n",
       "NormalizedUtilization                         -0.894044 -0.108104  0.845259   \n",
       "UtilizationPerAge                             -0.314875  0.000000  0.670842   \n",
       "90DaysLate_Squared                             0.000000  0.000000  0.000000   \n",
       "SevereDelinquency                              0.000000  0.000000  0.000000   \n",
       "DebtToIncomeAgeRisk                           -0.420889  0.031037  0.588833   \n",
       "DebtToIncome                                  -0.423783  0.033638  0.583821   \n",
       "IncomePerCreditLineHasDelinquencies            0.000000  0.000000  0.000000   \n",
       "IncomePerCreditLine                           -0.394545  0.016820  0.579388   \n",
       "AgeBucket                                      0.000000  2.000000  2.000000   \n",
       "DelinquencyBucket                              2.000000  2.000000  2.000000   \n",
       "UtilizationBucket                              1.000000  2.000000  4.000000   \n",
       "LatePaymentBucket                              2.000000  2.000000  2.000000   \n",
       "UtilizationBucketLateBucket                    1.000000  3.000000  4.000000   \n",
       "WasHasMajorDelinquencyImputed                  0.000000  0.000000  0.000000   \n",
       "WasLatePaymentsPerAgeImputed                   0.000000  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed                    0.000000  0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed            0.000000  0.000000  0.000000   \n",
       "WasTotalPastDue_SquaredImputed                 0.000000  0.000000  0.000000   \n",
       "WasNormalizedUtilizationImputed                0.000000  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed                    0.000000  0.000000  0.000000   \n",
       "Was90DaysLate_SquaredImputed                   0.000000  0.000000  0.000000   \n",
       "WasSevereDelinquencyImputed                    0.000000  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.000000  0.000000  0.000000   \n",
       "WasDebtToIncomeImputed                         0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed  0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed                  0.000000  0.000000  0.000000   \n",
       "WasAgeBucketImputed                            0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketImputed                    0.000000  0.000000  0.000000   \n",
       "WasLatePaymentBucketImputed                    0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.000000  0.000000  0.000000   \n",
       "\n",
       "                                                         max        skew  \\\n",
       "HasMajorDelinquency                                 1.000000    2.915086   \n",
       "LatePaymentsPerAge                                  1.428571   13.845509   \n",
       "HasAnyDelinquency                                   1.000000    1.450370   \n",
       "LatePaymentsPerCreditLine                          30.000000   18.355663   \n",
       "TotalPastDue_Squared                              900.000000   35.382023   \n",
       "NormalizedUtilization                               3.534759    0.258662   \n",
       "UtilizationPerAge                                   8.241714    1.680048   \n",
       "90DaysLate_Squared                                100.000000   23.931588   \n",
       "SevereDelinquency                                   1.000000    7.312712   \n",
       "DebtToIncomeAgeRisk                               230.122301   66.231184   \n",
       "DebtToIncome                                      191.043159   59.285196   \n",
       "IncomePerCreditLineHasDelinquencies            220000.000000  120.937250   \n",
       "IncomePerCreditLine                               279.287273   51.460893   \n",
       "AgeBucket                                           2.000000   -0.161482   \n",
       "DelinquencyBucket                                   3.000000   -1.613501   \n",
       "UtilizationBucket                                   4.000000   -0.149179   \n",
       "LatePaymentBucket                                   3.000000   -1.653581   \n",
       "UtilizationBucketLateBucket                         5.000000   -0.390698   \n",
       "WasHasMajorDelinquencyImputed                       0.000000    0.000000   \n",
       "WasLatePaymentsPerAgeImputed                        0.000000    0.000000   \n",
       "WasHasAnyDelinquencyImputed                         0.000000    0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed                 1.000000   12.760557   \n",
       "WasTotalPastDue_SquaredImputed                      0.000000    0.000000   \n",
       "WasNormalizedUtilizationImputed                     1.000000    3.918554   \n",
       "WasUtilizationPerAgeImputed                         1.000000    3.918554   \n",
       "Was90DaysLate_SquaredImputed                        0.000000    0.000000   \n",
       "WasSevereDelinquencyImputed                         0.000000    0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                       0.000000    0.000000   \n",
       "WasDebtToIncomeImputed                              0.000000    0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed       1.000000   12.760557   \n",
       "WasIncomePerCreditLineImputed                       1.000000   12.760557   \n",
       "WasAgeBucketImputed                                 0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed                         0.000000    0.000000   \n",
       "WasUtilizationBucketImputed                         1.000000    3.918554   \n",
       "WasLatePaymentBucketImputed                         0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed               0.000000    0.000000   \n",
       "\n",
       "                                               corr_with_target  \\\n",
       "HasMajorDelinquency                                         NaN   \n",
       "LatePaymentsPerAge                                     0.000254   \n",
       "HasAnyDelinquency                                      0.000112   \n",
       "LatePaymentsPerCreditLine                              0.002101   \n",
       "TotalPastDue_Squared                                   0.000112   \n",
       "NormalizedUtilization                                 -0.001378   \n",
       "UtilizationPerAge                                     -0.001071   \n",
       "90DaysLate_Squared                                          NaN   \n",
       "SevereDelinquency                                           NaN   \n",
       "DebtToIncomeAgeRisk                                   -0.000497   \n",
       "DebtToIncome                                          -0.000176   \n",
       "IncomePerCreditLineHasDelinquencies                    0.000153   \n",
       "IncomePerCreditLine                                   -0.006396   \n",
       "AgeBucket                                              0.001519   \n",
       "DelinquencyBucket                                     -0.000112   \n",
       "UtilizationBucket                                      0.001551   \n",
       "LatePaymentBucket                                     -0.000112   \n",
       "UtilizationBucketLateBucket                            0.001522   \n",
       "WasHasMajorDelinquencyImputed                               NaN   \n",
       "WasLatePaymentsPerAgeImputed                                NaN   \n",
       "WasHasAnyDelinquencyImputed                                 NaN   \n",
       "WasLatePaymentsPerCreditLineImputed                   -0.003527   \n",
       "WasTotalPastDue_SquaredImputed                              NaN   \n",
       "WasNormalizedUtilizationImputed                        0.002275   \n",
       "WasUtilizationPerAgeImputed                            0.002275   \n",
       "Was90DaysLate_SquaredImputed                                NaN   \n",
       "WasSevereDelinquencyImputed                                 NaN   \n",
       "WasDebtToIncomeAgeRiskImputed                               NaN   \n",
       "WasDebtToIncomeImputed                                      NaN   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed         -0.003527   \n",
       "WasIncomePerCreditLineImputed                         -0.003527   \n",
       "WasAgeBucketImputed                                         NaN   \n",
       "WasDelinquencyBucketImputed                                 NaN   \n",
       "WasUtilizationBucketImputed                            0.002275   \n",
       "WasLatePaymentBucketImputed                                 NaN   \n",
       "WasUtilizationBucketLateBucketImputed                       NaN   \n",
       "\n",
       "                                               high_corr_flag  \\\n",
       "HasMajorDelinquency                                     False   \n",
       "LatePaymentsPerAge                                       True   \n",
       "HasAnyDelinquency                                        True   \n",
       "LatePaymentsPerCreditLine                               False   \n",
       "TotalPastDue_Squared                                     True   \n",
       "NormalizedUtilization                                    True   \n",
       "UtilizationPerAge                                        True   \n",
       "90DaysLate_Squared                                       True   \n",
       "SevereDelinquency                                       False   \n",
       "DebtToIncomeAgeRisk                                      True   \n",
       "DebtToIncome                                             True   \n",
       "IncomePerCreditLineHasDelinquencies                     False   \n",
       "IncomePerCreditLine                                     False   \n",
       "AgeBucket                                               False   \n",
       "DelinquencyBucket                                        True   \n",
       "UtilizationBucket                                        True   \n",
       "LatePaymentBucket                                        True   \n",
       "UtilizationBucketLateBucket                              True   \n",
       "WasHasMajorDelinquencyImputed                           False   \n",
       "WasLatePaymentsPerAgeImputed                            False   \n",
       "WasHasAnyDelinquencyImputed                             False   \n",
       "WasLatePaymentsPerCreditLineImputed                      True   \n",
       "WasTotalPastDue_SquaredImputed                          False   \n",
       "WasNormalizedUtilizationImputed                          True   \n",
       "WasUtilizationPerAgeImputed                              True   \n",
       "Was90DaysLate_SquaredImputed                            False   \n",
       "WasSevereDelinquencyImputed                             False   \n",
       "WasDebtToIncomeAgeRiskImputed                           False   \n",
       "WasDebtToIncomeImputed                                  False   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed            True   \n",
       "WasIncomePerCreditLineImputed                            True   \n",
       "WasAgeBucketImputed                                     False   \n",
       "WasDelinquencyBucketImputed                             False   \n",
       "WasUtilizationBucketImputed                              True   \n",
       "WasLatePaymentBucketImputed                             False   \n",
       "WasUtilizationBucketLateBucketImputed                   False   \n",
       "\n",
       "                                                                                                                                 high_corr_with  \n",
       "HasMajorDelinquency                                                                                                                              \n",
       "LatePaymentsPerAge                                                                                                  TotalPastDue_Squared (0.75)  \n",
       "HasAnyDelinquency                                                                                                     LatePaymentBucket (-0.75)  \n",
       "LatePaymentsPerCreditLine                                                                                                                        \n",
       "TotalPastDue_Squared                                                                       90DaysLate_Squared (0.83), LatePaymentsPerAge (0.75)  \n",
       "NormalizedUtilization                                                                       UtilizationPerAge (0.88), UtilizationBucket (-0.78)  \n",
       "UtilizationPerAge                                                                                                  NormalizedUtilization (0.88)  \n",
       "90DaysLate_Squared                                                                                                  TotalPastDue_Squared (0.83)  \n",
       "SevereDelinquency                                                                                                                                \n",
       "DebtToIncomeAgeRisk                                                                                                         DebtToIncome (0.97)  \n",
       "DebtToIncome                                                                                                         DebtToIncomeAgeRisk (0.97)  \n",
       "IncomePerCreditLineHasDelinquencies                                                                                                              \n",
       "IncomePerCreditLine                                                                                                                              \n",
       "AgeBucket                                                                                                                                        \n",
       "DelinquencyBucket                                                                                                      LatePaymentBucket (0.86)  \n",
       "UtilizationBucket                                                             UtilizationBucketLateBucket (0.82), NormalizedUtilization (-0.78)  \n",
       "LatePaymentBucket                                                                           DelinquencyBucket (0.86), HasAnyDelinquency (-0.75)  \n",
       "UtilizationBucketLateBucket                                                                                            UtilizationBucket (0.82)  \n",
       "WasHasMajorDelinquencyImputed                                                                                                                    \n",
       "WasLatePaymentsPerAgeImputed                                                                                                                     \n",
       "WasHasAnyDelinquencyImputed                                                                                                                      \n",
       "WasLatePaymentsPerCreditLineImputed                  WasIncomePerCreditLineImputed (1.00), WasIncomePerCreditLineHasDelinquenciesImputed (1.00)  \n",
       "WasTotalPastDue_SquaredImputed                                                                                                                   \n",
       "WasNormalizedUtilizationImputed                                          WasUtilizationPerAgeImputed (1.00), WasUtilizationBucketImputed (1.00)  \n",
       "WasUtilizationPerAgeImputed                                          WasNormalizedUtilizationImputed (1.00), WasUtilizationBucketImputed (1.00)  \n",
       "Was90DaysLate_SquaredImputed                                                                                                                     \n",
       "WasSevereDelinquencyImputed                                                                                                                      \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                    \n",
       "WasDebtToIncomeImputed                                                                                                                           \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed                  WasLatePaymentsPerCreditLineImputed (1.00), WasIncomePerCreditLineImputed (1.00)  \n",
       "WasIncomePerCreditLineImputed                  WasLatePaymentsPerCreditLineImputed (1.00), WasIncomePerCreditLineHasDelinquenciesImputed (1.00)  \n",
       "WasAgeBucketImputed                                                                                                                              \n",
       "WasDelinquencyBucketImputed                                                                                                                      \n",
       "WasUtilizationBucketImputed                                          WasNormalizedUtilizationImputed (1.00), WasUtilizationPerAgeImputed (1.00)  \n",
       "WasLatePaymentBucketImputed                                                                                                                      \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                            "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols \n",
    "zero_importance_cols = [\n",
    "    \"WasHasAnyDelinquencyImputed\", \n",
    "    \"WasLatePaymentsPerAgeImputed\", \n",
    "    \"WasTotalPastDue_SquaredImputed\", \n",
    "    \"WasNormalizedUtilizationImputed\", \n",
    "    \"Was90DaysLate_SquaredImputed\", \n",
    "    \"WasUtilizationPerAgeImputed\", \n",
    "    \"WasHasMajorDelinquencyImputed\", \n",
    "    \"WasSevereDelinquencyImputed\", \n",
    "    \"WasDebtToIncomeAgeRiskImputed\", \n",
    "    \"WasDebtToIncomeImputed\", \n",
    "    \"WasAgeBucketImputed\", \n",
    "    \"WasDelinquencyBucketImputed\", \n",
    "    \"WasUtilizationBucketImputed\", \n",
    "    \"WasLatePaymentBucketImputed\", \n",
    "    \"WasUtilizationBucketLateBucketImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val   = X_val.drop(columns=zero_importance_cols)\n",
    "X_test  = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags   = flags_to_keep\n",
    "X_test_flags  = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 and int64\n",
    "X_train_num = X_train[num_col_order + X_train_flags].astype('float32').values\n",
    "X_val_num   = X_val[num_col_order + X_val_flags].astype('float32').values\n",
    "X_test_num  = X_test[num_col_order + X_test_flags].astype('float32').values\n",
    "\n",
    "X_train_cat = X_train[cat_col_order].astype('int64').values\n",
    "X_val_cat   = X_val[cat_col_order].astype('int64').values\n",
    "X_test_cat  = X_test[cat_col_order].astype('int64').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric input shape: torch.Size([92362, 16])\n",
      "Categorical input shape: torch.Size([92362, 5])\n",
      "Class weights: {np.int64(0): np.float64(0.5355498602590716), np.int64(1): np.float64(7.532376447561572)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_train_num_tensor = torch.tensor(X_train_num)\n",
    "X_val_num_tensor = torch.tensor(X_val_num)\n",
    "X_test_num_tensor = torch.tensor(X_test_num)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat)\n",
    "X_val_cat_tensor = torch.tensor(X_val_cat)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "print(\"Numeric input shape:\", X_train_num_tensor.shape)\n",
    "print(\"Categorical input shape:\", X_train_cat_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92362, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num, x_cat, y):\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor)\n",
    "val_ds = TabularDataset(X_val_num_tensor, X_val_cat_tensor, y_val_tensor)\n",
    "test_ds = TabularDataset(X_test_num_tensor, X_test_cat_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(3, 2)\n",
      "    (1): Embedding(4, 2)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(4, 2)\n",
      "    (4): Embedding(6, 3)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bn_num): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (cat_skip): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 52440\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim)\n",
    "            for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)\n",
    "        ])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "    \n",
    "        x_cat_emb = torch.cat([\n",
    "            emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)\n",
    "        ], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "\n",
    "        x_num = self.bn_num(x_num)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "cat_dims = [len(cat_maps[col]) for col in cat_col_order]\n",
    "emb_dims = [min(50, (cat_dim + 1) // 2) for cat_dim in cat_dims]\n",
    "\n",
    "model = NN(X_train_num.shape[1], cat_dims, emb_dims).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.027329 | Train AUC: 0.8198 | Val loss: 0.026360 | Val AUC: 0.8511\n",
      "Epoch 2/75 | Train loss: 0.025017 | Train AUC: 0.8445 | Val loss: 0.027795 | Val AUC: 0.8485\n",
      "Epoch 3/75 | Train loss: 0.024784 | Train AUC: 0.8487 | Val loss: 0.027028 | Val AUC: 0.8506\n",
      "Epoch 4/75 | Train loss: 0.024749 | Train AUC: 0.8484 | Val loss: 0.026013 | Val AUC: 0.8511\n",
      "Epoch 5/75 | Train loss: 0.024646 | Train AUC: 0.8504 | Val loss: 0.025881 | Val AUC: 0.8538\n",
      "Epoch 6/75 | Train loss: 0.024583 | Train AUC: 0.8514 | Val loss: 0.026870 | Val AUC: 0.8525\n",
      "Epoch 7/75 | Train loss: 0.024670 | Train AUC: 0.8502 | Val loss: 0.025896 | Val AUC: 0.8516\n",
      "Epoch 8/75 | Train loss: 0.024529 | Train AUC: 0.8528 | Val loss: 0.025127 | Val AUC: 0.8515\n",
      "Epoch 9/75 | Train loss: 0.024473 | Train AUC: 0.8534 | Val loss: 0.025538 | Val AUC: 0.8490\n",
      "Epoch 10/75 | Train loss: 0.024446 | Train AUC: 0.8545 | Val loss: 0.025494 | Val AUC: 0.8543\n",
      "Epoch 11/75 | Train loss: 0.024428 | Train AUC: 0.8546 | Val loss: 0.025082 | Val AUC: 0.8522\n",
      "Epoch 12/75 | Train loss: 0.024403 | Train AUC: 0.8547 | Val loss: 0.026968 | Val AUC: 0.8485\n",
      "Epoch 13/75 | Train loss: 0.024367 | Train AUC: 0.8557 | Val loss: 0.024896 | Val AUC: 0.8539\n",
      "Epoch 14/75 | Train loss: 0.024332 | Train AUC: 0.8561 | Val loss: 0.025033 | Val AUC: 0.8515\n",
      "Epoch 15/75 | Train loss: 0.024403 | Train AUC: 0.8549 | Val loss: 0.025363 | Val AUC: 0.8540\n",
      "Epoch 16/75 | Train loss: 0.024399 | Train AUC: 0.8547 | Val loss: 0.025339 | Val AUC: 0.8519\n",
      "Epoch 17/75 | Train loss: 0.024245 | Train AUC: 0.8571 | Val loss: 0.025191 | Val AUC: 0.8544\n",
      "Epoch 18/75 | Train loss: 0.024239 | Train AUC: 0.8569 | Val loss: 0.025317 | Val AUC: 0.8544\n",
      "Epoch 19/75 | Train loss: 0.024174 | Train AUC: 0.8582 | Val loss: 0.025179 | Val AUC: 0.8535\n",
      "Epoch 20/75 | Train loss: 0.024137 | Train AUC: 0.8592 | Val loss: 0.025731 | Val AUC: 0.8469\n",
      "Epoch 21/75 | Train loss: 0.024143 | Train AUC: 0.8589 | Val loss: 0.025009 | Val AUC: 0.8548\n",
      "Epoch 22/75 | Train loss: 0.024159 | Train AUC: 0.8582 | Val loss: 0.024888 | Val AUC: 0.8546\n",
      "Epoch 23/75 | Train loss: 0.024167 | Train AUC: 0.8585 | Val loss: 0.025906 | Val AUC: 0.8517\n",
      "Epoch 24/75 | Train loss: 0.024149 | Train AUC: 0.8589 | Val loss: 0.025022 | Val AUC: 0.8535\n",
      "Epoch 25/75 | Train loss: 0.024079 | Train AUC: 0.8600 | Val loss: 0.024820 | Val AUC: 0.8540\n",
      "Epoch 26/75 | Train loss: 0.024139 | Train AUC: 0.8588 | Val loss: 0.024803 | Val AUC: 0.8558\n",
      "Epoch 27/75 | Train loss: 0.024120 | Train AUC: 0.8588 | Val loss: 0.024933 | Val AUC: 0.8535\n",
      "Epoch 28/75 | Train loss: 0.024088 | Train AUC: 0.8597 | Val loss: 0.024948 | Val AUC: 0.8541\n",
      "Epoch 29/75 | Train loss: 0.024097 | Train AUC: 0.8593 | Val loss: 0.025007 | Val AUC: 0.8552\n",
      "Epoch 30/75 | Train loss: 0.024042 | Train AUC: 0.8603 | Val loss: 0.025193 | Val AUC: 0.8535\n",
      "Epoch 31/75 | Train loss: 0.024023 | Train AUC: 0.8604 | Val loss: 0.024996 | Val AUC: 0.8561\n",
      "Epoch 32/75 | Train loss: 0.024054 | Train AUC: 0.8605 | Val loss: 0.025041 | Val AUC: 0.8562\n",
      "Epoch 33/75 | Train loss: 0.024086 | Train AUC: 0.8598 | Val loss: 0.025539 | Val AUC: 0.8557\n",
      "Epoch 34/75 | Train loss: 0.024027 | Train AUC: 0.8604 | Val loss: 0.024829 | Val AUC: 0.8535\n",
      "Epoch 35/75 | Train loss: 0.024007 | Train AUC: 0.8609 | Val loss: 0.025175 | Val AUC: 0.8517\n",
      "Epoch 36/75 | Train loss: 0.024032 | Train AUC: 0.8602 | Val loss: 0.025590 | Val AUC: 0.8539\n",
      "Epoch 37/75 | Train loss: 0.024064 | Train AUC: 0.8601 | Val loss: 0.024991 | Val AUC: 0.8555\n",
      "Epoch 38/75 | Train loss: 0.024030 | Train AUC: 0.8602 | Val loss: 0.025534 | Val AUC: 0.8552\n",
      "Epoch 39/75 | Train loss: 0.023988 | Train AUC: 0.8611 | Val loss: 0.025017 | Val AUC: 0.8540\n",
      "Epoch 40/75 | Train loss: 0.023965 | Train AUC: 0.8613 | Val loss: 0.025848 | Val AUC: 0.8498\n",
      "Epoch 41/75 | Train loss: 0.023980 | Train AUC: 0.8613 | Val loss: 0.025091 | Val AUC: 0.8537\n",
      "Epoch 42/75 | Train loss: 0.023976 | Train AUC: 0.8614 | Val loss: 0.024934 | Val AUC: 0.8550\n",
      "Epoch 43/75 | Train loss: 0.023947 | Train AUC: 0.8616 | Val loss: 0.024872 | Val AUC: 0.8551\n",
      "Epoch 44/75 | Train loss: 0.024010 | Train AUC: 0.8608 | Val loss: 0.024775 | Val AUC: 0.8515\n",
      "Early stopping at epoch 45\n",
      "Run 1 best Val AUC: 0.8562\n",
      "\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.024190 | Train AUC: 0.8583 | Val loss: 0.025417 | Val AUC: 0.8555\n",
      "Epoch 2/75 | Train loss: 0.024143 | Train AUC: 0.8590 | Val loss: 0.025787 | Val AUC: 0.8520\n",
      "Epoch 3/75 | Train loss: 0.024145 | Train AUC: 0.8590 | Val loss: 0.025513 | Val AUC: 0.8513\n",
      "Epoch 4/75 | Train loss: 0.024192 | Train AUC: 0.8583 | Val loss: 0.025092 | Val AUC: 0.8485\n",
      "Epoch 5/75 | Train loss: 0.024215 | Train AUC: 0.8578 | Val loss: 0.024735 | Val AUC: 0.8542\n",
      "Epoch 6/75 | Train loss: 0.024126 | Train AUC: 0.8593 | Val loss: 0.025182 | Val AUC: 0.8552\n",
      "Epoch 7/75 | Train loss: 0.024158 | Train AUC: 0.8587 | Val loss: 0.025014 | Val AUC: 0.8533\n",
      "Epoch 8/75 | Train loss: 0.024100 | Train AUC: 0.8591 | Val loss: 0.024645 | Val AUC: 0.8545\n",
      "Epoch 9/75 | Train loss: 0.023985 | Train AUC: 0.8609 | Val loss: 0.025580 | Val AUC: 0.8542\n",
      "Epoch 10/75 | Train loss: 0.024006 | Train AUC: 0.8605 | Val loss: 0.025756 | Val AUC: 0.8514\n",
      "Epoch 11/75 | Train loss: 0.024046 | Train AUC: 0.8602 | Val loss: 0.024717 | Val AUC: 0.8545\n",
      "Epoch 12/75 | Train loss: 0.023974 | Train AUC: 0.8614 | Val loss: 0.025217 | Val AUC: 0.8545\n",
      "Epoch 13/75 | Train loss: 0.024028 | Train AUC: 0.8604 | Val loss: 0.024849 | Val AUC: 0.8527\n",
      "Early stopping at epoch 14\n",
      "Run 2 best Val AUC: 0.8555\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8562)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_num, x_cat, yb in train_loader:\n",
    "            x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_num, x_cat)  \n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_num.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_num, x_cat, yb in val_loader:\n",
    "                x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "                logits = model(x_num, x_cat)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_num.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "\n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.33394396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.73      0.35      1978\n",
      "\n",
      "    accuracy                           0.82     29846\n",
      "   macro avg       0.60      0.78      0.62     29846\n",
      "weighted avg       0.93      0.82      0.86     29846\n",
      "\n",
      "Accuracy: 82.21%\n",
      "ROC AUC: 0.857\n",
      "TP=1437, FP=4768, TN=23100, FN=541\n",
      "Accuracy for class 'Repaid': 82.89%\n",
      "Accuracy for class 'Defaulted': 72.65%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in val_loader:  \n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_val, y_val_probs, thresholds, beta=2.15)\n",
    "best_thresh_a = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdba09d8-8307-4ade-b197-9eb639de9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.129505790246288, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.129505790246288, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.129505790246288, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.064752895123144, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.064752895123144, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.064752895123144, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.16188223780786, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.16188223780786, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.16188223780786, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.129505790246288, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.129505790246288, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.129505790246288, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.064752895123144, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.194258685369434, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.194258685369434, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.129505790246288, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.064752895123144, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.097129342684717, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.16188223780786, subsample=0.9; total time=   0.7s\n",
      "Best params: {'subsample': 0.9, 'scale_pos_weight': np.float64(14.064752895123144), 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84732\n",
      "[1]\tvalidation_0-auc:0.84966\n",
      "[2]\tvalidation_0-auc:0.85052\n",
      "[3]\tvalidation_0-auc:0.85165\n",
      "[4]\tvalidation_0-auc:0.85149\n",
      "[5]\tvalidation_0-auc:0.85152\n",
      "[6]\tvalidation_0-auc:0.85211\n",
      "[7]\tvalidation_0-auc:0.85200\n",
      "[8]\tvalidation_0-auc:0.85170\n",
      "[9]\tvalidation_0-auc:0.85170\n",
      "[10]\tvalidation_0-auc:0.85172\n",
      "[11]\tvalidation_0-auc:0.85155\n",
      "[12]\tvalidation_0-auc:0.85154\n",
      "[13]\tvalidation_0-auc:0.85151\n",
      "[14]\tvalidation_0-auc:0.85160\n",
      "[15]\tvalidation_0-auc:0.85154\n",
      "[16]\tvalidation_0-auc:0.85152\n",
      "[17]\tvalidation_0-auc:0.85159\n",
      "[18]\tvalidation_0-auc:0.85160\n",
      "[19]\tvalidation_0-auc:0.85175\n",
      "[20]\tvalidation_0-auc:0.85178\n",
      "[21]\tvalidation_0-auc:0.85190\n",
      "[22]\tvalidation_0-auc:0.85195\n",
      "[23]\tvalidation_0-auc:0.85209\n",
      "[24]\tvalidation_0-auc:0.85201\n",
      "[25]\tvalidation_0-auc:0.85204\n",
      "[26]\tvalidation_0-auc:0.85199\n",
      "[27]\tvalidation_0-auc:0.85198\n",
      "[28]\tvalidation_0-auc:0.85197\n",
      "[29]\tvalidation_0-auc:0.85202\n",
      "[30]\tvalidation_0-auc:0.85216\n",
      "[31]\tvalidation_0-auc:0.85212\n",
      "[32]\tvalidation_0-auc:0.85238\n",
      "[33]\tvalidation_0-auc:0.85237\n",
      "[34]\tvalidation_0-auc:0.85240\n",
      "[35]\tvalidation_0-auc:0.85239\n",
      "[36]\tvalidation_0-auc:0.85250\n",
      "[37]\tvalidation_0-auc:0.85248\n",
      "[38]\tvalidation_0-auc:0.85277\n",
      "[39]\tvalidation_0-auc:0.85303\n",
      "[40]\tvalidation_0-auc:0.85305\n",
      "[41]\tvalidation_0-auc:0.85312\n",
      "[42]\tvalidation_0-auc:0.85318\n",
      "[43]\tvalidation_0-auc:0.85321\n",
      "[44]\tvalidation_0-auc:0.85325\n",
      "[45]\tvalidation_0-auc:0.85325\n",
      "[46]\tvalidation_0-auc:0.85322\n",
      "[47]\tvalidation_0-auc:0.85321\n",
      "[48]\tvalidation_0-auc:0.85310\n",
      "[49]\tvalidation_0-auc:0.85308\n",
      "[50]\tvalidation_0-auc:0.85310\n",
      "[51]\tvalidation_0-auc:0.85308\n",
      "[52]\tvalidation_0-auc:0.85310\n",
      "[53]\tvalidation_0-auc:0.85310\n",
      "[54]\tvalidation_0-auc:0.85311\n",
      "[55]\tvalidation_0-auc:0.85310\n",
      "[56]\tvalidation_0-auc:0.85313\n",
      "[57]\tvalidation_0-auc:0.85318\n",
      "[58]\tvalidation_0-auc:0.85323\n",
      "[59]\tvalidation_0-auc:0.85330\n",
      "[60]\tvalidation_0-auc:0.85330\n",
      "[61]\tvalidation_0-auc:0.85329\n",
      "[62]\tvalidation_0-auc:0.85337\n",
      "[63]\tvalidation_0-auc:0.85336\n",
      "[64]\tvalidation_0-auc:0.85335\n",
      "[65]\tvalidation_0-auc:0.85340\n",
      "[66]\tvalidation_0-auc:0.85345\n",
      "[67]\tvalidation_0-auc:0.85347\n",
      "[68]\tvalidation_0-auc:0.85359\n",
      "[69]\tvalidation_0-auc:0.85365\n",
      "[70]\tvalidation_0-auc:0.85369\n",
      "[71]\tvalidation_0-auc:0.85368\n",
      "[72]\tvalidation_0-auc:0.85369\n",
      "[73]\tvalidation_0-auc:0.85370\n",
      "[74]\tvalidation_0-auc:0.85372\n",
      "[75]\tvalidation_0-auc:0.85367\n",
      "[76]\tvalidation_0-auc:0.85369\n",
      "[77]\tvalidation_0-auc:0.85373\n",
      "[78]\tvalidation_0-auc:0.85375\n",
      "[79]\tvalidation_0-auc:0.85373\n",
      "[80]\tvalidation_0-auc:0.85372\n",
      "[81]\tvalidation_0-auc:0.85370\n",
      "[82]\tvalidation_0-auc:0.85369\n",
      "[83]\tvalidation_0-auc:0.85374\n",
      "[84]\tvalidation_0-auc:0.85373\n",
      "[85]\tvalidation_0-auc:0.85373\n",
      "[86]\tvalidation_0-auc:0.85377\n",
      "[87]\tvalidation_0-auc:0.85375\n",
      "[88]\tvalidation_0-auc:0.85372\n",
      "[89]\tvalidation_0-auc:0.85375\n",
      "[90]\tvalidation_0-auc:0.85377\n",
      "[91]\tvalidation_0-auc:0.85379\n",
      "[92]\tvalidation_0-auc:0.85381\n",
      "[93]\tvalidation_0-auc:0.85385\n",
      "[94]\tvalidation_0-auc:0.85383\n",
      "[95]\tvalidation_0-auc:0.85369\n",
      "[96]\tvalidation_0-auc:0.85380\n",
      "[97]\tvalidation_0-auc:0.85381\n",
      "[98]\tvalidation_0-auc:0.85380\n",
      "[99]\tvalidation_0-auc:0.85383\n",
      "[100]\tvalidation_0-auc:0.85382\n",
      "[101]\tvalidation_0-auc:0.85378\n",
      "[102]\tvalidation_0-auc:0.85398\n",
      "[103]\tvalidation_0-auc:0.85403\n",
      "[104]\tvalidation_0-auc:0.85403\n",
      "[105]\tvalidation_0-auc:0.85407\n",
      "[106]\tvalidation_0-auc:0.85411\n",
      "[107]\tvalidation_0-auc:0.85414\n",
      "[108]\tvalidation_0-auc:0.85413\n",
      "[109]\tvalidation_0-auc:0.85417\n",
      "[110]\tvalidation_0-auc:0.85419\n",
      "[111]\tvalidation_0-auc:0.85421\n",
      "[112]\tvalidation_0-auc:0.85418\n",
      "[113]\tvalidation_0-auc:0.85419\n",
      "[114]\tvalidation_0-auc:0.85417\n",
      "[115]\tvalidation_0-auc:0.85419\n",
      "[116]\tvalidation_0-auc:0.85418\n",
      "[117]\tvalidation_0-auc:0.85407\n",
      "[118]\tvalidation_0-auc:0.85408\n",
      "[119]\tvalidation_0-auc:0.85412\n",
      "[120]\tvalidation_0-auc:0.85410\n",
      "[121]\tvalidation_0-auc:0.85413\n",
      "[122]\tvalidation_0-auc:0.85413\n",
      "[123]\tvalidation_0-auc:0.85414\n",
      "[124]\tvalidation_0-auc:0.85411\n",
      "[125]\tvalidation_0-auc:0.85413\n",
      "[126]\tvalidation_0-auc:0.85411\n",
      "[127]\tvalidation_0-auc:0.85411\n",
      "[128]\tvalidation_0-auc:0.85410\n",
      "[129]\tvalidation_0-auc:0.85403\n",
      "[130]\tvalidation_0-auc:0.85404\n",
      "[131]\tvalidation_0-auc:0.85407\n",
      "[132]\tvalidation_0-auc:0.85408\n",
      "[133]\tvalidation_0-auc:0.85409\n",
      "[134]\tvalidation_0-auc:0.85415\n",
      "[135]\tvalidation_0-auc:0.85422\n",
      "[136]\tvalidation_0-auc:0.85425\n",
      "[137]\tvalidation_0-auc:0.85417\n",
      "[138]\tvalidation_0-auc:0.85423\n",
      "[139]\tvalidation_0-auc:0.85421\n",
      "[140]\tvalidation_0-auc:0.85424\n",
      "[141]\tvalidation_0-auc:0.85430\n",
      "[142]\tvalidation_0-auc:0.85435\n",
      "[143]\tvalidation_0-auc:0.85438\n",
      "[144]\tvalidation_0-auc:0.85442\n",
      "[145]\tvalidation_0-auc:0.85450\n",
      "[146]\tvalidation_0-auc:0.85452\n",
      "[147]\tvalidation_0-auc:0.85454\n",
      "[148]\tvalidation_0-auc:0.85455\n",
      "[149]\tvalidation_0-auc:0.85460\n",
      "[150]\tvalidation_0-auc:0.85457\n",
      "[151]\tvalidation_0-auc:0.85452\n",
      "[152]\tvalidation_0-auc:0.85454\n",
      "[153]\tvalidation_0-auc:0.85459\n",
      "[154]\tvalidation_0-auc:0.85461\n",
      "[155]\tvalidation_0-auc:0.85464\n",
      "[156]\tvalidation_0-auc:0.85463\n",
      "[157]\tvalidation_0-auc:0.85469\n",
      "[158]\tvalidation_0-auc:0.85473\n",
      "[159]\tvalidation_0-auc:0.85473\n",
      "[160]\tvalidation_0-auc:0.85472\n",
      "[161]\tvalidation_0-auc:0.85474\n",
      "[162]\tvalidation_0-auc:0.85474\n",
      "[163]\tvalidation_0-auc:0.85478\n",
      "[164]\tvalidation_0-auc:0.85478\n",
      "[165]\tvalidation_0-auc:0.85478\n",
      "[166]\tvalidation_0-auc:0.85480\n",
      "[167]\tvalidation_0-auc:0.85481\n",
      "[168]\tvalidation_0-auc:0.85481\n",
      "[169]\tvalidation_0-auc:0.85479\n",
      "[170]\tvalidation_0-auc:0.85482\n",
      "[171]\tvalidation_0-auc:0.85485\n",
      "[172]\tvalidation_0-auc:0.85489\n",
      "[173]\tvalidation_0-auc:0.85489\n",
      "[174]\tvalidation_0-auc:0.85490\n",
      "[175]\tvalidation_0-auc:0.85490\n",
      "[176]\tvalidation_0-auc:0.85491\n",
      "[177]\tvalidation_0-auc:0.85493\n",
      "[178]\tvalidation_0-auc:0.85497\n",
      "[179]\tvalidation_0-auc:0.85501\n",
      "[180]\tvalidation_0-auc:0.85500\n",
      "[181]\tvalidation_0-auc:0.85501\n",
      "[182]\tvalidation_0-auc:0.85502\n",
      "[183]\tvalidation_0-auc:0.85503\n",
      "[184]\tvalidation_0-auc:0.85505\n",
      "[185]\tvalidation_0-auc:0.85505\n",
      "[186]\tvalidation_0-auc:0.85508\n",
      "[187]\tvalidation_0-auc:0.85510\n",
      "[188]\tvalidation_0-auc:0.85514\n",
      "[189]\tvalidation_0-auc:0.85515\n",
      "[190]\tvalidation_0-auc:0.85514\n",
      "[191]\tvalidation_0-auc:0.85514\n",
      "[192]\tvalidation_0-auc:0.85515\n",
      "[193]\tvalidation_0-auc:0.85516\n",
      "[194]\tvalidation_0-auc:0.85518\n",
      "[195]\tvalidation_0-auc:0.85520\n",
      "[196]\tvalidation_0-auc:0.85521\n",
      "[197]\tvalidation_0-auc:0.85522\n",
      "[198]\tvalidation_0-auc:0.85523\n",
      "[199]\tvalidation_0-auc:0.85521\n",
      "[200]\tvalidation_0-auc:0.85522\n",
      "[201]\tvalidation_0-auc:0.85524\n",
      "[202]\tvalidation_0-auc:0.85525\n",
      "[203]\tvalidation_0-auc:0.85527\n",
      "[204]\tvalidation_0-auc:0.85526\n",
      "[205]\tvalidation_0-auc:0.85528\n",
      "[206]\tvalidation_0-auc:0.85529\n",
      "[207]\tvalidation_0-auc:0.85531\n",
      "[208]\tvalidation_0-auc:0.85534\n",
      "[209]\tvalidation_0-auc:0.85533\n",
      "[210]\tvalidation_0-auc:0.85533\n",
      "[211]\tvalidation_0-auc:0.85532\n",
      "[212]\tvalidation_0-auc:0.85533\n",
      "[213]\tvalidation_0-auc:0.85534\n",
      "[214]\tvalidation_0-auc:0.85533\n",
      "[215]\tvalidation_0-auc:0.85535\n",
      "[216]\tvalidation_0-auc:0.85535\n",
      "[217]\tvalidation_0-auc:0.85536\n",
      "[218]\tvalidation_0-auc:0.85534\n",
      "[219]\tvalidation_0-auc:0.85533\n",
      "[220]\tvalidation_0-auc:0.85534\n",
      "[221]\tvalidation_0-auc:0.85535\n",
      "[222]\tvalidation_0-auc:0.85537\n",
      "[223]\tvalidation_0-auc:0.85538\n",
      "[224]\tvalidation_0-auc:0.85537\n",
      "[225]\tvalidation_0-auc:0.85538\n",
      "[226]\tvalidation_0-auc:0.85537\n",
      "[227]\tvalidation_0-auc:0.85537\n",
      "[228]\tvalidation_0-auc:0.85537\n",
      "[229]\tvalidation_0-auc:0.85539\n",
      "[230]\tvalidation_0-auc:0.85542\n",
      "[231]\tvalidation_0-auc:0.85542\n",
      "[232]\tvalidation_0-auc:0.85542\n",
      "[233]\tvalidation_0-auc:0.85540\n",
      "[234]\tvalidation_0-auc:0.85543\n",
      "[235]\tvalidation_0-auc:0.85545\n",
      "[236]\tvalidation_0-auc:0.85547\n",
      "[237]\tvalidation_0-auc:0.85549\n",
      "[238]\tvalidation_0-auc:0.85548\n",
      "[239]\tvalidation_0-auc:0.85551\n",
      "[240]\tvalidation_0-auc:0.85554\n",
      "[241]\tvalidation_0-auc:0.85556\n",
      "[242]\tvalidation_0-auc:0.85557\n",
      "[243]\tvalidation_0-auc:0.85557\n",
      "[244]\tvalidation_0-auc:0.85557\n",
      "[245]\tvalidation_0-auc:0.85560\n",
      "[246]\tvalidation_0-auc:0.85560\n",
      "[247]\tvalidation_0-auc:0.85560\n",
      "[248]\tvalidation_0-auc:0.85560\n",
      "[249]\tvalidation_0-auc:0.85560\n",
      "[250]\tvalidation_0-auc:0.85560\n",
      "[251]\tvalidation_0-auc:0.85562\n",
      "[252]\tvalidation_0-auc:0.85563\n",
      "[253]\tvalidation_0-auc:0.85563\n",
      "[254]\tvalidation_0-auc:0.85563\n",
      "[255]\tvalidation_0-auc:0.85565\n",
      "[256]\tvalidation_0-auc:0.85566\n",
      "[257]\tvalidation_0-auc:0.85566\n",
      "[258]\tvalidation_0-auc:0.85571\n",
      "[259]\tvalidation_0-auc:0.85574\n",
      "[260]\tvalidation_0-auc:0.85576\n",
      "[261]\tvalidation_0-auc:0.85578\n",
      "[262]\tvalidation_0-auc:0.85579\n",
      "[263]\tvalidation_0-auc:0.85579\n",
      "[264]\tvalidation_0-auc:0.85580\n",
      "[265]\tvalidation_0-auc:0.85581\n",
      "[266]\tvalidation_0-auc:0.85581\n",
      "[267]\tvalidation_0-auc:0.85581\n",
      "[268]\tvalidation_0-auc:0.85581\n",
      "[269]\tvalidation_0-auc:0.85581\n",
      "[270]\tvalidation_0-auc:0.85584\n",
      "[271]\tvalidation_0-auc:0.85585\n",
      "[272]\tvalidation_0-auc:0.85584\n",
      "[273]\tvalidation_0-auc:0.85587\n",
      "[274]\tvalidation_0-auc:0.85587\n",
      "[275]\tvalidation_0-auc:0.85588\n",
      "[276]\tvalidation_0-auc:0.85590\n",
      "[277]\tvalidation_0-auc:0.85591\n",
      "[278]\tvalidation_0-auc:0.85593\n",
      "[279]\tvalidation_0-auc:0.85592\n",
      "[280]\tvalidation_0-auc:0.85594\n",
      "[281]\tvalidation_0-auc:0.85595\n",
      "[282]\tvalidation_0-auc:0.85595\n",
      "[283]\tvalidation_0-auc:0.85595\n",
      "[284]\tvalidation_0-auc:0.85595\n",
      "[285]\tvalidation_0-auc:0.85596\n",
      "[286]\tvalidation_0-auc:0.85597\n",
      "[287]\tvalidation_0-auc:0.85598\n",
      "[288]\tvalidation_0-auc:0.85598\n",
      "[289]\tvalidation_0-auc:0.85598\n",
      "[290]\tvalidation_0-auc:0.85599\n",
      "[291]\tvalidation_0-auc:0.85600\n",
      "[292]\tvalidation_0-auc:0.85602\n",
      "[293]\tvalidation_0-auc:0.85603\n",
      "[294]\tvalidation_0-auc:0.85603\n",
      "[295]\tvalidation_0-auc:0.85604\n",
      "[296]\tvalidation_0-auc:0.85605\n",
      "[297]\tvalidation_0-auc:0.85604\n",
      "[298]\tvalidation_0-auc:0.85604\n",
      "[299]\tvalidation_0-auc:0.85606\n",
      "[300]\tvalidation_0-auc:0.85604\n",
      "[301]\tvalidation_0-auc:0.85607\n",
      "[302]\tvalidation_0-auc:0.85607\n",
      "[303]\tvalidation_0-auc:0.85608\n",
      "[304]\tvalidation_0-auc:0.85608\n",
      "[305]\tvalidation_0-auc:0.85610\n",
      "[306]\tvalidation_0-auc:0.85611\n",
      "[307]\tvalidation_0-auc:0.85610\n",
      "[308]\tvalidation_0-auc:0.85611\n",
      "[309]\tvalidation_0-auc:0.85610\n",
      "[310]\tvalidation_0-auc:0.85612\n",
      "[311]\tvalidation_0-auc:0.85611\n",
      "[312]\tvalidation_0-auc:0.85615\n",
      "[313]\tvalidation_0-auc:0.85616\n",
      "[314]\tvalidation_0-auc:0.85619\n",
      "[315]\tvalidation_0-auc:0.85618\n",
      "[316]\tvalidation_0-auc:0.85621\n",
      "[317]\tvalidation_0-auc:0.85621\n",
      "[318]\tvalidation_0-auc:0.85621\n",
      "[319]\tvalidation_0-auc:0.85621\n",
      "[320]\tvalidation_0-auc:0.85620\n",
      "[321]\tvalidation_0-auc:0.85621\n",
      "[322]\tvalidation_0-auc:0.85622\n",
      "[323]\tvalidation_0-auc:0.85622\n",
      "[324]\tvalidation_0-auc:0.85621\n",
      "[325]\tvalidation_0-auc:0.85622\n",
      "[326]\tvalidation_0-auc:0.85622\n",
      "[327]\tvalidation_0-auc:0.85622\n",
      "[328]\tvalidation_0-auc:0.85621\n",
      "[329]\tvalidation_0-auc:0.85620\n",
      "[330]\tvalidation_0-auc:0.85620\n",
      "[331]\tvalidation_0-auc:0.85621\n",
      "[332]\tvalidation_0-auc:0.85620\n",
      "[333]\tvalidation_0-auc:0.85621\n",
      "[334]\tvalidation_0-auc:0.85620\n",
      "[335]\tvalidation_0-auc:0.85620\n",
      "[336]\tvalidation_0-auc:0.85621\n",
      "[337]\tvalidation_0-auc:0.85621\n",
      "[338]\tvalidation_0-auc:0.85622\n",
      "[339]\tvalidation_0-auc:0.85621\n",
      "[340]\tvalidation_0-auc:0.85622\n",
      "[341]\tvalidation_0-auc:0.85621\n",
      "[342]\tvalidation_0-auc:0.85621\n",
      "[343]\tvalidation_0-auc:0.85622\n",
      "[344]\tvalidation_0-auc:0.85623\n",
      "[345]\tvalidation_0-auc:0.85624\n",
      "[346]\tvalidation_0-auc:0.85625\n",
      "[347]\tvalidation_0-auc:0.85625\n",
      "[348]\tvalidation_0-auc:0.85625\n",
      "[349]\tvalidation_0-auc:0.85625\n",
      "[350]\tvalidation_0-auc:0.85626\n",
      "[351]\tvalidation_0-auc:0.85625\n",
      "[352]\tvalidation_0-auc:0.85623\n",
      "[353]\tvalidation_0-auc:0.85626\n",
      "[354]\tvalidation_0-auc:0.85626\n",
      "[355]\tvalidation_0-auc:0.85627\n",
      "[356]\tvalidation_0-auc:0.85628\n",
      "[357]\tvalidation_0-auc:0.85629\n",
      "[358]\tvalidation_0-auc:0.85631\n",
      "[359]\tvalidation_0-auc:0.85631\n",
      "[360]\tvalidation_0-auc:0.85630\n",
      "[361]\tvalidation_0-auc:0.85633\n",
      "[362]\tvalidation_0-auc:0.85631\n",
      "[363]\tvalidation_0-auc:0.85632\n",
      "[364]\tvalidation_0-auc:0.85633\n",
      "[365]\tvalidation_0-auc:0.85632\n",
      "[366]\tvalidation_0-auc:0.85631\n",
      "[367]\tvalidation_0-auc:0.85632\n",
      "[368]\tvalidation_0-auc:0.85634\n",
      "[369]\tvalidation_0-auc:0.85634\n",
      "[370]\tvalidation_0-auc:0.85633\n",
      "[371]\tvalidation_0-auc:0.85633\n",
      "[372]\tvalidation_0-auc:0.85633\n",
      "[373]\tvalidation_0-auc:0.85635\n",
      "[374]\tvalidation_0-auc:0.85635\n",
      "[375]\tvalidation_0-auc:0.85634\n",
      "[376]\tvalidation_0-auc:0.85634\n",
      "[377]\tvalidation_0-auc:0.85634\n",
      "[378]\tvalidation_0-auc:0.85634\n",
      "[379]\tvalidation_0-auc:0.85635\n",
      "[380]\tvalidation_0-auc:0.85636\n",
      "[381]\tvalidation_0-auc:0.85635\n",
      "[382]\tvalidation_0-auc:0.85637\n",
      "[383]\tvalidation_0-auc:0.85637\n",
      "[384]\tvalidation_0-auc:0.85637\n",
      "[385]\tvalidation_0-auc:0.85637\n",
      "[386]\tvalidation_0-auc:0.85636\n",
      "[387]\tvalidation_0-auc:0.85638\n",
      "[388]\tvalidation_0-auc:0.85638\n",
      "[389]\tvalidation_0-auc:0.85638\n",
      "[390]\tvalidation_0-auc:0.85639\n",
      "[391]\tvalidation_0-auc:0.85638\n",
      "[392]\tvalidation_0-auc:0.85639\n",
      "[393]\tvalidation_0-auc:0.85639\n",
      "[394]\tvalidation_0-auc:0.85640\n",
      "[395]\tvalidation_0-auc:0.85640\n",
      "[396]\tvalidation_0-auc:0.85640\n",
      "[397]\tvalidation_0-auc:0.85639\n",
      "[398]\tvalidation_0-auc:0.85639\n",
      "[399]\tvalidation_0-auc:0.85639\n",
      "[400]\tvalidation_0-auc:0.85638\n",
      "[401]\tvalidation_0-auc:0.85636\n",
      "[402]\tvalidation_0-auc:0.85637\n",
      "[403]\tvalidation_0-auc:0.85637\n",
      "[404]\tvalidation_0-auc:0.85638\n",
      "[405]\tvalidation_0-auc:0.85638\n",
      "[406]\tvalidation_0-auc:0.85638\n",
      "[407]\tvalidation_0-auc:0.85639\n",
      "[408]\tvalidation_0-auc:0.85640\n",
      "[409]\tvalidation_0-auc:0.85640\n",
      "[410]\tvalidation_0-auc:0.85640\n",
      "[411]\tvalidation_0-auc:0.85641\n",
      "[412]\tvalidation_0-auc:0.85642\n",
      "[413]\tvalidation_0-auc:0.85642\n",
      "[414]\tvalidation_0-auc:0.85641\n",
      "[415]\tvalidation_0-auc:0.85640\n",
      "[416]\tvalidation_0-auc:0.85640\n",
      "[417]\tvalidation_0-auc:0.85640\n",
      "[418]\tvalidation_0-auc:0.85640\n",
      "[419]\tvalidation_0-auc:0.85639\n",
      "[420]\tvalidation_0-auc:0.85639\n",
      "[421]\tvalidation_0-auc:0.85640\n",
      "[422]\tvalidation_0-auc:0.85640\n",
      "[423]\tvalidation_0-auc:0.85640\n",
      "[424]\tvalidation_0-auc:0.85640\n",
      "[425]\tvalidation_0-auc:0.85640\n",
      "[426]\tvalidation_0-auc:0.85639\n",
      "[427]\tvalidation_0-auc:0.85640\n",
      "[428]\tvalidation_0-auc:0.85640\n",
      "[429]\tvalidation_0-auc:0.85640\n",
      "[430]\tvalidation_0-auc:0.85640\n",
      "[431]\tvalidation_0-auc:0.85641\n",
      "[432]\tvalidation_0-auc:0.85642\n",
      "[433]\tvalidation_0-auc:0.85642\n",
      "[434]\tvalidation_0-auc:0.85640\n",
      "[435]\tvalidation_0-auc:0.85640\n",
      "[436]\tvalidation_0-auc:0.85640\n",
      "[437]\tvalidation_0-auc:0.85640\n",
      "[438]\tvalidation_0-auc:0.85639\n",
      "[439]\tvalidation_0-auc:0.85639\n",
      "[440]\tvalidation_0-auc:0.85640\n",
      "[441]\tvalidation_0-auc:0.85641\n",
      "[442]\tvalidation_0-auc:0.85641\n",
      "[443]\tvalidation_0-auc:0.85640\n",
      "[444]\tvalidation_0-auc:0.85640\n",
      "[445]\tvalidation_0-auc:0.85641\n",
      "[446]\tvalidation_0-auc:0.85641\n",
      "[447]\tvalidation_0-auc:0.85642\n",
      "[448]\tvalidation_0-auc:0.85643\n",
      "[449]\tvalidation_0-auc:0.85642\n",
      "[450]\tvalidation_0-auc:0.85643\n",
      "[451]\tvalidation_0-auc:0.85643\n",
      "[452]\tvalidation_0-auc:0.85644\n",
      "[453]\tvalidation_0-auc:0.85644\n",
      "[454]\tvalidation_0-auc:0.85644\n",
      "[455]\tvalidation_0-auc:0.85646\n",
      "[456]\tvalidation_0-auc:0.85645\n",
      "[457]\tvalidation_0-auc:0.85645\n",
      "[458]\tvalidation_0-auc:0.85645\n",
      "[459]\tvalidation_0-auc:0.85645\n",
      "[460]\tvalidation_0-auc:0.85646\n",
      "[461]\tvalidation_0-auc:0.85646\n",
      "[462]\tvalidation_0-auc:0.85646\n",
      "[463]\tvalidation_0-auc:0.85647\n",
      "[464]\tvalidation_0-auc:0.85647\n",
      "[465]\tvalidation_0-auc:0.85646\n",
      "[466]\tvalidation_0-auc:0.85647\n",
      "[467]\tvalidation_0-auc:0.85646\n",
      "[468]\tvalidation_0-auc:0.85645\n",
      "[469]\tvalidation_0-auc:0.85645\n",
      "[470]\tvalidation_0-auc:0.85645\n",
      "[471]\tvalidation_0-auc:0.85645\n",
      "[472]\tvalidation_0-auc:0.85644\n",
      "[473]\tvalidation_0-auc:0.85647\n",
      "[474]\tvalidation_0-auc:0.85647\n",
      "[475]\tvalidation_0-auc:0.85646\n",
      "[476]\tvalidation_0-auc:0.85646\n",
      "[477]\tvalidation_0-auc:0.85648\n",
      "[478]\tvalidation_0-auc:0.85649\n",
      "[479]\tvalidation_0-auc:0.85649\n",
      "[480]\tvalidation_0-auc:0.85649\n",
      "[481]\tvalidation_0-auc:0.85649\n",
      "[482]\tvalidation_0-auc:0.85649\n",
      "[483]\tvalidation_0-auc:0.85650\n",
      "[484]\tvalidation_0-auc:0.85649\n",
      "[485]\tvalidation_0-auc:0.85648\n",
      "[486]\tvalidation_0-auc:0.85649\n",
      "[487]\tvalidation_0-auc:0.85649\n",
      "[488]\tvalidation_0-auc:0.85648\n",
      "[489]\tvalidation_0-auc:0.85648\n",
      "[490]\tvalidation_0-auc:0.85647\n",
      "[491]\tvalidation_0-auc:0.85647\n",
      "[492]\tvalidation_0-auc:0.85646\n",
      "[493]\tvalidation_0-auc:0.85645\n",
      "[494]\tvalidation_0-auc:0.85645\n",
      "[495]\tvalidation_0-auc:0.85644\n",
      "[496]\tvalidation_0-auc:0.85644\n",
      "[497]\tvalidation_0-auc:0.85644\n",
      "[498]\tvalidation_0-auc:0.85643\n",
      "[499]\tvalidation_0-auc:0.85643\n",
      "[500]\tvalidation_0-auc:0.85643\n",
      "[501]\tvalidation_0-auc:0.85642\n",
      "[502]\tvalidation_0-auc:0.85643\n",
      "[503]\tvalidation_0-auc:0.85643\n",
      "[504]\tvalidation_0-auc:0.85644\n",
      "[505]\tvalidation_0-auc:0.85644\n",
      "[506]\tvalidation_0-auc:0.85643\n",
      "[507]\tvalidation_0-auc:0.85643\n",
      "[508]\tvalidation_0-auc:0.85644\n",
      "[509]\tvalidation_0-auc:0.85643\n",
      "[510]\tvalidation_0-auc:0.85645\n",
      "[511]\tvalidation_0-auc:0.85644\n",
      "[512]\tvalidation_0-auc:0.85644\n",
      "[513]\tvalidation_0-auc:0.85643\n",
      "[514]\tvalidation_0-auc:0.85644\n",
      "[515]\tvalidation_0-auc:0.85643\n",
      "[516]\tvalidation_0-auc:0.85644\n",
      "[517]\tvalidation_0-auc:0.85645\n",
      "[518]\tvalidation_0-auc:0.85644\n",
      "[519]\tvalidation_0-auc:0.85644\n",
      "[520]\tvalidation_0-auc:0.85643\n",
      "[521]\tvalidation_0-auc:0.85643\n",
      "[522]\tvalidation_0-auc:0.85642\n",
      "[523]\tvalidation_0-auc:0.85643\n",
      "[524]\tvalidation_0-auc:0.85642\n",
      "[525]\tvalidation_0-auc:0.85641\n",
      "[526]\tvalidation_0-auc:0.85641\n",
      "[527]\tvalidation_0-auc:0.85640\n",
      "[528]\tvalidation_0-auc:0.85640\n",
      "[529]\tvalidation_0-auc:0.85639\n",
      "[530]\tvalidation_0-auc:0.85640\n",
      "[531]\tvalidation_0-auc:0.85639\n",
      "[532]\tvalidation_0-auc:0.85638\n",
      "[533]\tvalidation_0-auc:0.85638\n",
      "[534]\tvalidation_0-auc:0.85638\n",
      "[535]\tvalidation_0-auc:0.85639\n",
      "[536]\tvalidation_0-auc:0.85638\n",
      "[537]\tvalidation_0-auc:0.85637\n",
      "[538]\tvalidation_0-auc:0.85637\n",
      "[539]\tvalidation_0-auc:0.85636\n",
      "[540]\tvalidation_0-auc:0.85636\n",
      "[541]\tvalidation_0-auc:0.85634\n",
      "[542]\tvalidation_0-auc:0.85635\n",
      "[543]\tvalidation_0-auc:0.85635\n",
      "[544]\tvalidation_0-auc:0.85635\n",
      "[545]\tvalidation_0-auc:0.85634\n",
      "[546]\tvalidation_0-auc:0.85634\n",
      "[547]\tvalidation_0-auc:0.85634\n",
      "[548]\tvalidation_0-auc:0.85634\n",
      "[549]\tvalidation_0-auc:0.85633\n",
      "[550]\tvalidation_0-auc:0.85633\n",
      "[551]\tvalidation_0-auc:0.85632\n",
      "[552]\tvalidation_0-auc:0.85633\n",
      "[553]\tvalidation_0-auc:0.85633\n",
      "[554]\tvalidation_0-auc:0.85632\n",
      "[555]\tvalidation_0-auc:0.85633\n",
      "[556]\tvalidation_0-auc:0.85633\n",
      "[557]\tvalidation_0-auc:0.85632\n",
      "[558]\tvalidation_0-auc:0.85632\n",
      "[559]\tvalidation_0-auc:0.85631\n",
      "[560]\tvalidation_0-auc:0.85631\n",
      "[561]\tvalidation_0-auc:0.85631\n",
      "[562]\tvalidation_0-auc:0.85631\n",
      "[563]\tvalidation_0-auc:0.85630\n",
      "[564]\tvalidation_0-auc:0.85630\n",
      "[565]\tvalidation_0-auc:0.85631\n",
      "[566]\tvalidation_0-auc:0.85632\n",
      "[567]\tvalidation_0-auc:0.85632\n",
      "[568]\tvalidation_0-auc:0.85631\n",
      "[569]\tvalidation_0-auc:0.85630\n",
      "[570]\tvalidation_0-auc:0.85630\n",
      "[571]\tvalidation_0-auc:0.85630\n",
      "[572]\tvalidation_0-auc:0.85630\n",
      "[573]\tvalidation_0-auc:0.85630\n",
      "[574]\tvalidation_0-auc:0.85629\n",
      "[575]\tvalidation_0-auc:0.85630\n",
      "[576]\tvalidation_0-auc:0.85630\n",
      "[577]\tvalidation_0-auc:0.85630\n",
      "[578]\tvalidation_0-auc:0.85630\n",
      "[579]\tvalidation_0-auc:0.85629\n",
      "[580]\tvalidation_0-auc:0.85630\n",
      "[581]\tvalidation_0-auc:0.85629\n",
      "[582]\tvalidation_0-auc:0.85629\n",
      "[583]\tvalidation_0-auc:0.85628\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.064752895123144)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.5564494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.72      0.35      1978\n",
      "\n",
      "    accuracy                           0.83     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.83      0.86     29846\n",
      "\n",
      "Accuracy: 82.51%\n",
      "ROC AUC: 0.858\n",
      "TP=1426, FP=4668, TN=23200, FN=552\n",
      "Accuracy for class 'Repaid': 83.25%\n",
      "Accuracy for class 'Defaulted': 72.09%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_test, y_probs, thresholds, beta=2.26)\n",
    "best_thresh_b = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Feature   Importance\n",
      "0                               DelinquencyBucket  3041.792236\n",
      "1                               HasAnyDelinquency  1835.132080\n",
      "2                              LatePaymentsPerAge  1018.494751\n",
      "3                     UtilizationBucketLateBucket   265.838470\n",
      "4                               UtilizationPerAge   262.352051\n",
      "5                             HasMajorDelinquency   251.983368\n",
      "6                            TotalPastDue_Squared   214.403793\n",
      "7                               UtilizationBucket   209.495300\n",
      "8                           NormalizedUtilization   109.057350\n",
      "9                             DebtToIncomeAgeRisk    64.137184\n",
      "10                              LatePaymentBucket    56.816349\n",
      "11                            IncomePerCreditLine    55.829552\n",
      "12                                   DebtToIncome    51.869873\n",
      "13                      LatePaymentsPerCreditLine    48.746033\n",
      "14                             90DaysLate_Squared    45.550854\n",
      "15                                      AgeBucket    41.756306\n",
      "16            IncomePerCreditLineHasDelinquencies    22.729578\n",
      "17                              SevereDelinquency    20.867311\n",
      "18  WasIncomePerCreditLineHasDelinquenciesImputed    12.084686\n",
      "19            WasLatePaymentsPerCreditLineImputed    11.857237\n",
      "20                  WasIncomePerCreditLineImputed     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4caf1fade34b99aeba95598292c64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  mean_abs_shap\n",
      "6                               UtilizationPerAge       0.020468\n",
      "2                               HasAnyDelinquency       0.014213\n",
      "5                           NormalizedUtilization       0.013881\n",
      "9                             DebtToIncomeAgeRisk       0.011585\n",
      "0                             HasMajorDelinquency       0.008729\n",
      "12                            IncomePerCreditLine       0.008696\n",
      "20                  WasIncomePerCreditLineImputed       0.006216\n",
      "17                    UtilizationBucketLateBucket       0.002940\n",
      "1                              LatePaymentsPerAge       0.002820\n",
      "16                              LatePaymentBucket       0.001772\n",
      "10                                   DebtToIncome       0.001610\n",
      "19  WasIncomePerCreditLineHasDelinquenciesImputed       0.001522\n",
      "8                               SevereDelinquency       0.001292\n",
      "18            WasLatePaymentsPerCreditLineImputed       0.001246\n",
      "3                       LatePaymentsPerCreditLine       0.000727\n",
      "7                              90DaysLate_Squared       0.000193\n",
      "4                            TotalPastDue_Squared       0.000129\n",
      "11            IncomePerCreditLineHasDelinquencies       0.000101\n",
      "15                              UtilizationBucket       0.000020\n",
      "13                                      AgeBucket       0.000000\n",
      "14                              DelinquencyBucket       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance NN\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "model_cpu.eval()\n",
    "\n",
    "def shap_cpu(X):\n",
    "    \"\"\"Wrapper that splits combined input into numeric & categorical parts before feeding to model.\"\"\"\n",
    "    n_num = X_train_num_tensor.shape[1]\n",
    "    n_cat = X_train_cat_tensor.shape[1]\n",
    "\n",
    "    X_num = X[:, :n_num].astype(np.float32)\n",
    "    X_cat = X[:, n_num:n_num + n_cat].astype(np.int64)\n",
    "\n",
    "    X_num_tensor = torch.tensor(X_num, dtype=torch.float32)\n",
    "    X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_num_tensor, X_cat_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "X_train_combined = np.hstack([\n",
    "    X_train_num_tensor.numpy(),\n",
    "    X_train_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_val_num_tensor.numpy(),\n",
    "    X_val_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "background = shap.sample(X_train_combined, 100, random_state=42)\n",
    "X_val_sample = X_val_combined[:500]\n",
    "\n",
    "explainer = shap.KernelExplainer(shap_cpu, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "\n",
    "feature_names = (\n",
    "    list(num_col_order) +\n",
    "    list(cat_col_order) +\n",
    "    list(X_train_flags)\n",
    ")\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
