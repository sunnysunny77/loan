{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    TotalPastDueCapped = TotalPastDue.clip(upper=10)\n",
    "\n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLog / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = RevolvingUtilizationCappedLog\n",
    "    df_e[\"TotalPastDueCapped\"] = TotalPastDueCapped\n",
    "    \n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationCappedLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationCapped, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"TotalPastDueCapped\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "\n",
    "    best_param = {\n",
    "        'subsample': 0.6,\n",
    "        'scale_pos_weight':\n",
    "        14.090657712818487,\n",
    "        'reg_lambda': 0.8,\n",
    "        'reg_alpha': 0.1,\n",
    "        'min_child_weight': 5,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.03,\n",
    "        'gamma': 1.0,\n",
    "        'colsample_bytree': 0.6\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=[\"auc\"],\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "\n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "    dropped_features = [f for f in feature_cols if f not in top_features]\n",
    "\n",
    "    print(f\"Kept {len(top_features)} select features\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[top_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 609 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyBucket                         0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasAnyDelinquency                         0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                    1043            1.09\n",
      "LatePaymentsPerCreditLine              1043            1.09\n",
      "RevolvingUtilizationCappedLog          6831            7.15\n",
      "TotalPastDueCapped                        0            0.00\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      6831            7.15\n",
      "UtilizationPerCreditLine               7874            8.24\n",
      "UtilizationTimesDelinquency            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 29 rare categories: ['Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'Very High_ModerateLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very High_FrequentLate', 'Low_ModerateLate', 'nan_FewLate', 'Very Low_ModerateLate', 'High_FrequentLate', 'Very High_ChronicLate', 'nan_ModerateLate', 'Moderate_FrequentLate', 'Extreme_NoLate', 'Low_FrequentLate', 'High_ChronicLate', 'Very Low_FrequentLate', 'Extreme_ModerateLate', 'Moderate_ChronicLate', 'nan_FrequentLate', 'Extreme_FewLate', 'Extreme_FrequentLate', 'Low_ChronicLate', 'nan_ChronicLate', 'Extreme_ChronicLate', 'Very Low_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 14 select features\n",
      "Dropped 0 features\n",
      "                          Feature  Importance\n",
      "0       LatePaymentsPerCreditLine  388.010773\n",
      "1                DelinquencyScore  358.740082\n",
      "2              TotalPastDueCapped  298.515686\n",
      "3     UtilizationTimesDelinquency  136.970551\n",
      "4               DelinquencyBucket  135.709625\n",
      "5     UtilizationBucketLateBucket  101.313957\n",
      "6               UtilizationPerAge   74.949860\n",
      "7             HasMajorDelinquency   74.041748\n",
      "8   RevolvingUtilizationCappedLog   60.334053\n",
      "9             DebtToIncomeAgeRisk   44.571373\n",
      "10       UtilizationPerCreditLine   40.673717\n",
      "11            IncomePerCreditLine   36.476421\n",
      "12              HasAnyDelinquency   35.808910\n",
      "13                HighAgeRiskFlag   32.019653\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2908 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92598, 28)\n",
      "Total rows: 92598\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076097</td>\n",
       "      <td>0.300314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.388191</td>\n",
       "      <td>0.309645</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.683308</td>\n",
       "      <td>2.492097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.231471</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDueCapped (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDueCapped</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>1.097088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.180515</td>\n",
       "      <td>0.399287</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.86), HasAnyDelinquency (0.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15842</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.093738</td>\n",
       "      <td>0.364758</td>\n",
       "      <td>True</td>\n",
       "      <td>HasAnyDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.816249</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.622637</td>\n",
       "      <td>0.053309</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.209562</td>\n",
       "      <td>1.775414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.241138</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.281012</td>\n",
       "      <td>0.771726</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681580</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>0.268645</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.924108</td>\n",
       "      <td>0.362474</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>0.216556</td>\n",
       "      <td>0.633069</td>\n",
       "      <td>-0.440434</td>\n",
       "      <td>-0.320875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673260</td>\n",
       "      <td>4.139011</td>\n",
       "      <td>1.117564</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>1.608289</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.422533</td>\n",
       "      <td>0.028949</td>\n",
       "      <td>0.586787</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.268737</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82039</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>2.314940</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.309695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707668</td>\n",
       "      <td>39.419312</td>\n",
       "      <td>4.650212</td>\n",
       "      <td>0.177593</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.321183</td>\n",
       "      <td>2.143377</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.399441</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.575909</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.497662</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205091</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.460809</td>\n",
       "      <td>0.311074</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationTimesDelinquency (0.74), TotalPastDueCapped (0.73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>-0.228439</td>\n",
       "      <td>-0.089933</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.777148</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyScoreImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasTotalPastDueCappedImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationTimesDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasRevolvingUtilizationCappedLogImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.969398</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>0.236548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.724540</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95), WasUtilizationPerAgeImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.777148</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHighAgeRiskFlagImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dtype  non_null  missing  \\\n",
       "LatePaymentsPerCreditLine                float64     92598        0   \n",
       "DelinquencyScore                         float64     92598        0   \n",
       "TotalPastDueCapped                       float64     92598        0   \n",
       "UtilizationTimesDelinquency              float64     92598        0   \n",
       "DelinquencyBucket                           int8     92598        0   \n",
       "UtilizationBucketLateBucket                 int8     92598        0   \n",
       "UtilizationPerAge                        float64     92598        0   \n",
       "HasMajorDelinquency                      float64     92598        0   \n",
       "RevolvingUtilizationCappedLog            float64     92598        0   \n",
       "DebtToIncomeAgeRisk                      float64     92598        0   \n",
       "UtilizationPerCreditLine                 float64     92598        0   \n",
       "IncomePerCreditLine                      float64     92598        0   \n",
       "HasAnyDelinquency                        float64     92598        0   \n",
       "HighAgeRiskFlag                          float64     92598        0   \n",
       "WasLatePaymentsPerCreditLineImputed        int64     92598        0   \n",
       "WasDelinquencyScoreImputed                 int64     92598        0   \n",
       "WasTotalPastDueCappedImputed               int64     92598        0   \n",
       "WasUtilizationTimesDelinquencyImputed      int64     92598        0   \n",
       "WasUtilizationPerAgeImputed                int64     92598        0   \n",
       "WasHasMajorDelinquencyImputed              int64     92598        0   \n",
       "WasRevolvingUtilizationCappedLogImputed    int64     92598        0   \n",
       "WasDebtToIncomeAgeRiskImputed              int64     92598        0   \n",
       "WasUtilizationPerCreditLineImputed         int64     92598        0   \n",
       "WasIncomePerCreditLineImputed              int64     92598        0   \n",
       "WasHasAnyDelinquencyImputed                int64     92598        0   \n",
       "WasHighAgeRiskFlagImputed                  int64     92598        0   \n",
       "WasDelinquencyBucketImputed                int64     92598        0   \n",
       "WasUtilizationBucketLateBucketImputed      int64     92598        0   \n",
       "\n",
       "                                         missing_%  unique      mean  \\\n",
       "LatePaymentsPerCreditLine                      0.0     201  0.076097   \n",
       "DelinquencyScore                               0.0      38  0.683308   \n",
       "TotalPastDueCapped                             0.0      11  0.409426   \n",
       "UtilizationTimesDelinquency                    0.0   15842  0.001908   \n",
       "DelinquencyBucket                              0.0       4  1.816249   \n",
       "UtilizationBucketLateBucket                    0.0       7  3.209562   \n",
       "UtilizationPerAge                              0.0   82305  0.281012   \n",
       "HasMajorDelinquency                            0.0       2  0.087302   \n",
       "RevolvingUtilizationCappedLog                  0.0   80850  0.216556   \n",
       "DebtToIncomeAgeRisk                            0.0   72746  0.268932   \n",
       "UtilizationPerCreditLine                       0.0   82039  0.726617   \n",
       "IncomePerCreditLine                            0.0   26180  0.321183   \n",
       "HasAnyDelinquency                              0.0       2  0.205091   \n",
       "HighAgeRiskFlag                                0.0       2 -0.001075   \n",
       "WasLatePaymentsPerCreditLineImputed            0.0       2  0.006015   \n",
       "WasDelinquencyScoreImputed                     0.0       1  0.000000   \n",
       "WasTotalPastDueCappedImputed                   0.0       1  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed          0.0       2  0.053478   \n",
       "WasUtilizationPerAgeImputed                    0.0       2  0.053478   \n",
       "WasHasMajorDelinquencyImputed                  0.0       1  0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed        0.0       2  0.053478   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.0       1  0.000000   \n",
       "WasUtilizationPerCreditLineImputed             0.0       2  0.059494   \n",
       "WasIncomePerCreditLineImputed                  0.0       2  0.006015   \n",
       "WasHasAnyDelinquencyImputed                    0.0       1  0.000000   \n",
       "WasHighAgeRiskFlagImputed                      0.0       1  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.0       1  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.0       1  0.000000   \n",
       "\n",
       "                                              std       min       25%  \\\n",
       "LatePaymentsPerCreditLine                0.300314  0.000000  0.000000   \n",
       "DelinquencyScore                         2.492097  0.000000  0.000000   \n",
       "TotalPastDueCapped                       1.097088  0.000000  0.000000   \n",
       "UtilizationTimesDelinquency              0.005049  0.000000  0.000000   \n",
       "DelinquencyBucket                        0.657420  0.000000  2.000000   \n",
       "UtilizationBucketLateBucket              1.775414  0.000000  2.000000   \n",
       "UtilizationPerAge                        0.771726 -0.416697 -0.314413   \n",
       "HasMajorDelinquency                      0.282279  0.000000  0.000000   \n",
       "RevolvingUtilizationCappedLog            0.633069 -0.440434 -0.320875   \n",
       "DebtToIncomeAgeRisk                      1.608289 -0.444698 -0.422533   \n",
       "UtilizationPerCreditLine                 2.314940 -0.439705 -0.309695   \n",
       "IncomePerCreditLine                      2.143377 -0.712727 -0.399441   \n",
       "HasAnyDelinquency                        0.403770  0.000000  0.000000   \n",
       "HighAgeRiskFlag                          1.000129 -1.121933 -1.121933   \n",
       "WasLatePaymentsPerCreditLineImputed      0.077325  0.000000  0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000  0.000000   \n",
       "WasTotalPastDueCappedImputed             0.000000  0.000000  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.224987  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed              0.224987  0.000000  0.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000  0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.224987  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000  0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.236548  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed            0.077325  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000  0.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000  0.000000   \n",
       "\n",
       "                                              50%       75%         max  \\\n",
       "LatePaymentsPerCreditLine                0.000000  0.000000   30.000000   \n",
       "DelinquencyScore                         0.000000  0.000000   60.000000   \n",
       "TotalPastDueCapped                       0.000000  0.000000   10.000000   \n",
       "UtilizationTimesDelinquency              0.000000  0.000000    0.071670   \n",
       "DelinquencyBucket                        2.000000  2.000000    3.000000   \n",
       "UtilizationBucketLateBucket              3.000000  5.000000    6.000000   \n",
       "UtilizationPerAge                        0.000000  0.681580    8.241714   \n",
       "HasMajorDelinquency                      0.000000  0.000000    1.000000   \n",
       "RevolvingUtilizationCappedLog            0.000000  0.673260    4.139011   \n",
       "DebtToIncomeAgeRisk                      0.028949  0.586787  230.122301   \n",
       "UtilizationPerCreditLine                 0.000000  0.707668   39.419312   \n",
       "IncomePerCreditLine                      0.014545  0.575909  279.287273   \n",
       "HasAnyDelinquency                        0.000000  0.000000    1.000000   \n",
       "HighAgeRiskFlag                          0.891319  0.891319    0.891319   \n",
       "WasLatePaymentsPerCreditLineImputed      0.000000  0.000000    1.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000    0.000000   \n",
       "WasTotalPastDueCappedImputed             0.000000  0.000000    0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerAgeImputed              0.000000  0.000000    1.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000    0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.000000  0.000000    1.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000    0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.000000  0.000000    1.000000   \n",
       "WasIncomePerCreditLineImputed            0.000000  0.000000    1.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000    0.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000    0.000000   \n",
       "\n",
       "                                              skew  corr_with_target  \\\n",
       "LatePaymentsPerCreditLine                18.388191          0.309645   \n",
       "DelinquencyScore                         11.231471          0.361854   \n",
       "TotalPastDueCapped                        4.180515          0.399287   \n",
       "UtilizationTimesDelinquency               3.093738          0.364758   \n",
       "DelinquencyBucket                        -1.622637          0.053309   \n",
       "UtilizationBucketLateBucket              -0.241138         -0.057175   \n",
       "UtilizationPerAge                         1.678331          0.268645   \n",
       "HasMajorDelinquency                       2.924108          0.362474   \n",
       "RevolvingUtilizationCappedLog             1.117564          0.271133   \n",
       "DebtToIncomeAgeRisk                      66.268737          0.031882   \n",
       "UtilizationPerCreditLine                  4.650212          0.177593   \n",
       "IncomePerCreditLine                      51.497662          0.003751   \n",
       "HasAnyDelinquency                         1.460809          0.311074   \n",
       "HighAgeRiskFlag                          -0.228439         -0.089933   \n",
       "WasLatePaymentsPerCreditLineImputed      12.777148          0.070744   \n",
       "WasDelinquencyScoreImputed                0.000000               NaN   \n",
       "WasTotalPastDueCappedImputed              0.000000               NaN   \n",
       "WasUtilizationTimesDelinquencyImputed     3.969398         -0.026322   \n",
       "WasUtilizationPerAgeImputed               3.969398         -0.026322   \n",
       "WasHasMajorDelinquencyImputed             0.000000               NaN   \n",
       "WasRevolvingUtilizationCappedLogImputed   3.969398         -0.026322   \n",
       "WasDebtToIncomeAgeRiskImputed             0.000000               NaN   \n",
       "WasUtilizationPerCreditLineImputed        3.724540         -0.001910   \n",
       "WasIncomePerCreditLineImputed            12.777148          0.070744   \n",
       "WasHasAnyDelinquencyImputed               0.000000               NaN   \n",
       "WasHighAgeRiskFlagImputed                 0.000000               NaN   \n",
       "WasDelinquencyBucketImputed               0.000000               NaN   \n",
       "WasUtilizationBucketLateBucketImputed     0.000000               NaN   \n",
       "\n",
       "                                         high_corr_flag  \\\n",
       "LatePaymentsPerCreditLine                         False   \n",
       "DelinquencyScore                                   True   \n",
       "TotalPastDueCapped                                 True   \n",
       "UtilizationTimesDelinquency                        True   \n",
       "DelinquencyBucket                                 False   \n",
       "UtilizationBucketLateBucket                       False   \n",
       "UtilizationPerAge                                  True   \n",
       "HasMajorDelinquency                               False   \n",
       "RevolvingUtilizationCappedLog                      True   \n",
       "DebtToIncomeAgeRisk                               False   \n",
       "UtilizationPerCreditLine                          False   \n",
       "IncomePerCreditLine                               False   \n",
       "HasAnyDelinquency                                  True   \n",
       "HighAgeRiskFlag                                   False   \n",
       "WasLatePaymentsPerCreditLineImputed                True   \n",
       "WasDelinquencyScoreImputed                        False   \n",
       "WasTotalPastDueCappedImputed                      False   \n",
       "WasUtilizationTimesDelinquencyImputed              True   \n",
       "WasUtilizationPerAgeImputed                        True   \n",
       "WasHasMajorDelinquencyImputed                     False   \n",
       "WasRevolvingUtilizationCappedLogImputed            True   \n",
       "WasDebtToIncomeAgeRiskImputed                     False   \n",
       "WasUtilizationPerCreditLineImputed                 True   \n",
       "WasIncomePerCreditLineImputed                      True   \n",
       "WasHasAnyDelinquencyImputed                       False   \n",
       "WasHighAgeRiskFlagImputed                         False   \n",
       "WasDelinquencyBucketImputed                       False   \n",
       "WasUtilizationBucketLateBucketImputed             False   \n",
       "\n",
       "                                                                                                                                                                  high_corr_with  \n",
       "LatePaymentsPerCreditLine                                                                                                                                                         \n",
       "DelinquencyScore                                                                                                                                       TotalPastDueCapped (0.86)  \n",
       "TotalPastDueCapped                                                                                                             DelinquencyScore (0.86), HasAnyDelinquency (0.73)  \n",
       "UtilizationTimesDelinquency                                                                                                                             HasAnyDelinquency (0.74)  \n",
       "DelinquencyBucket                                                                                                                                                                 \n",
       "UtilizationBucketLateBucket                                                                                                                                                       \n",
       "UtilizationPerAge                                                                                                                           RevolvingUtilizationCappedLog (0.92)  \n",
       "HasMajorDelinquency                                                                                                                                                               \n",
       "RevolvingUtilizationCappedLog                                                                                                                           UtilizationPerAge (0.92)  \n",
       "DebtToIncomeAgeRisk                                                                                                                                                               \n",
       "UtilizationPerCreditLine                                                                                                                                                          \n",
       "IncomePerCreditLine                                                                                                                                                               \n",
       "HasAnyDelinquency                                                                                                  UtilizationTimesDelinquency (0.74), TotalPastDueCapped (0.73)  \n",
       "HighAgeRiskFlag                                                                                                                                                                   \n",
       "WasLatePaymentsPerCreditLineImputed                                                                                                         WasIncomePerCreditLineImputed (1.00)  \n",
       "WasDelinquencyScoreImputed                                                                                                                                                        \n",
       "WasTotalPastDueCappedImputed                                                                                                                                                      \n",
       "WasUtilizationTimesDelinquencyImputed              WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasUtilizationPerAgeImputed              WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasHasMajorDelinquencyImputed                                                                                                                                                     \n",
       "WasRevolvingUtilizationCappedLogImputed              WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                                                     \n",
       "WasUtilizationPerCreditLineImputed              WasUtilizationTimesDelinquencyImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95), WasUtilizationPerAgeImputed (0.95)  \n",
       "WasIncomePerCreditLineImputed                                                                                                         WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasHasAnyDelinquencyImputed                                                                                                                                                       \n",
       "WasHighAgeRiskFlagImputed                                                                                                                                                         \n",
       "WasDelinquencyBucketImputed                                                                                                                                                       \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                                                             "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasDelinquencyBucketImputed\",\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasHasAnyDelinquencyImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasIncomePerCreditLineImputed\",\n",
    "    \"WasLatePaymentsPerCreditLineImputed\",\n",
    "    \"WasRevolvingUtilizationCappedLogImputed\",\n",
    "    \"WasTotalPastDueCappedImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "    \"WasUtilizationPerAgeImputed\",\n",
    "    \"WasUtilizationPerCreditLineImputed\",\n",
    "    \"WasUtilizationTimesDelinquencyImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# NN\n",
    "X_train_flags_nn = X_train[X_train_flags]\n",
    "X_val_flags_nn = X_val[X_val_flags]\n",
    "X_test_flags_nn = X_test[X_test_flags]\n",
    "\n",
    "X_train_nn_encoded = pd.get_dummies(X_train, columns=cat_col_order)\n",
    "X_val_nn_encoded = pd.get_dummies(X_val, columns=cat_col_order)\n",
    "X_test_nn_encoded = pd.get_dummies(X_test, columns=cat_col_order)\n",
    "\n",
    "X_val_nn_encoded = X_val_nn_encoded.reindex(columns=X_train_nn_encoded.columns)\n",
    "X_test_nn_encoded = X_test_nn_encoded.reindex(columns=X_train_nn_encoded.columns)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_nn_encoded, X_train[num_col_order], X_train_flags_nn], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_nn_encoded, X_val[num_col_order], X_val_flags_nn], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_nn_encoded, X_test[num_col_order], X_test_flags_nn], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([92598, 35])\n",
      "Class weights: {np.int64(0): np.float64(0.5355209586379198), np.int64(1): np.float64(7.538098339303159)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92598, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 53703\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model = NN(X_train_tensor.shape[1]).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.037126 | Train AUC: 0.8266 | Val loss: 0.034616 | Val AUC: 0.8519\n",
      "Epoch 2/75 | Train loss: 0.034286 | Train AUC: 0.8484 | Val loss: 0.034613 | Val AUC: 0.8540\n",
      "Epoch 3/75 | Train loss: 0.034057 | Train AUC: 0.8508 | Val loss: 0.034370 | Val AUC: 0.8509\n",
      "Epoch 4/75 | Train loss: 0.033978 | Train AUC: 0.8525 | Val loss: 0.035046 | Val AUC: 0.8455\n",
      "Epoch 5/75 | Train loss: 0.033806 | Train AUC: 0.8543 | Val loss: 0.034479 | Val AUC: 0.8532\n",
      "Epoch 6/75 | Train loss: 0.033722 | Train AUC: 0.8546 | Val loss: 0.034200 | Val AUC: 0.8536\n",
      "Epoch 7/75 | Train loss: 0.033769 | Train AUC: 0.8545 | Val loss: 0.034570 | Val AUC: 0.8535\n",
      "Epoch 8/75 | Train loss: 0.033677 | Train AUC: 0.8555 | Val loss: 0.034028 | Val AUC: 0.8559\n",
      "Epoch 9/75 | Train loss: 0.033637 | Train AUC: 0.8564 | Val loss: 0.034466 | Val AUC: 0.8529\n",
      "Epoch 10/75 | Train loss: 0.033628 | Train AUC: 0.8561 | Val loss: 0.034130 | Val AUC: 0.8533\n",
      "Epoch 11/75 | Train loss: 0.033584 | Train AUC: 0.8567 | Val loss: 0.034294 | Val AUC: 0.8539\n",
      "Epoch 12/75 | Train loss: 0.033677 | Train AUC: 0.8556 | Val loss: 0.034104 | Val AUC: 0.8554\n",
      "Epoch 13/75 | Train loss: 0.033628 | Train AUC: 0.8563 | Val loss: 0.034020 | Val AUC: 0.8551\n",
      "Epoch 14/75 | Train loss: 0.033548 | Train AUC: 0.8576 | Val loss: 0.034334 | Val AUC: 0.8540\n",
      "Epoch 15/75 | Train loss: 0.033453 | Train AUC: 0.8577 | Val loss: 0.034083 | Val AUC: 0.8532\n",
      "Epoch 16/75 | Train loss: 0.033423 | Train AUC: 0.8578 | Val loss: 0.034044 | Val AUC: 0.8559\n",
      "Epoch 17/75 | Train loss: 0.033351 | Train AUC: 0.8590 | Val loss: 0.033986 | Val AUC: 0.8559\n",
      "Epoch 18/75 | Train loss: 0.033396 | Train AUC: 0.8587 | Val loss: 0.034239 | Val AUC: 0.8554\n",
      "Epoch 19/75 | Train loss: 0.033312 | Train AUC: 0.8596 | Val loss: 0.034219 | Val AUC: 0.8551\n",
      "Epoch 20/75 | Train loss: 0.033408 | Train AUC: 0.8582 | Val loss: 0.034216 | Val AUC: 0.8556\n",
      "Epoch 21/75 | Train loss: 0.033242 | Train AUC: 0.8600 | Val loss: 0.033953 | Val AUC: 0.8566\n",
      "Epoch 22/75 | Train loss: 0.033255 | Train AUC: 0.8602 | Val loss: 0.034260 | Val AUC: 0.8518\n",
      "Epoch 23/75 | Train loss: 0.033209 | Train AUC: 0.8605 | Val loss: 0.034429 | Val AUC: 0.8562\n",
      "Epoch 24/75 | Train loss: 0.033201 | Train AUC: 0.8606 | Val loss: 0.034021 | Val AUC: 0.8562\n",
      "Epoch 25/75 | Train loss: 0.033283 | Train AUC: 0.8597 | Val loss: 0.033954 | Val AUC: 0.8564\n",
      "Epoch 26/75 | Train loss: 0.033106 | Train AUC: 0.8617 | Val loss: 0.034091 | Val AUC: 0.8544\n",
      "Epoch 27/75 | Train loss: 0.033191 | Train AUC: 0.8604 | Val loss: 0.034257 | Val AUC: 0.8563\n",
      "Epoch 28/75 | Train loss: 0.033171 | Train AUC: 0.8610 | Val loss: 0.034110 | Val AUC: 0.8565\n",
      "Epoch 29/75 | Train loss: 0.033103 | Train AUC: 0.8618 | Val loss: 0.034226 | Val AUC: 0.8524\n",
      "Epoch 30/75 | Train loss: 0.033119 | Train AUC: 0.8612 | Val loss: 0.034092 | Val AUC: 0.8561\n",
      "Epoch 31/75 | Train loss: 0.033106 | Train AUC: 0.8619 | Val loss: 0.033898 | Val AUC: 0.8565\n",
      "Epoch 32/75 | Train loss: 0.033104 | Train AUC: 0.8613 | Val loss: 0.033864 | Val AUC: 0.8563\n",
      "Epoch 33/75 | Train loss: 0.033136 | Train AUC: 0.8614 | Val loss: 0.033968 | Val AUC: 0.8567\n",
      "Epoch 34/75 | Train loss: 0.033102 | Train AUC: 0.8620 | Val loss: 0.034254 | Val AUC: 0.8556\n",
      "Epoch 35/75 | Train loss: 0.033100 | Train AUC: 0.8615 | Val loss: 0.033860 | Val AUC: 0.8558\n",
      "Epoch 36/75 | Train loss: 0.033173 | Train AUC: 0.8610 | Val loss: 0.034033 | Val AUC: 0.8566\n",
      "Epoch 37/75 | Train loss: 0.033071 | Train AUC: 0.8620 | Val loss: 0.033966 | Val AUC: 0.8560\n",
      "Epoch 38/75 | Train loss: 0.033069 | Train AUC: 0.8623 | Val loss: 0.034221 | Val AUC: 0.8546\n",
      "Epoch 39/75 | Train loss: 0.033081 | Train AUC: 0.8620 | Val loss: 0.034343 | Val AUC: 0.8564\n",
      "Epoch 40/75 | Train loss: 0.033072 | Train AUC: 0.8617 | Val loss: 0.034048 | Val AUC: 0.8567\n",
      "Epoch 41/75 | Train loss: 0.033039 | Train AUC: 0.8623 | Val loss: 0.033939 | Val AUC: 0.8565\n",
      "Epoch 42/75 | Train loss: 0.033031 | Train AUC: 0.8626 | Val loss: 0.033891 | Val AUC: 0.8569\n",
      "Epoch 43/75 | Train loss: 0.032988 | Train AUC: 0.8631 | Val loss: 0.034330 | Val AUC: 0.8541\n",
      "Epoch 44/75 | Train loss: 0.033067 | Train AUC: 0.8623 | Val loss: 0.034079 | Val AUC: 0.8568\n",
      "Epoch 45/75 | Train loss: 0.033074 | Train AUC: 0.8618 | Val loss: 0.034327 | Val AUC: 0.8541\n",
      "Epoch 46/75 | Train loss: 0.033065 | Train AUC: 0.8620 | Val loss: 0.033952 | Val AUC: 0.8561\n",
      "Epoch 47/75 | Train loss: 0.033015 | Train AUC: 0.8627 | Val loss: 0.033985 | Val AUC: 0.8563\n",
      "Epoch 48/75 | Train loss: 0.033046 | Train AUC: 0.8619 | Val loss: 0.034128 | Val AUC: 0.8561\n",
      "Epoch 49/75 | Train loss: 0.033074 | Train AUC: 0.8617 | Val loss: 0.034168 | Val AUC: 0.8535\n",
      "Epoch 50/75 | Train loss: 0.033058 | Train AUC: 0.8619 | Val loss: 0.034243 | Val AUC: 0.8558\n",
      "Epoch 51/75 | Train loss: 0.032999 | Train AUC: 0.8627 | Val loss: 0.033929 | Val AUC: 0.8567\n",
      "Epoch 52/75 | Train loss: 0.033032 | Train AUC: 0.8624 | Val loss: 0.034119 | Val AUC: 0.8565\n",
      "Epoch 53/75 | Train loss: 0.032959 | Train AUC: 0.8635 | Val loss: 0.033827 | Val AUC: 0.8565\n",
      "Epoch 54/75 | Train loss: 0.033085 | Train AUC: 0.8619 | Val loss: 0.033932 | Val AUC: 0.8566\n",
      "Early stopping at epoch 55\n",
      "Run 1 best Val AUC: 0.8569\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.033429 | Train AUC: 0.8586 | Val loss: 0.033969 | Val AUC: 0.8560\n",
      "Epoch 2/75 | Train loss: 0.033371 | Train AUC: 0.8594 | Val loss: 0.034589 | Val AUC: 0.8547\n",
      "Epoch 3/75 | Train loss: 0.033395 | Train AUC: 0.8584 | Val loss: 0.034419 | Val AUC: 0.8505\n",
      "Epoch 4/75 | Train loss: 0.033353 | Train AUC: 0.8591 | Val loss: 0.035133 | Val AUC: 0.8515\n",
      "Epoch 5/75 | Train loss: 0.033460 | Train AUC: 0.8580 | Val loss: 0.034431 | Val AUC: 0.8529\n",
      "Epoch 6/75 | Train loss: 0.033455 | Train AUC: 0.8581 | Val loss: 0.034079 | Val AUC: 0.8549\n",
      "Epoch 7/75 | Train loss: 0.033451 | Train AUC: 0.8581 | Val loss: 0.034054 | Val AUC: 0.8561\n",
      "Epoch 8/75 | Train loss: 0.033422 | Train AUC: 0.8580 | Val loss: 0.034139 | Val AUC: 0.8527\n",
      "Epoch 9/75 | Train loss: 0.033350 | Train AUC: 0.8590 | Val loss: 0.034280 | Val AUC: 0.8541\n",
      "Epoch 10/75 | Train loss: 0.033449 | Train AUC: 0.8580 | Val loss: 0.034024 | Val AUC: 0.8553\n",
      "Epoch 11/75 | Train loss: 0.033369 | Train AUC: 0.8586 | Val loss: 0.033989 | Val AUC: 0.8562\n",
      "Epoch 12/75 | Train loss: 0.033401 | Train AUC: 0.8588 | Val loss: 0.033847 | Val AUC: 0.8559\n",
      "Epoch 13/75 | Train loss: 0.033326 | Train AUC: 0.8595 | Val loss: 0.034186 | Val AUC: 0.8554\n",
      "Epoch 14/75 | Train loss: 0.033305 | Train AUC: 0.8595 | Val loss: 0.034063 | Val AUC: 0.8564\n",
      "Epoch 15/75 | Train loss: 0.033327 | Train AUC: 0.8594 | Val loss: 0.033980 | Val AUC: 0.8561\n",
      "Epoch 16/75 | Train loss: 0.033266 | Train AUC: 0.8603 | Val loss: 0.034284 | Val AUC: 0.8521\n",
      "Epoch 17/75 | Train loss: 0.033300 | Train AUC: 0.8599 | Val loss: 0.033933 | Val AUC: 0.8560\n",
      "Epoch 18/75 | Train loss: 0.033255 | Train AUC: 0.8601 | Val loss: 0.034371 | Val AUC: 0.8523\n",
      "Epoch 19/75 | Train loss: 0.033347 | Train AUC: 0.8593 | Val loss: 0.034264 | Val AUC: 0.8570\n",
      "Epoch 20/75 | Train loss: 0.033277 | Train AUC: 0.8598 | Val loss: 0.033853 | Val AUC: 0.8563\n",
      "Epoch 21/75 | Train loss: 0.033369 | Train AUC: 0.8588 | Val loss: 0.033800 | Val AUC: 0.8557\n",
      "Epoch 22/75 | Train loss: 0.033324 | Train AUC: 0.8593 | Val loss: 0.034226 | Val AUC: 0.8536\n",
      "Epoch 23/75 | Train loss: 0.033243 | Train AUC: 0.8603 | Val loss: 0.034132 | Val AUC: 0.8542\n",
      "Epoch 24/75 | Train loss: 0.033211 | Train AUC: 0.8607 | Val loss: 0.034297 | Val AUC: 0.8525\n",
      "Epoch 25/75 | Train loss: 0.033310 | Train AUC: 0.8600 | Val loss: 0.033977 | Val AUC: 0.8569\n",
      "Epoch 26/75 | Train loss: 0.033040 | Train AUC: 0.8627 | Val loss: 0.033902 | Val AUC: 0.8557\n",
      "Epoch 27/75 | Train loss: 0.033094 | Train AUC: 0.8619 | Val loss: 0.033850 | Val AUC: 0.8575\n",
      "Epoch 28/75 | Train loss: 0.033087 | Train AUC: 0.8622 | Val loss: 0.033872 | Val AUC: 0.8555\n",
      "Epoch 29/75 | Train loss: 0.033059 | Train AUC: 0.8619 | Val loss: 0.034013 | Val AUC: 0.8556\n",
      "Epoch 30/75 | Train loss: 0.033084 | Train AUC: 0.8620 | Val loss: 0.033869 | Val AUC: 0.8559\n",
      "Epoch 31/75 | Train loss: 0.033078 | Train AUC: 0.8622 | Val loss: 0.033767 | Val AUC: 0.8564\n",
      "Epoch 32/75 | Train loss: 0.033069 | Train AUC: 0.8623 | Val loss: 0.034329 | Val AUC: 0.8552\n",
      "Epoch 33/75 | Train loss: 0.033000 | Train AUC: 0.8633 | Val loss: 0.033930 | Val AUC: 0.8562\n",
      "Epoch 34/75 | Train loss: 0.032979 | Train AUC: 0.8634 | Val loss: 0.033863 | Val AUC: 0.8560\n",
      "Epoch 35/75 | Train loss: 0.032989 | Train AUC: 0.8627 | Val loss: 0.033888 | Val AUC: 0.8570\n",
      "Epoch 36/75 | Train loss: 0.032930 | Train AUC: 0.8636 | Val loss: 0.033968 | Val AUC: 0.8542\n",
      "Epoch 37/75 | Train loss: 0.033005 | Train AUC: 0.8627 | Val loss: 0.033817 | Val AUC: 0.8556\n",
      "Epoch 38/75 | Train loss: 0.032930 | Train AUC: 0.8636 | Val loss: 0.034073 | Val AUC: 0.8531\n",
      "Epoch 39/75 | Train loss: 0.032916 | Train AUC: 0.8639 | Val loss: 0.034035 | Val AUC: 0.8542\n",
      "Early stopping at epoch 40\n",
      "Run 2 best Val AUC: 0.8575\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8575)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F-beta (=2): 0.3142205476760864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.73      0.35      1978\n",
      "\n",
      "    accuracy                           0.82     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.82      0.86     29846\n",
      "\n",
      "Accuracy: 82.36%\n",
      "ROC AUC: 0.859\n",
      "TP=1437, FP=4724, TN=23144, FN=541\n",
      "Accuracy for class 'Repaid': 83.05%\n",
      "Accuracy for class 'Defaulted': 72.65%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, target_recall=0.71)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F-beta (=2):\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best params: {'subsample': 0.9, 'scale_pos_weight': np.float64(14.076196678606317), 'reg_lambda': 1.0, 'reg_alpha': 0.3, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0.5, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83419\n",
      "[1]\tvalidation_0-auc:0.84761\n",
      "[2]\tvalidation_0-auc:0.84937\n",
      "[3]\tvalidation_0-auc:0.85061\n",
      "[4]\tvalidation_0-auc:0.85113\n",
      "[5]\tvalidation_0-auc:0.85200\n",
      "[6]\tvalidation_0-auc:0.85257\n",
      "[7]\tvalidation_0-auc:0.85263\n",
      "[8]\tvalidation_0-auc:0.85303\n",
      "[9]\tvalidation_0-auc:0.85271\n",
      "[10]\tvalidation_0-auc:0.85328\n",
      "[11]\tvalidation_0-auc:0.85356\n",
      "[12]\tvalidation_0-auc:0.85354\n",
      "[13]\tvalidation_0-auc:0.85357\n",
      "[14]\tvalidation_0-auc:0.85379\n",
      "[15]\tvalidation_0-auc:0.85399\n",
      "[16]\tvalidation_0-auc:0.85402\n",
      "[17]\tvalidation_0-auc:0.85407\n",
      "[18]\tvalidation_0-auc:0.85436\n",
      "[19]\tvalidation_0-auc:0.85429\n",
      "[20]\tvalidation_0-auc:0.85443\n",
      "[21]\tvalidation_0-auc:0.85462\n",
      "[22]\tvalidation_0-auc:0.85462\n",
      "[23]\tvalidation_0-auc:0.85470\n",
      "[24]\tvalidation_0-auc:0.85485\n",
      "[25]\tvalidation_0-auc:0.85485\n",
      "[26]\tvalidation_0-auc:0.85491\n",
      "[27]\tvalidation_0-auc:0.85507\n",
      "[28]\tvalidation_0-auc:0.85508\n",
      "[29]\tvalidation_0-auc:0.85509\n",
      "[30]\tvalidation_0-auc:0.85526\n",
      "[31]\tvalidation_0-auc:0.85524\n",
      "[32]\tvalidation_0-auc:0.85528\n",
      "[33]\tvalidation_0-auc:0.85530\n",
      "[34]\tvalidation_0-auc:0.85542\n",
      "[35]\tvalidation_0-auc:0.85543\n",
      "[36]\tvalidation_0-auc:0.85547\n",
      "[37]\tvalidation_0-auc:0.85559\n",
      "[38]\tvalidation_0-auc:0.85562\n",
      "[39]\tvalidation_0-auc:0.85577\n",
      "[40]\tvalidation_0-auc:0.85586\n",
      "[41]\tvalidation_0-auc:0.85583\n",
      "[42]\tvalidation_0-auc:0.85597\n",
      "[43]\tvalidation_0-auc:0.85606\n",
      "[44]\tvalidation_0-auc:0.85616\n",
      "[45]\tvalidation_0-auc:0.85621\n",
      "[46]\tvalidation_0-auc:0.85630\n",
      "[47]\tvalidation_0-auc:0.85637\n",
      "[48]\tvalidation_0-auc:0.85643\n",
      "[49]\tvalidation_0-auc:0.85651\n",
      "[50]\tvalidation_0-auc:0.85653\n",
      "[51]\tvalidation_0-auc:0.85650\n",
      "[52]\tvalidation_0-auc:0.85649\n",
      "[53]\tvalidation_0-auc:0.85657\n",
      "[54]\tvalidation_0-auc:0.85654\n",
      "[55]\tvalidation_0-auc:0.85664\n",
      "[56]\tvalidation_0-auc:0.85675\n",
      "[57]\tvalidation_0-auc:0.85680\n",
      "[58]\tvalidation_0-auc:0.85684\n",
      "[59]\tvalidation_0-auc:0.85691\n",
      "[60]\tvalidation_0-auc:0.85695\n",
      "[61]\tvalidation_0-auc:0.85701\n",
      "[62]\tvalidation_0-auc:0.85710\n",
      "[63]\tvalidation_0-auc:0.85714\n",
      "[64]\tvalidation_0-auc:0.85717\n",
      "[65]\tvalidation_0-auc:0.85714\n",
      "[66]\tvalidation_0-auc:0.85719\n",
      "[67]\tvalidation_0-auc:0.85718\n",
      "[68]\tvalidation_0-auc:0.85723\n",
      "[69]\tvalidation_0-auc:0.85733\n",
      "[70]\tvalidation_0-auc:0.85738\n",
      "[71]\tvalidation_0-auc:0.85748\n",
      "[72]\tvalidation_0-auc:0.85749\n",
      "[73]\tvalidation_0-auc:0.85750\n",
      "[74]\tvalidation_0-auc:0.85758\n",
      "[75]\tvalidation_0-auc:0.85767\n",
      "[76]\tvalidation_0-auc:0.85775\n",
      "[77]\tvalidation_0-auc:0.85778\n",
      "[78]\tvalidation_0-auc:0.85779\n",
      "[79]\tvalidation_0-auc:0.85777\n",
      "[80]\tvalidation_0-auc:0.85785\n",
      "[81]\tvalidation_0-auc:0.85784\n",
      "[82]\tvalidation_0-auc:0.85787\n",
      "[83]\tvalidation_0-auc:0.85787\n",
      "[84]\tvalidation_0-auc:0.85792\n",
      "[85]\tvalidation_0-auc:0.85797\n",
      "[86]\tvalidation_0-auc:0.85799\n",
      "[87]\tvalidation_0-auc:0.85797\n",
      "[88]\tvalidation_0-auc:0.85798\n",
      "[89]\tvalidation_0-auc:0.85799\n",
      "[90]\tvalidation_0-auc:0.85800\n",
      "[91]\tvalidation_0-auc:0.85800\n",
      "[92]\tvalidation_0-auc:0.85795\n",
      "[93]\tvalidation_0-auc:0.85798\n",
      "[94]\tvalidation_0-auc:0.85793\n",
      "[95]\tvalidation_0-auc:0.85791\n",
      "[96]\tvalidation_0-auc:0.85785\n",
      "[97]\tvalidation_0-auc:0.85783\n",
      "[98]\tvalidation_0-auc:0.85782\n",
      "[99]\tvalidation_0-auc:0.85783\n",
      "[100]\tvalidation_0-auc:0.85785\n",
      "[101]\tvalidation_0-auc:0.85786\n",
      "[102]\tvalidation_0-auc:0.85784\n",
      "[103]\tvalidation_0-auc:0.85787\n",
      "[104]\tvalidation_0-auc:0.85787\n",
      "[105]\tvalidation_0-auc:0.85797\n",
      "[106]\tvalidation_0-auc:0.85796\n",
      "[107]\tvalidation_0-auc:0.85797\n",
      "[108]\tvalidation_0-auc:0.85801\n",
      "[109]\tvalidation_0-auc:0.85792\n",
      "[110]\tvalidation_0-auc:0.85790\n",
      "[111]\tvalidation_0-auc:0.85790\n",
      "[112]\tvalidation_0-auc:0.85790\n",
      "[113]\tvalidation_0-auc:0.85792\n",
      "[114]\tvalidation_0-auc:0.85791\n",
      "[115]\tvalidation_0-auc:0.85789\n",
      "[116]\tvalidation_0-auc:0.85792\n",
      "[117]\tvalidation_0-auc:0.85795\n",
      "[118]\tvalidation_0-auc:0.85787\n",
      "[119]\tvalidation_0-auc:0.85782\n",
      "[120]\tvalidation_0-auc:0.85780\n",
      "[121]\tvalidation_0-auc:0.85781\n",
      "[122]\tvalidation_0-auc:0.85783\n",
      "[123]\tvalidation_0-auc:0.85777\n",
      "[124]\tvalidation_0-auc:0.85773\n",
      "[125]\tvalidation_0-auc:0.85774\n",
      "[126]\tvalidation_0-auc:0.85776\n",
      "[127]\tvalidation_0-auc:0.85775\n",
      "[128]\tvalidation_0-auc:0.85778\n",
      "[129]\tvalidation_0-auc:0.85774\n",
      "[130]\tvalidation_0-auc:0.85772\n",
      "[131]\tvalidation_0-auc:0.85773\n",
      "[132]\tvalidation_0-auc:0.85777\n",
      "[133]\tvalidation_0-auc:0.85782\n",
      "[134]\tvalidation_0-auc:0.85784\n",
      "[135]\tvalidation_0-auc:0.85780\n",
      "[136]\tvalidation_0-auc:0.85782\n",
      "[137]\tvalidation_0-auc:0.85781\n",
      "[138]\tvalidation_0-auc:0.85782\n",
      "[139]\tvalidation_0-auc:0.85777\n",
      "[140]\tvalidation_0-auc:0.85776\n",
      "[141]\tvalidation_0-auc:0.85771\n",
      "[142]\tvalidation_0-auc:0.85770\n",
      "[143]\tvalidation_0-auc:0.85768\n",
      "[144]\tvalidation_0-auc:0.85773\n",
      "[145]\tvalidation_0-auc:0.85770\n",
      "[146]\tvalidation_0-auc:0.85760\n",
      "[147]\tvalidation_0-auc:0.85765\n",
      "[148]\tvalidation_0-auc:0.85765\n",
      "[149]\tvalidation_0-auc:0.85764\n",
      "[150]\tvalidation_0-auc:0.85761\n",
      "[151]\tvalidation_0-auc:0.85760\n",
      "[152]\tvalidation_0-auc:0.85761\n",
      "[153]\tvalidation_0-auc:0.85755\n",
      "[154]\tvalidation_0-auc:0.85761\n",
      "[155]\tvalidation_0-auc:0.85765\n",
      "[156]\tvalidation_0-auc:0.85754\n",
      "[157]\tvalidation_0-auc:0.85756\n",
      "[158]\tvalidation_0-auc:0.85758\n",
      "[159]\tvalidation_0-auc:0.85757\n",
      "[160]\tvalidation_0-auc:0.85754\n",
      "[161]\tvalidation_0-auc:0.85756\n",
      "[162]\tvalidation_0-auc:0.85751\n",
      "[163]\tvalidation_0-auc:0.85759\n",
      "[164]\tvalidation_0-auc:0.85749\n",
      "[165]\tvalidation_0-auc:0.85751\n",
      "[166]\tvalidation_0-auc:0.85748\n",
      "[167]\tvalidation_0-auc:0.85750\n",
      "[168]\tvalidation_0-auc:0.85751\n",
      "[169]\tvalidation_0-auc:0.85750\n",
      "[170]\tvalidation_0-auc:0.85753\n",
      "[171]\tvalidation_0-auc:0.85756\n",
      "[172]\tvalidation_0-auc:0.85757\n",
      "[173]\tvalidation_0-auc:0.85754\n",
      "[174]\tvalidation_0-auc:0.85751\n",
      "[175]\tvalidation_0-auc:0.85744\n",
      "[176]\tvalidation_0-auc:0.85742\n",
      "[177]\tvalidation_0-auc:0.85741\n",
      "[178]\tvalidation_0-auc:0.85740\n",
      "[179]\tvalidation_0-auc:0.85742\n",
      "[180]\tvalidation_0-auc:0.85740\n",
      "[181]\tvalidation_0-auc:0.85733\n",
      "[182]\tvalidation_0-auc:0.85733\n",
      "[183]\tvalidation_0-auc:0.85730\n",
      "[184]\tvalidation_0-auc:0.85731\n",
      "[185]\tvalidation_0-auc:0.85728\n",
      "[186]\tvalidation_0-auc:0.85730\n",
      "[187]\tvalidation_0-auc:0.85730\n",
      "[188]\tvalidation_0-auc:0.85730\n",
      "[189]\tvalidation_0-auc:0.85729\n",
      "[190]\tvalidation_0-auc:0.85724\n",
      "[191]\tvalidation_0-auc:0.85724\n",
      "[192]\tvalidation_0-auc:0.85724\n",
      "[193]\tvalidation_0-auc:0.85723\n",
      "[194]\tvalidation_0-auc:0.85722\n",
      "[195]\tvalidation_0-auc:0.85720\n",
      "[196]\tvalidation_0-auc:0.85725\n",
      "[197]\tvalidation_0-auc:0.85730\n",
      "[198]\tvalidation_0-auc:0.85728\n",
      "[199]\tvalidation_0-auc:0.85716\n",
      "[200]\tvalidation_0-auc:0.85712\n",
      "[201]\tvalidation_0-auc:0.85707\n",
      "[202]\tvalidation_0-auc:0.85700\n",
      "[203]\tvalidation_0-auc:0.85699\n",
      "[204]\tvalidation_0-auc:0.85698\n",
      "[205]\tvalidation_0-auc:0.85700\n",
      "[206]\tvalidation_0-auc:0.85698\n",
      "[207]\tvalidation_0-auc:0.85694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=0.5, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.076196678606317)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=0.5, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.5473201274871826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.72      0.35      1978\n",
      "\n",
      "    accuracy                           0.83     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.83      0.86     29846\n",
      "\n",
      "Accuracy: 82.57%\n",
      "ROC AUC: 0.859\n",
      "TP=1424, FP=4649, TN=23219, FN=554\n",
      "Accuracy for class 'Repaid': 83.32%\n",
      "Accuracy for class 'Defaulted': 71.99%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, target_recall=0.72)\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Feature   Importance\n",
      "0               DelinquencyBucket  1698.652710\n",
      "1                DelinquencyScore  1040.542969\n",
      "2              TotalPastDueCapped   829.418152\n",
      "3     UtilizationBucketLateBucket   288.403503\n",
      "4     UtilizationTimesDelinquency   155.876221\n",
      "5               UtilizationPerAge   133.719009\n",
      "6   RevolvingUtilizationCappedLog    97.272995\n",
      "7             HasMajorDelinquency    56.899364\n",
      "8             DebtToIncomeAgeRisk    51.891441\n",
      "9        UtilizationPerCreditLine    45.241066\n",
      "10                HighAgeRiskFlag    43.982548\n",
      "11            IncomePerCreditLine    38.672436\n",
      "12      LatePaymentsPerCreditLine    26.654411\n",
      "13              HasAnyDelinquency     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fc47bede924860a9faa0033d25a929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "14                        DelinquencyBucket_None       0.016326\n",
      "4                              UtilizationPerAge       0.015738\n",
      "21   UtilizationBucketLateBucket_Very Low_NoLate       0.014451\n",
      "27                             UtilizationPerAge       0.009313\n",
      "28                           HasMajorDelinquency       0.007480\n",
      "29                 RevolvingUtilizationCappedLog       0.006083\n",
      "7                            DebtToIncomeAgeRisk       0.005333\n",
      "17        UtilizationBucketLateBucket_Low_NoLate       0.005182\n",
      "32                           IncomePerCreditLine       0.005180\n",
      "30                           DebtToIncomeAgeRisk       0.004093\n",
      "18   UtilizationBucketLateBucket_Moderate_NoLate       0.003711\n",
      "1                               DelinquencyScore       0.002861\n",
      "9                            IncomePerCreditLine       0.002479\n",
      "12                         DelinquencyBucket_Few       0.001665\n",
      "2                             TotalPastDueCapped       0.001589\n",
      "15                       DelinquencyBucket_Other       0.001447\n",
      "22        UtilizationBucketLateBucket_nan_NoLate       0.001281\n",
      "31                      UtilizationPerCreditLine       0.000690\n",
      "13                    DelinquencyBucket_Moderate       0.000658\n",
      "26                   UtilizationTimesDelinquency       0.000587\n",
      "23                     LatePaymentsPerCreditLine       0.000499\n",
      "11                               HighAgeRiskFlag       0.000393\n",
      "8                       UtilizationPerCreditLine       0.000327\n",
      "16       UtilizationBucketLateBucket_High_NoLate       0.000322\n",
      "20  UtilizationBucketLateBucket_Very High_NoLate       0.000251\n",
      "34                               HighAgeRiskFlag       0.000220\n",
      "6                  RevolvingUtilizationCappedLog       0.000139\n",
      "3                    UtilizationTimesDelinquency       0.000038\n",
      "5                            HasMajorDelinquency       0.000005\n",
      "0                      LatePaymentsPerCreditLine       0.000000\n",
      "10                             HasAnyDelinquency       0.000000\n",
      "25                            TotalPastDueCapped       0.000000\n",
      "24                              DelinquencyScore       0.000000\n",
      "19             UtilizationBucketLateBucket_Other       0.000000\n",
      "33                             HasAnyDelinquency       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Shap\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "\n",
    "def shap_ohe(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    model_cpu.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "\n",
    "background = shap.sample(X_train_nn_full.astype('float32').values, 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_nn_full.astype('float32').values[:500])\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
