{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLog / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = RevolvingUtilizationCappedLog\n",
    "    \n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationCappedLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationCapped, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10, random_state=42, bias_mode=None):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "    \n",
    "    minority_class = 1 if pos_count < neg_count else 0\n",
    "    majority_class = 0 if minority_class == 1 else 1\n",
    "\n",
    "    if bias_mode is False:\n",
    "        scale_pos_weight = neg_count / max(1, pos_count)\n",
    "        print(\"Biasing toward minority class\")\n",
    "    elif bias_mode is True:\n",
    "        scale_pos_weight = pos_count / max(1, neg_count)\n",
    "        print(\"Biasing toward majority class\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Using normal class weights\")\n",
    "        \n",
    "    tuned_params = {\n",
    "        'subsample': 0.9, \n",
    "        'reg_lambda': 0.5, \n",
    "        'reg_alpha': 0.1, \n",
    "        'min_child_weight': 7, \n",
    "        'max_depth': 5, \n",
    "        'learning_rate': 0.01, \n",
    "        'gamma': 0.2, \n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=800,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        **tuned_params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "    \n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    numeric_feats = [f for f in feature_cols if f not in cat_cols]\n",
    "    top_numeric = importance_df[importance_df[\"Feature\"].isin(numeric_feats)][\"Feature\"].head(n_to_keep).tolist()\n",
    "    kept_features = top_numeric + cat_cols\n",
    "    dropped_features = [f for f in numeric_feats if f not in top_numeric]\n",
    "\n",
    "    print(f\"Kept {len(kept_features)} select features (including all {len(cat_cols)} categorical)\")\n",
    "    print(f\"Dropped:{len(dropped_features)} numeric select features cols\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols:{dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[kept_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None, drop_target_na=False, show_info=True):\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    target_cleaned = None\n",
    "    \n",
    "    total_duplicates = df_cleaned.duplicated().sum()\n",
    "    if total_duplicates > 0:\n",
    "        df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "        if show_info:\n",
    "            print(f\"Dropped {total_duplicates} duplicate rows. Remaining: {len(df_cleaned)}\")\n",
    "    \n",
    "    if target is not None:\n",
    "        target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "        if drop_target_na:\n",
    "            mask = target_cleaned.notna()\n",
    "            dropped = len(target_cleaned) - mask.sum()\n",
    "            if dropped > 0 and show_info:\n",
    "                print(f\"Dropped {dropped} rows with missing target values\")\n",
    "            df_cleaned = df_cleaned.loc[mask].reset_index(drop=True)\n",
    "            target_cleaned = target_cleaned.loc[mask].reset_index(drop=True)\n",
    "        else:\n",
    "            target_cleaned = target_cleaned.reset_index(drop=True)\n",
    "        return df_cleaned, target_cleaned\n",
    "    else:\n",
    "        return df_cleaned\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def fast_fbeta_scores(y_true, y_probs, thresholds, beta=2, return_details=False):\n",
    "\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FP = (preds & (y_true[:, None] == 0)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "    f_beta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall + 1e-8)\n",
    "\n",
    "    if return_details:\n",
    "        return f_beta, precision, recall\n",
    "    return f_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 609 duplicate rows. Remaining: 149391\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyBucket                         0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasAnyDelinquency                         0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                    1043            1.09\n",
      "LatePaymentsPerCreditLine              1043            1.09\n",
      "RevolvingUtilizationCappedLog          6831            7.15\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      6831            7.15\n",
      "UtilizationPerCreditLine               7874            8.24\n",
      "UtilizationTimesDelinquency            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 29 rare categories: ['Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'Very High_ModerateLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very High_FrequentLate', 'Low_ModerateLate', 'nan_FewLate', 'Very Low_ModerateLate', 'High_FrequentLate', 'Very High_ChronicLate', 'nan_ModerateLate', 'Moderate_FrequentLate', 'Extreme_NoLate', 'Low_FrequentLate', 'High_ChronicLate', 'Very Low_FrequentLate', 'Extreme_ModerateLate', 'Moderate_ChronicLate', 'nan_FrequentLate', 'Extreme_FewLate', 'Extreme_FrequentLate', 'Low_ChronicLate', 'nan_ChronicLate', 'Extreme_ChronicLate', 'Very Low_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normal class weights\n",
      "Kept 13 select features (including all 2 categorical)\n",
      "Dropped:0 numeric select features cols\n",
      "                          Feature  Importance\n",
      "0             HasMajorDelinquency  192.691238\n",
      "1                DelinquencyScore  177.577148\n",
      "2               DelinquencyBucket  161.885620\n",
      "3               HasAnyDelinquency  120.891273\n",
      "4     UtilizationTimesDelinquency   51.297321\n",
      "5     UtilizationBucketLateBucket   46.239021\n",
      "6       LatePaymentsPerCreditLine   39.113415\n",
      "7               UtilizationPerAge   21.187981\n",
      "8   RevolvingUtilizationCappedLog   19.835800\n",
      "9             DebtToIncomeAgeRisk    6.946866\n",
      "10            IncomePerCreditLine    5.722909\n",
      "11       UtilizationPerCreditLine    5.563872\n",
      "12                HighAgeRiskFlag    5.039105\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=15, bias_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2912 duplicate rows. Remaining: 92594\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92594, 26)\n",
      "Total rows: 92594\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087263</td>\n",
       "      <td>0.282221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.924985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.683090</td>\n",
       "      <td>2.491862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.234710</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205056</td>\n",
       "      <td>0.403745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.461070</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationTimesDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15842</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.094077</td>\n",
       "      <td>-0.004518</td>\n",
       "      <td>True</td>\n",
       "      <td>HasAnyDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076095</td>\n",
       "      <td>0.300319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.388049</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.280998</td>\n",
       "      <td>0.771729</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681490</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.678399</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.633060</td>\n",
       "      <td>-0.440434</td>\n",
       "      <td>-0.320879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673136</td>\n",
       "      <td>4.139011</td>\n",
       "      <td>1.117631</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.268963</td>\n",
       "      <td>1.608317</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.422533</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>0.586876</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.268097</td>\n",
       "      <td>-0.003953</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.321212</td>\n",
       "      <td>2.143418</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.399441</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.575962</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.496937</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82039</td>\n",
       "      <td>0.726648</td>\n",
       "      <td>2.314985</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.309696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707815</td>\n",
       "      <td>39.419312</td>\n",
       "      <td>4.650102</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>1.000128</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>-0.228449</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.816241</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.622902</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.209571</td>\n",
       "      <td>1.775452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.241148</td>\n",
       "      <td>-0.005203</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyScoreImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationTimesDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.077188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.800288</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasRevolvingUtilizationCappedLogImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.077188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.800288</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059453</td>\n",
       "      <td>0.236472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.726076</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (0.95), WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHighAgeRiskFlagImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dtype  non_null  missing  \\\n",
       "HasMajorDelinquency                      float64     92594        0   \n",
       "DelinquencyScore                         float64     92594        0   \n",
       "HasAnyDelinquency                        float64     92594        0   \n",
       "UtilizationTimesDelinquency              float64     92594        0   \n",
       "LatePaymentsPerCreditLine                float64     92594        0   \n",
       "UtilizationPerAge                        float64     92594        0   \n",
       "RevolvingUtilizationCappedLog            float64     92594        0   \n",
       "DebtToIncomeAgeRisk                      float64     92594        0   \n",
       "IncomePerCreditLine                      float64     92594        0   \n",
       "UtilizationPerCreditLine                 float64     92594        0   \n",
       "HighAgeRiskFlag                          float64     92594        0   \n",
       "DelinquencyBucket                           int8     92594        0   \n",
       "UtilizationBucketLateBucket                 int8     92594        0   \n",
       "WasHasMajorDelinquencyImputed              int64     92594        0   \n",
       "WasDelinquencyScoreImputed                 int64     92594        0   \n",
       "WasHasAnyDelinquencyImputed                int64     92594        0   \n",
       "WasUtilizationTimesDelinquencyImputed      int64     92594        0   \n",
       "WasLatePaymentsPerCreditLineImputed        int64     92594        0   \n",
       "WasUtilizationPerAgeImputed                int64     92594        0   \n",
       "WasRevolvingUtilizationCappedLogImputed    int64     92594        0   \n",
       "WasDebtToIncomeAgeRiskImputed              int64     92594        0   \n",
       "WasIncomePerCreditLineImputed              int64     92594        0   \n",
       "WasUtilizationPerCreditLineImputed         int64     92594        0   \n",
       "WasHighAgeRiskFlagImputed                  int64     92594        0   \n",
       "WasDelinquencyBucketImputed                int64     92594        0   \n",
       "WasUtilizationBucketLateBucketImputed      int64     92594        0   \n",
       "\n",
       "                                         missing_%  unique      mean  \\\n",
       "HasMajorDelinquency                            0.0       2  0.087263   \n",
       "DelinquencyScore                               0.0      38  0.683090   \n",
       "HasAnyDelinquency                              0.0       2  0.205056   \n",
       "UtilizationTimesDelinquency                    0.0   15842  0.001908   \n",
       "LatePaymentsPerCreditLine                      0.0     201  0.076095   \n",
       "UtilizationPerAge                              0.0   82305  0.280998   \n",
       "RevolvingUtilizationCappedLog                  0.0   80850  0.216537   \n",
       "DebtToIncomeAgeRisk                            0.0   72746  0.268963   \n",
       "IncomePerCreditLine                            0.0   26180  0.321212   \n",
       "UtilizationPerCreditLine                       0.0   82039  0.726648   \n",
       "HighAgeRiskFlag                                0.0       2 -0.001070   \n",
       "DelinquencyBucket                              0.0       4  1.816241   \n",
       "UtilizationBucketLateBucket                    0.0       7  3.209571   \n",
       "WasHasMajorDelinquencyImputed                  0.0       1  0.000000   \n",
       "WasDelinquencyScoreImputed                     0.0       1  0.000000   \n",
       "WasHasAnyDelinquencyImputed                    0.0       1  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed          0.0       2  0.053459   \n",
       "WasLatePaymentsPerCreditLineImputed            0.0       2  0.005994   \n",
       "WasUtilizationPerAgeImputed                    0.0       2  0.053459   \n",
       "WasRevolvingUtilizationCappedLogImputed        0.0       2  0.053459   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.0       1  0.000000   \n",
       "WasIncomePerCreditLineImputed                  0.0       2  0.005994   \n",
       "WasUtilizationPerCreditLineImputed             0.0       2  0.059453   \n",
       "WasHighAgeRiskFlagImputed                      0.0       1  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.0       1  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.0       1  0.000000   \n",
       "\n",
       "                                              std       min       25%  \\\n",
       "HasMajorDelinquency                      0.282221  0.000000  0.000000   \n",
       "DelinquencyScore                         2.491862  0.000000  0.000000   \n",
       "HasAnyDelinquency                        0.403745  0.000000  0.000000   \n",
       "UtilizationTimesDelinquency              0.005049  0.000000  0.000000   \n",
       "LatePaymentsPerCreditLine                0.300319  0.000000  0.000000   \n",
       "UtilizationPerAge                        0.771729 -0.416697 -0.314414   \n",
       "RevolvingUtilizationCappedLog            0.633060 -0.440434 -0.320879   \n",
       "DebtToIncomeAgeRisk                      1.608317 -0.444698 -0.422533   \n",
       "IncomePerCreditLine                      2.143418 -0.712727 -0.399441   \n",
       "UtilizationPerCreditLine                 2.314985 -0.439705 -0.309696   \n",
       "HighAgeRiskFlag                          1.000128 -1.121933 -1.121933   \n",
       "DelinquencyBucket                        0.657400  0.000000  2.000000   \n",
       "UtilizationBucketLateBucket              1.775452  0.000000  2.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000  0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.224949  0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.077188  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed              0.224949  0.000000  0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.224949  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed            0.077188  0.000000  0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.236472  0.000000  0.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000  0.000000   \n",
       "\n",
       "                                              50%       75%         max  \\\n",
       "HasMajorDelinquency                      0.000000  0.000000    1.000000   \n",
       "DelinquencyScore                         0.000000  0.000000   60.000000   \n",
       "HasAnyDelinquency                        0.000000  0.000000    1.000000   \n",
       "UtilizationTimesDelinquency              0.000000  0.000000    0.071670   \n",
       "LatePaymentsPerCreditLine                0.000000  0.000000   30.000000   \n",
       "UtilizationPerAge                        0.000000  0.681490    8.241714   \n",
       "RevolvingUtilizationCappedLog            0.000000  0.673136    4.139011   \n",
       "DebtToIncomeAgeRisk                      0.028985  0.586876  230.122301   \n",
       "IncomePerCreditLine                      0.014545  0.575962  279.287273   \n",
       "UtilizationPerCreditLine                 0.000000  0.707815   39.419312   \n",
       "HighAgeRiskFlag                          0.891319  0.891319    0.891319   \n",
       "DelinquencyBucket                        2.000000  2.000000    3.000000   \n",
       "UtilizationBucketLateBucket              3.000000  5.000000    6.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000    0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000    0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000    0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.000000  0.000000    1.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerAgeImputed              0.000000  0.000000    1.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.000000  0.000000    1.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000    0.000000   \n",
       "WasIncomePerCreditLineImputed            0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.000000  0.000000    1.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000    0.000000   \n",
       "\n",
       "                                              skew  corr_with_target  \\\n",
       "HasMajorDelinquency                       2.924985               NaN   \n",
       "DelinquencyScore                         11.234710         -0.001659   \n",
       "HasAnyDelinquency                         1.461070         -0.001659   \n",
       "UtilizationTimesDelinquency               3.094077         -0.004518   \n",
       "LatePaymentsPerCreditLine                18.388049         -0.003994   \n",
       "UtilizationPerAge                         1.678399         -0.004013   \n",
       "RevolvingUtilizationCappedLog             1.117631         -0.003140   \n",
       "DebtToIncomeAgeRisk                      66.268097         -0.003953   \n",
       "IncomePerCreditLine                      51.496937         -0.003028   \n",
       "UtilizationPerCreditLine                  4.650102          0.001484   \n",
       "HighAgeRiskFlag                          -0.228449          0.000610   \n",
       "DelinquencyBucket                        -1.622902          0.001659   \n",
       "UtilizationBucketLateBucket              -0.241148         -0.005203   \n",
       "WasHasMajorDelinquencyImputed             0.000000               NaN   \n",
       "WasDelinquencyScoreImputed                0.000000               NaN   \n",
       "WasHasAnyDelinquencyImputed               0.000000               NaN   \n",
       "WasUtilizationTimesDelinquencyImputed     3.970245         -0.002538   \n",
       "WasLatePaymentsPerCreditLineImputed      12.800288         -0.003863   \n",
       "WasUtilizationPerAgeImputed               3.970245         -0.002538   \n",
       "WasRevolvingUtilizationCappedLogImputed   3.970245         -0.002538   \n",
       "WasDebtToIncomeAgeRiskImputed             0.000000               NaN   \n",
       "WasIncomePerCreditLineImputed            12.800288         -0.003863   \n",
       "WasUtilizationPerCreditLineImputed        3.726076         -0.002754   \n",
       "WasHighAgeRiskFlagImputed                 0.000000               NaN   \n",
       "WasDelinquencyBucketImputed               0.000000               NaN   \n",
       "WasUtilizationBucketLateBucketImputed     0.000000               NaN   \n",
       "\n",
       "                                         high_corr_flag  \\\n",
       "HasMajorDelinquency                               False   \n",
       "DelinquencyScore                                  False   \n",
       "HasAnyDelinquency                                  True   \n",
       "UtilizationTimesDelinquency                        True   \n",
       "LatePaymentsPerCreditLine                         False   \n",
       "UtilizationPerAge                                  True   \n",
       "RevolvingUtilizationCappedLog                      True   \n",
       "DebtToIncomeAgeRisk                               False   \n",
       "IncomePerCreditLine                               False   \n",
       "UtilizationPerCreditLine                          False   \n",
       "HighAgeRiskFlag                                   False   \n",
       "DelinquencyBucket                                 False   \n",
       "UtilizationBucketLateBucket                       False   \n",
       "WasHasMajorDelinquencyImputed                     False   \n",
       "WasDelinquencyScoreImputed                        False   \n",
       "WasHasAnyDelinquencyImputed                       False   \n",
       "WasUtilizationTimesDelinquencyImputed              True   \n",
       "WasLatePaymentsPerCreditLineImputed                True   \n",
       "WasUtilizationPerAgeImputed                        True   \n",
       "WasRevolvingUtilizationCappedLogImputed            True   \n",
       "WasDebtToIncomeAgeRiskImputed                     False   \n",
       "WasIncomePerCreditLineImputed                      True   \n",
       "WasUtilizationPerCreditLineImputed                 True   \n",
       "WasHighAgeRiskFlagImputed                         False   \n",
       "WasDelinquencyBucketImputed                       False   \n",
       "WasUtilizationBucketLateBucketImputed             False   \n",
       "\n",
       "                                                                                                                                                                  high_corr_with  \n",
       "HasMajorDelinquency                                                                                                                                                               \n",
       "DelinquencyScore                                                                                                                                                                  \n",
       "HasAnyDelinquency                                                                                                                             UtilizationTimesDelinquency (0.74)  \n",
       "UtilizationTimesDelinquency                                                                                                                             HasAnyDelinquency (0.74)  \n",
       "LatePaymentsPerCreditLine                                                                                                                                                         \n",
       "UtilizationPerAge                                                                                                                           RevolvingUtilizationCappedLog (0.92)  \n",
       "RevolvingUtilizationCappedLog                                                                                                                           UtilizationPerAge (0.92)  \n",
       "DebtToIncomeAgeRisk                                                                                                                                                               \n",
       "IncomePerCreditLine                                                                                                                                                               \n",
       "UtilizationPerCreditLine                                                                                                                                                          \n",
       "HighAgeRiskFlag                                                                                                                                                                   \n",
       "DelinquencyBucket                                                                                                                                                                 \n",
       "UtilizationBucketLateBucket                                                                                                                                                       \n",
       "WasHasMajorDelinquencyImputed                                                                                                                                                     \n",
       "WasDelinquencyScoreImputed                                                                                                                                                        \n",
       "WasHasAnyDelinquencyImputed                                                                                                                                                       \n",
       "WasUtilizationTimesDelinquencyImputed              WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasLatePaymentsPerCreditLineImputed                                                                                                         WasIncomePerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerAgeImputed              WasUtilizationTimesDelinquencyImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasRevolvingUtilizationCappedLogImputed              WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                                                     \n",
       "WasIncomePerCreditLineImputed                                                                                                         WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerCreditLineImputed              WasUtilizationTimesDelinquencyImputed (0.95), WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95)  \n",
       "WasHighAgeRiskFlagImputed                                                                                                                                                         \n",
       "WasDelinquencyBucketImputed                                                                                                                                                       \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                                                             "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols \n",
    "zero_importance_cols = [\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasHasAnyDelinquencyImputed\",\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasDelinquencyBucketImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val   = X_val.drop(columns=zero_importance_cols)\n",
    "X_test  = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags   = flags_to_keep\n",
    "X_test_flags  = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 and int64\n",
    "X_train_num = X_train[num_col_order + X_train_flags].astype('float32').values\n",
    "X_val_num   = X_val[num_col_order + X_val_flags].astype('float32').values\n",
    "X_test_num  = X_test[num_col_order + X_test_flags].astype('float32').values\n",
    "\n",
    "X_train_cat = X_train[cat_col_order].astype('int64').values\n",
    "X_val_cat   = X_val[cat_col_order].astype('int64').values\n",
    "X_test_cat  = X_test[cat_col_order].astype('int64').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric input shape: torch.Size([92594, 17])\n",
      "Categorical input shape: torch.Size([92594, 2])\n",
      "Class weights: {np.int64(0): np.float64(0.5355164077591292), np.int64(1): np.float64(7.539000162839928)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_train_num_tensor = torch.tensor(X_train_num)\n",
    "X_val_num_tensor = torch.tensor(X_val_num)\n",
    "X_test_num_tensor = torch.tensor(X_test_num)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat)\n",
    "X_val_cat_tensor = torch.tensor(X_val_cat)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "print(\"Numeric input shape:\", X_train_num_tensor.shape)\n",
    "print(\"Categorical input shape:\", X_train_cat_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92594, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num, x_cat, y):\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor)\n",
    "val_ds = TabularDataset(X_val_num_tensor, X_val_cat_tensor, y_val_tensor)\n",
    "test_ds = TabularDataset(X_test_num_tensor, X_test_cat_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(7, 4)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bn_num): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (cat_skip): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 50439\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim)\n",
    "            for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)\n",
    "        ])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "    \n",
    "        x_cat_emb = torch.cat([\n",
    "            emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)\n",
    "        ], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "\n",
    "        x_num = self.bn_num(x_num)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "cat_dims = [len(cat_maps[col]) for col in cat_col_order]\n",
    "emb_dims = [min(50, (cat_dim + 1) // 2) for cat_dim in cat_dims]\n",
    "\n",
    "model = NN(X_train_num.shape[1], cat_dims, emb_dims).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.051743 | Train AUC: 0.8188 | Val loss: 0.048096 | Val AUC: 0.8495\n",
      "Epoch 2/75 | Train loss: 0.047476 | Train AUC: 0.8463 | Val loss: 0.048677 | Val AUC: 0.8490\n",
      "Epoch 3/75 | Train loss: 0.047046 | Train AUC: 0.8492 | Val loss: 0.047976 | Val AUC: 0.8477\n",
      "Epoch 4/75 | Train loss: 0.047075 | Train AUC: 0.8485 | Val loss: 0.047963 | Val AUC: 0.8477\n",
      "Epoch 5/75 | Train loss: 0.046919 | Train AUC: 0.8508 | Val loss: 0.048240 | Val AUC: 0.8525\n",
      "Epoch 6/75 | Train loss: 0.046832 | Train AUC: 0.8512 | Val loss: 0.047899 | Val AUC: 0.8510\n",
      "Epoch 7/75 | Train loss: 0.046675 | Train AUC: 0.8526 | Val loss: 0.048507 | Val AUC: 0.8483\n",
      "Epoch 8/75 | Train loss: 0.046737 | Train AUC: 0.8520 | Val loss: 0.047216 | Val AUC: 0.8545\n",
      "Epoch 9/75 | Train loss: 0.046592 | Train AUC: 0.8529 | Val loss: 0.047430 | Val AUC: 0.8528\n",
      "Epoch 10/75 | Train loss: 0.046507 | Train AUC: 0.8542 | Val loss: 0.047411 | Val AUC: 0.8519\n",
      "Epoch 11/75 | Train loss: 0.046467 | Train AUC: 0.8542 | Val loss: 0.047567 | Val AUC: 0.8503\n",
      "Epoch 12/75 | Train loss: 0.046499 | Train AUC: 0.8539 | Val loss: 0.047433 | Val AUC: 0.8525\n",
      "Epoch 13/75 | Train loss: 0.046449 | Train AUC: 0.8538 | Val loss: 0.047423 | Val AUC: 0.8533\n",
      "Epoch 14/75 | Train loss: 0.046258 | Train AUC: 0.8562 | Val loss: 0.047458 | Val AUC: 0.8542\n",
      "Epoch 15/75 | Train loss: 0.046071 | Train AUC: 0.8580 | Val loss: 0.047602 | Val AUC: 0.8528\n",
      "Epoch 16/75 | Train loss: 0.046137 | Train AUC: 0.8565 | Val loss: 0.047322 | Val AUC: 0.8527\n",
      "Epoch 17/75 | Train loss: 0.045965 | Train AUC: 0.8583 | Val loss: 0.047814 | Val AUC: 0.8542\n",
      "Epoch 18/75 | Train loss: 0.046187 | Train AUC: 0.8564 | Val loss: 0.047481 | Val AUC: 0.8557\n",
      "Epoch 19/75 | Train loss: 0.046106 | Train AUC: 0.8572 | Val loss: 0.047511 | Val AUC: 0.8528\n",
      "Epoch 20/75 | Train loss: 0.046049 | Train AUC: 0.8576 | Val loss: 0.047623 | Val AUC: 0.8553\n",
      "Epoch 21/75 | Train loss: 0.046005 | Train AUC: 0.8581 | Val loss: 0.047163 | Val AUC: 0.8543\n",
      "Epoch 22/75 | Train loss: 0.046011 | Train AUC: 0.8579 | Val loss: 0.047280 | Val AUC: 0.8547\n",
      "Epoch 23/75 | Train loss: 0.045970 | Train AUC: 0.8584 | Val loss: 0.047312 | Val AUC: 0.8536\n",
      "Epoch 24/75 | Train loss: 0.045926 | Train AUC: 0.8584 | Val loss: 0.047787 | Val AUC: 0.8537\n",
      "Epoch 25/75 | Train loss: 0.045808 | Train AUC: 0.8592 | Val loss: 0.047308 | Val AUC: 0.8546\n",
      "Epoch 26/75 | Train loss: 0.045858 | Train AUC: 0.8589 | Val loss: 0.047050 | Val AUC: 0.8549\n",
      "Epoch 27/75 | Train loss: 0.045766 | Train AUC: 0.8603 | Val loss: 0.047393 | Val AUC: 0.8543\n",
      "Epoch 28/75 | Train loss: 0.045745 | Train AUC: 0.8603 | Val loss: 0.047256 | Val AUC: 0.8544\n",
      "Epoch 29/75 | Train loss: 0.045851 | Train AUC: 0.8592 | Val loss: 0.047185 | Val AUC: 0.8538\n",
      "Epoch 30/75 | Train loss: 0.045698 | Train AUC: 0.8605 | Val loss: 0.047465 | Val AUC: 0.8561\n",
      "Epoch 31/75 | Train loss: 0.045786 | Train AUC: 0.8599 | Val loss: 0.047163 | Val AUC: 0.8555\n",
      "Epoch 32/75 | Train loss: 0.045848 | Train AUC: 0.8591 | Val loss: 0.047124 | Val AUC: 0.8545\n",
      "Epoch 33/75 | Train loss: 0.045708 | Train AUC: 0.8608 | Val loss: 0.047529 | Val AUC: 0.8546\n",
      "Epoch 34/75 | Train loss: 0.045710 | Train AUC: 0.8602 | Val loss: 0.047625 | Val AUC: 0.8552\n",
      "Epoch 35/75 | Train loss: 0.045788 | Train AUC: 0.8599 | Val loss: 0.047815 | Val AUC: 0.8515\n",
      "Epoch 36/75 | Train loss: 0.045752 | Train AUC: 0.8601 | Val loss: 0.047187 | Val AUC: 0.8549\n",
      "Epoch 37/75 | Train loss: 0.045644 | Train AUC: 0.8609 | Val loss: 0.047200 | Val AUC: 0.8549\n",
      "Epoch 38/75 | Train loss: 0.045743 | Train AUC: 0.8604 | Val loss: 0.047291 | Val AUC: 0.8553\n",
      "Epoch 39/75 | Train loss: 0.045643 | Train AUC: 0.8609 | Val loss: 0.047078 | Val AUC: 0.8557\n",
      "Epoch 40/75 | Train loss: 0.045663 | Train AUC: 0.8612 | Val loss: 0.047156 | Val AUC: 0.8556\n",
      "Epoch 41/75 | Train loss: 0.045646 | Train AUC: 0.8610 | Val loss: 0.047107 | Val AUC: 0.8527\n",
      "Epoch 42/75 | Train loss: 0.045657 | Train AUC: 0.8611 | Val loss: 0.047239 | Val AUC: 0.8551\n",
      "Early stopping at epoch 43\n",
      "Run 1 best Val AUC: 0.8561\n",
      "\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.046041 | Train AUC: 0.8580 | Val loss: 0.047673 | Val AUC: 0.8555\n",
      "Epoch 2/75 | Train loss: 0.046125 | Train AUC: 0.8569 | Val loss: 0.048710 | Val AUC: 0.8477\n",
      "Epoch 3/75 | Train loss: 0.046150 | Train AUC: 0.8568 | Val loss: 0.047189 | Val AUC: 0.8543\n",
      "Epoch 4/75 | Train loss: 0.046113 | Train AUC: 0.8576 | Val loss: 0.047587 | Val AUC: 0.8543\n",
      "Epoch 5/75 | Train loss: 0.046060 | Train AUC: 0.8579 | Val loss: 0.047600 | Val AUC: 0.8539\n",
      "Epoch 6/75 | Train loss: 0.046062 | Train AUC: 0.8578 | Val loss: 0.047256 | Val AUC: 0.8533\n",
      "Epoch 7/75 | Train loss: 0.046002 | Train AUC: 0.8584 | Val loss: 0.047530 | Val AUC: 0.8534\n",
      "Epoch 8/75 | Train loss: 0.045873 | Train AUC: 0.8590 | Val loss: 0.048028 | Val AUC: 0.8536\n",
      "Epoch 9/75 | Train loss: 0.045853 | Train AUC: 0.8598 | Val loss: 0.047470 | Val AUC: 0.8564\n",
      "Epoch 10/75 | Train loss: 0.045892 | Train AUC: 0.8591 | Val loss: 0.046825 | Val AUC: 0.8558\n",
      "Epoch 11/75 | Train loss: 0.045698 | Train AUC: 0.8609 | Val loss: 0.047521 | Val AUC: 0.8513\n",
      "Epoch 12/75 | Train loss: 0.045776 | Train AUC: 0.8598 | Val loss: 0.047399 | Val AUC: 0.8533\n",
      "Epoch 13/75 | Train loss: 0.045836 | Train AUC: 0.8598 | Val loss: 0.047556 | Val AUC: 0.8492\n",
      "Epoch 14/75 | Train loss: 0.045781 | Train AUC: 0.8600 | Val loss: 0.047405 | Val AUC: 0.8556\n",
      "Epoch 15/75 | Train loss: 0.045842 | Train AUC: 0.8594 | Val loss: 0.047800 | Val AUC: 0.8536\n",
      "Epoch 16/75 | Train loss: 0.045583 | Train AUC: 0.8620 | Val loss: 0.048255 | Val AUC: 0.8498\n",
      "Epoch 17/75 | Train loss: 0.045549 | Train AUC: 0.8621 | Val loss: 0.047230 | Val AUC: 0.8565\n",
      "Epoch 18/75 | Train loss: 0.045652 | Train AUC: 0.8610 | Val loss: 0.047335 | Val AUC: 0.8564\n",
      "Epoch 19/75 | Train loss: 0.045588 | Train AUC: 0.8614 | Val loss: 0.047718 | Val AUC: 0.8497\n",
      "Epoch 20/75 | Train loss: 0.045550 | Train AUC: 0.8623 | Val loss: 0.047217 | Val AUC: 0.8550\n",
      "Epoch 21/75 | Train loss: 0.045602 | Train AUC: 0.8618 | Val loss: 0.046847 | Val AUC: 0.8561\n",
      "Epoch 22/75 | Train loss: 0.045540 | Train AUC: 0.8616 | Val loss: 0.047309 | Val AUC: 0.8553\n",
      "Epoch 23/75 | Train loss: 0.045600 | Train AUC: 0.8616 | Val loss: 0.046850 | Val AUC: 0.8555\n",
      "Epoch 24/75 | Train loss: 0.045498 | Train AUC: 0.8623 | Val loss: 0.047084 | Val AUC: 0.8566\n",
      "Epoch 25/75 | Train loss: 0.045435 | Train AUC: 0.8628 | Val loss: 0.047831 | Val AUC: 0.8486\n",
      "Epoch 26/75 | Train loss: 0.045551 | Train AUC: 0.8623 | Val loss: 0.046813 | Val AUC: 0.8565\n",
      "Epoch 27/75 | Train loss: 0.045376 | Train AUC: 0.8634 | Val loss: 0.046931 | Val AUC: 0.8561\n",
      "Epoch 28/75 | Train loss: 0.045546 | Train AUC: 0.8617 | Val loss: 0.047732 | Val AUC: 0.8490\n",
      "Epoch 29/75 | Train loss: 0.045516 | Train AUC: 0.8622 | Val loss: 0.047166 | Val AUC: 0.8552\n",
      "Epoch 30/75 | Train loss: 0.045406 | Train AUC: 0.8631 | Val loss: 0.047500 | Val AUC: 0.8544\n",
      "Epoch 31/75 | Train loss: 0.045559 | Train AUC: 0.8617 | Val loss: 0.046938 | Val AUC: 0.8558\n",
      "Epoch 32/75 | Train loss: 0.045396 | Train AUC: 0.8630 | Val loss: 0.047003 | Val AUC: 0.8565\n",
      "Epoch 33/75 | Train loss: 0.045471 | Train AUC: 0.8625 | Val loss: 0.047404 | Val AUC: 0.8532\n",
      "Epoch 34/75 | Train loss: 0.045406 | Train AUC: 0.8633 | Val loss: 0.047616 | Val AUC: 0.8535\n",
      "Epoch 35/75 | Train loss: 0.045474 | Train AUC: 0.8626 | Val loss: 0.046848 | Val AUC: 0.8554\n",
      "Epoch 36/75 | Train loss: 0.045409 | Train AUC: 0.8633 | Val loss: 0.046944 | Val AUC: 0.8565\n",
      "Early stopping at epoch 37\n",
      "Run 2 best Val AUC: 0.8566\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8566)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_num, x_cat, yb in train_loader:\n",
    "            x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_num, x_cat)  \n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_num.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_num, x_cat, yb in val_loader:\n",
    "                x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "                logits = model(x_num, x_cat)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_num.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "\n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.27594987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.82      0.89     27868\n",
      "   Defaulted       0.22      0.75      0.34      1978\n",
      "\n",
      "    accuracy                           0.81     29846\n",
      "   macro avg       0.60      0.78      0.62     29846\n",
      "weighted avg       0.93      0.81      0.85     29846\n",
      "\n",
      "Accuracy: 81.18%\n",
      "ROC AUC: 0.858\n",
      "TP=1477, FP=5117, TN=22751, FN=501\n",
      "Accuracy for class 'Repaid': 81.64%\n",
      "Accuracy for class 'Defaulted': 74.67%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in val_loader:  \n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_val, y_val_probs, thresholds, beta=2.4)\n",
    "best_thresh_a = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdba09d8-8307-4ade-b197-9eb639de9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "Best params: {'subsample': 0.6, 'scale_pos_weight': np.float64(14.078000325679856), 'reg_lambda': 0.8, 'reg_alpha': 0.1, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.03, 'gamma': 1.0, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83930\n",
      "[1]\tvalidation_0-auc:0.84466\n",
      "[2]\tvalidation_0-auc:0.84779\n",
      "[3]\tvalidation_0-auc:0.84981\n",
      "[4]\tvalidation_0-auc:0.85009\n",
      "[5]\tvalidation_0-auc:0.85058\n",
      "[6]\tvalidation_0-auc:0.85097\n",
      "[7]\tvalidation_0-auc:0.85101\n",
      "[8]\tvalidation_0-auc:0.85114\n",
      "[9]\tvalidation_0-auc:0.85132\n",
      "[10]\tvalidation_0-auc:0.85148\n",
      "[11]\tvalidation_0-auc:0.85151\n",
      "[12]\tvalidation_0-auc:0.85158\n",
      "[13]\tvalidation_0-auc:0.85182\n",
      "[14]\tvalidation_0-auc:0.85172\n",
      "[15]\tvalidation_0-auc:0.85201\n",
      "[16]\tvalidation_0-auc:0.85196\n",
      "[17]\tvalidation_0-auc:0.85206\n",
      "[18]\tvalidation_0-auc:0.85219\n",
      "[19]\tvalidation_0-auc:0.85208\n",
      "[20]\tvalidation_0-auc:0.85218\n",
      "[21]\tvalidation_0-auc:0.85212\n",
      "[22]\tvalidation_0-auc:0.85216\n",
      "[23]\tvalidation_0-auc:0.85210\n",
      "[24]\tvalidation_0-auc:0.85223\n",
      "[25]\tvalidation_0-auc:0.85218\n",
      "[26]\tvalidation_0-auc:0.85247\n",
      "[27]\tvalidation_0-auc:0.85247\n",
      "[28]\tvalidation_0-auc:0.85244\n",
      "[29]\tvalidation_0-auc:0.85268\n",
      "[30]\tvalidation_0-auc:0.85282\n",
      "[31]\tvalidation_0-auc:0.85305\n",
      "[32]\tvalidation_0-auc:0.85303\n",
      "[33]\tvalidation_0-auc:0.85308\n",
      "[34]\tvalidation_0-auc:0.85313\n",
      "[35]\tvalidation_0-auc:0.85322\n",
      "[36]\tvalidation_0-auc:0.85347\n",
      "[37]\tvalidation_0-auc:0.85355\n",
      "[38]\tvalidation_0-auc:0.85350\n",
      "[39]\tvalidation_0-auc:0.85355\n",
      "[40]\tvalidation_0-auc:0.85355\n",
      "[41]\tvalidation_0-auc:0.85359\n",
      "[42]\tvalidation_0-auc:0.85367\n",
      "[43]\tvalidation_0-auc:0.85368\n",
      "[44]\tvalidation_0-auc:0.85371\n",
      "[45]\tvalidation_0-auc:0.85375\n",
      "[46]\tvalidation_0-auc:0.85392\n",
      "[47]\tvalidation_0-auc:0.85404\n",
      "[48]\tvalidation_0-auc:0.85417\n",
      "[49]\tvalidation_0-auc:0.85424\n",
      "[50]\tvalidation_0-auc:0.85441\n",
      "[51]\tvalidation_0-auc:0.85451\n",
      "[52]\tvalidation_0-auc:0.85456\n",
      "[53]\tvalidation_0-auc:0.85467\n",
      "[54]\tvalidation_0-auc:0.85486\n",
      "[55]\tvalidation_0-auc:0.85487\n",
      "[56]\tvalidation_0-auc:0.85484\n",
      "[57]\tvalidation_0-auc:0.85491\n",
      "[58]\tvalidation_0-auc:0.85486\n",
      "[59]\tvalidation_0-auc:0.85484\n",
      "[60]\tvalidation_0-auc:0.85493\n",
      "[61]\tvalidation_0-auc:0.85491\n",
      "[62]\tvalidation_0-auc:0.85495\n",
      "[63]\tvalidation_0-auc:0.85498\n",
      "[64]\tvalidation_0-auc:0.85505\n",
      "[65]\tvalidation_0-auc:0.85506\n",
      "[66]\tvalidation_0-auc:0.85511\n",
      "[67]\tvalidation_0-auc:0.85510\n",
      "[68]\tvalidation_0-auc:0.85510\n",
      "[69]\tvalidation_0-auc:0.85512\n",
      "[70]\tvalidation_0-auc:0.85521\n",
      "[71]\tvalidation_0-auc:0.85518\n",
      "[72]\tvalidation_0-auc:0.85517\n",
      "[73]\tvalidation_0-auc:0.85522\n",
      "[74]\tvalidation_0-auc:0.85523\n",
      "[75]\tvalidation_0-auc:0.85527\n",
      "[76]\tvalidation_0-auc:0.85530\n",
      "[77]\tvalidation_0-auc:0.85532\n",
      "[78]\tvalidation_0-auc:0.85547\n",
      "[79]\tvalidation_0-auc:0.85548\n",
      "[80]\tvalidation_0-auc:0.85549\n",
      "[81]\tvalidation_0-auc:0.85546\n",
      "[82]\tvalidation_0-auc:0.85545\n",
      "[83]\tvalidation_0-auc:0.85551\n",
      "[84]\tvalidation_0-auc:0.85570\n",
      "[85]\tvalidation_0-auc:0.85573\n",
      "[86]\tvalidation_0-auc:0.85578\n",
      "[87]\tvalidation_0-auc:0.85586\n",
      "[88]\tvalidation_0-auc:0.85589\n",
      "[89]\tvalidation_0-auc:0.85590\n",
      "[90]\tvalidation_0-auc:0.85596\n",
      "[91]\tvalidation_0-auc:0.85601\n",
      "[92]\tvalidation_0-auc:0.85608\n",
      "[93]\tvalidation_0-auc:0.85614\n",
      "[94]\tvalidation_0-auc:0.85620\n",
      "[95]\tvalidation_0-auc:0.85628\n",
      "[96]\tvalidation_0-auc:0.85631\n",
      "[97]\tvalidation_0-auc:0.85634\n",
      "[98]\tvalidation_0-auc:0.85641\n",
      "[99]\tvalidation_0-auc:0.85646\n",
      "[100]\tvalidation_0-auc:0.85647\n",
      "[101]\tvalidation_0-auc:0.85653\n",
      "[102]\tvalidation_0-auc:0.85657\n",
      "[103]\tvalidation_0-auc:0.85659\n",
      "[104]\tvalidation_0-auc:0.85666\n",
      "[105]\tvalidation_0-auc:0.85669\n",
      "[106]\tvalidation_0-auc:0.85671\n",
      "[107]\tvalidation_0-auc:0.85674\n",
      "[108]\tvalidation_0-auc:0.85681\n",
      "[109]\tvalidation_0-auc:0.85681\n",
      "[110]\tvalidation_0-auc:0.85683\n",
      "[111]\tvalidation_0-auc:0.85683\n",
      "[112]\tvalidation_0-auc:0.85687\n",
      "[113]\tvalidation_0-auc:0.85691\n",
      "[114]\tvalidation_0-auc:0.85697\n",
      "[115]\tvalidation_0-auc:0.85701\n",
      "[116]\tvalidation_0-auc:0.85701\n",
      "[117]\tvalidation_0-auc:0.85705\n",
      "[118]\tvalidation_0-auc:0.85706\n",
      "[119]\tvalidation_0-auc:0.85709\n",
      "[120]\tvalidation_0-auc:0.85716\n",
      "[121]\tvalidation_0-auc:0.85717\n",
      "[122]\tvalidation_0-auc:0.85719\n",
      "[123]\tvalidation_0-auc:0.85721\n",
      "[124]\tvalidation_0-auc:0.85722\n",
      "[125]\tvalidation_0-auc:0.85729\n",
      "[126]\tvalidation_0-auc:0.85734\n",
      "[127]\tvalidation_0-auc:0.85736\n",
      "[128]\tvalidation_0-auc:0.85737\n",
      "[129]\tvalidation_0-auc:0.85740\n",
      "[130]\tvalidation_0-auc:0.85738\n",
      "[131]\tvalidation_0-auc:0.85742\n",
      "[132]\tvalidation_0-auc:0.85744\n",
      "[133]\tvalidation_0-auc:0.85747\n",
      "[134]\tvalidation_0-auc:0.85748\n",
      "[135]\tvalidation_0-auc:0.85747\n",
      "[136]\tvalidation_0-auc:0.85750\n",
      "[137]\tvalidation_0-auc:0.85751\n",
      "[138]\tvalidation_0-auc:0.85754\n",
      "[139]\tvalidation_0-auc:0.85759\n",
      "[140]\tvalidation_0-auc:0.85759\n",
      "[141]\tvalidation_0-auc:0.85763\n",
      "[142]\tvalidation_0-auc:0.85767\n",
      "[143]\tvalidation_0-auc:0.85766\n",
      "[144]\tvalidation_0-auc:0.85766\n",
      "[145]\tvalidation_0-auc:0.85766\n",
      "[146]\tvalidation_0-auc:0.85770\n",
      "[147]\tvalidation_0-auc:0.85768\n",
      "[148]\tvalidation_0-auc:0.85763\n",
      "[149]\tvalidation_0-auc:0.85764\n",
      "[150]\tvalidation_0-auc:0.85766\n",
      "[151]\tvalidation_0-auc:0.85768\n",
      "[152]\tvalidation_0-auc:0.85771\n",
      "[153]\tvalidation_0-auc:0.85772\n",
      "[154]\tvalidation_0-auc:0.85769\n",
      "[155]\tvalidation_0-auc:0.85776\n",
      "[156]\tvalidation_0-auc:0.85781\n",
      "[157]\tvalidation_0-auc:0.85781\n",
      "[158]\tvalidation_0-auc:0.85783\n",
      "[159]\tvalidation_0-auc:0.85783\n",
      "[160]\tvalidation_0-auc:0.85786\n",
      "[161]\tvalidation_0-auc:0.85786\n",
      "[162]\tvalidation_0-auc:0.85788\n",
      "[163]\tvalidation_0-auc:0.85788\n",
      "[164]\tvalidation_0-auc:0.85786\n",
      "[165]\tvalidation_0-auc:0.85785\n",
      "[166]\tvalidation_0-auc:0.85793\n",
      "[167]\tvalidation_0-auc:0.85789\n",
      "[168]\tvalidation_0-auc:0.85787\n",
      "[169]\tvalidation_0-auc:0.85784\n",
      "[170]\tvalidation_0-auc:0.85783\n",
      "[171]\tvalidation_0-auc:0.85784\n",
      "[172]\tvalidation_0-auc:0.85780\n",
      "[173]\tvalidation_0-auc:0.85780\n",
      "[174]\tvalidation_0-auc:0.85783\n",
      "[175]\tvalidation_0-auc:0.85789\n",
      "[176]\tvalidation_0-auc:0.85795\n",
      "[177]\tvalidation_0-auc:0.85795\n",
      "[178]\tvalidation_0-auc:0.85795\n",
      "[179]\tvalidation_0-auc:0.85797\n",
      "[180]\tvalidation_0-auc:0.85798\n",
      "[181]\tvalidation_0-auc:0.85801\n",
      "[182]\tvalidation_0-auc:0.85800\n",
      "[183]\tvalidation_0-auc:0.85803\n",
      "[184]\tvalidation_0-auc:0.85806\n",
      "[185]\tvalidation_0-auc:0.85805\n",
      "[186]\tvalidation_0-auc:0.85806\n",
      "[187]\tvalidation_0-auc:0.85807\n",
      "[188]\tvalidation_0-auc:0.85808\n",
      "[189]\tvalidation_0-auc:0.85808\n",
      "[190]\tvalidation_0-auc:0.85806\n",
      "[191]\tvalidation_0-auc:0.85807\n",
      "[192]\tvalidation_0-auc:0.85805\n",
      "[193]\tvalidation_0-auc:0.85805\n",
      "[194]\tvalidation_0-auc:0.85808\n",
      "[195]\tvalidation_0-auc:0.85806\n",
      "[196]\tvalidation_0-auc:0.85806\n",
      "[197]\tvalidation_0-auc:0.85808\n",
      "[198]\tvalidation_0-auc:0.85806\n",
      "[199]\tvalidation_0-auc:0.85809\n",
      "[200]\tvalidation_0-auc:0.85812\n",
      "[201]\tvalidation_0-auc:0.85815\n",
      "[202]\tvalidation_0-auc:0.85817\n",
      "[203]\tvalidation_0-auc:0.85819\n",
      "[204]\tvalidation_0-auc:0.85814\n",
      "[205]\tvalidation_0-auc:0.85812\n",
      "[206]\tvalidation_0-auc:0.85809\n",
      "[207]\tvalidation_0-auc:0.85808\n",
      "[208]\tvalidation_0-auc:0.85812\n",
      "[209]\tvalidation_0-auc:0.85814\n",
      "[210]\tvalidation_0-auc:0.85811\n",
      "[211]\tvalidation_0-auc:0.85813\n",
      "[212]\tvalidation_0-auc:0.85813\n",
      "[213]\tvalidation_0-auc:0.85812\n",
      "[214]\tvalidation_0-auc:0.85809\n",
      "[215]\tvalidation_0-auc:0.85812\n",
      "[216]\tvalidation_0-auc:0.85813\n",
      "[217]\tvalidation_0-auc:0.85815\n",
      "[218]\tvalidation_0-auc:0.85820\n",
      "[219]\tvalidation_0-auc:0.85819\n",
      "[220]\tvalidation_0-auc:0.85819\n",
      "[221]\tvalidation_0-auc:0.85821\n",
      "[222]\tvalidation_0-auc:0.85821\n",
      "[223]\tvalidation_0-auc:0.85821\n",
      "[224]\tvalidation_0-auc:0.85820\n",
      "[225]\tvalidation_0-auc:0.85815\n",
      "[226]\tvalidation_0-auc:0.85813\n",
      "[227]\tvalidation_0-auc:0.85814\n",
      "[228]\tvalidation_0-auc:0.85813\n",
      "[229]\tvalidation_0-auc:0.85812\n",
      "[230]\tvalidation_0-auc:0.85814\n",
      "[231]\tvalidation_0-auc:0.85814\n",
      "[232]\tvalidation_0-auc:0.85816\n",
      "[233]\tvalidation_0-auc:0.85818\n",
      "[234]\tvalidation_0-auc:0.85816\n",
      "[235]\tvalidation_0-auc:0.85815\n",
      "[236]\tvalidation_0-auc:0.85816\n",
      "[237]\tvalidation_0-auc:0.85816\n",
      "[238]\tvalidation_0-auc:0.85815\n",
      "[239]\tvalidation_0-auc:0.85812\n",
      "[240]\tvalidation_0-auc:0.85815\n",
      "[241]\tvalidation_0-auc:0.85812\n",
      "[242]\tvalidation_0-auc:0.85811\n",
      "[243]\tvalidation_0-auc:0.85808\n",
      "[244]\tvalidation_0-auc:0.85811\n",
      "[245]\tvalidation_0-auc:0.85812\n",
      "[246]\tvalidation_0-auc:0.85814\n",
      "[247]\tvalidation_0-auc:0.85816\n",
      "[248]\tvalidation_0-auc:0.85816\n",
      "[249]\tvalidation_0-auc:0.85817\n",
      "[250]\tvalidation_0-auc:0.85816\n",
      "[251]\tvalidation_0-auc:0.85813\n",
      "[252]\tvalidation_0-auc:0.85814\n",
      "[253]\tvalidation_0-auc:0.85815\n",
      "[254]\tvalidation_0-auc:0.85813\n",
      "[255]\tvalidation_0-auc:0.85811\n",
      "[256]\tvalidation_0-auc:0.85812\n",
      "[257]\tvalidation_0-auc:0.85814\n",
      "[258]\tvalidation_0-auc:0.85813\n",
      "[259]\tvalidation_0-auc:0.85815\n",
      "[260]\tvalidation_0-auc:0.85813\n",
      "[261]\tvalidation_0-auc:0.85811\n",
      "[262]\tvalidation_0-auc:0.85811\n",
      "[263]\tvalidation_0-auc:0.85811\n",
      "[264]\tvalidation_0-auc:0.85810\n",
      "[265]\tvalidation_0-auc:0.85812\n",
      "[266]\tvalidation_0-auc:0.85815\n",
      "[267]\tvalidation_0-auc:0.85816\n",
      "[268]\tvalidation_0-auc:0.85815\n",
      "[269]\tvalidation_0-auc:0.85812\n",
      "[270]\tvalidation_0-auc:0.85808\n",
      "[271]\tvalidation_0-auc:0.85811\n",
      "[272]\tvalidation_0-auc:0.85817\n",
      "[273]\tvalidation_0-auc:0.85819\n",
      "[274]\tvalidation_0-auc:0.85816\n",
      "[275]\tvalidation_0-auc:0.85814\n",
      "[276]\tvalidation_0-auc:0.85812\n",
      "[277]\tvalidation_0-auc:0.85810\n",
      "[278]\tvalidation_0-auc:0.85808\n",
      "[279]\tvalidation_0-auc:0.85806\n",
      "[280]\tvalidation_0-auc:0.85803\n",
      "[281]\tvalidation_0-auc:0.85806\n",
      "[282]\tvalidation_0-auc:0.85807\n",
      "[283]\tvalidation_0-auc:0.85807\n",
      "[284]\tvalidation_0-auc:0.85810\n",
      "[285]\tvalidation_0-auc:0.85808\n",
      "[286]\tvalidation_0-auc:0.85806\n",
      "[287]\tvalidation_0-auc:0.85805\n",
      "[288]\tvalidation_0-auc:0.85808\n",
      "[289]\tvalidation_0-auc:0.85812\n",
      "[290]\tvalidation_0-auc:0.85814\n",
      "[291]\tvalidation_0-auc:0.85814\n",
      "[292]\tvalidation_0-auc:0.85814\n",
      "[293]\tvalidation_0-auc:0.85815\n",
      "[294]\tvalidation_0-auc:0.85815\n",
      "[295]\tvalidation_0-auc:0.85812\n",
      "[296]\tvalidation_0-auc:0.85812\n",
      "[297]\tvalidation_0-auc:0.85815\n",
      "[298]\tvalidation_0-auc:0.85811\n",
      "[299]\tvalidation_0-auc:0.85813\n",
      "[300]\tvalidation_0-auc:0.85812\n",
      "[301]\tvalidation_0-auc:0.85813\n",
      "[302]\tvalidation_0-auc:0.85812\n",
      "[303]\tvalidation_0-auc:0.85813\n",
      "[304]\tvalidation_0-auc:0.85815\n",
      "[305]\tvalidation_0-auc:0.85813\n",
      "[306]\tvalidation_0-auc:0.85809\n",
      "[307]\tvalidation_0-auc:0.85811\n",
      "[308]\tvalidation_0-auc:0.85812\n",
      "[309]\tvalidation_0-auc:0.85811\n",
      "[310]\tvalidation_0-auc:0.85807\n",
      "[311]\tvalidation_0-auc:0.85808\n",
      "[312]\tvalidation_0-auc:0.85811\n",
      "[313]\tvalidation_0-auc:0.85811\n",
      "[314]\tvalidation_0-auc:0.85810\n",
      "[315]\tvalidation_0-auc:0.85808\n",
      "[316]\tvalidation_0-auc:0.85808\n",
      "[317]\tvalidation_0-auc:0.85808\n",
      "[318]\tvalidation_0-auc:0.85808\n",
      "[319]\tvalidation_0-auc:0.85805\n",
      "[320]\tvalidation_0-auc:0.85806\n",
      "[321]\tvalidation_0-auc:0.85807\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=1.0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.03</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.078000325679856)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=1.0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.5462868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.73      0.35      1978\n",
      "\n",
      "    accuracy                           0.82     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.82      0.86     29846\n",
      "\n",
      "Accuracy: 82.28%\n",
      "ROC AUC: 0.859\n",
      "TP=1450, FP=4761, TN=23107, FN=528\n",
      "Accuracy for class 'Repaid': 82.92%\n",
      "Accuracy for class 'Defaulted': 73.31%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_test, y_probs, thresholds, beta=2.4)\n",
    "best_thresh_b = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Feature   Importance\n",
      "0                         HasAnyDelinquency  5796.887695\n",
      "1                         DelinquencyBucket  1169.402100\n",
      "2                          DelinquencyScore   867.172607\n",
      "3               UtilizationBucketLateBucket   353.038177\n",
      "4               UtilizationTimesDelinquency   298.520233\n",
      "5                         UtilizationPerAge   206.630341\n",
      "6                       HasMajorDelinquency   142.021790\n",
      "7             RevolvingUtilizationCappedLog   124.418823\n",
      "8                 LatePaymentsPerCreditLine    90.634506\n",
      "9                       DebtToIncomeAgeRisk    68.952614\n",
      "10                      IncomePerCreditLine    53.174171\n",
      "11                          HighAgeRiskFlag    46.918972\n",
      "12                 UtilizationPerCreditLine    46.668156\n",
      "13  WasRevolvingUtilizationCappedLogImputed    35.961945\n",
      "14    WasUtilizationTimesDelinquencyImputed    30.456097\n",
      "15              WasUtilizationPerAgeImputed    28.812967\n",
      "16       WasUtilizationPerCreditLineImputed    24.932991\n",
      "17      WasLatePaymentsPerCreditLineImputed    24.537033\n",
      "18            WasIncomePerCreditLineImputed     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27237c8825cf494cbe8e67c4e816685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    feature  mean_abs_shap\n",
      "5                         UtilizationPerAge       0.024862\n",
      "6             RevolvingUtilizationCappedLog       0.020158\n",
      "0                       HasMajorDelinquency       0.010716\n",
      "8                       IncomePerCreditLine       0.010619\n",
      "2                         HasAnyDelinquency       0.009642\n",
      "7                       DebtToIncomeAgeRisk       0.007907\n",
      "1                          DelinquencyScore       0.007856\n",
      "18       WasUtilizationPerCreditLineImputed       0.006318\n",
      "9                  UtilizationPerCreditLine       0.002916\n",
      "17            WasIncomePerCreditLineImputed       0.002462\n",
      "4                 LatePaymentsPerCreditLine       0.002423\n",
      "3               UtilizationTimesDelinquency       0.002408\n",
      "10                          HighAgeRiskFlag       0.002317\n",
      "15              WasUtilizationPerAgeImputed       0.000418\n",
      "12              UtilizationBucketLateBucket       0.000104\n",
      "13    WasUtilizationTimesDelinquencyImputed       0.000094\n",
      "11                        DelinquencyBucket       0.000030\n",
      "16  WasRevolvingUtilizationCappedLogImputed       0.000017\n",
      "14      WasLatePaymentsPerCreditLineImputed       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance NN\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "model_cpu.eval()\n",
    "\n",
    "def shap_cpu(X):\n",
    "    n_num = X_train_num_tensor.shape[1]\n",
    "    n_cat = X_train_cat_tensor.shape[1]\n",
    "\n",
    "    X_num = X[:, :n_num].astype(np.float32)\n",
    "    X_cat = X[:, n_num:n_num + n_cat].astype(np.int64)\n",
    "\n",
    "    X_num_tensor = torch.tensor(X_num, dtype=torch.float32)\n",
    "    X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_num_tensor, X_cat_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "X_train_combined = np.hstack([\n",
    "    X_train_num_tensor.numpy(),\n",
    "    X_train_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_val_num_tensor.numpy(),\n",
    "    X_val_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "background = shap.sample(X_train_combined, 100, random_state=42)\n",
    "X_val_sample = X_val_combined[:500]\n",
    "\n",
    "explainer = shap.KernelExplainer(shap_cpu, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "\n",
    "feature_names = (\n",
    "    list(num_col_order) +\n",
    "    list(cat_col_order) +\n",
    "    list(X_train_flags)\n",
    ")\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
