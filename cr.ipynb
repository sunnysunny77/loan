{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "        \n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    imputed_flags = [col for col in numeric_cols if col.startswith(\"Was\") or col.endswith(\"Imputed\")]\n",
    "    regular_numeric_cols = [col for col in numeric_cols if col not in imputed_flags]\n",
    "\n",
    "    df_num = df_copy[regular_numeric_cols].copy()\n",
    "    \n",
    "    df_num.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    print(f\"Dataset shape: {df_num.shape}\")\n",
    "    print(f\"Total rows: {len(df_num)}\")\n",
    "    print(f\"Total duplicate rows: {df_num.duplicated().sum()}\")\n",
    "\n",
    "    desc = df_num.describe().T\n",
    "    desc[\"skew\"] = df_num.skew()\n",
    "    \n",
    "    desc[\"dtype\"] = df_copy[desc.index].dtypes\n",
    "    desc[\"non_null\"] = df_copy[desc.index].notna().sum()\n",
    "    desc[\"missing\"] = df_copy[desc.index].isna().sum()\n",
    "    desc[\"missing_%\"] = (df_copy[desc.index].isna().mean() * 100).round(2)\n",
    "    desc[\"unique\"] = df_copy[desc.index].nunique()\n",
    "    \n",
    "    if y is not None:\n",
    "        df_num['target'] = y\n",
    "        desc[\"corr_with_target\"] = df_num.corr()['target'].drop('target')\n",
    "    \n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "       \n",
    "    corr_pairs = (\n",
    "        corr_matrix\n",
    "        .where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "      \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "     \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    high_corr_flags = []\n",
    "    high_corr_with = []\n",
    "    \n",
    "    for col in desc.index:\n",
    "        if col in corr_map:\n",
    "            high_corr_flags.append(True)\n",
    "            high_corr_with.append(\", \".join(corr_map[col]))\n",
    "        else:\n",
    "            high_corr_flags.append(False)\n",
    "            high_corr_with.append(\"\")\n",
    "    \n",
    "    desc[\"high_corr_flag\"] = high_corr_flags\n",
    "    desc[\"high_corr_with\"] = high_corr_with\n",
    "    \n",
    "    return desc.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(X, y, n_high=100, n_low=10):\n",
    "    \n",
    "    X_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "    \n",
    "    numeric_cols = X_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    X_copy[numeric_cols] = X_copy[numeric_cols].fillna(0)\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X_copy, y_copy)\n",
    "    y_pred_proba = hgb.predict_proba(X_copy)[:, 1]\n",
    "\n",
    "    df_combined = X_copy.copy()\n",
    "    df_combined[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_combined[\"__target__\"] = y_copy.values\n",
    "\n",
    "    df_sorted = df_combined.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    X_filtered = df_filtered.drop(columns=[\"__pred_proba__\", \"__target__\"])\n",
    "    y_filtered = df_filtered[\"__target__\"]\n",
    "\n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    \n",
    "    TotalPastDueLog = np.log1p(TotalPastDue)\n",
    "    \n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationFilled = RevolvingUtilizationCapped.fillna(0)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationFilled)\n",
    "    RevolvingUtilizationCappedLogSafe = RevolvingUtilizationCappedLog.replace(0, np.nan)\n",
    "        \n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].fillna(0).clip(upper=10000.0)\n",
    "        \n",
    "    DebtRatioCappedLog = np.log1p(DebtRatioCapped)\n",
    "    \n",
    "    DebtRatioSafe =  DebtRatioCappedLog.replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeLog = np.log1p(df_e[\"MonthlyIncome\"].fillna(0))\n",
    "\n",
    "    MonthlyIncomeSafe = MonthlyIncomeLog.replace(0, np.nan)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    NumberRealEstateLoansOrLinesfilled = df_e[\"NumberRealEstateLoansOrLines\"].fillna(0)\n",
    "\n",
    "    DebtToIncome = DebtRatioSafe * MonthlyIncomeSafe\n",
    "    \n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "    \n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLogSafe / AgeSafe\n",
    "\n",
    "    df_e[\"RevolvingUtilization\"] = RevolvingUtilizationCappedLogSafe\n",
    "    df_e[\"TotalPastDue\"] = TotalPastDueLog\n",
    "\n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationPerCreditLine\"] =  RevolvingUtilizationCappedLogSafe / CreditLinesSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDueLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"RealEstateLeverage\"] = NumberRealEstateLoansOrLinesfilled * RevolvingUtilizationCappedLogSafe\n",
    "    \n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationFilled, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDueLog, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"RevolvingUtilization\",\n",
    "        \"TotalPastDue\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"RealEstateLeverage\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    best_param = {\n",
    "        \"learning_rate\": 0.3,\n",
    "        \"max_depth\": 6,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"gamma\": 0,\n",
    "        \"subsample\": 1.0,\n",
    "        \"colsample_bytree\": 1.0,\n",
    "        \"reg_alpha\": 0,\n",
    "        \"reg_lambda\": 1\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),\n",
    "        n_estimators=800,\n",
    "        max_bin=1024,\n",
    "        booster=\"gbtree\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": X_train.columns,\n",
    "        \"Importance\": mean_abs_shap\n",
    "    }).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "\n",
    "    final_features = list(set(top_features + cat_cols))\n",
    "\n",
    "    dropped_features = [f for f in df_temp.columns if f not in final_features]\n",
    "\n",
    "    print(f\"Kept {len(final_features)} features (including categorical columns)\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[final_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    \n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    \n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>120269.0</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>146076.0</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count         mean           std  \\\n",
       "MonthlyIncome                         120269.0  6670.221237  14384.674215   \n",
       "NumberOfDependents                    146076.0     0.757222      1.115086   \n",
       "age                                   150000.0    52.295207     14.771866   \n",
       "RevolvingUtilizationOfUnsecuredLines  150000.0     6.048438    249.755371   \n",
       "DebtRatio                             150000.0   353.005076   2037.818523   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  150000.0     0.421033      4.192781   \n",
       "NumberOfOpenCreditLinesAndLoans       150000.0     8.452760      5.145951   \n",
       "NumberOfTimes90DaysLate               150000.0     0.265973      4.169304   \n",
       "NumberRealEstateLoansOrLines          150000.0     1.018240      1.129771   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  150000.0     0.240387      4.155179   \n",
       "\n",
       "                                      min          25%          50%  \\\n",
       "MonthlyIncome                         0.0  3400.000000  5400.000000   \n",
       "NumberOfDependents                    0.0     0.000000     0.000000   \n",
       "age                                   0.0    41.000000    52.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines  0.0     0.029867     0.154181   \n",
       "DebtRatio                             0.0     0.175074     0.366508   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans       0.0     5.000000     8.000000   \n",
       "NumberOfTimes90DaysLate               0.0     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines          0.0     0.000000     1.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "\n",
       "                                              75%        max        skew  \\\n",
       "MonthlyIncome                         8249.000000  3008750.0  114.040318   \n",
       "NumberOfDependents                       1.000000       20.0    1.588242   \n",
       "age                                     63.000000      109.0    0.188995   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.559046    50708.0   97.631574   \n",
       "DebtRatio                                0.868254   329664.0   95.157793   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000       98.0   22.597108   \n",
       "NumberOfOpenCreditLinesAndLoans         11.000000       58.0    1.215314   \n",
       "NumberOfTimes90DaysLate                  0.000000       98.0   23.087345   \n",
       "NumberRealEstateLoansOrLines             2.000000       54.0    3.482484   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000       98.0   23.331743   \n",
       "\n",
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique  corr_with_target  \\\n",
       "MonthlyIncome                          13594         -0.019746   \n",
       "NumberOfDependents                        13          0.046048   \n",
       "age                                       86         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728         -0.001802   \n",
       "DebtRatio                             114194         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans           58         -0.029669   \n",
       "NumberOfTimes90DaysLate                   19          0.117175   \n",
       "NumberRealEstateLoansOrLines              28         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>1.202670e+05</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>146074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066841</td>\n",
       "      <td>6.048512</td>\n",
       "      <td>52.295557</td>\n",
       "      <td>0.421032</td>\n",
       "      <td>353.009780</td>\n",
       "      <td>6.645265e+03</td>\n",
       "      <td>8.452766</td>\n",
       "      <td>0.265977</td>\n",
       "      <td>1.018234</td>\n",
       "      <td>0.240390</td>\n",
       "      <td>0.757198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249747</td>\n",
       "      <td>249.757035</td>\n",
       "      <td>14.771347</td>\n",
       "      <td>4.192809</td>\n",
       "      <td>2037.831702</td>\n",
       "      <td>1.148842e+04</td>\n",
       "      <td>5.145980</td>\n",
       "      <td>4.169331</td>\n",
       "      <td>1.129776</td>\n",
       "      <td>4.155207</td>\n",
       "      <td>1.115074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029869</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>3.400000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>5.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559044</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868260</td>\n",
       "      <td>8.249000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149998.000000                         149998.000000  149998.000000   \n",
       "mean           0.066841                              6.048512      52.295557   \n",
       "std            0.249747                            249.757035      14.771347   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.029869      41.000000   \n",
       "50%            0.000000                              0.154181      52.000000   \n",
       "75%            0.000000                              0.559044      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                         149998.000000  149998.000000   1.202670e+05   \n",
       "mean                               0.421032     353.009780   6.645265e+03   \n",
       "std                                4.192809    2037.831702   1.148842e+04   \n",
       "min                                0.000000       0.000000   0.000000e+00   \n",
       "25%                                0.000000       0.175074   3.400000e+03   \n",
       "50%                                0.000000       0.366508   5.400000e+03   \n",
       "75%                                0.000000       0.868260   8.249000e+03   \n",
       "max                               98.000000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149998.000000            149998.000000   \n",
       "mean                          8.452766                 0.265977   \n",
       "std                           5.145980                 4.169331   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149998.000000                         149998.000000   \n",
       "mean                       1.018234                              0.240390   \n",
       "std                        1.129776                              4.155207   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       146074.000000  \n",
       "mean             0.757198  \n",
       "std              1.115074  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling Manual\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139972\n",
      "1     10026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_train)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Outlier Handling \n",
    "X_train_cut, y_train_cut = outlier_handling(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_cut, y_train_cut, test_size=0.2, stratify=y_train_cut, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026bc2c6-c772-4a73-9cbf-5e29c2b410e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 451 duplicates\n",
      "Dropped: 45 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)\n",
    "X_val, y_val = check_and_drop_duplicates(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95419 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bd0425-dbbf-491a-aee0-b602edf86033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2694 duplicates\n"
     ]
    }
   ],
   "source": [
    "df_e, y_train = check_and_drop_duplicates(df_e, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                 18348           19.79\n",
      "DelinquencyScore                        0            0.00\n",
      "HighAgeRiskFlag                         0            0.00\n",
      "IncomePerCreditLine                 17631           19.01\n",
      "LatePaymentsPerCreditLine             537            0.58\n",
      "RealEstateLeverage                   4927            5.31\n",
      "RevolvingUtilization                 4927            5.31\n",
      "TotalPastDue                            0            0.00\n",
      "UtilizationBucketLateBucket             0            0.00\n",
      "UtilizationPerAge                    4927            5.31\n",
      "UtilizationPerCreditLine             5464            5.89\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           19           0.02\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'UtilizationBucketLateBucket': collapsed 14 rare categories: ['Very High_ModerateLate', 'Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very Low_ModerateLate', 'Low_ModerateLate', 'Extreme_NoLate', 'Extreme_ModerateLate', 'Very High_FrequentLate', 'Extreme_FewLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da8189b-60a9-4cc7-a082-1a56c327dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 11 features (including categorical columns)\n",
      "Dropped 0 features\n",
      "                        Feature  Importance\n",
      "0           DebtToIncomeAgeRisk    0.954654\n",
      "1             UtilizationPerAge    0.891413\n",
      "2          RevolvingUtilization    0.790622\n",
      "3     LatePaymentsPerCreditLine    0.757745\n",
      "4           IncomePerCreditLine    0.721917\n",
      "5      UtilizationPerCreditLine    0.638555\n",
      "6              DelinquencyScore    0.531128\n",
      "7            RealEstateLeverage    0.400309\n",
      "8                  TotalPastDue    0.152552\n",
      "9   UtilizationBucketLateBucket    0.110294\n",
      "10              HighAgeRiskFlag    0.093927\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n",
      "['DelinquencyScore', 'DebtToIncomeAgeRisk', 'LatePaymentsPerCreditLine', 'UtilizationPerAge', 'IncomePerCreditLine', 'TotalPastDue', 'RevolvingUtilization', 'UtilizationPerCreditLine', 'RealEstateLeverage', 'HighAgeRiskFlag']\n",
      "['UtilizationBucketLateBucket']\n",
      "{'UtilizationBucketLateBucket': {'Very Low_NoLate': 0, 'Low_NoLate': 1, 'Moderate_NoLate': 2, 'High_NoLate': 3, 'Other': 4, 'Very High_NoLate': 5}}\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")\n",
    "print(num_col_order)\n",
    "print(cat_col_order)\n",
    "print(cat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23923 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 30000 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92725, 11)\n",
      "Total rows: 92725\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>6.774980e-01</td>\n",
       "      <td>2.453629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.162218</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.352806</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>1.719824e-01</td>\n",
       "      <td>1.138875</td>\n",
       "      <td>-1.367330</td>\n",
       "      <td>-0.457108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542892</td>\n",
       "      <td>29.104658</td>\n",
       "      <td>2.807291</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73017</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>3.844893e-02</td>\n",
       "      <td>0.125785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>6.581883</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "      <td>0.305015</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.911665e-01</td>\n",
       "      <td>0.772839</td>\n",
       "      <td>-0.409007</td>\n",
       "      <td>-0.305323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694677</td>\n",
       "      <td>8.239514</td>\n",
       "      <td>1.675551</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82266</td>\n",
       "      <td>0.261912</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilization (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>4.839945e-01</td>\n",
       "      <td>1.877196</td>\n",
       "      <td>-1.682442</td>\n",
       "      <td>-0.404051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595949</td>\n",
       "      <td>17.366549</td>\n",
       "      <td>3.841591</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34404</td>\n",
       "      <td>0.044586</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDue</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.048315e-01</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.354847</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.387168</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>3.163926e+00</td>\n",
       "      <td>1.717489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.331477</td>\n",
       "      <td>int8</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.054811</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilization</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.277991e-01</td>\n",
       "      <td>0.634013</td>\n",
       "      <td>-0.431953</td>\n",
       "      <td>-0.310826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689174</td>\n",
       "      <td>4.146705</td>\n",
       "      <td>1.099702</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80873</td>\n",
       "      <td>0.265002</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>7.191053e-01</td>\n",
       "      <td>2.270139</td>\n",
       "      <td>-0.426381</td>\n",
       "      <td>-0.299496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700504</td>\n",
       "      <td>38.250113</td>\n",
       "      <td>4.565031</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82002</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealEstateLeverage</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>5.928118e-01</td>\n",
       "      <td>1.345818</td>\n",
       "      <td>-0.151205</td>\n",
       "      <td>-0.151205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848795</td>\n",
       "      <td>51.397576</td>\n",
       "      <td>5.030255</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53518</td>\n",
       "      <td>0.113533</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>4.597742e-17</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-1.119283</td>\n",
       "      <td>-1.119283</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>-0.225857</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.091812</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean       std       min  \\\n",
       "DelinquencyScore             92725.0  6.774980e-01  2.453629  0.000000   \n",
       "DebtToIncomeAgeRisk          92725.0  1.719824e-01  1.138875 -1.367330   \n",
       "LatePaymentsPerCreditLine    92725.0  3.844893e-02  0.125785  0.000000   \n",
       "UtilizationPerAge            92725.0  2.911665e-01  0.772839 -0.409007   \n",
       "IncomePerCreditLine          92725.0  4.839945e-01  1.877196 -1.682442   \n",
       "TotalPastDue                 92725.0  2.048315e-01  0.446746  0.000000   \n",
       "UtilizationBucketLateBucket  92725.0  3.163926e+00  1.717489  0.000000   \n",
       "RevolvingUtilization         92725.0  2.277991e-01  0.634013 -0.431953   \n",
       "UtilizationPerCreditLine     92725.0  7.191053e-01  2.270139 -0.426381   \n",
       "RealEstateLeverage           92725.0  5.928118e-01  1.345818 -0.151205   \n",
       "HighAgeRiskFlag              92725.0  4.597742e-17  1.000005 -1.119283   \n",
       "\n",
       "                                  25%       50%       75%        max  \\\n",
       "DelinquencyScore             0.000000  0.000000  0.000000  60.000000   \n",
       "DebtToIncomeAgeRisk         -0.457108  0.000000  0.542892  29.104658   \n",
       "LatePaymentsPerCreditLine    0.000000  0.000000  0.000000   3.433987   \n",
       "UtilizationPerAge           -0.305323  0.000000  0.694677   8.239514   \n",
       "IncomePerCreditLine         -0.404051  0.000000  0.595949  17.366549   \n",
       "TotalPastDue                 0.000000  0.000000  0.000000   3.433987   \n",
       "UtilizationBucketLateBucket  2.000000  3.000000  5.000000   5.000000   \n",
       "RevolvingUtilization        -0.310826  0.000000  0.689174   4.146705   \n",
       "UtilizationPerCreditLine    -0.299496  0.000000  0.700504  38.250113   \n",
       "RealEstateLeverage          -0.151205  0.000000  0.848795  51.397576   \n",
       "HighAgeRiskFlag             -1.119283  0.893429  0.893429   0.893429   \n",
       "\n",
       "                                  skew    dtype  non_null  missing  missing_%  \\\n",
       "DelinquencyScore             11.162218  float64     92725        0        0.0   \n",
       "DebtToIncomeAgeRisk           2.807291  float64     92725        0        0.0   \n",
       "LatePaymentsPerCreditLine     6.581883  float64     92725        0        0.0   \n",
       "UtilizationPerAge             1.675551  float64     92725        0        0.0   \n",
       "IncomePerCreditLine           3.841591  float64     92725        0        0.0   \n",
       "TotalPastDue                  2.354847  float64     92725        0        0.0   \n",
       "UtilizationBucketLateBucket  -0.331477     int8     92725        0        0.0   \n",
       "RevolvingUtilization          1.099702  float64     92725        0        0.0   \n",
       "UtilizationPerCreditLine      4.565031  float64     92725        0        0.0   \n",
       "RealEstateLeverage            5.030255  float64     92725        0        0.0   \n",
       "HighAgeRiskFlag              -0.225857  float64     92725        0        0.0   \n",
       "\n",
       "                             unique  corr_with_target  high_corr_flag  \\\n",
       "DelinquencyScore                 37          0.352806            True   \n",
       "DebtToIncomeAgeRisk           73017          0.074956           False   \n",
       "LatePaymentsPerCreditLine       278          0.305015           False   \n",
       "UtilizationPerAge             82266          0.261912            True   \n",
       "IncomePerCreditLine           34404          0.044586           False   \n",
       "TotalPastDue                     18          0.387168            True   \n",
       "UtilizationBucketLateBucket       6         -0.054811           False   \n",
       "RevolvingUtilization          80873          0.265002            True   \n",
       "UtilizationPerCreditLine      82002          0.167203           False   \n",
       "RealEstateLeverage            53518          0.113533           False   \n",
       "HighAgeRiskFlag                   2         -0.091812           False   \n",
       "\n",
       "                                          high_corr_with  \n",
       "DelinquencyScore                     TotalPastDue (0.78)  \n",
       "DebtToIncomeAgeRisk                                       \n",
       "LatePaymentsPerCreditLine                                 \n",
       "UtilizationPerAge            RevolvingUtilization (0.92)  \n",
       "IncomePerCreditLine                                       \n",
       "TotalPastDue                     DelinquencyScore (0.78)  \n",
       "UtilizationBucketLateBucket                               \n",
       "RevolvingUtilization            UtilizationPerAge (0.92)  \n",
       "UtilizationPerCreditLine                                  \n",
       "RealEstateLeverage                                        \n",
       "HighAgeRiskFlag                                           "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WasLatePaymentsPerCreditLineImputed', 'WasRevolvingUtilizationImputed', 'WasUtilizationPerCreditLineImputed', 'WasRealEstateLeverageImputed']\n"
     ]
    }
   ],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "    \"WasIncomePerCreditLineImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",         \n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasUtilizationPerAgeImputed\",\n",
    "    \"WasTotalPastDueImputed\",\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep\n",
    "print(X_train_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Flags\n",
    "X_train_flags = X_train[X_train_flags]\n",
    "X_val_flags = X_val[X_val_flags]\n",
    "X_test_flags = X_test[X_test_flags]\n",
    "\n",
    "# NN\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_col_order])\n",
    "X_val_cat = encoder.transform(X_val[cat_col_order])\n",
    "X_test_cat = encoder.transform(X_test[cat_col_order])\n",
    "\n",
    "cat_feature_names = encoder.get_feature_names_out(cat_col_order)\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "X_val_cat_df = pd.DataFrame(X_val_cat, columns=cat_feature_names, index=X_val.index)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat, columns=cat_feature_names, index=X_test.index)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_cat_df, X_train[num_col_order], X_train_flags], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_cat_df, X_val[num_col_order], X_val_flags], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_cat_df, X_test[num_col_order], X_test_flags], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([92725, 20])\n",
      "Class weights: {np.int64(0): np.float64(0.5353822880700255), np.int64(1): np.float64(7.565682114882507)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92725, Val: 23923, Test: 30000\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 48873\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model = NN(X_train_tensor.shape[1]).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.028339 | Train AUC: 0.8084 | Val loss: 0.025061 | Val AUC: 0.8512\n",
      "Epoch 2/75 | Train loss: 0.025325 | Train AUC: 0.8407 | Val loss: 0.025904 | Val AUC: 0.8487\n",
      "Epoch 3/75 | Train loss: 0.024868 | Train AUC: 0.8469 | Val loss: 0.025844 | Val AUC: 0.8486\n",
      "Epoch 4/75 | Train loss: 0.024755 | Train AUC: 0.8486 | Val loss: 0.024928 | Val AUC: 0.8490\n",
      "Epoch 5/75 | Train loss: 0.024737 | Train AUC: 0.8488 | Val loss: 0.025095 | Val AUC: 0.8499\n",
      "Epoch 6/75 | Train loss: 0.024703 | Train AUC: 0.8494 | Val loss: 0.024949 | Val AUC: 0.8541\n",
      "Epoch 7/75 | Train loss: 0.024569 | Train AUC: 0.8518 | Val loss: 0.024728 | Val AUC: 0.8534\n",
      "Epoch 8/75 | Train loss: 0.024554 | Train AUC: 0.8520 | Val loss: 0.024959 | Val AUC: 0.8545\n",
      "Epoch 9/75 | Train loss: 0.024577 | Train AUC: 0.8514 | Val loss: 0.024925 | Val AUC: 0.8538\n",
      "Epoch 10/75 | Train loss: 0.024512 | Train AUC: 0.8525 | Val loss: 0.024723 | Val AUC: 0.8528\n",
      "Epoch 11/75 | Train loss: 0.024497 | Train AUC: 0.8528 | Val loss: 0.025068 | Val AUC: 0.8528\n",
      "Epoch 12/75 | Train loss: 0.024513 | Train AUC: 0.8533 | Val loss: 0.024800 | Val AUC: 0.8547\n",
      "Epoch 13/75 | Train loss: 0.024398 | Train AUC: 0.8545 | Val loss: 0.024865 | Val AUC: 0.8543\n",
      "Epoch 14/75 | Train loss: 0.024479 | Train AUC: 0.8533 | Val loss: 0.024753 | Val AUC: 0.8538\n",
      "Epoch 15/75 | Train loss: 0.024394 | Train AUC: 0.8544 | Val loss: 0.024822 | Val AUC: 0.8533\n",
      "Epoch 16/75 | Train loss: 0.024449 | Train AUC: 0.8537 | Val loss: 0.024669 | Val AUC: 0.8546\n",
      "Epoch 17/75 | Train loss: 0.024409 | Train AUC: 0.8543 | Val loss: 0.024676 | Val AUC: 0.8548\n",
      "Epoch 18/75 | Train loss: 0.024410 | Train AUC: 0.8550 | Val loss: 0.024708 | Val AUC: 0.8548\n",
      "Epoch 19/75 | Train loss: 0.024367 | Train AUC: 0.8554 | Val loss: 0.024551 | Val AUC: 0.8548\n",
      "Epoch 20/75 | Train loss: 0.024370 | Train AUC: 0.8552 | Val loss: 0.024666 | Val AUC: 0.8545\n",
      "Epoch 21/75 | Train loss: 0.024368 | Train AUC: 0.8555 | Val loss: 0.024579 | Val AUC: 0.8552\n",
      "Epoch 22/75 | Train loss: 0.024369 | Train AUC: 0.8553 | Val loss: 0.024668 | Val AUC: 0.8556\n",
      "Epoch 23/75 | Train loss: 0.024350 | Train AUC: 0.8555 | Val loss: 0.024654 | Val AUC: 0.8543\n",
      "Epoch 24/75 | Train loss: 0.024320 | Train AUC: 0.8560 | Val loss: 0.024610 | Val AUC: 0.8546\n",
      "Epoch 25/75 | Train loss: 0.024341 | Train AUC: 0.8558 | Val loss: 0.024554 | Val AUC: 0.8556\n",
      "Epoch 26/75 | Train loss: 0.024321 | Train AUC: 0.8561 | Val loss: 0.024544 | Val AUC: 0.8545\n",
      "Epoch 27/75 | Train loss: 0.024218 | Train AUC: 0.8579 | Val loss: 0.024555 | Val AUC: 0.8544\n",
      "Epoch 28/75 | Train loss: 0.024351 | Train AUC: 0.8553 | Val loss: 0.024568 | Val AUC: 0.8539\n",
      "Epoch 29/75 | Train loss: 0.024277 | Train AUC: 0.8568 | Val loss: 0.024541 | Val AUC: 0.8560\n",
      "Epoch 30/75 | Train loss: 0.024208 | Train AUC: 0.8578 | Val loss: 0.024491 | Val AUC: 0.8559\n",
      "Epoch 31/75 | Train loss: 0.024171 | Train AUC: 0.8586 | Val loss: 0.024445 | Val AUC: 0.8556\n",
      "Epoch 32/75 | Train loss: 0.024259 | Train AUC: 0.8571 | Val loss: 0.024398 | Val AUC: 0.8557\n",
      "Epoch 33/75 | Train loss: 0.024194 | Train AUC: 0.8581 | Val loss: 0.024415 | Val AUC: 0.8556\n",
      "Epoch 34/75 | Train loss: 0.024162 | Train AUC: 0.8584 | Val loss: 0.024574 | Val AUC: 0.8556\n",
      "Epoch 35/75 | Train loss: 0.024130 | Train AUC: 0.8592 | Val loss: 0.024509 | Val AUC: 0.8551\n",
      "Epoch 36/75 | Train loss: 0.024141 | Train AUC: 0.8589 | Val loss: 0.024539 | Val AUC: 0.8555\n",
      "Epoch 37/75 | Train loss: 0.024099 | Train AUC: 0.8593 | Val loss: 0.024392 | Val AUC: 0.8560\n",
      "Epoch 38/75 | Train loss: 0.024145 | Train AUC: 0.8587 | Val loss: 0.024387 | Val AUC: 0.8562\n",
      "Epoch 39/75 | Train loss: 0.024112 | Train AUC: 0.8596 | Val loss: 0.024471 | Val AUC: 0.8555\n",
      "Epoch 40/75 | Train loss: 0.024088 | Train AUC: 0.8598 | Val loss: 0.024449 | Val AUC: 0.8553\n",
      "Epoch 41/75 | Train loss: 0.024161 | Train AUC: 0.8583 | Val loss: 0.024356 | Val AUC: 0.8561\n",
      "Epoch 42/75 | Train loss: 0.024120 | Train AUC: 0.8597 | Val loss: 0.024338 | Val AUC: 0.8564\n",
      "Epoch 43/75 | Train loss: 0.024082 | Train AUC: 0.8596 | Val loss: 0.024394 | Val AUC: 0.8561\n",
      "Epoch 44/75 | Train loss: 0.024182 | Train AUC: 0.8583 | Val loss: 0.024342 | Val AUC: 0.8561\n",
      "Epoch 45/75 | Train loss: 0.024081 | Train AUC: 0.8600 | Val loss: 0.024359 | Val AUC: 0.8565\n",
      "Epoch 46/75 | Train loss: 0.024057 | Train AUC: 0.8602 | Val loss: 0.024418 | Val AUC: 0.8559\n",
      "Epoch 47/75 | Train loss: 0.024059 | Train AUC: 0.8600 | Val loss: 0.024325 | Val AUC: 0.8563\n",
      "Epoch 48/75 | Train loss: 0.024025 | Train AUC: 0.8608 | Val loss: 0.024520 | Val AUC: 0.8548\n",
      "Epoch 49/75 | Train loss: 0.024103 | Train AUC: 0.8591 | Val loss: 0.024537 | Val AUC: 0.8539\n",
      "Epoch 50/75 | Train loss: 0.024009 | Train AUC: 0.8609 | Val loss: 0.024384 | Val AUC: 0.8556\n",
      "Epoch 51/75 | Train loss: 0.024112 | Train AUC: 0.8590 | Val loss: 0.024361 | Val AUC: 0.8564\n",
      "Epoch 52/75 | Train loss: 0.024028 | Train AUC: 0.8606 | Val loss: 0.024427 | Val AUC: 0.8564\n",
      "Epoch 53/75 | Train loss: 0.024065 | Train AUC: 0.8600 | Val loss: 0.024454 | Val AUC: 0.8558\n",
      "Epoch 54/75 | Train loss: 0.024025 | Train AUC: 0.8608 | Val loss: 0.024355 | Val AUC: 0.8564\n",
      "Epoch 55/75 | Train loss: 0.024036 | Train AUC: 0.8605 | Val loss: 0.024400 | Val AUC: 0.8564\n",
      "Epoch 56/75 | Train loss: 0.024065 | Train AUC: 0.8599 | Val loss: 0.024323 | Val AUC: 0.8561\n",
      "Epoch 57/75 | Train loss: 0.024069 | Train AUC: 0.8601 | Val loss: 0.024337 | Val AUC: 0.8563\n",
      "Early stopping at epoch 58\n",
      "Run 1 best Val AUC: 0.8565\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.024273 | Train AUC: 0.8570 | Val loss: 0.024432 | Val AUC: 0.8542\n",
      "Epoch 2/75 | Train loss: 0.024221 | Train AUC: 0.8576 | Val loss: 0.024631 | Val AUC: 0.8541\n",
      "Epoch 3/75 | Train loss: 0.024206 | Train AUC: 0.8577 | Val loss: 0.024553 | Val AUC: 0.8559\n",
      "Epoch 4/75 | Train loss: 0.024211 | Train AUC: 0.8578 | Val loss: 0.024379 | Val AUC: 0.8555\n",
      "Epoch 5/75 | Train loss: 0.024179 | Train AUC: 0.8585 | Val loss: 0.024364 | Val AUC: 0.8548\n",
      "Epoch 6/75 | Train loss: 0.024235 | Train AUC: 0.8573 | Val loss: 0.024739 | Val AUC: 0.8547\n",
      "Epoch 7/75 | Train loss: 0.024307 | Train AUC: 0.8565 | Val loss: 0.024494 | Val AUC: 0.8541\n",
      "Epoch 8/75 | Train loss: 0.024200 | Train AUC: 0.8583 | Val loss: 0.024378 | Val AUC: 0.8555\n",
      "Epoch 9/75 | Train loss: 0.024186 | Train AUC: 0.8584 | Val loss: 0.024387 | Val AUC: 0.8558\n",
      "Epoch 10/75 | Train loss: 0.024098 | Train AUC: 0.8599 | Val loss: 0.024395 | Val AUC: 0.8554\n",
      "Epoch 11/75 | Train loss: 0.024085 | Train AUC: 0.8598 | Val loss: 0.024458 | Val AUC: 0.8557\n",
      "Epoch 12/75 | Train loss: 0.024125 | Train AUC: 0.8591 | Val loss: 0.024465 | Val AUC: 0.8556\n",
      "Epoch 13/75 | Train loss: 0.024087 | Train AUC: 0.8600 | Val loss: 0.024471 | Val AUC: 0.8551\n",
      "Epoch 14/75 | Train loss: 0.024098 | Train AUC: 0.8595 | Val loss: 0.024386 | Val AUC: 0.8563\n",
      "Epoch 15/75 | Train loss: 0.024145 | Train AUC: 0.8586 | Val loss: 0.024325 | Val AUC: 0.8565\n",
      "Epoch 16/75 | Train loss: 0.024094 | Train AUC: 0.8596 | Val loss: 0.024404 | Val AUC: 0.8551\n",
      "Epoch 17/75 | Train loss: 0.024070 | Train AUC: 0.8597 | Val loss: 0.024491 | Val AUC: 0.8553\n",
      "Epoch 18/75 | Train loss: 0.024054 | Train AUC: 0.8603 | Val loss: 0.024347 | Val AUC: 0.8566\n",
      "Epoch 19/75 | Train loss: 0.024066 | Train AUC: 0.8600 | Val loss: 0.024384 | Val AUC: 0.8554\n",
      "Epoch 20/75 | Train loss: 0.024073 | Train AUC: 0.8600 | Val loss: 0.024330 | Val AUC: 0.8562\n",
      "Epoch 21/75 | Train loss: 0.024043 | Train AUC: 0.8603 | Val loss: 0.024386 | Val AUC: 0.8560\n",
      "Epoch 22/75 | Train loss: 0.023995 | Train AUC: 0.8612 | Val loss: 0.024568 | Val AUC: 0.8550\n",
      "Epoch 23/75 | Train loss: 0.024060 | Train AUC: 0.8601 | Val loss: 0.024782 | Val AUC: 0.8554\n",
      "Epoch 24/75 | Train loss: 0.024066 | Train AUC: 0.8602 | Val loss: 0.024370 | Val AUC: 0.8558\n",
      "Epoch 25/75 | Train loss: 0.023958 | Train AUC: 0.8619 | Val loss: 0.024412 | Val AUC: 0.8561\n",
      "Epoch 26/75 | Train loss: 0.023953 | Train AUC: 0.8618 | Val loss: 0.024392 | Val AUC: 0.8562\n",
      "Epoch 27/75 | Train loss: 0.023953 | Train AUC: 0.8621 | Val loss: 0.024397 | Val AUC: 0.8562\n",
      "Epoch 28/75 | Train loss: 0.023973 | Train AUC: 0.8618 | Val loss: 0.024334 | Val AUC: 0.8564\n",
      "Epoch 29/75 | Train loss: 0.023927 | Train AUC: 0.8624 | Val loss: 0.024324 | Val AUC: 0.8558\n",
      "Epoch 30/75 | Train loss: 0.023987 | Train AUC: 0.8612 | Val loss: 0.024420 | Val AUC: 0.8562\n",
      "Early stopping at epoch 31\n",
      "Run 2 best Val AUC: 0.8566\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8566)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3505413234233856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.86      0.91     27995\n",
      "   Defaulted       0.26      0.71      0.38      2005\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.85      0.88     30000\n",
      "\n",
      "Accuracy: 84.65%\n",
      "ROC AUC: 0.869\n",
      "TP=1417, FP=4017, TN=23978, FN=588\n",
      "Accuracy for class 'Repaid': 85.65%\n",
      "Accuracy for class 'Defaulted': 70.67%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, 0.69)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running model 1/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.012, 'gamma': 0.0, 'colsample_bytree': 0.75, 'booster': 'dart'}\n",
      "[INFO] Running model 2/10 with params: {'subsample': 0.9, 'reg_lambda': 6, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.75, 'booster': 'gbtree'}\n",
      "[INFO] Running model 3/10 with params: {'subsample': 0.9, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 4/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 5/10 with params: {'subsample': 0.75, 'reg_lambda': 6, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'dart'}\n",
      "[INFO] Running model 6/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 5, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.9, 'booster': 'dart'}\n",
      "[INFO] Running model 7/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 3, 'min_child_weight': 8, 'max_depth': 5, 'learning_rate': 0.012, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 8/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 1, 'min_child_weight': 6, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 1.0, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 9/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.75, 'booster': 'gbtree'}\n",
      "[INFO] Running model 10/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.008, 'gamma': 0.0, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "Best AUC: 0.8569094070418574\n",
      "Best params: {'subsample': 0.9, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"booster\": [\"gbtree\", \"dart\"],\n",
    "    \"learning_rate\": [0.008, 0.01, 0.012],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"min_child_weight\": [4, 6, 8],\n",
    "    \"gamma\": [0.0, 0.5, 1.0],\n",
    "    \"subsample\": [0.75, 0.85, 0.9],\n",
    "    \"colsample_bytree\": [0.75, 0.85, 0.9],\n",
    "    \"reg_alpha\": [1, 3, 5],\n",
    "    \"reg_lambda\": [4, 6, 8],\n",
    "}\n",
    "\n",
    "n_iter = 10  \n",
    "sampler = ParameterSampler(param_dist, n_iter=n_iter, random_state=42)\n",
    "\n",
    "best_auc, best_params = 0.0, None\n",
    "\n",
    "for i, params in enumerate(sampler, start=1):\n",
    "    print(f\"[INFO] Running model {i}/{len(sampler)} with params: {params}\")\n",
    "\n",
    "    model_b = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),\n",
    "        n_estimators=800,\n",
    "        max_bin=1024,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        early_stopping_rounds=100,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    model_b.fit(\n",
    "        X_train_xgb, y_train,\n",
    "        eval_set=[(X_val_xgb, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if model_b.best_score > best_auc:\n",
    "        best_auc, best_params = model_b.best_score, params\n",
    "\n",
    "print(\"Best AUC:\", best_auc)\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5806382298469543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.86      0.92     27995\n",
      "   Defaulted       0.27      0.70      0.39      2005\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.85      0.88     30000\n",
      "\n",
      "Accuracy: 85.13%\n",
      "ROC AUC: 0.869\n",
      "TP=1404, FP=3859, TN=24136, FN=601\n",
      "Accuracy for class 'Repaid': 86.22%\n",
      "Accuracy for class 'Defaulted': 70.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "dtest = xgb.DMatrix(X_test_xgb)\n",
    "y_probs = model_b.get_booster().predict(dtest) \n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, 0.7)\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                Feature  Importance\n",
      "0           UtilizationBucketLateBucket    0.612250\n",
      "1                      DelinquencyScore    0.496187\n",
      "2                     UtilizationPerAge    0.445636\n",
      "3                   IncomePerCreditLine    0.152290\n",
      "4                   DebtToIncomeAgeRisk    0.141680\n",
      "5                  RevolvingUtilization    0.114919\n",
      "6                    RealEstateLeverage    0.064077\n",
      "7              UtilizationPerCreditLine    0.057079\n",
      "8                          TotalPastDue    0.050488\n",
      "9             LatePaymentsPerCreditLine    0.034787\n",
      "10                      HighAgeRiskFlag    0.020234\n",
      "11       WasRevolvingUtilizationImputed    0.000576\n",
      "12   WasUtilizationPerCreditLineImputed    0.000155\n",
      "13  WasLatePaymentsPerCreditLineImputed    0.000000\n",
      "14         WasRealEstateLeverageImputed    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Shap xgb\n",
    "explainer = shap.TreeExplainer(model_b)\n",
    "shap_values = explainer.shap_values(X_train_xgb)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_xgb.columns,\n",
    "    \"Importance\": mean_abs_shap\n",
    "}).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33e5f3a59b94c9d9992ef16b5dbf53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "0                              UtilizationPerAge       0.025015\n",
      "1                                   TotalPastDue       0.012533\n",
      "2                               DelinquencyScore       0.012050\n",
      "3    UtilizationBucketLateBucket_Very Low_NoLate       0.011558\n",
      "4                           RevolvingUtilization       0.009060\n",
      "5                            DebtToIncomeAgeRisk       0.008001\n",
      "6                            IncomePerCreditLine       0.005674\n",
      "7         UtilizationBucketLateBucket_Low_NoLate       0.004826\n",
      "8                                HighAgeRiskFlag       0.003404\n",
      "9                             RealEstateLeverage       0.002882\n",
      "10   UtilizationBucketLateBucket_Moderate_NoLate       0.002832\n",
      "11             UtilizationBucketLateBucket_Other       0.002418\n",
      "12                      UtilizationPerCreditLine       0.001844\n",
      "13  UtilizationBucketLateBucket_Very High_NoLate       0.000969\n",
      "14       UtilizationBucketLateBucket_High_NoLate       0.000838\n",
      "15                     LatePaymentsPerCreditLine       0.000772\n",
      "16                  WasRealEstateLeverageImputed       0.000118\n",
      "17            WasUtilizationPerCreditLineImputed       0.000063\n",
      "18           WasLatePaymentsPerCreditLineImputed       0.000037\n",
      "19                WasRevolvingUtilizationImputed       0.000030\n"
     ]
    }
   ],
   "source": [
    "# Shap NN\n",
    "model_gpu = copy.deepcopy(model).to(device)\n",
    "model_gpu.eval()\n",
    "\n",
    "def shap_ohe_gpu(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        logits = model_gpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "background = shap.sample(X_train_tensor.cpu().numpy(), 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe_gpu, background)\n",
    "shap_values = explainer.shap_values(X_val_tensor[:500].cpu().numpy())\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_xgb.columns.tolist(), \"xgb_col_order.pkl\")\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfb507-cce9-4894-b873-e5e1f5d657ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
