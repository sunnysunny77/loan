{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 5\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "        \n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    imputed_flags = [col for col in numeric_cols if col.startswith(\"Was\") or col.endswith(\"Imputed\")]\n",
    "    regular_numeric_cols = [col for col in numeric_cols if col not in imputed_flags]\n",
    "\n",
    "    df_num = df_copy[regular_numeric_cols].copy()\n",
    "    \n",
    "    df_num.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    print(f\"Dataset shape: {df_num.shape}\")\n",
    "    print(f\"Total rows: {len(df_num)}\")\n",
    "    print(f\"Total duplicate rows: {df_num.duplicated().sum()}\")\n",
    "\n",
    "    desc = df_num.describe().T\n",
    "    desc[\"skew\"] = df_num.skew()\n",
    "    \n",
    "    desc[\"dtype\"] = df_copy[desc.index].dtypes\n",
    "    desc[\"non_null\"] = df_copy[desc.index].notna().sum()\n",
    "    desc[\"missing\"] = df_copy[desc.index].isna().sum()\n",
    "    desc[\"missing_%\"] = (df_copy[desc.index].isna().mean() * 100).round(2)\n",
    "    desc[\"unique\"] = df_copy[desc.index].nunique()\n",
    "    \n",
    "    if y is not None:\n",
    "        df_num['target'] = y\n",
    "        desc[\"corr_with_target\"] = df_num.corr()['target'].drop('target')\n",
    "    \n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "       \n",
    "    corr_pairs = (\n",
    "        corr_matrix\n",
    "        .where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "      \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "     \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    high_corr_flags = []\n",
    "    high_corr_with = []\n",
    "    \n",
    "    for col in desc.index:\n",
    "        if col in corr_map:\n",
    "            high_corr_flags.append(True)\n",
    "            high_corr_with.append(\", \".join(corr_map[col]))\n",
    "        else:\n",
    "            high_corr_flags.append(False)\n",
    "            high_corr_with.append(\"\")\n",
    "    \n",
    "    desc[\"high_corr_flag\"] = high_corr_flags\n",
    "    desc[\"high_corr_with\"] = high_corr_with\n",
    "    \n",
    "    return desc.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    \n",
    "    TotalPastDueCapped = TotalPastDue.clip(upper=10)\n",
    "    \n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationFilled = RevolvingUtilizationCapped.fillna(0.0)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationFilled).replace(0, np.nan)\n",
    "        \n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * df_e[\"MonthlyIncome\"]\n",
    "    \n",
    "    IncomePerCreditLine = df_e[\"MonthlyIncome\"] / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLog / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDueCapped > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = RevolvingUtilizationCappedLog\n",
    "    df_e[\"TotalPastDueCapped\"] = TotalPastDueCapped\n",
    "\n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationCappedLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationFilled, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"TotalPastDueCapped\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    best_param = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"scale_pos_weight\": sum(y_train==0)/sum(y_train==1),\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"subsample\": 0.85,\n",
    "        \"colsample_bytree\": 0.85,\n",
    "        \"gamma\": 1,\n",
    "        \"reg_alpha\": 1,\n",
    "        \"reg_lambda\": 2,\n",
    "        \"n_estimators\": 1000,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\", \n",
    "        \"device\": \"cuda\",\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": X_train.columns,\n",
    "        \"Importance\": mean_abs_shap\n",
    "    }).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "\n",
    "    final_features = list(set(top_features + cat_cols))\n",
    "\n",
    "    dropped_features = [f for f in df_temp.columns if f not in final_features]\n",
    "\n",
    "    print(f\"Kept {len(final_features)} features (including categorical columns)\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[final_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    \n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    \n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>120269.0</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>146076.0</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count         mean           std  \\\n",
       "MonthlyIncome                         120269.0  6670.221237  14384.674215   \n",
       "NumberOfDependents                    146076.0     0.757222      1.115086   \n",
       "age                                   150000.0    52.295207     14.771866   \n",
       "RevolvingUtilizationOfUnsecuredLines  150000.0     6.048438    249.755371   \n",
       "DebtRatio                             150000.0   353.005076   2037.818523   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  150000.0     0.421033      4.192781   \n",
       "NumberOfOpenCreditLinesAndLoans       150000.0     8.452760      5.145951   \n",
       "NumberOfTimes90DaysLate               150000.0     0.265973      4.169304   \n",
       "NumberRealEstateLoansOrLines          150000.0     1.018240      1.129771   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  150000.0     0.240387      4.155179   \n",
       "\n",
       "                                      min          25%          50%  \\\n",
       "MonthlyIncome                         0.0  3400.000000  5400.000000   \n",
       "NumberOfDependents                    0.0     0.000000     0.000000   \n",
       "age                                   0.0    41.000000    52.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines  0.0     0.029867     0.154181   \n",
       "DebtRatio                             0.0     0.175074     0.366508   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans       0.0     5.000000     8.000000   \n",
       "NumberOfTimes90DaysLate               0.0     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines          0.0     0.000000     1.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "\n",
       "                                              75%        max        skew  \\\n",
       "MonthlyIncome                         8249.000000  3008750.0  114.040318   \n",
       "NumberOfDependents                       1.000000       20.0    1.588242   \n",
       "age                                     63.000000      109.0    0.188995   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.559046    50708.0   97.631574   \n",
       "DebtRatio                                0.868254   329664.0   95.157793   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000       98.0   22.597108   \n",
       "NumberOfOpenCreditLinesAndLoans         11.000000       58.0    1.215314   \n",
       "NumberOfTimes90DaysLate                  0.000000       98.0   23.087345   \n",
       "NumberRealEstateLoansOrLines             2.000000       54.0    3.482484   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000       98.0   23.331743   \n",
       "\n",
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique  corr_with_target  \\\n",
       "MonthlyIncome                          13594         -0.019746   \n",
       "NumberOfDependents                        13          0.046048   \n",
       "age                                       86         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728         -0.001802   \n",
       "DebtRatio                             114194         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans           58         -0.029669   \n",
       "NumberOfTimes90DaysLate                   19          0.117175   \n",
       "NumberRealEstateLoansOrLines              28         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 609 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyBucket                         0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                    1043            1.09\n",
      "LatePaymentsPerCreditLine              1043            1.09\n",
      "RevolvingUtilizationCappedLog          6831            7.15\n",
      "TotalPastDueCapped                        0            0.00\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      6831            7.15\n",
      "UtilizationPerCreditLine               7874            8.24\n",
      "UtilizationTimesDelinquency            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           30           0.03\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 25 rare categories: ['Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'Very High_ModerateLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very High_FrequentLate', 'Very Low_ModerateLate', 'Low_ModerateLate', 'High_FrequentLate', 'Very High_ChronicLate', 'Moderate_FrequentLate', 'Extreme_NoLate', 'Very Low_FrequentLate', 'Low_FrequentLate', 'High_ChronicLate', 'Extreme_ModerateLate', 'Moderate_ChronicLate', 'Extreme_FewLate', 'Extreme_FrequentLate', 'Very Low_ChronicLate', 'Low_ChronicLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da8189b-60a9-4cc7-a082-1a56c327dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 13 features (including categorical columns)\n",
      "Dropped 0 features\n",
      "                          Feature  Importance\n",
      "0               UtilizationPerAge    0.638913\n",
      "1       LatePaymentsPerCreditLine    0.419793\n",
      "2                DelinquencyScore    0.355361\n",
      "3     UtilizationTimesDelinquency    0.244818\n",
      "4             DebtToIncomeAgeRisk    0.197384\n",
      "5             IncomePerCreditLine    0.190788\n",
      "6   RevolvingUtilizationCappedLog    0.185628\n",
      "7        UtilizationPerCreditLine    0.132337\n",
      "8     UtilizationBucketLateBucket    0.058416\n",
      "9             HasMajorDelinquency    0.031806\n",
      "10             TotalPastDueCapped    0.023745\n",
      "11              DelinquencyBucket    0.020186\n",
      "12                HighAgeRiskFlag    0.016817\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n",
      "['DelinquencyScore', 'TotalPastDueCapped', 'UtilizationTimesDelinquency', 'UtilizationPerCreditLine', 'HighAgeRiskFlag', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'HasMajorDelinquency', 'RevolvingUtilizationCappedLog']\n",
      "['UtilizationBucketLateBucket', 'DelinquencyBucket']\n",
      "{'UtilizationBucketLateBucket': {'Low_NoLate': 0, 'Very Low_NoLate': 1, 'High_NoLate': 2, 'Very High_NoLate': 3, 'Other': 4, 'Moderate_NoLate': 5}, 'DelinquencyBucket': {'None': 0, 'Few': 1, 'Moderate': 2, 'Other': 3}}\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")\n",
    "print(num_col_order)\n",
    "print(cat_col_order)\n",
    "print(cat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['TotalPastDueCapped', 'DelinquencyScore', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2908 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92598, 13)\n",
      "Total rows: 92598\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.683308</td>\n",
       "      <td>2.492097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.231471</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDueCapped (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDueCapped</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>1.097088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.180515</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.399287</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.093738</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15842</td>\n",
       "      <td>0.364758</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>3.165392</td>\n",
       "      <td>1.716918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.328975</td>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.054086</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>2.314940</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.309695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707668</td>\n",
       "      <td>39.419312</td>\n",
       "      <td>4.650212</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82039</td>\n",
       "      <td>0.177593</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>1.816249</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.622637</td>\n",
       "      <td>int8</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.053309</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>-0.228439</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.089933</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.321183</td>\n",
       "      <td>2.143377</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.399441</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.575909</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.497662</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>1.608289</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.422533</td>\n",
       "      <td>0.028949</td>\n",
       "      <td>0.586787</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.268737</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.031882</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.281012</td>\n",
       "      <td>0.771726</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681580</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.678331</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.268645</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.076097</td>\n",
       "      <td>0.300314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.388191</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.309645</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.282279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.924108</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.362474</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>92598.0</td>\n",
       "      <td>0.216556</td>\n",
       "      <td>0.633069</td>\n",
       "      <td>-0.440434</td>\n",
       "      <td>-0.320875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673260</td>\n",
       "      <td>4.139011</td>\n",
       "      <td>1.117564</td>\n",
       "      <td>float64</td>\n",
       "      <td>92598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>0.271133</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count      mean       std       min  \\\n",
       "DelinquencyScore               92598.0  0.683308  2.492097  0.000000   \n",
       "TotalPastDueCapped             92598.0  0.409426  1.097088  0.000000   \n",
       "UtilizationTimesDelinquency    92598.0  0.001908  0.005049  0.000000   \n",
       "UtilizationBucketLateBucket    92598.0  3.165392  1.716918  0.000000   \n",
       "UtilizationPerCreditLine       92598.0  0.726617  2.314940 -0.439705   \n",
       "DelinquencyBucket              92598.0  1.816249  0.657420  0.000000   \n",
       "HighAgeRiskFlag                92598.0 -0.001075  1.000129 -1.121933   \n",
       "IncomePerCreditLine            92598.0  0.321183  2.143377 -0.712727   \n",
       "DebtToIncomeAgeRisk            92598.0  0.268932  1.608289 -0.444698   \n",
       "UtilizationPerAge              92598.0  0.281012  0.771726 -0.416697   \n",
       "LatePaymentsPerCreditLine      92598.0  0.076097  0.300314  0.000000   \n",
       "HasMajorDelinquency            92598.0  0.087302  0.282279  0.000000   \n",
       "RevolvingUtilizationCappedLog  92598.0  0.216556  0.633069 -0.440434   \n",
       "\n",
       "                                    25%       50%       75%         max  \\\n",
       "DelinquencyScore               0.000000  0.000000  0.000000   60.000000   \n",
       "TotalPastDueCapped             0.000000  0.000000  0.000000   10.000000   \n",
       "UtilizationTimesDelinquency    0.000000  0.000000  0.000000    0.071670   \n",
       "UtilizationBucketLateBucket    2.000000  3.000000  5.000000    5.000000   \n",
       "UtilizationPerCreditLine      -0.309695  0.000000  0.707668   39.419312   \n",
       "DelinquencyBucket              2.000000  2.000000  2.000000    3.000000   \n",
       "HighAgeRiskFlag               -1.121933  0.891319  0.891319    0.891319   \n",
       "IncomePerCreditLine           -0.399441  0.014545  0.575909  279.287273   \n",
       "DebtToIncomeAgeRisk           -0.422533  0.028949  0.586787  230.122301   \n",
       "UtilizationPerAge             -0.314413  0.000000  0.681580    8.241714   \n",
       "LatePaymentsPerCreditLine      0.000000  0.000000  0.000000   30.000000   \n",
       "HasMajorDelinquency            0.000000  0.000000  0.000000    1.000000   \n",
       "RevolvingUtilizationCappedLog -0.320875  0.000000  0.673260    4.139011   \n",
       "\n",
       "                                    skew    dtype  non_null  missing  \\\n",
       "DelinquencyScore               11.231471  float64     92598        0   \n",
       "TotalPastDueCapped              4.180515  float64     92598        0   \n",
       "UtilizationTimesDelinquency     3.093738  float64     92598        0   \n",
       "UtilizationBucketLateBucket    -0.328975     int8     92598        0   \n",
       "UtilizationPerCreditLine        4.650212  float64     92598        0   \n",
       "DelinquencyBucket              -1.622637     int8     92598        0   \n",
       "HighAgeRiskFlag                -0.228439  float64     92598        0   \n",
       "IncomePerCreditLine            51.497662  float64     92598        0   \n",
       "DebtToIncomeAgeRisk            66.268737  float64     92598        0   \n",
       "UtilizationPerAge               1.678331  float64     92598        0   \n",
       "LatePaymentsPerCreditLine      18.388191  float64     92598        0   \n",
       "HasMajorDelinquency             2.924108  float64     92598        0   \n",
       "RevolvingUtilizationCappedLog   1.117564  float64     92598        0   \n",
       "\n",
       "                               missing_%  unique  corr_with_target  \\\n",
       "DelinquencyScore                     0.0      38          0.361854   \n",
       "TotalPastDueCapped                   0.0      11          0.399287   \n",
       "UtilizationTimesDelinquency          0.0   15842          0.364758   \n",
       "UtilizationBucketLateBucket          0.0       6         -0.054086   \n",
       "UtilizationPerCreditLine             0.0   82039          0.177593   \n",
       "DelinquencyBucket                    0.0       4          0.053309   \n",
       "HighAgeRiskFlag                      0.0       2         -0.089933   \n",
       "IncomePerCreditLine                  0.0   26180          0.003751   \n",
       "DebtToIncomeAgeRisk                  0.0   72746          0.031882   \n",
       "UtilizationPerAge                    0.0   82305          0.268645   \n",
       "LatePaymentsPerCreditLine            0.0     201          0.309645   \n",
       "HasMajorDelinquency                  0.0       2          0.362474   \n",
       "RevolvingUtilizationCappedLog        0.0   80850          0.271133   \n",
       "\n",
       "                               high_corr_flag  \\\n",
       "DelinquencyScore                         True   \n",
       "TotalPastDueCapped                       True   \n",
       "UtilizationTimesDelinquency             False   \n",
       "UtilizationBucketLateBucket             False   \n",
       "UtilizationPerCreditLine                False   \n",
       "DelinquencyBucket                       False   \n",
       "HighAgeRiskFlag                         False   \n",
       "IncomePerCreditLine                     False   \n",
       "DebtToIncomeAgeRisk                     False   \n",
       "UtilizationPerAge                        True   \n",
       "LatePaymentsPerCreditLine               False   \n",
       "HasMajorDelinquency                     False   \n",
       "RevolvingUtilizationCappedLog            True   \n",
       "\n",
       "                                                     high_corr_with  \n",
       "DelinquencyScore                          TotalPastDueCapped (0.86)  \n",
       "TotalPastDueCapped                          DelinquencyScore (0.86)  \n",
       "UtilizationTimesDelinquency                                          \n",
       "UtilizationBucketLateBucket                                          \n",
       "UtilizationPerCreditLine                                             \n",
       "DelinquencyBucket                                                    \n",
       "HighAgeRiskFlag                                                      \n",
       "IncomePerCreditLine                                                  \n",
       "DebtToIncomeAgeRisk                                                  \n",
       "UtilizationPerAge              RevolvingUtilizationCappedLog (0.92)  \n",
       "LatePaymentsPerCreditLine                                            \n",
       "HasMajorDelinquency                                                  \n",
       "RevolvingUtilizationCappedLog              UtilizationPerAge (0.92)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WasUtilizationPerCreditLineImputed', 'WasIncomePerCreditLineImputed', 'WasUtilizationPerAgeImputed', 'WasLatePaymentsPerCreditLineImputed']\n"
     ]
    }
   ],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasTotalPastDueCappedImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasUtilizationTimesDelinquencyImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasRevolvingUtilizationCappedLogImputed\",\n",
    "    \"WasDelinquencyBucketImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep\n",
    "print(X_train_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Flags\n",
    "X_train_flags = X_train[X_train_flags]\n",
    "X_val_flags = X_val[X_val_flags]\n",
    "X_test_flags = X_test[X_test_flags]\n",
    "\n",
    "# NN\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_col_order])\n",
    "X_val_cat = encoder.transform(X_val[cat_col_order])\n",
    "X_test_cat = encoder.transform(X_test[cat_col_order])\n",
    "\n",
    "cat_feature_names = encoder.get_feature_names_out(cat_col_order)\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "X_val_cat_df = pd.DataFrame(X_val_cat, columns=cat_feature_names, index=X_val.index)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat, columns=cat_feature_names, index=X_test.index)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_cat_df, X_train[num_col_order], X_train_flags], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_cat_df, X_val[num_col_order], X_val_flags], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_cat_df, X_test[num_col_order], X_test_flags], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([92598, 25])\n",
      "Class weights: {np.int64(0): np.float64(0.5355209586379198), np.int64(1): np.float64(7.538098339303159)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92598, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=25, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=25, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 50483\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model = NN(X_train_tensor.shape[1]).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/5 ===\n",
      "Epoch 1/75 | Train loss: 0.027600 | Train AUC: 0.8167 | Val loss: 0.024838 | Val AUC: 0.8497\n",
      "Epoch 2/75 | Train loss: 0.024965 | Train AUC: 0.8463 | Val loss: 0.024709 | Val AUC: 0.8515\n",
      "Epoch 3/75 | Train loss: 0.024698 | Train AUC: 0.8498 | Val loss: 0.024780 | Val AUC: 0.8517\n",
      "Epoch 4/75 | Train loss: 0.024492 | Train AUC: 0.8529 | Val loss: 0.025082 | Val AUC: 0.8526\n",
      "Epoch 5/75 | Train loss: 0.024448 | Train AUC: 0.8534 | Val loss: 0.024917 | Val AUC: 0.8531\n",
      "Epoch 6/75 | Train loss: 0.024443 | Train AUC: 0.8533 | Val loss: 0.024839 | Val AUC: 0.8553\n",
      "Epoch 7/75 | Train loss: 0.024401 | Train AUC: 0.8546 | Val loss: 0.024790 | Val AUC: 0.8518\n",
      "Epoch 8/75 | Train loss: 0.024378 | Train AUC: 0.8551 | Val loss: 0.024789 | Val AUC: 0.8530\n",
      "Epoch 9/75 | Train loss: 0.024370 | Train AUC: 0.8552 | Val loss: 0.024871 | Val AUC: 0.8550\n",
      "Epoch 10/75 | Train loss: 0.024234 | Train AUC: 0.8570 | Val loss: 0.025168 | Val AUC: 0.8479\n",
      "Epoch 11/75 | Train loss: 0.024258 | Train AUC: 0.8570 | Val loss: 0.025058 | Val AUC: 0.8497\n",
      "Epoch 12/75 | Train loss: 0.024307 | Train AUC: 0.8559 | Val loss: 0.024762 | Val AUC: 0.8543\n",
      "Epoch 13/75 | Train loss: 0.024187 | Train AUC: 0.8581 | Val loss: 0.024869 | Val AUC: 0.8549\n",
      "Epoch 14/75 | Train loss: 0.024116 | Train AUC: 0.8591 | Val loss: 0.024949 | Val AUC: 0.8550\n",
      "Epoch 15/75 | Train loss: 0.024124 | Train AUC: 0.8593 | Val loss: 0.024822 | Val AUC: 0.8538\n",
      "Epoch 16/75 | Train loss: 0.024135 | Train AUC: 0.8588 | Val loss: 0.024780 | Val AUC: 0.8555\n",
      "Epoch 17/75 | Train loss: 0.024119 | Train AUC: 0.8586 | Val loss: 0.024788 | Val AUC: 0.8555\n",
      "Epoch 18/75 | Train loss: 0.024132 | Train AUC: 0.8588 | Val loss: 0.024760 | Val AUC: 0.8535\n",
      "Epoch 19/75 | Train loss: 0.024133 | Train AUC: 0.8586 | Val loss: 0.024678 | Val AUC: 0.8568\n",
      "Epoch 20/75 | Train loss: 0.024068 | Train AUC: 0.8595 | Val loss: 0.025042 | Val AUC: 0.8549\n",
      "Epoch 21/75 | Train loss: 0.023993 | Train AUC: 0.8606 | Val loss: 0.024837 | Val AUC: 0.8536\n",
      "Epoch 22/75 | Train loss: 0.024119 | Train AUC: 0.8589 | Val loss: 0.024668 | Val AUC: 0.8545\n",
      "Epoch 23/75 | Train loss: 0.024072 | Train AUC: 0.8593 | Val loss: 0.024710 | Val AUC: 0.8539\n",
      "Epoch 24/75 | Train loss: 0.024053 | Train AUC: 0.8599 | Val loss: 0.024849 | Val AUC: 0.8564\n",
      "Epoch 25/75 | Train loss: 0.024049 | Train AUC: 0.8598 | Val loss: 0.024684 | Val AUC: 0.8561\n",
      "Epoch 26/75 | Train loss: 0.023987 | Train AUC: 0.8611 | Val loss: 0.024585 | Val AUC: 0.8562\n",
      "Epoch 27/75 | Train loss: 0.023991 | Train AUC: 0.8607 | Val loss: 0.024757 | Val AUC: 0.8561\n",
      "Epoch 28/75 | Train loss: 0.023960 | Train AUC: 0.8614 | Val loss: 0.024769 | Val AUC: 0.8568\n",
      "Epoch 29/75 | Train loss: 0.023961 | Train AUC: 0.8615 | Val loss: 0.024687 | Val AUC: 0.8555\n",
      "Epoch 30/75 | Train loss: 0.023975 | Train AUC: 0.8610 | Val loss: 0.024552 | Val AUC: 0.8547\n",
      "Epoch 31/75 | Train loss: 0.023987 | Train AUC: 0.8608 | Val loss: 0.024551 | Val AUC: 0.8560\n",
      "Epoch 32/75 | Train loss: 0.023915 | Train AUC: 0.8620 | Val loss: 0.024734 | Val AUC: 0.8555\n",
      "Epoch 33/75 | Train loss: 0.023978 | Train AUC: 0.8608 | Val loss: 0.024740 | Val AUC: 0.8565\n",
      "Epoch 34/75 | Train loss: 0.023984 | Train AUC: 0.8611 | Val loss: 0.024593 | Val AUC: 0.8551\n",
      "Epoch 35/75 | Train loss: 0.023960 | Train AUC: 0.8612 | Val loss: 0.024579 | Val AUC: 0.8555\n",
      "Epoch 36/75 | Train loss: 0.023923 | Train AUC: 0.8615 | Val loss: 0.024628 | Val AUC: 0.8562\n",
      "Epoch 37/75 | Train loss: 0.023921 | Train AUC: 0.8617 | Val loss: 0.024742 | Val AUC: 0.8530\n",
      "Epoch 38/75 | Train loss: 0.023926 | Train AUC: 0.8616 | Val loss: 0.024550 | Val AUC: 0.8570\n",
      "Epoch 39/75 | Train loss: 0.023888 | Train AUC: 0.8621 | Val loss: 0.024538 | Val AUC: 0.8567\n",
      "Epoch 40/75 | Train loss: 0.023869 | Train AUC: 0.8624 | Val loss: 0.024558 | Val AUC: 0.8570\n",
      "Epoch 41/75 | Train loss: 0.023951 | Train AUC: 0.8612 | Val loss: 0.024614 | Val AUC: 0.8568\n",
      "Epoch 42/75 | Train loss: 0.023906 | Train AUC: 0.8621 | Val loss: 0.024584 | Val AUC: 0.8566\n",
      "Epoch 43/75 | Train loss: 0.023894 | Train AUC: 0.8624 | Val loss: 0.024561 | Val AUC: 0.8566\n",
      "Epoch 44/75 | Train loss: 0.023868 | Train AUC: 0.8626 | Val loss: 0.024603 | Val AUC: 0.8569\n",
      "Epoch 45/75 | Train loss: 0.023845 | Train AUC: 0.8630 | Val loss: 0.024576 | Val AUC: 0.8571\n",
      "Epoch 46/75 | Train loss: 0.023851 | Train AUC: 0.8628 | Val loss: 0.024532 | Val AUC: 0.8563\n",
      "Epoch 47/75 | Train loss: 0.023802 | Train AUC: 0.8638 | Val loss: 0.024560 | Val AUC: 0.8561\n",
      "Epoch 48/75 | Train loss: 0.023912 | Train AUC: 0.8623 | Val loss: 0.024481 | Val AUC: 0.8569\n",
      "Epoch 49/75 | Train loss: 0.023830 | Train AUC: 0.8631 | Val loss: 0.024576 | Val AUC: 0.8557\n",
      "Epoch 50/75 | Train loss: 0.023841 | Train AUC: 0.8632 | Val loss: 0.024644 | Val AUC: 0.8562\n",
      "Epoch 51/75 | Train loss: 0.023853 | Train AUC: 0.8625 | Val loss: 0.024439 | Val AUC: 0.8570\n",
      "Epoch 52/75 | Train loss: 0.023857 | Train AUC: 0.8631 | Val loss: 0.024480 | Val AUC: 0.8566\n",
      "Epoch 53/75 | Train loss: 0.023806 | Train AUC: 0.8635 | Val loss: 0.024603 | Val AUC: 0.8562\n",
      "Epoch 54/75 | Train loss: 0.023862 | Train AUC: 0.8627 | Val loss: 0.024545 | Val AUC: 0.8562\n",
      "Epoch 55/75 | Train loss: 0.023810 | Train AUC: 0.8637 | Val loss: 0.024617 | Val AUC: 0.8567\n",
      "Epoch 56/75 | Train loss: 0.023918 | Train AUC: 0.8620 | Val loss: 0.024795 | Val AUC: 0.8526\n",
      "Epoch 57/75 | Train loss: 0.023884 | Train AUC: 0.8620 | Val loss: 0.024604 | Val AUC: 0.8563\n",
      "Early stopping at epoch 58\n",
      "Run 1 best Val AUC: 0.8571\n",
      "=== Run 2/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024087 | Train AUC: 0.8592 | Val loss: 0.024808 | Val AUC: 0.8532\n",
      "Epoch 2/75 | Train loss: 0.024105 | Train AUC: 0.8595 | Val loss: 0.024676 | Val AUC: 0.8562\n",
      "Epoch 3/75 | Train loss: 0.024099 | Train AUC: 0.8595 | Val loss: 0.024837 | Val AUC: 0.8555\n",
      "Epoch 4/75 | Train loss: 0.024069 | Train AUC: 0.8598 | Val loss: 0.024617 | Val AUC: 0.8544\n",
      "Epoch 5/75 | Train loss: 0.024098 | Train AUC: 0.8593 | Val loss: 0.024947 | Val AUC: 0.8548\n",
      "Epoch 6/75 | Train loss: 0.024095 | Train AUC: 0.8595 | Val loss: 0.024559 | Val AUC: 0.8555\n",
      "Epoch 7/75 | Train loss: 0.024060 | Train AUC: 0.8600 | Val loss: 0.024915 | Val AUC: 0.8506\n",
      "Epoch 8/75 | Train loss: 0.024093 | Train AUC: 0.8596 | Val loss: 0.024840 | Val AUC: 0.8534\n",
      "Epoch 9/75 | Train loss: 0.023981 | Train AUC: 0.8610 | Val loss: 0.024705 | Val AUC: 0.8560\n",
      "Epoch 10/75 | Train loss: 0.023908 | Train AUC: 0.8620 | Val loss: 0.024585 | Val AUC: 0.8542\n",
      "Epoch 11/75 | Train loss: 0.023955 | Train AUC: 0.8614 | Val loss: 0.024746 | Val AUC: 0.8564\n",
      "Epoch 12/75 | Train loss: 0.023943 | Train AUC: 0.8616 | Val loss: 0.024654 | Val AUC: 0.8541\n",
      "Epoch 13/75 | Train loss: 0.023984 | Train AUC: 0.8612 | Val loss: 0.024652 | Val AUC: 0.8562\n",
      "Epoch 14/75 | Train loss: 0.023945 | Train AUC: 0.8617 | Val loss: 0.024529 | Val AUC: 0.8569\n",
      "Epoch 15/75 | Train loss: 0.023939 | Train AUC: 0.8614 | Val loss: 0.024548 | Val AUC: 0.8546\n",
      "Epoch 16/75 | Train loss: 0.023903 | Train AUC: 0.8624 | Val loss: 0.024616 | Val AUC: 0.8556\n",
      "Epoch 17/75 | Train loss: 0.023914 | Train AUC: 0.8620 | Val loss: 0.024698 | Val AUC: 0.8547\n",
      "Epoch 18/75 | Train loss: 0.023877 | Train AUC: 0.8624 | Val loss: 0.024905 | Val AUC: 0.8520\n",
      "Epoch 19/75 | Train loss: 0.023938 | Train AUC: 0.8619 | Val loss: 0.024659 | Val AUC: 0.8546\n",
      "Epoch 20/75 | Train loss: 0.023934 | Train AUC: 0.8614 | Val loss: 0.024501 | Val AUC: 0.8557\n",
      "Epoch 21/75 | Train loss: 0.023881 | Train AUC: 0.8626 | Val loss: 0.024536 | Val AUC: 0.8568\n",
      "Epoch 22/75 | Train loss: 0.023878 | Train AUC: 0.8625 | Val loss: 0.024531 | Val AUC: 0.8564\n",
      "Epoch 23/75 | Train loss: 0.023820 | Train AUC: 0.8635 | Val loss: 0.024784 | Val AUC: 0.8524\n",
      "Epoch 24/75 | Train loss: 0.023921 | Train AUC: 0.8621 | Val loss: 0.024600 | Val AUC: 0.8530\n",
      "Epoch 25/75 | Train loss: 0.023766 | Train AUC: 0.8643 | Val loss: 0.024486 | Val AUC: 0.8562\n",
      "Epoch 26/75 | Train loss: 0.023848 | Train AUC: 0.8625 | Val loss: 0.024566 | Val AUC: 0.8569\n",
      "Epoch 27/75 | Train loss: 0.023813 | Train AUC: 0.8636 | Val loss: 0.024508 | Val AUC: 0.8563\n",
      "Epoch 28/75 | Train loss: 0.023776 | Train AUC: 0.8639 | Val loss: 0.024497 | Val AUC: 0.8569\n",
      "Epoch 29/75 | Train loss: 0.023838 | Train AUC: 0.8630 | Val loss: 0.024644 | Val AUC: 0.8535\n",
      "Epoch 30/75 | Train loss: 0.023795 | Train AUC: 0.8637 | Val loss: 0.024498 | Val AUC: 0.8568\n",
      "Epoch 31/75 | Train loss: 0.023803 | Train AUC: 0.8637 | Val loss: 0.024481 | Val AUC: 0.8562\n",
      "Epoch 32/75 | Train loss: 0.023822 | Train AUC: 0.8634 | Val loss: 0.024561 | Val AUC: 0.8564\n",
      "Epoch 33/75 | Train loss: 0.023801 | Train AUC: 0.8635 | Val loss: 0.024563 | Val AUC: 0.8549\n",
      "Epoch 34/75 | Train loss: 0.023826 | Train AUC: 0.8633 | Val loss: 0.024421 | Val AUC: 0.8573\n",
      "Epoch 35/75 | Train loss: 0.023775 | Train AUC: 0.8641 | Val loss: 0.024498 | Val AUC: 0.8573\n",
      "Epoch 36/75 | Train loss: 0.023811 | Train AUC: 0.8634 | Val loss: 0.024456 | Val AUC: 0.8567\n",
      "Epoch 37/75 | Train loss: 0.023787 | Train AUC: 0.8638 | Val loss: 0.024592 | Val AUC: 0.8550\n",
      "Epoch 38/75 | Train loss: 0.023763 | Train AUC: 0.8641 | Val loss: 0.024443 | Val AUC: 0.8570\n",
      "Epoch 39/75 | Train loss: 0.023788 | Train AUC: 0.8638 | Val loss: 0.024505 | Val AUC: 0.8557\n",
      "Epoch 40/75 | Train loss: 0.023810 | Train AUC: 0.8632 | Val loss: 0.024538 | Val AUC: 0.8568\n",
      "Epoch 41/75 | Train loss: 0.023790 | Train AUC: 0.8637 | Val loss: 0.024518 | Val AUC: 0.8560\n",
      "Epoch 42/75 | Train loss: 0.023723 | Train AUC: 0.8649 | Val loss: 0.024435 | Val AUC: 0.8567\n",
      "Epoch 43/75 | Train loss: 0.023747 | Train AUC: 0.8641 | Val loss: 0.024494 | Val AUC: 0.8570\n",
      "Epoch 44/75 | Train loss: 0.023796 | Train AUC: 0.8637 | Val loss: 0.024480 | Val AUC: 0.8563\n",
      "Epoch 45/75 | Train loss: 0.023764 | Train AUC: 0.8643 | Val loss: 0.024498 | Val AUC: 0.8570\n",
      "Epoch 46/75 | Train loss: 0.023792 | Train AUC: 0.8637 | Val loss: 0.024476 | Val AUC: 0.8561\n",
      "Early stopping at epoch 47\n",
      "Run 2 best Val AUC: 0.8573\n",
      "=== Run 3/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024014 | Train AUC: 0.8604 | Val loss: 0.024520 | Val AUC: 0.8559\n",
      "Epoch 2/75 | Train loss: 0.023988 | Train AUC: 0.8612 | Val loss: 0.024686 | Val AUC: 0.8529\n",
      "Epoch 3/75 | Train loss: 0.024077 | Train AUC: 0.8595 | Val loss: 0.024821 | Val AUC: 0.8542\n",
      "Epoch 4/75 | Train loss: 0.024024 | Train AUC: 0.8602 | Val loss: 0.024491 | Val AUC: 0.8579\n",
      "Epoch 5/75 | Train loss: 0.024059 | Train AUC: 0.8601 | Val loss: 0.024870 | Val AUC: 0.8551\n",
      "Epoch 6/75 | Train loss: 0.023990 | Train AUC: 0.8612 | Val loss: 0.024513 | Val AUC: 0.8554\n",
      "Epoch 7/75 | Train loss: 0.023916 | Train AUC: 0.8622 | Val loss: 0.024777 | Val AUC: 0.8538\n",
      "Epoch 8/75 | Train loss: 0.024057 | Train AUC: 0.8599 | Val loss: 0.024601 | Val AUC: 0.8547\n",
      "Epoch 9/75 | Train loss: 0.024004 | Train AUC: 0.8606 | Val loss: 0.024529 | Val AUC: 0.8569\n",
      "Epoch 10/75 | Train loss: 0.024021 | Train AUC: 0.8606 | Val loss: 0.024733 | Val AUC: 0.8538\n",
      "Epoch 11/75 | Train loss: 0.023869 | Train AUC: 0.8627 | Val loss: 0.024376 | Val AUC: 0.8579\n",
      "Epoch 12/75 | Train loss: 0.023875 | Train AUC: 0.8625 | Val loss: 0.024767 | Val AUC: 0.8550\n",
      "Epoch 13/75 | Train loss: 0.023944 | Train AUC: 0.8617 | Val loss: 0.024510 | Val AUC: 0.8573\n",
      "Epoch 14/75 | Train loss: 0.023906 | Train AUC: 0.8618 | Val loss: 0.024487 | Val AUC: 0.8562\n",
      "Epoch 15/75 | Train loss: 0.023883 | Train AUC: 0.8623 | Val loss: 0.024527 | Val AUC: 0.8556\n",
      "Epoch 16/75 | Train loss: 0.023904 | Train AUC: 0.8620 | Val loss: 0.024502 | Val AUC: 0.8549\n",
      "Early stopping at epoch 17\n",
      "Run 3 best Val AUC: 0.8579\n",
      "=== Run 4/5 ===\n",
      "Epoch 1/75 | Train loss: 0.023936 | Train AUC: 0.8616 | Val loss: 0.024637 | Val AUC: 0.8556\n",
      "Epoch 2/75 | Train loss: 0.023952 | Train AUC: 0.8616 | Val loss: 0.024572 | Val AUC: 0.8564\n",
      "Epoch 3/75 | Train loss: 0.023971 | Train AUC: 0.8616 | Val loss: 0.024484 | Val AUC: 0.8569\n",
      "Epoch 4/75 | Train loss: 0.023944 | Train AUC: 0.8621 | Val loss: 0.024744 | Val AUC: 0.8558\n",
      "Epoch 5/75 | Train loss: 0.023982 | Train AUC: 0.8610 | Val loss: 0.024391 | Val AUC: 0.8579\n",
      "Epoch 6/75 | Train loss: 0.023957 | Train AUC: 0.8613 | Val loss: 0.024566 | Val AUC: 0.8563\n",
      "Epoch 7/75 | Train loss: 0.023931 | Train AUC: 0.8620 | Val loss: 0.024741 | Val AUC: 0.8538\n",
      "Epoch 8/75 | Train loss: 0.023899 | Train AUC: 0.8623 | Val loss: 0.024526 | Val AUC: 0.8560\n",
      "Epoch 9/75 | Train loss: 0.023980 | Train AUC: 0.8612 | Val loss: 0.024670 | Val AUC: 0.8538\n",
      "Epoch 10/75 | Train loss: 0.023974 | Train AUC: 0.8615 | Val loss: 0.024500 | Val AUC: 0.8551\n",
      "Epoch 11/75 | Train loss: 0.023936 | Train AUC: 0.8617 | Val loss: 0.024378 | Val AUC: 0.8560\n",
      "Epoch 12/75 | Train loss: 0.023823 | Train AUC: 0.8635 | Val loss: 0.024465 | Val AUC: 0.8560\n",
      "Epoch 13/75 | Train loss: 0.023826 | Train AUC: 0.8631 | Val loss: 0.024477 | Val AUC: 0.8558\n",
      "Epoch 14/75 | Train loss: 0.023850 | Train AUC: 0.8630 | Val loss: 0.024433 | Val AUC: 0.8573\n",
      "Epoch 15/75 | Train loss: 0.023822 | Train AUC: 0.8637 | Val loss: 0.024625 | Val AUC: 0.8526\n",
      "Epoch 16/75 | Train loss: 0.023823 | Train AUC: 0.8634 | Val loss: 0.024520 | Val AUC: 0.8564\n",
      "Epoch 17/75 | Train loss: 0.023775 | Train AUC: 0.8643 | Val loss: 0.024352 | Val AUC: 0.8574\n",
      "Early stopping at epoch 18\n",
      "Run 4 best Val AUC: 0.8579\n",
      "=== Run 5/5 ===\n",
      "Epoch 1/75 | Train loss: 0.023942 | Train AUC: 0.8618 | Val loss: 0.024555 | Val AUC: 0.8538\n",
      "Epoch 2/75 | Train loss: 0.023868 | Train AUC: 0.8630 | Val loss: 0.024500 | Val AUC: 0.8551\n",
      "Epoch 3/75 | Train loss: 0.023887 | Train AUC: 0.8630 | Val loss: 0.024793 | Val AUC: 0.8540\n",
      "Epoch 4/75 | Train loss: 0.023952 | Train AUC: 0.8619 | Val loss: 0.024489 | Val AUC: 0.8559\n",
      "Epoch 5/75 | Train loss: 0.023901 | Train AUC: 0.8624 | Val loss: 0.024824 | Val AUC: 0.8532\n",
      "Epoch 6/75 | Train loss: 0.023888 | Train AUC: 0.8627 | Val loss: 0.024497 | Val AUC: 0.8554\n",
      "Epoch 7/75 | Train loss: 0.023904 | Train AUC: 0.8625 | Val loss: 0.024467 | Val AUC: 0.8560\n",
      "Epoch 8/75 | Train loss: 0.023895 | Train AUC: 0.8624 | Val loss: 0.024797 | Val AUC: 0.8510\n",
      "Epoch 9/75 | Train loss: 0.023906 | Train AUC: 0.8621 | Val loss: 0.024491 | Val AUC: 0.8541\n",
      "Epoch 10/75 | Train loss: 0.023881 | Train AUC: 0.8627 | Val loss: 0.024475 | Val AUC: 0.8557\n",
      "Epoch 11/75 | Train loss: 0.023889 | Train AUC: 0.8621 | Val loss: 0.024680 | Val AUC: 0.8557\n",
      "Epoch 12/75 | Train loss: 0.023845 | Train AUC: 0.8633 | Val loss: 0.024470 | Val AUC: 0.8570\n",
      "Epoch 13/75 | Train loss: 0.023889 | Train AUC: 0.8622 | Val loss: 0.024765 | Val AUC: 0.8546\n",
      "Epoch 14/75 | Train loss: 0.023868 | Train AUC: 0.8627 | Val loss: 0.024471 | Val AUC: 0.8553\n",
      "Epoch 15/75 | Train loss: 0.023909 | Train AUC: 0.8621 | Val loss: 0.024558 | Val AUC: 0.8551\n",
      "Epoch 16/75 | Train loss: 0.023921 | Train AUC: 0.8619 | Val loss: 0.024468 | Val AUC: 0.8559\n",
      "Epoch 17/75 | Train loss: 0.023869 | Train AUC: 0.8629 | Val loss: 0.024847 | Val AUC: 0.8514\n",
      "Epoch 18/75 | Train loss: 0.023834 | Train AUC: 0.8631 | Val loss: 0.024527 | Val AUC: 0.8562\n",
      "Epoch 19/75 | Train loss: 0.023764 | Train AUC: 0.8642 | Val loss: 0.024474 | Val AUC: 0.8564\n",
      "Epoch 20/75 | Train loss: 0.023758 | Train AUC: 0.8645 | Val loss: 0.024312 | Val AUC: 0.8571\n",
      "Epoch 21/75 | Train loss: 0.023764 | Train AUC: 0.8642 | Val loss: 0.024697 | Val AUC: 0.8526\n",
      "Epoch 22/75 | Train loss: 0.023747 | Train AUC: 0.8646 | Val loss: 0.024662 | Val AUC: 0.8515\n",
      "Epoch 23/75 | Train loss: 0.023736 | Train AUC: 0.8649 | Val loss: 0.024416 | Val AUC: 0.8563\n",
      "Epoch 24/75 | Train loss: 0.023708 | Train AUC: 0.8653 | Val loss: 0.024534 | Val AUC: 0.8533\n",
      "Epoch 25/75 | Train loss: 0.023619 | Train AUC: 0.8664 | Val loss: 0.024666 | Val AUC: 0.8531\n",
      "Epoch 26/75 | Train loss: 0.023687 | Train AUC: 0.8653 | Val loss: 0.024374 | Val AUC: 0.8574\n",
      "Epoch 27/75 | Train loss: 0.023698 | Train AUC: 0.8650 | Val loss: 0.024492 | Val AUC: 0.8549\n",
      "Epoch 28/75 | Train loss: 0.023720 | Train AUC: 0.8652 | Val loss: 0.024548 | Val AUC: 0.8538\n",
      "Epoch 29/75 | Train loss: 0.023683 | Train AUC: 0.8653 | Val loss: 0.024463 | Val AUC: 0.8553\n",
      "Epoch 30/75 | Train loss: 0.023747 | Train AUC: 0.8645 | Val loss: 0.024365 | Val AUC: 0.8563\n",
      "Epoch 31/75 | Train loss: 0.023629 | Train AUC: 0.8665 | Val loss: 0.024612 | Val AUC: 0.8522\n",
      "Epoch 32/75 | Train loss: 0.023651 | Train AUC: 0.8656 | Val loss: 0.024471 | Val AUC: 0.8557\n",
      "Epoch 33/75 | Train loss: 0.023648 | Train AUC: 0.8658 | Val loss: 0.024651 | Val AUC: 0.8514\n",
      "Epoch 34/75 | Train loss: 0.023611 | Train AUC: 0.8664 | Val loss: 0.024437 | Val AUC: 0.8562\n",
      "Epoch 35/75 | Train loss: 0.023572 | Train AUC: 0.8674 | Val loss: 0.024965 | Val AUC: 0.8500\n",
      "Epoch 36/75 | Train loss: 0.023600 | Train AUC: 0.8667 | Val loss: 0.024457 | Val AUC: 0.8557\n",
      "Epoch 37/75 | Train loss: 0.023718 | Train AUC: 0.8649 | Val loss: 0.024685 | Val AUC: 0.8516\n",
      "Epoch 38/75 | Train loss: 0.023654 | Train AUC: 0.8663 | Val loss: 0.024452 | Val AUC: 0.8566\n",
      "Early stopping at epoch 39\n",
      "Run 5 best Val AUC: 0.8574\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8579)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3424242436885834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.84      0.91     27868\n",
      "   Defaulted       0.24      0.70      0.36      1978\n",
      "\n",
      "    accuracy                           0.84     29846\n",
      "   macro avg       0.61      0.77      0.63     29846\n",
      "weighted avg       0.93      0.84      0.87     29846\n",
      "\n",
      "Accuracy: 83.53%\n",
      "ROC AUC: 0.859\n",
      "TP=1394, FP=4332, TN=23536, FN=584\n",
      "Accuracy for class 'Repaid': 84.46%\n",
      "Accuracy for class 'Defaulted': 70.48%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, 0.69)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "best_param = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"scale_pos_weight\": sum(y_train==0)/sum(y_train==1),\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_alpha\": 1,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"tree_method\": \"hist\", \n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83548\n",
      "[1]\tvalidation_0-auc:0.84466\n",
      "[2]\tvalidation_0-auc:0.84518\n",
      "[3]\tvalidation_0-auc:0.84706\n",
      "[4]\tvalidation_0-auc:0.84777\n",
      "[5]\tvalidation_0-auc:0.84882\n",
      "[6]\tvalidation_0-auc:0.84924\n",
      "[7]\tvalidation_0-auc:0.84949\n",
      "[8]\tvalidation_0-auc:0.84970\n",
      "[9]\tvalidation_0-auc:0.85010\n",
      "[10]\tvalidation_0-auc:0.85010\n",
      "[11]\tvalidation_0-auc:0.85000\n",
      "[12]\tvalidation_0-auc:0.85010\n",
      "[13]\tvalidation_0-auc:0.85009\n",
      "[14]\tvalidation_0-auc:0.85018\n",
      "[15]\tvalidation_0-auc:0.85015\n",
      "[16]\tvalidation_0-auc:0.85013\n",
      "[17]\tvalidation_0-auc:0.85007\n",
      "[18]\tvalidation_0-auc:0.85012\n",
      "[19]\tvalidation_0-auc:0.85035\n",
      "[20]\tvalidation_0-auc:0.85029\n",
      "[21]\tvalidation_0-auc:0.85049\n",
      "[22]\tvalidation_0-auc:0.85067\n",
      "[23]\tvalidation_0-auc:0.85078\n",
      "[24]\tvalidation_0-auc:0.85089\n",
      "[25]\tvalidation_0-auc:0.85084\n",
      "[26]\tvalidation_0-auc:0.85122\n",
      "[27]\tvalidation_0-auc:0.85146\n",
      "[28]\tvalidation_0-auc:0.85191\n",
      "[29]\tvalidation_0-auc:0.85236\n",
      "[30]\tvalidation_0-auc:0.85234\n",
      "[31]\tvalidation_0-auc:0.85238\n",
      "[32]\tvalidation_0-auc:0.85230\n",
      "[33]\tvalidation_0-auc:0.85243\n",
      "[34]\tvalidation_0-auc:0.85257\n",
      "[35]\tvalidation_0-auc:0.85251\n",
      "[36]\tvalidation_0-auc:0.85246\n",
      "[37]\tvalidation_0-auc:0.85242\n",
      "[38]\tvalidation_0-auc:0.85241\n",
      "[39]\tvalidation_0-auc:0.85241\n",
      "[40]\tvalidation_0-auc:0.85230\n",
      "[41]\tvalidation_0-auc:0.85239\n",
      "[42]\tvalidation_0-auc:0.85240\n",
      "[43]\tvalidation_0-auc:0.85251\n",
      "[44]\tvalidation_0-auc:0.85267\n",
      "[45]\tvalidation_0-auc:0.85267\n",
      "[46]\tvalidation_0-auc:0.85274\n",
      "[47]\tvalidation_0-auc:0.85277\n",
      "[48]\tvalidation_0-auc:0.85281\n",
      "[49]\tvalidation_0-auc:0.85285\n",
      "[50]\tvalidation_0-auc:0.85288\n",
      "[51]\tvalidation_0-auc:0.85275\n",
      "[52]\tvalidation_0-auc:0.85286\n",
      "[53]\tvalidation_0-auc:0.85285\n",
      "[54]\tvalidation_0-auc:0.85289\n",
      "[55]\tvalidation_0-auc:0.85290\n",
      "[56]\tvalidation_0-auc:0.85279\n",
      "[57]\tvalidation_0-auc:0.85290\n",
      "[58]\tvalidation_0-auc:0.85296\n",
      "[59]\tvalidation_0-auc:0.85291\n",
      "[60]\tvalidation_0-auc:0.85296\n",
      "[61]\tvalidation_0-auc:0.85292\n",
      "[62]\tvalidation_0-auc:0.85305\n",
      "[63]\tvalidation_0-auc:0.85312\n",
      "[64]\tvalidation_0-auc:0.85315\n",
      "[65]\tvalidation_0-auc:0.85310\n",
      "[66]\tvalidation_0-auc:0.85321\n",
      "[67]\tvalidation_0-auc:0.85319\n",
      "[68]\tvalidation_0-auc:0.85313\n",
      "[69]\tvalidation_0-auc:0.85329\n",
      "[70]\tvalidation_0-auc:0.85330\n",
      "[71]\tvalidation_0-auc:0.85335\n",
      "[72]\tvalidation_0-auc:0.85330\n",
      "[73]\tvalidation_0-auc:0.85334\n",
      "[74]\tvalidation_0-auc:0.85335\n",
      "[75]\tvalidation_0-auc:0.85339\n",
      "[76]\tvalidation_0-auc:0.85343\n",
      "[77]\tvalidation_0-auc:0.85349\n",
      "[78]\tvalidation_0-auc:0.85352\n",
      "[79]\tvalidation_0-auc:0.85359\n",
      "[80]\tvalidation_0-auc:0.85362\n",
      "[81]\tvalidation_0-auc:0.85368\n",
      "[82]\tvalidation_0-auc:0.85371\n",
      "[83]\tvalidation_0-auc:0.85381\n",
      "[84]\tvalidation_0-auc:0.85384\n",
      "[85]\tvalidation_0-auc:0.85378\n",
      "[86]\tvalidation_0-auc:0.85388\n",
      "[87]\tvalidation_0-auc:0.85392\n",
      "[88]\tvalidation_0-auc:0.85392\n",
      "[89]\tvalidation_0-auc:0.85400\n",
      "[90]\tvalidation_0-auc:0.85407\n",
      "[91]\tvalidation_0-auc:0.85405\n",
      "[92]\tvalidation_0-auc:0.85407\n",
      "[93]\tvalidation_0-auc:0.85413\n",
      "[94]\tvalidation_0-auc:0.85421\n",
      "[95]\tvalidation_0-auc:0.85424\n",
      "[96]\tvalidation_0-auc:0.85422\n",
      "[97]\tvalidation_0-auc:0.85431\n",
      "[98]\tvalidation_0-auc:0.85439\n",
      "[99]\tvalidation_0-auc:0.85455\n",
      "[100]\tvalidation_0-auc:0.85465\n",
      "[101]\tvalidation_0-auc:0.85467\n",
      "[102]\tvalidation_0-auc:0.85467\n",
      "[103]\tvalidation_0-auc:0.85476\n",
      "[104]\tvalidation_0-auc:0.85467\n",
      "[105]\tvalidation_0-auc:0.85476\n",
      "[106]\tvalidation_0-auc:0.85484\n",
      "[107]\tvalidation_0-auc:0.85483\n",
      "[108]\tvalidation_0-auc:0.85490\n",
      "[109]\tvalidation_0-auc:0.85486\n",
      "[110]\tvalidation_0-auc:0.85483\n",
      "[111]\tvalidation_0-auc:0.85485\n",
      "[112]\tvalidation_0-auc:0.85489\n",
      "[113]\tvalidation_0-auc:0.85486\n",
      "[114]\tvalidation_0-auc:0.85490\n",
      "[115]\tvalidation_0-auc:0.85494\n",
      "[116]\tvalidation_0-auc:0.85502\n",
      "[117]\tvalidation_0-auc:0.85508\n",
      "[118]\tvalidation_0-auc:0.85509\n",
      "[119]\tvalidation_0-auc:0.85513\n",
      "[120]\tvalidation_0-auc:0.85517\n",
      "[121]\tvalidation_0-auc:0.85516\n",
      "[122]\tvalidation_0-auc:0.85519\n",
      "[123]\tvalidation_0-auc:0.85525\n",
      "[124]\tvalidation_0-auc:0.85530\n",
      "[125]\tvalidation_0-auc:0.85533\n",
      "[126]\tvalidation_0-auc:0.85540\n",
      "[127]\tvalidation_0-auc:0.85540\n",
      "[128]\tvalidation_0-auc:0.85540\n",
      "[129]\tvalidation_0-auc:0.85541\n",
      "[130]\tvalidation_0-auc:0.85547\n",
      "[131]\tvalidation_0-auc:0.85551\n",
      "[132]\tvalidation_0-auc:0.85554\n",
      "[133]\tvalidation_0-auc:0.85562\n",
      "[134]\tvalidation_0-auc:0.85564\n",
      "[135]\tvalidation_0-auc:0.85562\n",
      "[136]\tvalidation_0-auc:0.85568\n",
      "[137]\tvalidation_0-auc:0.85573\n",
      "[138]\tvalidation_0-auc:0.85580\n",
      "[139]\tvalidation_0-auc:0.85583\n",
      "[140]\tvalidation_0-auc:0.85586\n",
      "[141]\tvalidation_0-auc:0.85587\n",
      "[142]\tvalidation_0-auc:0.85588\n",
      "[143]\tvalidation_0-auc:0.85592\n",
      "[144]\tvalidation_0-auc:0.85597\n",
      "[145]\tvalidation_0-auc:0.85599\n",
      "[146]\tvalidation_0-auc:0.85601\n",
      "[147]\tvalidation_0-auc:0.85601\n",
      "[148]\tvalidation_0-auc:0.85602\n",
      "[149]\tvalidation_0-auc:0.85606\n",
      "[150]\tvalidation_0-auc:0.85610\n",
      "[151]\tvalidation_0-auc:0.85608\n",
      "[152]\tvalidation_0-auc:0.85609\n",
      "[153]\tvalidation_0-auc:0.85612\n",
      "[154]\tvalidation_0-auc:0.85615\n",
      "[155]\tvalidation_0-auc:0.85615\n",
      "[156]\tvalidation_0-auc:0.85621\n",
      "[157]\tvalidation_0-auc:0.85622\n",
      "[158]\tvalidation_0-auc:0.85621\n",
      "[159]\tvalidation_0-auc:0.85622\n",
      "[160]\tvalidation_0-auc:0.85623\n",
      "[161]\tvalidation_0-auc:0.85630\n",
      "[162]\tvalidation_0-auc:0.85633\n",
      "[163]\tvalidation_0-auc:0.85634\n",
      "[164]\tvalidation_0-auc:0.85639\n",
      "[165]\tvalidation_0-auc:0.85642\n",
      "[166]\tvalidation_0-auc:0.85646\n",
      "[167]\tvalidation_0-auc:0.85648\n",
      "[168]\tvalidation_0-auc:0.85649\n",
      "[169]\tvalidation_0-auc:0.85651\n",
      "[170]\tvalidation_0-auc:0.85652\n",
      "[171]\tvalidation_0-auc:0.85653\n",
      "[172]\tvalidation_0-auc:0.85654\n",
      "[173]\tvalidation_0-auc:0.85657\n",
      "[174]\tvalidation_0-auc:0.85658\n",
      "[175]\tvalidation_0-auc:0.85664\n",
      "[176]\tvalidation_0-auc:0.85667\n",
      "[177]\tvalidation_0-auc:0.85666\n",
      "[178]\tvalidation_0-auc:0.85666\n",
      "[179]\tvalidation_0-auc:0.85667\n",
      "[180]\tvalidation_0-auc:0.85666\n",
      "[181]\tvalidation_0-auc:0.85671\n",
      "[182]\tvalidation_0-auc:0.85672\n",
      "[183]\tvalidation_0-auc:0.85672\n",
      "[184]\tvalidation_0-auc:0.85677\n",
      "[185]\tvalidation_0-auc:0.85676\n",
      "[186]\tvalidation_0-auc:0.85679\n",
      "[187]\tvalidation_0-auc:0.85682\n",
      "[188]\tvalidation_0-auc:0.85682\n",
      "[189]\tvalidation_0-auc:0.85684\n",
      "[190]\tvalidation_0-auc:0.85685\n",
      "[191]\tvalidation_0-auc:0.85687\n",
      "[192]\tvalidation_0-auc:0.85688\n",
      "[193]\tvalidation_0-auc:0.85690\n",
      "[194]\tvalidation_0-auc:0.85693\n",
      "[195]\tvalidation_0-auc:0.85695\n",
      "[196]\tvalidation_0-auc:0.85696\n",
      "[197]\tvalidation_0-auc:0.85695\n",
      "[198]\tvalidation_0-auc:0.85697\n",
      "[199]\tvalidation_0-auc:0.85699\n",
      "[200]\tvalidation_0-auc:0.85701\n",
      "[201]\tvalidation_0-auc:0.85704\n",
      "[202]\tvalidation_0-auc:0.85706\n",
      "[203]\tvalidation_0-auc:0.85707\n",
      "[204]\tvalidation_0-auc:0.85712\n",
      "[205]\tvalidation_0-auc:0.85711\n",
      "[206]\tvalidation_0-auc:0.85711\n",
      "[207]\tvalidation_0-auc:0.85713\n",
      "[208]\tvalidation_0-auc:0.85717\n",
      "[209]\tvalidation_0-auc:0.85720\n",
      "[210]\tvalidation_0-auc:0.85722\n",
      "[211]\tvalidation_0-auc:0.85725\n",
      "[212]\tvalidation_0-auc:0.85726\n",
      "[213]\tvalidation_0-auc:0.85728\n",
      "[214]\tvalidation_0-auc:0.85729\n",
      "[215]\tvalidation_0-auc:0.85732\n",
      "[216]\tvalidation_0-auc:0.85733\n",
      "[217]\tvalidation_0-auc:0.85735\n",
      "[218]\tvalidation_0-auc:0.85738\n",
      "[219]\tvalidation_0-auc:0.85737\n",
      "[220]\tvalidation_0-auc:0.85738\n",
      "[221]\tvalidation_0-auc:0.85740\n",
      "[222]\tvalidation_0-auc:0.85743\n",
      "[223]\tvalidation_0-auc:0.85742\n",
      "[224]\tvalidation_0-auc:0.85743\n",
      "[225]\tvalidation_0-auc:0.85743\n",
      "[226]\tvalidation_0-auc:0.85744\n",
      "[227]\tvalidation_0-auc:0.85745\n",
      "[228]\tvalidation_0-auc:0.85745\n",
      "[229]\tvalidation_0-auc:0.85748\n",
      "[230]\tvalidation_0-auc:0.85749\n",
      "[231]\tvalidation_0-auc:0.85749\n",
      "[232]\tvalidation_0-auc:0.85752\n",
      "[233]\tvalidation_0-auc:0.85754\n",
      "[234]\tvalidation_0-auc:0.85755\n",
      "[235]\tvalidation_0-auc:0.85757\n",
      "[236]\tvalidation_0-auc:0.85760\n",
      "[237]\tvalidation_0-auc:0.85761\n",
      "[238]\tvalidation_0-auc:0.85759\n",
      "[239]\tvalidation_0-auc:0.85758\n",
      "[240]\tvalidation_0-auc:0.85756\n",
      "[241]\tvalidation_0-auc:0.85755\n",
      "[242]\tvalidation_0-auc:0.85755\n",
      "[243]\tvalidation_0-auc:0.85754\n",
      "[244]\tvalidation_0-auc:0.85754\n",
      "[245]\tvalidation_0-auc:0.85754\n",
      "[246]\tvalidation_0-auc:0.85755\n",
      "[247]\tvalidation_0-auc:0.85756\n",
      "[248]\tvalidation_0-auc:0.85757\n",
      "[249]\tvalidation_0-auc:0.85759\n",
      "[250]\tvalidation_0-auc:0.85759\n",
      "[251]\tvalidation_0-auc:0.85760\n",
      "[252]\tvalidation_0-auc:0.85761\n",
      "[253]\tvalidation_0-auc:0.85761\n",
      "[254]\tvalidation_0-auc:0.85762\n",
      "[255]\tvalidation_0-auc:0.85760\n",
      "[256]\tvalidation_0-auc:0.85757\n",
      "[257]\tvalidation_0-auc:0.85758\n",
      "[258]\tvalidation_0-auc:0.85758\n",
      "[259]\tvalidation_0-auc:0.85759\n",
      "[260]\tvalidation_0-auc:0.85760\n",
      "[261]\tvalidation_0-auc:0.85762\n",
      "[262]\tvalidation_0-auc:0.85764\n",
      "[263]\tvalidation_0-auc:0.85763\n",
      "[264]\tvalidation_0-auc:0.85764\n",
      "[265]\tvalidation_0-auc:0.85766\n",
      "[266]\tvalidation_0-auc:0.85766\n",
      "[267]\tvalidation_0-auc:0.85764\n",
      "[268]\tvalidation_0-auc:0.85764\n",
      "[269]\tvalidation_0-auc:0.85767\n",
      "[270]\tvalidation_0-auc:0.85766\n",
      "[271]\tvalidation_0-auc:0.85766\n",
      "[272]\tvalidation_0-auc:0.85766\n",
      "[273]\tvalidation_0-auc:0.85768\n",
      "[274]\tvalidation_0-auc:0.85768\n",
      "[275]\tvalidation_0-auc:0.85768\n",
      "[276]\tvalidation_0-auc:0.85767\n",
      "[277]\tvalidation_0-auc:0.85765\n",
      "[278]\tvalidation_0-auc:0.85766\n",
      "[279]\tvalidation_0-auc:0.85767\n",
      "[280]\tvalidation_0-auc:0.85767\n",
      "[281]\tvalidation_0-auc:0.85766\n",
      "[282]\tvalidation_0-auc:0.85765\n",
      "[283]\tvalidation_0-auc:0.85767\n",
      "[284]\tvalidation_0-auc:0.85768\n",
      "[285]\tvalidation_0-auc:0.85767\n",
      "[286]\tvalidation_0-auc:0.85768\n",
      "[287]\tvalidation_0-auc:0.85768\n",
      "[288]\tvalidation_0-auc:0.85769\n",
      "[289]\tvalidation_0-auc:0.85769\n",
      "[290]\tvalidation_0-auc:0.85770\n",
      "[291]\tvalidation_0-auc:0.85770\n",
      "[292]\tvalidation_0-auc:0.85769\n",
      "[293]\tvalidation_0-auc:0.85768\n",
      "[294]\tvalidation_0-auc:0.85769\n",
      "[295]\tvalidation_0-auc:0.85767\n",
      "[296]\tvalidation_0-auc:0.85768\n",
      "[297]\tvalidation_0-auc:0.85768\n",
      "[298]\tvalidation_0-auc:0.85769\n",
      "[299]\tvalidation_0-auc:0.85767\n",
      "[300]\tvalidation_0-auc:0.85765\n",
      "[301]\tvalidation_0-auc:0.85766\n",
      "[302]\tvalidation_0-auc:0.85765\n",
      "[303]\tvalidation_0-auc:0.85767\n",
      "[304]\tvalidation_0-auc:0.85766\n",
      "[305]\tvalidation_0-auc:0.85766\n",
      "[306]\tvalidation_0-auc:0.85766\n",
      "[307]\tvalidation_0-auc:0.85768\n",
      "[308]\tvalidation_0-auc:0.85766\n",
      "[309]\tvalidation_0-auc:0.85765\n",
      "[310]\tvalidation_0-auc:0.85768\n",
      "[311]\tvalidation_0-auc:0.85767\n",
      "[312]\tvalidation_0-auc:0.85765\n",
      "[313]\tvalidation_0-auc:0.85765\n",
      "[314]\tvalidation_0-auc:0.85765\n",
      "[315]\tvalidation_0-auc:0.85764\n",
      "[316]\tvalidation_0-auc:0.85766\n",
      "[317]\tvalidation_0-auc:0.85765\n",
      "[318]\tvalidation_0-auc:0.85765\n",
      "[319]\tvalidation_0-auc:0.85767\n",
      "[320]\tvalidation_0-auc:0.85767\n",
      "[321]\tvalidation_0-auc:0.85767\n",
      "[322]\tvalidation_0-auc:0.85768\n",
      "[323]\tvalidation_0-auc:0.85768\n",
      "[324]\tvalidation_0-auc:0.85766\n",
      "[325]\tvalidation_0-auc:0.85767\n",
      "[326]\tvalidation_0-auc:0.85765\n",
      "[327]\tvalidation_0-auc:0.85767\n",
      "[328]\tvalidation_0-auc:0.85768\n",
      "[329]\tvalidation_0-auc:0.85768\n",
      "[330]\tvalidation_0-auc:0.85770\n",
      "[331]\tvalidation_0-auc:0.85772\n",
      "[332]\tvalidation_0-auc:0.85772\n",
      "[333]\tvalidation_0-auc:0.85772\n",
      "[334]\tvalidation_0-auc:0.85772\n",
      "[335]\tvalidation_0-auc:0.85773\n",
      "[336]\tvalidation_0-auc:0.85776\n",
      "[337]\tvalidation_0-auc:0.85774\n",
      "[338]\tvalidation_0-auc:0.85774\n",
      "[339]\tvalidation_0-auc:0.85773\n",
      "[340]\tvalidation_0-auc:0.85774\n",
      "[341]\tvalidation_0-auc:0.85773\n",
      "[342]\tvalidation_0-auc:0.85771\n",
      "[343]\tvalidation_0-auc:0.85771\n",
      "[344]\tvalidation_0-auc:0.85771\n",
      "[345]\tvalidation_0-auc:0.85772\n",
      "[346]\tvalidation_0-auc:0.85773\n",
      "[347]\tvalidation_0-auc:0.85772\n",
      "[348]\tvalidation_0-auc:0.85771\n",
      "[349]\tvalidation_0-auc:0.85772\n",
      "[350]\tvalidation_0-auc:0.85772\n",
      "[351]\tvalidation_0-auc:0.85771\n",
      "[352]\tvalidation_0-auc:0.85770\n",
      "[353]\tvalidation_0-auc:0.85771\n",
      "[354]\tvalidation_0-auc:0.85772\n",
      "[355]\tvalidation_0-auc:0.85773\n",
      "[356]\tvalidation_0-auc:0.85774\n",
      "[357]\tvalidation_0-auc:0.85773\n",
      "[358]\tvalidation_0-auc:0.85773\n",
      "[359]\tvalidation_0-auc:0.85772\n",
      "[360]\tvalidation_0-auc:0.85772\n",
      "[361]\tvalidation_0-auc:0.85773\n",
      "[362]\tvalidation_0-auc:0.85773\n",
      "[363]\tvalidation_0-auc:0.85776\n",
      "[364]\tvalidation_0-auc:0.85777\n",
      "[365]\tvalidation_0-auc:0.85777\n",
      "[366]\tvalidation_0-auc:0.85778\n",
      "[367]\tvalidation_0-auc:0.85777\n",
      "[368]\tvalidation_0-auc:0.85777\n",
      "[369]\tvalidation_0-auc:0.85778\n",
      "[370]\tvalidation_0-auc:0.85779\n",
      "[371]\tvalidation_0-auc:0.85781\n",
      "[372]\tvalidation_0-auc:0.85781\n",
      "[373]\tvalidation_0-auc:0.85779\n",
      "[374]\tvalidation_0-auc:0.85779\n",
      "[375]\tvalidation_0-auc:0.85779\n",
      "[376]\tvalidation_0-auc:0.85779\n",
      "[377]\tvalidation_0-auc:0.85780\n",
      "[378]\tvalidation_0-auc:0.85779\n",
      "[379]\tvalidation_0-auc:0.85779\n",
      "[380]\tvalidation_0-auc:0.85778\n",
      "[381]\tvalidation_0-auc:0.85778\n",
      "[382]\tvalidation_0-auc:0.85780\n",
      "[383]\tvalidation_0-auc:0.85779\n",
      "[384]\tvalidation_0-auc:0.85779\n",
      "[385]\tvalidation_0-auc:0.85780\n",
      "[386]\tvalidation_0-auc:0.85780\n",
      "[387]\tvalidation_0-auc:0.85779\n",
      "[388]\tvalidation_0-auc:0.85778\n",
      "[389]\tvalidation_0-auc:0.85777\n",
      "[390]\tvalidation_0-auc:0.85777\n",
      "[391]\tvalidation_0-auc:0.85780\n",
      "[392]\tvalidation_0-auc:0.85779\n",
      "[393]\tvalidation_0-auc:0.85779\n",
      "[394]\tvalidation_0-auc:0.85777\n",
      "[395]\tvalidation_0-auc:0.85775\n",
      "[396]\tvalidation_0-auc:0.85775\n",
      "[397]\tvalidation_0-auc:0.85776\n",
      "[398]\tvalidation_0-auc:0.85776\n",
      "[399]\tvalidation_0-auc:0.85775\n",
      "[400]\tvalidation_0-auc:0.85775\n",
      "[401]\tvalidation_0-auc:0.85774\n",
      "[402]\tvalidation_0-auc:0.85774\n",
      "[403]\tvalidation_0-auc:0.85774\n",
      "[404]\tvalidation_0-auc:0.85774\n",
      "[405]\tvalidation_0-auc:0.85775\n",
      "[406]\tvalidation_0-auc:0.85777\n",
      "[407]\tvalidation_0-auc:0.85777\n",
      "[408]\tvalidation_0-auc:0.85776\n",
      "[409]\tvalidation_0-auc:0.85777\n",
      "[410]\tvalidation_0-auc:0.85777\n",
      "[411]\tvalidation_0-auc:0.85777\n",
      "[412]\tvalidation_0-auc:0.85778\n",
      "[413]\tvalidation_0-auc:0.85779\n",
      "[414]\tvalidation_0-auc:0.85780\n",
      "[415]\tvalidation_0-auc:0.85779\n",
      "[416]\tvalidation_0-auc:0.85779\n",
      "[417]\tvalidation_0-auc:0.85780\n",
      "[418]\tvalidation_0-auc:0.85778\n",
      "[419]\tvalidation_0-auc:0.85778\n",
      "[420]\tvalidation_0-auc:0.85779\n",
      "[421]\tvalidation_0-auc:0.85778\n",
      "[422]\tvalidation_0-auc:0.85779\n",
      "[423]\tvalidation_0-auc:0.85778\n",
      "[424]\tvalidation_0-auc:0.85780\n",
      "[425]\tvalidation_0-auc:0.85780\n",
      "[426]\tvalidation_0-auc:0.85778\n",
      "[427]\tvalidation_0-auc:0.85779\n",
      "[428]\tvalidation_0-auc:0.85778\n",
      "[429]\tvalidation_0-auc:0.85780\n",
      "[430]\tvalidation_0-auc:0.85781\n",
      "[431]\tvalidation_0-auc:0.85780\n",
      "[432]\tvalidation_0-auc:0.85780\n",
      "[433]\tvalidation_0-auc:0.85779\n",
      "[434]\tvalidation_0-auc:0.85781\n",
      "[435]\tvalidation_0-auc:0.85780\n",
      "[436]\tvalidation_0-auc:0.85780\n",
      "[437]\tvalidation_0-auc:0.85782\n",
      "[438]\tvalidation_0-auc:0.85783\n",
      "[439]\tvalidation_0-auc:0.85781\n",
      "[440]\tvalidation_0-auc:0.85782\n",
      "[441]\tvalidation_0-auc:0.85782\n",
      "[442]\tvalidation_0-auc:0.85779\n",
      "[443]\tvalidation_0-auc:0.85779\n",
      "[444]\tvalidation_0-auc:0.85777\n",
      "[445]\tvalidation_0-auc:0.85779\n",
      "[446]\tvalidation_0-auc:0.85780\n",
      "[447]\tvalidation_0-auc:0.85779\n",
      "[448]\tvalidation_0-auc:0.85779\n",
      "[449]\tvalidation_0-auc:0.85779\n",
      "[450]\tvalidation_0-auc:0.85778\n",
      "[451]\tvalidation_0-auc:0.85778\n",
      "[452]\tvalidation_0-auc:0.85779\n",
      "[453]\tvalidation_0-auc:0.85780\n",
      "[454]\tvalidation_0-auc:0.85781\n",
      "[455]\tvalidation_0-auc:0.85780\n",
      "[456]\tvalidation_0-auc:0.85778\n",
      "[457]\tvalidation_0-auc:0.85777\n",
      "[458]\tvalidation_0-auc:0.85777\n",
      "[459]\tvalidation_0-auc:0.85777\n",
      "[460]\tvalidation_0-auc:0.85777\n",
      "[461]\tvalidation_0-auc:0.85776\n",
      "[462]\tvalidation_0-auc:0.85777\n",
      "[463]\tvalidation_0-auc:0.85777\n",
      "[464]\tvalidation_0-auc:0.85777\n",
      "[465]\tvalidation_0-auc:0.85775\n",
      "[466]\tvalidation_0-auc:0.85776\n",
      "[467]\tvalidation_0-auc:0.85776\n",
      "[468]\tvalidation_0-auc:0.85774\n",
      "[469]\tvalidation_0-auc:0.85772\n",
      "[470]\tvalidation_0-auc:0.85771\n",
      "[471]\tvalidation_0-auc:0.85772\n",
      "[472]\tvalidation_0-auc:0.85771\n",
      "[473]\tvalidation_0-auc:0.85771\n",
      "[474]\tvalidation_0-auc:0.85771\n",
      "[475]\tvalidation_0-auc:0.85771\n",
      "[476]\tvalidation_0-auc:0.85772\n",
      "[477]\tvalidation_0-auc:0.85773\n",
      "[478]\tvalidation_0-auc:0.85771\n",
      "[479]\tvalidation_0-auc:0.85768\n",
      "[480]\tvalidation_0-auc:0.85768\n",
      "[481]\tvalidation_0-auc:0.85767\n",
      "[482]\tvalidation_0-auc:0.85767\n",
      "[483]\tvalidation_0-auc:0.85766\n",
      "[484]\tvalidation_0-auc:0.85769\n",
      "[485]\tvalidation_0-auc:0.85767\n",
      "[486]\tvalidation_0-auc:0.85767\n",
      "[487]\tvalidation_0-auc:0.85768\n",
      "[488]\tvalidation_0-auc:0.85768\n",
      "[489]\tvalidation_0-auc:0.85768\n",
      "[490]\tvalidation_0-auc:0.85769\n",
      "[491]\tvalidation_0-auc:0.85769\n",
      "[492]\tvalidation_0-auc:0.85768\n",
      "[493]\tvalidation_0-auc:0.85767\n",
      "[494]\tvalidation_0-auc:0.85767\n",
      "[495]\tvalidation_0-auc:0.85767\n",
      "[496]\tvalidation_0-auc:0.85768\n",
      "[497]\tvalidation_0-auc:0.85766\n",
      "[498]\tvalidation_0-auc:0.85767\n",
      "[499]\tvalidation_0-auc:0.85767\n",
      "[500]\tvalidation_0-auc:0.85769\n",
      "[501]\tvalidation_0-auc:0.85768\n",
      "[502]\tvalidation_0-auc:0.85771\n",
      "[503]\tvalidation_0-auc:0.85770\n",
      "[504]\tvalidation_0-auc:0.85771\n",
      "[505]\tvalidation_0-auc:0.85772\n",
      "[506]\tvalidation_0-auc:0.85772\n",
      "[507]\tvalidation_0-auc:0.85773\n",
      "[508]\tvalidation_0-auc:0.85775\n",
      "[509]\tvalidation_0-auc:0.85776\n",
      "[510]\tvalidation_0-auc:0.85777\n",
      "[511]\tvalidation_0-auc:0.85778\n",
      "[512]\tvalidation_0-auc:0.85778\n",
      "[513]\tvalidation_0-auc:0.85777\n",
      "[514]\tvalidation_0-auc:0.85779\n",
      "[515]\tvalidation_0-auc:0.85779\n",
      "[516]\tvalidation_0-auc:0.85778\n",
      "[517]\tvalidation_0-auc:0.85779\n",
      "[518]\tvalidation_0-auc:0.85778\n",
      "[519]\tvalidation_0-auc:0.85777\n",
      "[520]\tvalidation_0-auc:0.85776\n",
      "[521]\tvalidation_0-auc:0.85777\n",
      "[522]\tvalidation_0-auc:0.85776\n",
      "[523]\tvalidation_0-auc:0.85774\n",
      "[524]\tvalidation_0-auc:0.85773\n",
      "[525]\tvalidation_0-auc:0.85775\n",
      "[526]\tvalidation_0-auc:0.85778\n",
      "[527]\tvalidation_0-auc:0.85778\n",
      "[528]\tvalidation_0-auc:0.85778\n",
      "[529]\tvalidation_0-auc:0.85778\n",
      "[530]\tvalidation_0-auc:0.85778\n",
      "[531]\tvalidation_0-auc:0.85778\n",
      "[532]\tvalidation_0-auc:0.85779\n",
      "[533]\tvalidation_0-auc:0.85779\n",
      "[534]\tvalidation_0-auc:0.85776\n",
      "[535]\tvalidation_0-auc:0.85777\n",
      "[536]\tvalidation_0-auc:0.85776\n",
      "[537]\tvalidation_0-auc:0.85775\n",
      "[538]\tvalidation_0-auc:0.85776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.85, device=&#x27;cuda&#x27;, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.85</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auc&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.02</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.076196678606317)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.85</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;hist&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.85, device='cuda', early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              feature_weights=None, gamma=1, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5746368765830994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.85      0.91     27868\n",
      "   Defaulted       0.25      0.70      0.37      1978\n",
      "\n",
      "    accuracy                           0.84     29846\n",
      "   macro avg       0.61      0.78      0.64     29846\n",
      "weighted avg       0.93      0.84      0.87     29846\n",
      "\n",
      "Accuracy: 84.18%\n",
      "ROC AUC: 0.859\n",
      "TP=1385, FP=4128, TN=23740, FN=593\n",
      "Accuracy for class 'Repaid': 85.19%\n",
      "Accuracy for class 'Defaulted': 70.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "dtest = xgb.DMatrix(X_test_xgb)\n",
    "y_probs = model_b.get_booster().predict(dtest) \n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, 0.70)\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                Feature  Importance\n",
      "0                      DelinquencyScore    0.552303\n",
      "1                     UtilizationPerAge    0.443500\n",
      "2           UtilizationBucketLateBucket    0.237569\n",
      "3           UtilizationTimesDelinquency    0.226054\n",
      "4                   IncomePerCreditLine    0.170514\n",
      "5                   DebtToIncomeAgeRisk    0.164777\n",
      "6         RevolvingUtilizationCappedLog    0.143730\n",
      "7                     DelinquencyBucket    0.104251\n",
      "8              UtilizationPerCreditLine    0.073386\n",
      "9             LatePaymentsPerCreditLine    0.046085\n",
      "10                  HasMajorDelinquency    0.025513\n",
      "11                   TotalPastDueCapped    0.025495\n",
      "12                      HighAgeRiskFlag    0.014924\n",
      "13   WasUtilizationPerCreditLineImputed    0.000569\n",
      "14          WasUtilizationPerAgeImputed    0.000202\n",
      "15        WasIncomePerCreditLineImputed    0.000000\n",
      "16  WasLatePaymentsPerCreditLineImputed    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Shap xgb\n",
    "explainer = shap.TreeExplainer(model_b)\n",
    "shap_values = explainer.shap_values(X_train_xgb)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_xgb.columns,\n",
    "    \"Importance\": mean_abs_shap\n",
    "}).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea9266c7f2442c989db0d206ef0cfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "0                              UtilizationPerAge       0.022896\n",
      "1    UtilizationBucketLateBucket_Very Low_NoLate       0.012323\n",
      "2                         DelinquencyBucket_None       0.012047\n",
      "3                  RevolvingUtilizationCappedLog       0.009405\n",
      "4                            IncomePerCreditLine       0.008064\n",
      "5                            DebtToIncomeAgeRisk       0.006835\n",
      "6                            HasMajorDelinquency       0.006257\n",
      "7         UtilizationBucketLateBucket_Low_NoLate       0.005089\n",
      "8    UtilizationBucketLateBucket_Moderate_NoLate       0.003325\n",
      "9                                HighAgeRiskFlag       0.003308\n",
      "10                      UtilizationPerCreditLine       0.002423\n",
      "11                         DelinquencyBucket_Few       0.001876\n",
      "12                              DelinquencyScore       0.001799\n",
      "13                       DelinquencyBucket_Other       0.001652\n",
      "14                            TotalPastDueCapped       0.001408\n",
      "15                     LatePaymentsPerCreditLine       0.001056\n",
      "16                   UtilizationTimesDelinquency       0.000745\n",
      "17             UtilizationBucketLateBucket_Other       0.000670\n",
      "18                   WasUtilizationPerAgeImputed       0.000589\n",
      "19  UtilizationBucketLateBucket_Very High_NoLate       0.000510\n",
      "20            WasUtilizationPerCreditLineImputed       0.000397\n",
      "21                    DelinquencyBucket_Moderate       0.000341\n",
      "22       UtilizationBucketLateBucket_High_NoLate       0.000176\n",
      "23           WasLatePaymentsPerCreditLineImputed       0.000115\n",
      "24                 WasIncomePerCreditLineImputed       0.000056\n"
     ]
    }
   ],
   "source": [
    "# Shap NN\n",
    "model_gpu = copy.deepcopy(model).to(device)\n",
    "model_gpu.eval()\n",
    "\n",
    "def shap_ohe_gpu(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        logits = model_gpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "background = shap.sample(X_train_tensor.cpu().numpy(), 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe_gpu, background)\n",
    "shap_values = explainer.shap_values(X_val_tensor[:500].cpu().numpy())\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_xgb.columns.tolist(), \"xgb_col_order.pkl\")\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfb507-cce9-4894-b873-e5e1f5d657ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
