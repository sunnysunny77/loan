{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationOfUnsecuredLinesCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0).fillna(0.0).replace(0, np.nan)\n",
    "    RevolvingUtilizationOfUnsecuredLines = np.log1p(RevolvingUtilizationOfUnsecuredLinesCapped)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    UtilizationPerAge = RevolvingUtilizationOfUnsecuredLines / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilizationCappedLog\"] = np.log1p(RevolvingUtilizationOfUnsecuredLines.clip(upper=5.0))\n",
    "    \n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationTimesDelinquency\"] = UtilizationPerAge * HasAnyDelinquency\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "    df_e[\"UtilizationPerCreditLine\"] = RevolvingUtilizationOfUnsecuredLines / CreditLinesSafe\n",
    "\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationOfUnsecuredLines, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"DelinquencyScore\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"UtilizationTimesDelinquency\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "        \"RevolvingUtilizationCappedLog\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10, random_state=42, bias_mode=None):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "    \n",
    "    minority_class = 1 if pos_count < neg_count else 0\n",
    "    majority_class = 0 if minority_class == 1 else 1\n",
    "\n",
    "    if bias_mode is False:\n",
    "        scale_pos_weight = neg_count / max(1, pos_count)\n",
    "        print(\"Biasing toward minority class\")\n",
    "    elif bias_mode is True:\n",
    "        scale_pos_weight = pos_count / max(1, neg_count)\n",
    "        print(\"Biasing toward majority class\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Using normal class weights\")\n",
    "        \n",
    "    tuned_params = {\n",
    "        'subsample': 0.9, \n",
    "        'reg_lambda': 0.5, \n",
    "        'reg_alpha': 0.1, \n",
    "        'min_child_weight': 7, \n",
    "        'max_depth': 5, \n",
    "        'learning_rate': 0.01, \n",
    "        'gamma': 0.2, \n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=800,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        **tuned_params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "    \n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    numeric_feats = [f for f in feature_cols if f not in cat_cols]\n",
    "    top_numeric = importance_df[importance_df[\"Feature\"].isin(numeric_feats)][\"Feature\"].head(n_to_keep).tolist()\n",
    "    kept_features = top_numeric + cat_cols\n",
    "    dropped_features = [f for f in numeric_feats if f not in top_numeric]\n",
    "\n",
    "    print(f\"Kept {len(kept_features)} select features (including all {len(cat_cols)} categorical)\")\n",
    "    print(f\"Dropped:{len(dropped_features)} numeric select features cols\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols:{dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[kept_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None, drop_target_na=False, show_info=True):\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    target_cleaned = None\n",
    "    \n",
    "    total_duplicates = df_cleaned.duplicated().sum()\n",
    "    if total_duplicates > 0:\n",
    "        df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "        if show_info:\n",
    "            print(f\"Dropped {total_duplicates} duplicate rows. Remaining: {len(df_cleaned)}\")\n",
    "    \n",
    "    if target is not None:\n",
    "        target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "        if drop_target_na:\n",
    "            mask = target_cleaned.notna()\n",
    "            dropped = len(target_cleaned) - mask.sum()\n",
    "            if dropped > 0 and show_info:\n",
    "                print(f\"Dropped {dropped} rows with missing target values\")\n",
    "            df_cleaned = df_cleaned.loc[mask].reset_index(drop=True)\n",
    "            target_cleaned = target_cleaned.loc[mask].reset_index(drop=True)\n",
    "        else:\n",
    "            target_cleaned = target_cleaned.reset_index(drop=True)\n",
    "        return df_cleaned, target_cleaned\n",
    "    else:\n",
    "        return df_cleaned\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def fast_fbeta_scores(y_true, y_probs, thresholds, beta=2, return_details=False):\n",
    "\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FP = (preds & (y_true[:, None] == 0)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "    f_beta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall + 1e-8)\n",
    "\n",
    "    if return_details:\n",
    "        return f_beta, precision, recall\n",
    "    return f_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 609 duplicate rows. Remaining: 149391\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_train = check_and_drop_duplicates(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.00000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>1.492290e+05</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "      <td>149229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066267</td>\n",
       "      <td>6.076759</td>\n",
       "      <td>52.306978</td>\n",
       "      <td>0.37423</td>\n",
       "      <td>354.503939</td>\n",
       "      <td>5.352233e+03</td>\n",
       "      <td>8.483096</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>1.022321</td>\n",
       "      <td>0.192670</td>\n",
       "      <td>0.740118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248750</td>\n",
       "      <td>250.399417</td>\n",
       "      <td>14.720557</td>\n",
       "      <td>3.61494</td>\n",
       "      <td>2042.760501</td>\n",
       "      <td>1.064388e+04</td>\n",
       "      <td>5.136317</td>\n",
       "      <td>3.584188</td>\n",
       "      <td>1.129660</td>\n",
       "      <td>3.568789</td>\n",
       "      <td>1.107738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>1.600000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153960</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>4.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>7.405000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149229.000000                         149229.000000  149229.000000   \n",
       "mean           0.066267                              6.076759      52.306978   \n",
       "std            0.248750                            250.399417      14.720557   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.030109      41.000000   \n",
       "50%            0.000000                              0.153960      52.000000   \n",
       "75%            0.000000                              0.555169      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                          149229.00000  149229.000000   1.492290e+05   \n",
       "mean                                0.37423     354.503939   5.352233e+03   \n",
       "std                                 3.61494    2042.760501   1.064388e+04   \n",
       "min                                 0.00000       0.000000   0.000000e+00   \n",
       "25%                                 0.00000       0.177387   1.600000e+03   \n",
       "50%                                 0.00000       0.367899   4.400000e+03   \n",
       "75%                                 0.00000       0.873533   7.405000e+03   \n",
       "max                                98.00000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149229.000000            149229.000000   \n",
       "mean                          8.483096                 0.216995   \n",
       "std                           5.136317                 3.584188   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149229.000000                         149229.000000   \n",
       "mean                       1.022321                              0.192670   \n",
       "std                        1.129660                              3.568789   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149229.000000  \n",
       "mean             0.740118  \n",
       "std              1.107738  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139340\n",
      "1      9889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95506 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                       0            0.00\n",
      "DelinquencyBucket                         0            0.00\n",
      "DelinquencyScore                          0            0.00\n",
      "HasAnyDelinquency                         0            0.00\n",
      "HasMajorDelinquency                       0            0.00\n",
      "HighAgeRiskFlag                           0            0.00\n",
      "IncomePerCreditLine                    1043            1.09\n",
      "LatePaymentsPerCreditLine              1043            1.09\n",
      "RevolvingUtilizationCappedLog          6831            7.15\n",
      "UtilizationBucketLateBucket               0            0.00\n",
      "UtilizationPerAge                      6831            7.15\n",
      "UtilizationPerCreditLine               7874            8.24\n",
      "UtilizationTimesDelinquency            6831            7.15\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "DelinquencyBucket                      5           0.01\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 30 rare categories: ['Moderate_FewLate', 'High_FewLate', 'Very Low_FewLate', 'Low_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'High_FrequentLate', 'Low_ModerateLate', 'Very Low_ModerateLate', 'nan_FewLate', 'Moderate_FrequentLate', 'High_ChronicLate', 'nan_ModerateLate', 'Low_FrequentLate', 'Extreme_NoLate', 'Moderate_ChronicLate', 'Very Low_FrequentLate', 'Very High_ModerateLate', 'nan_FrequentLate', 'Very High_NoLate', 'Very High_FrequentLate', 'Very High_FewLate', 'Low_ChronicLate', 'Very High_ChronicLate', 'nan_ChronicLate', 'Extreme_FewLate', 'Very Low_ChronicLate', 'Extreme_ModerateLate', 'Extreme_FrequentLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normal class weights\n",
      "Kept 13 select features (including all 2 categorical)\n",
      "Dropped:0 numeric select features cols\n",
      "                          Feature  Importance\n",
      "0             HasMajorDelinquency  196.662521\n",
      "1                DelinquencyScore  181.204071\n",
      "2               DelinquencyBucket  168.791214\n",
      "3               HasAnyDelinquency  133.700653\n",
      "4     UtilizationBucketLateBucket   56.504864\n",
      "5     UtilizationTimesDelinquency   52.251080\n",
      "6       LatePaymentsPerCreditLine   38.592911\n",
      "7               UtilizationPerAge   21.270874\n",
      "8   RevolvingUtilizationCappedLog   19.192410\n",
      "9             DebtToIncomeAgeRisk    6.921986\n",
      "10            IncomePerCreditLine    5.640026\n",
      "11       UtilizationPerCreditLine    5.484928\n",
      "12                HighAgeRiskFlag    5.124939\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=15, bias_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23877 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 29846 features\n",
      "Engineered cols: ['DelinquencyScore', 'HasAnyDelinquency', 'HasMajorDelinquency', 'UtilizationPerAge', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'DelinquencyBucket', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'UtilizationTimesDelinquency', 'HighAgeRiskFlag', 'RevolvingUtilizationCappedLog']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc7cd0a-ca7e-4c15-a3e9-da43703bb0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2912 duplicate rows. Remaining: 92594\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92594, 26)\n",
      "Total rows: 92594\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087263</td>\n",
       "      <td>0.282221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.924985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.683090</td>\n",
       "      <td>2.491862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.234710</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205056</td>\n",
       "      <td>0.403745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.461070</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationTimesDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationTimesDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15842</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>3.094077</td>\n",
       "      <td>-0.004518</td>\n",
       "      <td>True</td>\n",
       "      <td>HasAnyDelinquency (0.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.076095</td>\n",
       "      <td>0.300319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.388049</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82305</td>\n",
       "      <td>0.280998</td>\n",
       "      <td>0.771729</td>\n",
       "      <td>-0.416697</td>\n",
       "      <td>-0.314414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681490</td>\n",
       "      <td>8.241714</td>\n",
       "      <td>1.678399</td>\n",
       "      <td>-0.004013</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilizationCappedLog (0.91)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationCappedLog</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80850</td>\n",
       "      <td>-0.012896</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>-1.156035</td>\n",
       "      <td>-0.908416</td>\n",
       "      <td>-0.294879</td>\n",
       "      <td>0.802831</td>\n",
       "      <td>4.404912</td>\n",
       "      <td>0.708248</td>\n",
       "      <td>-0.002539</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.91)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72746</td>\n",
       "      <td>0.268963</td>\n",
       "      <td>1.608317</td>\n",
       "      <td>-0.444698</td>\n",
       "      <td>-0.422533</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>0.586876</td>\n",
       "      <td>230.122301</td>\n",
       "      <td>66.268097</td>\n",
       "      <td>-0.003953</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26180</td>\n",
       "      <td>0.321212</td>\n",
       "      <td>2.143418</td>\n",
       "      <td>-0.712727</td>\n",
       "      <td>-0.399441</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.575962</td>\n",
       "      <td>279.287273</td>\n",
       "      <td>51.496937</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82039</td>\n",
       "      <td>0.726648</td>\n",
       "      <td>2.314985</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.309696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707815</td>\n",
       "      <td>39.419312</td>\n",
       "      <td>4.650102</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>float64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>1.000128</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>-1.121933</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>0.891319</td>\n",
       "      <td>-0.228449</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.816241</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.622902</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.680919</td>\n",
       "      <td>1.418079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.387655</td>\n",
       "      <td>-0.005332</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyScoreImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationTimesDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.077188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.800288</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasRevolvingUtilizationCappedLogImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.224949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.970245</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.077188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.800288</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>True</td>\n",
       "      <td>WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059453</td>\n",
       "      <td>0.236472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.726076</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationTimesDelinquencyImputed (0.95), WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHighAgeRiskFlagImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>92594</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dtype  non_null  missing  \\\n",
       "HasMajorDelinquency                      float64     92594        0   \n",
       "DelinquencyScore                         float64     92594        0   \n",
       "HasAnyDelinquency                        float64     92594        0   \n",
       "UtilizationTimesDelinquency              float64     92594        0   \n",
       "LatePaymentsPerCreditLine                float64     92594        0   \n",
       "UtilizationPerAge                        float64     92594        0   \n",
       "RevolvingUtilizationCappedLog            float64     92594        0   \n",
       "DebtToIncomeAgeRisk                      float64     92594        0   \n",
       "IncomePerCreditLine                      float64     92594        0   \n",
       "UtilizationPerCreditLine                 float64     92594        0   \n",
       "HighAgeRiskFlag                          float64     92594        0   \n",
       "DelinquencyBucket                           int8     92594        0   \n",
       "UtilizationBucketLateBucket                 int8     92594        0   \n",
       "WasHasMajorDelinquencyImputed              int64     92594        0   \n",
       "WasDelinquencyScoreImputed                 int64     92594        0   \n",
       "WasHasAnyDelinquencyImputed                int64     92594        0   \n",
       "WasUtilizationTimesDelinquencyImputed      int64     92594        0   \n",
       "WasLatePaymentsPerCreditLineImputed        int64     92594        0   \n",
       "WasUtilizationPerAgeImputed                int64     92594        0   \n",
       "WasRevolvingUtilizationCappedLogImputed    int64     92594        0   \n",
       "WasDebtToIncomeAgeRiskImputed              int64     92594        0   \n",
       "WasIncomePerCreditLineImputed              int64     92594        0   \n",
       "WasUtilizationPerCreditLineImputed         int64     92594        0   \n",
       "WasHighAgeRiskFlagImputed                  int64     92594        0   \n",
       "WasDelinquencyBucketImputed                int64     92594        0   \n",
       "WasUtilizationBucketLateBucketImputed      int64     92594        0   \n",
       "\n",
       "                                         missing_%  unique      mean  \\\n",
       "HasMajorDelinquency                            0.0       2  0.087263   \n",
       "DelinquencyScore                               0.0      38  0.683090   \n",
       "HasAnyDelinquency                              0.0       2  0.205056   \n",
       "UtilizationTimesDelinquency                    0.0   15842  0.001908   \n",
       "LatePaymentsPerCreditLine                      0.0     201  0.076095   \n",
       "UtilizationPerAge                              0.0   82305  0.280998   \n",
       "RevolvingUtilizationCappedLog                  0.0   80850 -0.012896   \n",
       "DebtToIncomeAgeRisk                            0.0   72746  0.268963   \n",
       "IncomePerCreditLine                            0.0   26180  0.321212   \n",
       "UtilizationPerCreditLine                       0.0   82039  0.726648   \n",
       "HighAgeRiskFlag                                0.0       2 -0.001070   \n",
       "DelinquencyBucket                              0.0       4  1.816241   \n",
       "UtilizationBucketLateBucket                    0.0       6  2.680919   \n",
       "WasHasMajorDelinquencyImputed                  0.0       1  0.000000   \n",
       "WasDelinquencyScoreImputed                     0.0       1  0.000000   \n",
       "WasHasAnyDelinquencyImputed                    0.0       1  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed          0.0       2  0.053459   \n",
       "WasLatePaymentsPerCreditLineImputed            0.0       2  0.005994   \n",
       "WasUtilizationPerAgeImputed                    0.0       2  0.053459   \n",
       "WasRevolvingUtilizationCappedLogImputed        0.0       2  0.053459   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.0       1  0.000000   \n",
       "WasIncomePerCreditLineImputed                  0.0       2  0.005994   \n",
       "WasUtilizationPerCreditLineImputed             0.0       2  0.059453   \n",
       "WasHighAgeRiskFlagImputed                      0.0       1  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.0       1  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.0       1  0.000000   \n",
       "\n",
       "                                              std       min       25%  \\\n",
       "HasMajorDelinquency                      0.282221  0.000000  0.000000   \n",
       "DelinquencyScore                         2.491862  0.000000  0.000000   \n",
       "HasAnyDelinquency                        0.403745  0.000000  0.000000   \n",
       "UtilizationTimesDelinquency              0.005049  0.000000  0.000000   \n",
       "LatePaymentsPerCreditLine                0.300319  0.000000  0.000000   \n",
       "UtilizationPerAge                        0.771729 -0.416697 -0.314414   \n",
       "RevolvingUtilizationCappedLog            0.998745 -1.156035 -0.908416   \n",
       "DebtToIncomeAgeRisk                      1.608317 -0.444698 -0.422533   \n",
       "IncomePerCreditLine                      2.143418 -0.712727 -0.399441   \n",
       "UtilizationPerCreditLine                 2.314985 -0.439705 -0.309696   \n",
       "HighAgeRiskFlag                          1.000128 -1.121933 -1.121933   \n",
       "DelinquencyBucket                        0.657400  0.000000  2.000000   \n",
       "UtilizationBucketLateBucket              1.418079  0.000000  1.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000  0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000  0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.224949  0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.077188  0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed              0.224949  0.000000  0.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.224949  0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed            0.077188  0.000000  0.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.236472  0.000000  0.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000  0.000000   \n",
       "\n",
       "                                              50%       75%         max  \\\n",
       "HasMajorDelinquency                      0.000000  0.000000    1.000000   \n",
       "DelinquencyScore                         0.000000  0.000000   60.000000   \n",
       "HasAnyDelinquency                        0.000000  0.000000    1.000000   \n",
       "UtilizationTimesDelinquency              0.000000  0.000000    0.071670   \n",
       "LatePaymentsPerCreditLine                0.000000  0.000000   30.000000   \n",
       "UtilizationPerAge                        0.000000  0.681490    8.241714   \n",
       "RevolvingUtilizationCappedLog           -0.294879  0.802831    4.404912   \n",
       "DebtToIncomeAgeRisk                      0.028985  0.586876  230.122301   \n",
       "IncomePerCreditLine                      0.014545  0.575962  279.287273   \n",
       "UtilizationPerCreditLine                 0.000000  0.707815   39.419312   \n",
       "HighAgeRiskFlag                          0.891319  0.891319    0.891319   \n",
       "DelinquencyBucket                        2.000000  2.000000    3.000000   \n",
       "UtilizationBucketLateBucket              3.000000  4.000000    5.000000   \n",
       "WasHasMajorDelinquencyImputed            0.000000  0.000000    0.000000   \n",
       "WasDelinquencyScoreImputed               0.000000  0.000000    0.000000   \n",
       "WasHasAnyDelinquencyImputed              0.000000  0.000000    0.000000   \n",
       "WasUtilizationTimesDelinquencyImputed    0.000000  0.000000    1.000000   \n",
       "WasLatePaymentsPerCreditLineImputed      0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerAgeImputed              0.000000  0.000000    1.000000   \n",
       "WasRevolvingUtilizationCappedLogImputed  0.000000  0.000000    1.000000   \n",
       "WasDebtToIncomeAgeRiskImputed            0.000000  0.000000    0.000000   \n",
       "WasIncomePerCreditLineImputed            0.000000  0.000000    1.000000   \n",
       "WasUtilizationPerCreditLineImputed       0.000000  0.000000    1.000000   \n",
       "WasHighAgeRiskFlagImputed                0.000000  0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed              0.000000  0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed    0.000000  0.000000    0.000000   \n",
       "\n",
       "                                              skew  corr_with_target  \\\n",
       "HasMajorDelinquency                       2.924985               NaN   \n",
       "DelinquencyScore                         11.234710         -0.001659   \n",
       "HasAnyDelinquency                         1.461070         -0.001659   \n",
       "UtilizationTimesDelinquency               3.094077         -0.004518   \n",
       "LatePaymentsPerCreditLine                18.388049         -0.003994   \n",
       "UtilizationPerAge                         1.678399         -0.004013   \n",
       "RevolvingUtilizationCappedLog             0.708248         -0.002539   \n",
       "DebtToIncomeAgeRisk                      66.268097         -0.003953   \n",
       "IncomePerCreditLine                      51.496937         -0.003028   \n",
       "UtilizationPerCreditLine                  4.650102          0.001484   \n",
       "HighAgeRiskFlag                          -0.228449          0.000610   \n",
       "DelinquencyBucket                        -1.622902          0.001659   \n",
       "UtilizationBucketLateBucket              -0.387655         -0.005332   \n",
       "WasHasMajorDelinquencyImputed             0.000000               NaN   \n",
       "WasDelinquencyScoreImputed                0.000000               NaN   \n",
       "WasHasAnyDelinquencyImputed               0.000000               NaN   \n",
       "WasUtilizationTimesDelinquencyImputed     3.970245         -0.002538   \n",
       "WasLatePaymentsPerCreditLineImputed      12.800288         -0.003863   \n",
       "WasUtilizationPerAgeImputed               3.970245         -0.002538   \n",
       "WasRevolvingUtilizationCappedLogImputed   3.970245         -0.002538   \n",
       "WasDebtToIncomeAgeRiskImputed             0.000000               NaN   \n",
       "WasIncomePerCreditLineImputed            12.800288         -0.003863   \n",
       "WasUtilizationPerCreditLineImputed        3.726076         -0.002754   \n",
       "WasHighAgeRiskFlagImputed                 0.000000               NaN   \n",
       "WasDelinquencyBucketImputed               0.000000               NaN   \n",
       "WasUtilizationBucketLateBucketImputed     0.000000               NaN   \n",
       "\n",
       "                                         high_corr_flag  \\\n",
       "HasMajorDelinquency                               False   \n",
       "DelinquencyScore                                  False   \n",
       "HasAnyDelinquency                                  True   \n",
       "UtilizationTimesDelinquency                        True   \n",
       "LatePaymentsPerCreditLine                         False   \n",
       "UtilizationPerAge                                  True   \n",
       "RevolvingUtilizationCappedLog                      True   \n",
       "DebtToIncomeAgeRisk                               False   \n",
       "IncomePerCreditLine                               False   \n",
       "UtilizationPerCreditLine                          False   \n",
       "HighAgeRiskFlag                                   False   \n",
       "DelinquencyBucket                                 False   \n",
       "UtilizationBucketLateBucket                       False   \n",
       "WasHasMajorDelinquencyImputed                     False   \n",
       "WasDelinquencyScoreImputed                        False   \n",
       "WasHasAnyDelinquencyImputed                       False   \n",
       "WasUtilizationTimesDelinquencyImputed              True   \n",
       "WasLatePaymentsPerCreditLineImputed                True   \n",
       "WasUtilizationPerAgeImputed                        True   \n",
       "WasRevolvingUtilizationCappedLogImputed            True   \n",
       "WasDebtToIncomeAgeRiskImputed                     False   \n",
       "WasIncomePerCreditLineImputed                      True   \n",
       "WasUtilizationPerCreditLineImputed                 True   \n",
       "WasHighAgeRiskFlagImputed                         False   \n",
       "WasDelinquencyBucketImputed                       False   \n",
       "WasUtilizationBucketLateBucketImputed             False   \n",
       "\n",
       "                                                                                                                                                                  high_corr_with  \n",
       "HasMajorDelinquency                                                                                                                                                               \n",
       "DelinquencyScore                                                                                                                                                                  \n",
       "HasAnyDelinquency                                                                                                                             UtilizationTimesDelinquency (0.74)  \n",
       "UtilizationTimesDelinquency                                                                                                                             HasAnyDelinquency (0.74)  \n",
       "LatePaymentsPerCreditLine                                                                                                                                                         \n",
       "UtilizationPerAge                                                                                                                           RevolvingUtilizationCappedLog (0.91)  \n",
       "RevolvingUtilizationCappedLog                                                                                                                           UtilizationPerAge (0.91)  \n",
       "DebtToIncomeAgeRisk                                                                                                                                                               \n",
       "IncomePerCreditLine                                                                                                                                                               \n",
       "UtilizationPerCreditLine                                                                                                                                                          \n",
       "HighAgeRiskFlag                                                                                                                                                                   \n",
       "DelinquencyBucket                                                                                                                                                                 \n",
       "UtilizationBucketLateBucket                                                                                                                                                       \n",
       "WasHasMajorDelinquencyImputed                                                                                                                                                     \n",
       "WasDelinquencyScoreImputed                                                                                                                                                        \n",
       "WasHasAnyDelinquencyImputed                                                                                                                                                       \n",
       "WasUtilizationTimesDelinquencyImputed              WasUtilizationPerAgeImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasLatePaymentsPerCreditLineImputed                                                                                                         WasIncomePerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerAgeImputed              WasUtilizationTimesDelinquencyImputed (1.00), WasRevolvingUtilizationCappedLogImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasRevolvingUtilizationCappedLogImputed              WasUtilizationPerAgeImputed (1.00), WasUtilizationTimesDelinquencyImputed (1.00), WasUtilizationPerCreditLineImputed (0.95)  \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                                                     \n",
       "WasIncomePerCreditLineImputed                                                                                                         WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasUtilizationPerCreditLineImputed              WasUtilizationTimesDelinquencyImputed (0.95), WasUtilizationPerAgeImputed (0.95), WasRevolvingUtilizationCappedLogImputed (0.95)  \n",
       "WasHighAgeRiskFlagImputed                                                                                                                                                         \n",
       "WasDelinquencyBucketImputed                                                                                                                                                       \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                                                             "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols \n",
    "zero_importance_cols = [\n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasHasMajorDelinquencyImputed\",\n",
    "    \"WasHasAnyDelinquencyImputed\",\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",\n",
    "    \"WasDelinquencyBucketImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val   = X_val.drop(columns=zero_importance_cols)\n",
    "X_test  = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags   = flags_to_keep\n",
    "X_test_flags  = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 and int64\n",
    "X_train_num = X_train[num_col_order + X_train_flags].astype('float32').values\n",
    "X_val_num   = X_val[num_col_order + X_val_flags].astype('float32').values\n",
    "X_test_num  = X_test[num_col_order + X_test_flags].astype('float32').values\n",
    "\n",
    "X_train_cat = X_train[cat_col_order].astype('int64').values\n",
    "X_val_cat   = X_val[cat_col_order].astype('int64').values\n",
    "X_test_cat  = X_test[cat_col_order].astype('int64').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric input shape: torch.Size([92594, 17])\n",
      "Categorical input shape: torch.Size([92594, 2])\n",
      "Class weights: {np.int64(0): np.float64(0.5355164077591292), np.int64(1): np.float64(7.539000162839928)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_train_num_tensor = torch.tensor(X_train_num)\n",
    "X_val_num_tensor = torch.tensor(X_val_num)\n",
    "X_test_num_tensor = torch.tensor(X_test_num)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat)\n",
    "X_val_cat_tensor = torch.tensor(X_val_cat)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "print(\"Numeric input shape:\", X_train_num_tensor.shape)\n",
    "print(\"Categorical input shape:\", X_train_cat_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92594, Val: 23877, Test: 29846\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num, x_cat, y):\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor)\n",
    "val_ds = TabularDataset(X_val_num_tensor, X_val_cat_tensor, y_val_tensor)\n",
    "test_ds = TabularDataset(X_test_num_tensor, X_test_cat_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(6, 3)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bn_num): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=22, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=22, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (cat_skip): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 50045\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim)\n",
    "            for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)\n",
    "        ])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "    \n",
    "        x_cat_emb = torch.cat([\n",
    "            emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)\n",
    "        ], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "\n",
    "        x_num = self.bn_num(x_num)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "cat_dims = [len(cat_maps[col]) for col in cat_col_order]\n",
    "emb_dims = [min(50, (cat_dim + 1) // 2) for cat_dim in cat_dims]\n",
    "\n",
    "model = NN(X_train_num.shape[1], cat_dims, emb_dims).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.050957 | Train AUC: 0.8273 | Val loss: 0.049647 | Val AUC: 0.8263\n",
      "Epoch 2/75 | Train loss: 0.047399 | Train AUC: 0.8461 | Val loss: 0.047594 | Val AUC: 0.8470\n",
      "Epoch 3/75 | Train loss: 0.047125 | Train AUC: 0.8491 | Val loss: 0.047766 | Val AUC: 0.8509\n",
      "Epoch 4/75 | Train loss: 0.046866 | Train AUC: 0.8505 | Val loss: 0.048549 | Val AUC: 0.8523\n",
      "Epoch 5/75 | Train loss: 0.046682 | Train AUC: 0.8523 | Val loss: 0.048604 | Val AUC: 0.8534\n",
      "Epoch 6/75 | Train loss: 0.046691 | Train AUC: 0.8524 | Val loss: 0.048046 | Val AUC: 0.8494\n",
      "Epoch 7/75 | Train loss: 0.046567 | Train AUC: 0.8537 | Val loss: 0.048096 | Val AUC: 0.8468\n",
      "Epoch 8/75 | Train loss: 0.046575 | Train AUC: 0.8536 | Val loss: 0.048658 | Val AUC: 0.8480\n",
      "Epoch 9/75 | Train loss: 0.046613 | Train AUC: 0.8530 | Val loss: 0.048324 | Val AUC: 0.8512\n",
      "Epoch 10/75 | Train loss: 0.046480 | Train AUC: 0.8543 | Val loss: 0.048224 | Val AUC: 0.8506\n",
      "Epoch 11/75 | Train loss: 0.046413 | Train AUC: 0.8549 | Val loss: 0.048139 | Val AUC: 0.8541\n",
      "Epoch 12/75 | Train loss: 0.046263 | Train AUC: 0.8559 | Val loss: 0.047187 | Val AUC: 0.8552\n",
      "Epoch 13/75 | Train loss: 0.046295 | Train AUC: 0.8559 | Val loss: 0.047865 | Val AUC: 0.8537\n",
      "Epoch 14/75 | Train loss: 0.046387 | Train AUC: 0.8556 | Val loss: 0.049162 | Val AUC: 0.8530\n",
      "Epoch 15/75 | Train loss: 0.046220 | Train AUC: 0.8566 | Val loss: 0.047864 | Val AUC: 0.8535\n",
      "Epoch 16/75 | Train loss: 0.046331 | Train AUC: 0.8556 | Val loss: 0.047977 | Val AUC: 0.8543\n",
      "Epoch 17/75 | Train loss: 0.046213 | Train AUC: 0.8563 | Val loss: 0.047932 | Val AUC: 0.8519\n",
      "Epoch 18/75 | Train loss: 0.046196 | Train AUC: 0.8569 | Val loss: 0.047463 | Val AUC: 0.8530\n",
      "Epoch 19/75 | Train loss: 0.046092 | Train AUC: 0.8574 | Val loss: 0.047540 | Val AUC: 0.8543\n",
      "Epoch 20/75 | Train loss: 0.046021 | Train AUC: 0.8582 | Val loss: 0.047833 | Val AUC: 0.8551\n",
      "Epoch 21/75 | Train loss: 0.045877 | Train AUC: 0.8591 | Val loss: 0.047471 | Val AUC: 0.8560\n",
      "Epoch 22/75 | Train loss: 0.046060 | Train AUC: 0.8577 | Val loss: 0.047445 | Val AUC: 0.8553\n",
      "Epoch 23/75 | Train loss: 0.046004 | Train AUC: 0.8582 | Val loss: 0.047474 | Val AUC: 0.8526\n",
      "Epoch 24/75 | Train loss: 0.046020 | Train AUC: 0.8579 | Val loss: 0.047820 | Val AUC: 0.8550\n",
      "Epoch 25/75 | Train loss: 0.045984 | Train AUC: 0.8583 | Val loss: 0.047387 | Val AUC: 0.8541\n",
      "Epoch 26/75 | Train loss: 0.045921 | Train AUC: 0.8590 | Val loss: 0.047613 | Val AUC: 0.8542\n",
      "Epoch 27/75 | Train loss: 0.046030 | Train AUC: 0.8581 | Val loss: 0.047225 | Val AUC: 0.8535\n",
      "Epoch 28/75 | Train loss: 0.045812 | Train AUC: 0.8600 | Val loss: 0.047187 | Val AUC: 0.8548\n",
      "Epoch 29/75 | Train loss: 0.045774 | Train AUC: 0.8602 | Val loss: 0.047292 | Val AUC: 0.8542\n",
      "Epoch 30/75 | Train loss: 0.045877 | Train AUC: 0.8592 | Val loss: 0.047390 | Val AUC: 0.8540\n",
      "Epoch 31/75 | Train loss: 0.045850 | Train AUC: 0.8596 | Val loss: 0.047084 | Val AUC: 0.8558\n",
      "Epoch 32/75 | Train loss: 0.045735 | Train AUC: 0.8604 | Val loss: 0.047002 | Val AUC: 0.8550\n",
      "Epoch 33/75 | Train loss: 0.045776 | Train AUC: 0.8602 | Val loss: 0.046993 | Val AUC: 0.8551\n",
      "Early stopping at epoch 34\n",
      "Run 1 best Val AUC: 0.8560\n",
      "\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.046111 | Train AUC: 0.8569 | Val loss: 0.047263 | Val AUC: 0.8549\n",
      "Epoch 2/75 | Train loss: 0.046175 | Train AUC: 0.8563 | Val loss: 0.048274 | Val AUC: 0.8543\n",
      "Epoch 3/75 | Train loss: 0.046159 | Train AUC: 0.8569 | Val loss: 0.047389 | Val AUC: 0.8542\n",
      "Epoch 4/75 | Train loss: 0.045933 | Train AUC: 0.8589 | Val loss: 0.047513 | Val AUC: 0.8554\n",
      "Epoch 5/75 | Train loss: 0.045997 | Train AUC: 0.8586 | Val loss: 0.047237 | Val AUC: 0.8540\n",
      "Epoch 6/75 | Train loss: 0.045978 | Train AUC: 0.8583 | Val loss: 0.047448 | Val AUC: 0.8521\n",
      "Epoch 7/75 | Train loss: 0.046034 | Train AUC: 0.8579 | Val loss: 0.047515 | Val AUC: 0.8528\n",
      "Epoch 8/75 | Train loss: 0.046042 | Train AUC: 0.8575 | Val loss: 0.047200 | Val AUC: 0.8527\n",
      "Epoch 9/75 | Train loss: 0.045943 | Train AUC: 0.8584 | Val loss: 0.047381 | Val AUC: 0.8551\n",
      "Epoch 10/75 | Train loss: 0.045999 | Train AUC: 0.8586 | Val loss: 0.047195 | Val AUC: 0.8550\n",
      "Epoch 11/75 | Train loss: 0.045788 | Train AUC: 0.8601 | Val loss: 0.046930 | Val AUC: 0.8556\n",
      "Epoch 12/75 | Train loss: 0.045719 | Train AUC: 0.8608 | Val loss: 0.047120 | Val AUC: 0.8553\n",
      "Epoch 13/75 | Train loss: 0.045834 | Train AUC: 0.8594 | Val loss: 0.047293 | Val AUC: 0.8559\n",
      "Epoch 14/75 | Train loss: 0.045674 | Train AUC: 0.8609 | Val loss: 0.047072 | Val AUC: 0.8557\n",
      "Epoch 15/75 | Train loss: 0.045733 | Train AUC: 0.8605 | Val loss: 0.047309 | Val AUC: 0.8519\n",
      "Epoch 16/75 | Train loss: 0.045679 | Train AUC: 0.8613 | Val loss: 0.047920 | Val AUC: 0.8514\n",
      "Epoch 17/75 | Train loss: 0.045748 | Train AUC: 0.8607 | Val loss: 0.047210 | Val AUC: 0.8542\n",
      "Epoch 18/75 | Train loss: 0.045708 | Train AUC: 0.8604 | Val loss: 0.047375 | Val AUC: 0.8541\n",
      "Epoch 19/75 | Train loss: 0.045805 | Train AUC: 0.8595 | Val loss: 0.047751 | Val AUC: 0.8556\n",
      "Epoch 20/75 | Train loss: 0.045690 | Train AUC: 0.8607 | Val loss: 0.047276 | Val AUC: 0.8534\n",
      "Epoch 21/75 | Train loss: 0.045561 | Train AUC: 0.8621 | Val loss: 0.047226 | Val AUC: 0.8548\n",
      "Epoch 22/75 | Train loss: 0.045573 | Train AUC: 0.8621 | Val loss: 0.047085 | Val AUC: 0.8563\n",
      "Epoch 23/75 | Train loss: 0.045544 | Train AUC: 0.8619 | Val loss: 0.047058 | Val AUC: 0.8554\n",
      "Epoch 24/75 | Train loss: 0.045541 | Train AUC: 0.8617 | Val loss: 0.047025 | Val AUC: 0.8557\n",
      "Epoch 25/75 | Train loss: 0.045605 | Train AUC: 0.8616 | Val loss: 0.046951 | Val AUC: 0.8559\n",
      "Epoch 26/75 | Train loss: 0.045607 | Train AUC: 0.8618 | Val loss: 0.047294 | Val AUC: 0.8544\n",
      "Epoch 27/75 | Train loss: 0.045611 | Train AUC: 0.8613 | Val loss: 0.046955 | Val AUC: 0.8563\n",
      "Epoch 28/75 | Train loss: 0.045600 | Train AUC: 0.8618 | Val loss: 0.046895 | Val AUC: 0.8545\n",
      "Epoch 29/75 | Train loss: 0.045478 | Train AUC: 0.8627 | Val loss: 0.046796 | Val AUC: 0.8554\n",
      "Epoch 30/75 | Train loss: 0.045374 | Train AUC: 0.8630 | Val loss: 0.046891 | Val AUC: 0.8547\n",
      "Epoch 31/75 | Train loss: 0.045463 | Train AUC: 0.8625 | Val loss: 0.046937 | Val AUC: 0.8562\n",
      "Epoch 32/75 | Train loss: 0.045494 | Train AUC: 0.8624 | Val loss: 0.046742 | Val AUC: 0.8554\n",
      "Epoch 33/75 | Train loss: 0.045497 | Train AUC: 0.8625 | Val loss: 0.047121 | Val AUC: 0.8547\n",
      "Epoch 34/75 | Train loss: 0.045465 | Train AUC: 0.8628 | Val loss: 0.046905 | Val AUC: 0.8565\n",
      "Epoch 35/75 | Train loss: 0.045455 | Train AUC: 0.8627 | Val loss: 0.047282 | Val AUC: 0.8531\n",
      "Epoch 36/75 | Train loss: 0.045505 | Train AUC: 0.8624 | Val loss: 0.047369 | Val AUC: 0.8534\n",
      "Epoch 37/75 | Train loss: 0.045532 | Train AUC: 0.8622 | Val loss: 0.047107 | Val AUC: 0.8532\n",
      "Epoch 38/75 | Train loss: 0.045532 | Train AUC: 0.8619 | Val loss: 0.047845 | Val AUC: 0.8509\n",
      "Epoch 39/75 | Train loss: 0.045429 | Train AUC: 0.8630 | Val loss: 0.047185 | Val AUC: 0.8558\n",
      "Epoch 40/75 | Train loss: 0.045438 | Train AUC: 0.8623 | Val loss: 0.047423 | Val AUC: 0.8488\n",
      "Epoch 41/75 | Train loss: 0.045376 | Train AUC: 0.8634 | Val loss: 0.047211 | Val AUC: 0.8538\n",
      "Epoch 42/75 | Train loss: 0.045468 | Train AUC: 0.8624 | Val loss: 0.047128 | Val AUC: 0.8552\n",
      "Epoch 43/75 | Train loss: 0.045436 | Train AUC: 0.8627 | Val loss: 0.047394 | Val AUC: 0.8482\n",
      "Epoch 44/75 | Train loss: 0.045369 | Train AUC: 0.8635 | Val loss: 0.047123 | Val AUC: 0.8537\n",
      "Epoch 45/75 | Train loss: 0.045490 | Train AUC: 0.8622 | Val loss: 0.047313 | Val AUC: 0.8526\n",
      "Epoch 46/75 | Train loss: 0.045392 | Train AUC: 0.8631 | Val loss: 0.047457 | Val AUC: 0.8510\n",
      "Early stopping at epoch 47\n",
      "Run 2 best Val AUC: 0.8565\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8565)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_num, x_cat, yb in train_loader:\n",
    "            x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_num, x_cat)  \n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_num.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_num, x_cat, yb in val_loader:\n",
    "                x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "                logits = model(x_num, x_cat)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_num.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "\n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.29560235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.84      0.90     27868\n",
      "   Defaulted       0.24      0.71      0.36      1978\n",
      "\n",
      "    accuracy                           0.83     29846\n",
      "   macro avg       0.61      0.78      0.63     29846\n",
      "weighted avg       0.93      0.83      0.87     29846\n",
      "\n",
      "Accuracy: 82.90%\n",
      "ROC AUC: 0.859\n",
      "TP=1411, FP=4537, TN=23331, FN=567\n",
      "Accuracy for class 'Repaid': 83.72%\n",
      "Accuracy for class 'Defaulted': 71.33%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in val_loader:  \n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_val, y_val_probs, thresholds, beta=2.4)\n",
    "best_thresh_a = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdba09d8-8307-4ade-b197-9eb639de9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=28.15600065135971, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=14.078000325679856, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=35.19500081419964, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=28.15600065135971, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=14.078000325679856, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=42.23400097703957, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=42.23400097703957, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=28.15600065135971, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=14.078000325679856, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=21.117000488519786, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=35.19500081419964, subsample=0.9; total time=   0.7s\n",
      "Best params: {'subsample': 0.9, 'scale_pos_weight': np.float64(14.078000325679856), 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84926\n",
      "[1]\tvalidation_0-auc:0.84963\n",
      "[2]\tvalidation_0-auc:0.85120\n",
      "[3]\tvalidation_0-auc:0.85170\n",
      "[4]\tvalidation_0-auc:0.85219\n",
      "[5]\tvalidation_0-auc:0.85232\n",
      "[6]\tvalidation_0-auc:0.85232\n",
      "[7]\tvalidation_0-auc:0.85261\n",
      "[8]\tvalidation_0-auc:0.85271\n",
      "[9]\tvalidation_0-auc:0.85292\n",
      "[10]\tvalidation_0-auc:0.85305\n",
      "[11]\tvalidation_0-auc:0.85276\n",
      "[12]\tvalidation_0-auc:0.85279\n",
      "[13]\tvalidation_0-auc:0.85289\n",
      "[14]\tvalidation_0-auc:0.85294\n",
      "[15]\tvalidation_0-auc:0.85307\n",
      "[16]\tvalidation_0-auc:0.85286\n",
      "[17]\tvalidation_0-auc:0.85315\n",
      "[18]\tvalidation_0-auc:0.85316\n",
      "[19]\tvalidation_0-auc:0.85302\n",
      "[20]\tvalidation_0-auc:0.85311\n",
      "[21]\tvalidation_0-auc:0.85333\n",
      "[22]\tvalidation_0-auc:0.85345\n",
      "[23]\tvalidation_0-auc:0.85352\n",
      "[24]\tvalidation_0-auc:0.85345\n",
      "[25]\tvalidation_0-auc:0.85343\n",
      "[26]\tvalidation_0-auc:0.85346\n",
      "[27]\tvalidation_0-auc:0.85346\n",
      "[28]\tvalidation_0-auc:0.85366\n",
      "[29]\tvalidation_0-auc:0.85360\n",
      "[30]\tvalidation_0-auc:0.85353\n",
      "[31]\tvalidation_0-auc:0.85364\n",
      "[32]\tvalidation_0-auc:0.85368\n",
      "[33]\tvalidation_0-auc:0.85380\n",
      "[34]\tvalidation_0-auc:0.85371\n",
      "[35]\tvalidation_0-auc:0.85372\n",
      "[36]\tvalidation_0-auc:0.85373\n",
      "[37]\tvalidation_0-auc:0.85371\n",
      "[38]\tvalidation_0-auc:0.85370\n",
      "[39]\tvalidation_0-auc:0.85373\n",
      "[40]\tvalidation_0-auc:0.85386\n",
      "[41]\tvalidation_0-auc:0.85370\n",
      "[42]\tvalidation_0-auc:0.85368\n",
      "[43]\tvalidation_0-auc:0.85365\n",
      "[44]\tvalidation_0-auc:0.85361\n",
      "[45]\tvalidation_0-auc:0.85365\n",
      "[46]\tvalidation_0-auc:0.85363\n",
      "[47]\tvalidation_0-auc:0.85363\n",
      "[48]\tvalidation_0-auc:0.85370\n",
      "[49]\tvalidation_0-auc:0.85370\n",
      "[50]\tvalidation_0-auc:0.85369\n",
      "[51]\tvalidation_0-auc:0.85369\n",
      "[52]\tvalidation_0-auc:0.85366\n",
      "[53]\tvalidation_0-auc:0.85366\n",
      "[54]\tvalidation_0-auc:0.85368\n",
      "[55]\tvalidation_0-auc:0.85369\n",
      "[56]\tvalidation_0-auc:0.85383\n",
      "[57]\tvalidation_0-auc:0.85375\n",
      "[58]\tvalidation_0-auc:0.85380\n",
      "[59]\tvalidation_0-auc:0.85385\n",
      "[60]\tvalidation_0-auc:0.85383\n",
      "[61]\tvalidation_0-auc:0.85383\n",
      "[62]\tvalidation_0-auc:0.85383\n",
      "[63]\tvalidation_0-auc:0.85382\n",
      "[64]\tvalidation_0-auc:0.85386\n",
      "[65]\tvalidation_0-auc:0.85384\n",
      "[66]\tvalidation_0-auc:0.85384\n",
      "[67]\tvalidation_0-auc:0.85384\n",
      "[68]\tvalidation_0-auc:0.85386\n",
      "[69]\tvalidation_0-auc:0.85383\n",
      "[70]\tvalidation_0-auc:0.85384\n",
      "[71]\tvalidation_0-auc:0.85393\n",
      "[72]\tvalidation_0-auc:0.85397\n",
      "[73]\tvalidation_0-auc:0.85399\n",
      "[74]\tvalidation_0-auc:0.85405\n",
      "[75]\tvalidation_0-auc:0.85410\n",
      "[76]\tvalidation_0-auc:0.85411\n",
      "[77]\tvalidation_0-auc:0.85413\n",
      "[78]\tvalidation_0-auc:0.85418\n",
      "[79]\tvalidation_0-auc:0.85417\n",
      "[80]\tvalidation_0-auc:0.85418\n",
      "[81]\tvalidation_0-auc:0.85419\n",
      "[82]\tvalidation_0-auc:0.85422\n",
      "[83]\tvalidation_0-auc:0.85422\n",
      "[84]\tvalidation_0-auc:0.85423\n",
      "[85]\tvalidation_0-auc:0.85425\n",
      "[86]\tvalidation_0-auc:0.85428\n",
      "[87]\tvalidation_0-auc:0.85428\n",
      "[88]\tvalidation_0-auc:0.85428\n",
      "[89]\tvalidation_0-auc:0.85430\n",
      "[90]\tvalidation_0-auc:0.85429\n",
      "[91]\tvalidation_0-auc:0.85430\n",
      "[92]\tvalidation_0-auc:0.85430\n",
      "[93]\tvalidation_0-auc:0.85437\n",
      "[94]\tvalidation_0-auc:0.85441\n",
      "[95]\tvalidation_0-auc:0.85446\n",
      "[96]\tvalidation_0-auc:0.85446\n",
      "[97]\tvalidation_0-auc:0.85448\n",
      "[98]\tvalidation_0-auc:0.85450\n",
      "[99]\tvalidation_0-auc:0.85436\n",
      "[100]\tvalidation_0-auc:0.85440\n",
      "[101]\tvalidation_0-auc:0.85438\n",
      "[102]\tvalidation_0-auc:0.85442\n",
      "[103]\tvalidation_0-auc:0.85443\n",
      "[104]\tvalidation_0-auc:0.85444\n",
      "[105]\tvalidation_0-auc:0.85445\n",
      "[106]\tvalidation_0-auc:0.85448\n",
      "[107]\tvalidation_0-auc:0.85448\n",
      "[108]\tvalidation_0-auc:0.85449\n",
      "[109]\tvalidation_0-auc:0.85451\n",
      "[110]\tvalidation_0-auc:0.85454\n",
      "[111]\tvalidation_0-auc:0.85454\n",
      "[112]\tvalidation_0-auc:0.85457\n",
      "[113]\tvalidation_0-auc:0.85458\n",
      "[114]\tvalidation_0-auc:0.85463\n",
      "[115]\tvalidation_0-auc:0.85470\n",
      "[116]\tvalidation_0-auc:0.85469\n",
      "[117]\tvalidation_0-auc:0.85473\n",
      "[118]\tvalidation_0-auc:0.85469\n",
      "[119]\tvalidation_0-auc:0.85470\n",
      "[120]\tvalidation_0-auc:0.85470\n",
      "[121]\tvalidation_0-auc:0.85470\n",
      "[122]\tvalidation_0-auc:0.85470\n",
      "[123]\tvalidation_0-auc:0.85473\n",
      "[124]\tvalidation_0-auc:0.85476\n",
      "[125]\tvalidation_0-auc:0.85481\n",
      "[126]\tvalidation_0-auc:0.85482\n",
      "[127]\tvalidation_0-auc:0.85485\n",
      "[128]\tvalidation_0-auc:0.85483\n",
      "[129]\tvalidation_0-auc:0.85482\n",
      "[130]\tvalidation_0-auc:0.85481\n",
      "[131]\tvalidation_0-auc:0.85486\n",
      "[132]\tvalidation_0-auc:0.85486\n",
      "[133]\tvalidation_0-auc:0.85488\n",
      "[134]\tvalidation_0-auc:0.85495\n",
      "[135]\tvalidation_0-auc:0.85500\n",
      "[136]\tvalidation_0-auc:0.85500\n",
      "[137]\tvalidation_0-auc:0.85502\n",
      "[138]\tvalidation_0-auc:0.85503\n",
      "[139]\tvalidation_0-auc:0.85502\n",
      "[140]\tvalidation_0-auc:0.85503\n",
      "[141]\tvalidation_0-auc:0.85506\n",
      "[142]\tvalidation_0-auc:0.85506\n",
      "[143]\tvalidation_0-auc:0.85509\n",
      "[144]\tvalidation_0-auc:0.85512\n",
      "[145]\tvalidation_0-auc:0.85513\n",
      "[146]\tvalidation_0-auc:0.85516\n",
      "[147]\tvalidation_0-auc:0.85518\n",
      "[148]\tvalidation_0-auc:0.85524\n",
      "[149]\tvalidation_0-auc:0.85526\n",
      "[150]\tvalidation_0-auc:0.85523\n",
      "[151]\tvalidation_0-auc:0.85522\n",
      "[152]\tvalidation_0-auc:0.85525\n",
      "[153]\tvalidation_0-auc:0.85529\n",
      "[154]\tvalidation_0-auc:0.85530\n",
      "[155]\tvalidation_0-auc:0.85531\n",
      "[156]\tvalidation_0-auc:0.85533\n",
      "[157]\tvalidation_0-auc:0.85534\n",
      "[158]\tvalidation_0-auc:0.85534\n",
      "[159]\tvalidation_0-auc:0.85536\n",
      "[160]\tvalidation_0-auc:0.85538\n",
      "[161]\tvalidation_0-auc:0.85540\n",
      "[162]\tvalidation_0-auc:0.85543\n",
      "[163]\tvalidation_0-auc:0.85542\n",
      "[164]\tvalidation_0-auc:0.85548\n",
      "[165]\tvalidation_0-auc:0.85551\n",
      "[166]\tvalidation_0-auc:0.85551\n",
      "[167]\tvalidation_0-auc:0.85553\n",
      "[168]\tvalidation_0-auc:0.85553\n",
      "[169]\tvalidation_0-auc:0.85554\n",
      "[170]\tvalidation_0-auc:0.85558\n",
      "[171]\tvalidation_0-auc:0.85558\n",
      "[172]\tvalidation_0-auc:0.85562\n",
      "[173]\tvalidation_0-auc:0.85565\n",
      "[174]\tvalidation_0-auc:0.85567\n",
      "[175]\tvalidation_0-auc:0.85568\n",
      "[176]\tvalidation_0-auc:0.85571\n",
      "[177]\tvalidation_0-auc:0.85572\n",
      "[178]\tvalidation_0-auc:0.85574\n",
      "[179]\tvalidation_0-auc:0.85575\n",
      "[180]\tvalidation_0-auc:0.85575\n",
      "[181]\tvalidation_0-auc:0.85575\n",
      "[182]\tvalidation_0-auc:0.85579\n",
      "[183]\tvalidation_0-auc:0.85584\n",
      "[184]\tvalidation_0-auc:0.85587\n",
      "[185]\tvalidation_0-auc:0.85588\n",
      "[186]\tvalidation_0-auc:0.85589\n",
      "[187]\tvalidation_0-auc:0.85590\n",
      "[188]\tvalidation_0-auc:0.85590\n",
      "[189]\tvalidation_0-auc:0.85592\n",
      "[190]\tvalidation_0-auc:0.85593\n",
      "[191]\tvalidation_0-auc:0.85592\n",
      "[192]\tvalidation_0-auc:0.85592\n",
      "[193]\tvalidation_0-auc:0.85596\n",
      "[194]\tvalidation_0-auc:0.85597\n",
      "[195]\tvalidation_0-auc:0.85598\n",
      "[196]\tvalidation_0-auc:0.85599\n",
      "[197]\tvalidation_0-auc:0.85601\n",
      "[198]\tvalidation_0-auc:0.85600\n",
      "[199]\tvalidation_0-auc:0.85602\n",
      "[200]\tvalidation_0-auc:0.85605\n",
      "[201]\tvalidation_0-auc:0.85606\n",
      "[202]\tvalidation_0-auc:0.85608\n",
      "[203]\tvalidation_0-auc:0.85609\n",
      "[204]\tvalidation_0-auc:0.85613\n",
      "[205]\tvalidation_0-auc:0.85614\n",
      "[206]\tvalidation_0-auc:0.85615\n",
      "[207]\tvalidation_0-auc:0.85617\n",
      "[208]\tvalidation_0-auc:0.85620\n",
      "[209]\tvalidation_0-auc:0.85619\n",
      "[210]\tvalidation_0-auc:0.85621\n",
      "[211]\tvalidation_0-auc:0.85621\n",
      "[212]\tvalidation_0-auc:0.85620\n",
      "[213]\tvalidation_0-auc:0.85623\n",
      "[214]\tvalidation_0-auc:0.85623\n",
      "[215]\tvalidation_0-auc:0.85623\n",
      "[216]\tvalidation_0-auc:0.85623\n",
      "[217]\tvalidation_0-auc:0.85626\n",
      "[218]\tvalidation_0-auc:0.85629\n",
      "[219]\tvalidation_0-auc:0.85630\n",
      "[220]\tvalidation_0-auc:0.85631\n",
      "[221]\tvalidation_0-auc:0.85631\n",
      "[222]\tvalidation_0-auc:0.85633\n",
      "[223]\tvalidation_0-auc:0.85635\n",
      "[224]\tvalidation_0-auc:0.85635\n",
      "[225]\tvalidation_0-auc:0.85634\n",
      "[226]\tvalidation_0-auc:0.85636\n",
      "[227]\tvalidation_0-auc:0.85634\n",
      "[228]\tvalidation_0-auc:0.85634\n",
      "[229]\tvalidation_0-auc:0.85635\n",
      "[230]\tvalidation_0-auc:0.85638\n",
      "[231]\tvalidation_0-auc:0.85639\n",
      "[232]\tvalidation_0-auc:0.85640\n",
      "[233]\tvalidation_0-auc:0.85641\n",
      "[234]\tvalidation_0-auc:0.85642\n",
      "[235]\tvalidation_0-auc:0.85643\n",
      "[236]\tvalidation_0-auc:0.85644\n",
      "[237]\tvalidation_0-auc:0.85646\n",
      "[238]\tvalidation_0-auc:0.85645\n",
      "[239]\tvalidation_0-auc:0.85646\n",
      "[240]\tvalidation_0-auc:0.85648\n",
      "[241]\tvalidation_0-auc:0.85648\n",
      "[242]\tvalidation_0-auc:0.85650\n",
      "[243]\tvalidation_0-auc:0.85652\n",
      "[244]\tvalidation_0-auc:0.85653\n",
      "[245]\tvalidation_0-auc:0.85655\n",
      "[246]\tvalidation_0-auc:0.85656\n",
      "[247]\tvalidation_0-auc:0.85657\n",
      "[248]\tvalidation_0-auc:0.85657\n",
      "[249]\tvalidation_0-auc:0.85658\n",
      "[250]\tvalidation_0-auc:0.85659\n",
      "[251]\tvalidation_0-auc:0.85660\n",
      "[252]\tvalidation_0-auc:0.85658\n",
      "[253]\tvalidation_0-auc:0.85659\n",
      "[254]\tvalidation_0-auc:0.85662\n",
      "[255]\tvalidation_0-auc:0.85662\n",
      "[256]\tvalidation_0-auc:0.85663\n",
      "[257]\tvalidation_0-auc:0.85665\n",
      "[258]\tvalidation_0-auc:0.85665\n",
      "[259]\tvalidation_0-auc:0.85665\n",
      "[260]\tvalidation_0-auc:0.85665\n",
      "[261]\tvalidation_0-auc:0.85667\n",
      "[262]\tvalidation_0-auc:0.85667\n",
      "[263]\tvalidation_0-auc:0.85674\n",
      "[264]\tvalidation_0-auc:0.85675\n",
      "[265]\tvalidation_0-auc:0.85675\n",
      "[266]\tvalidation_0-auc:0.85676\n",
      "[267]\tvalidation_0-auc:0.85676\n",
      "[268]\tvalidation_0-auc:0.85677\n",
      "[269]\tvalidation_0-auc:0.85680\n",
      "[270]\tvalidation_0-auc:0.85682\n",
      "[271]\tvalidation_0-auc:0.85683\n",
      "[272]\tvalidation_0-auc:0.85684\n",
      "[273]\tvalidation_0-auc:0.85684\n",
      "[274]\tvalidation_0-auc:0.85684\n",
      "[275]\tvalidation_0-auc:0.85685\n",
      "[276]\tvalidation_0-auc:0.85684\n",
      "[277]\tvalidation_0-auc:0.85688\n",
      "[278]\tvalidation_0-auc:0.85688\n",
      "[279]\tvalidation_0-auc:0.85689\n",
      "[280]\tvalidation_0-auc:0.85691\n",
      "[281]\tvalidation_0-auc:0.85690\n",
      "[282]\tvalidation_0-auc:0.85694\n",
      "[283]\tvalidation_0-auc:0.85693\n",
      "[284]\tvalidation_0-auc:0.85693\n",
      "[285]\tvalidation_0-auc:0.85695\n",
      "[286]\tvalidation_0-auc:0.85695\n",
      "[287]\tvalidation_0-auc:0.85696\n",
      "[288]\tvalidation_0-auc:0.85698\n",
      "[289]\tvalidation_0-auc:0.85699\n",
      "[290]\tvalidation_0-auc:0.85701\n",
      "[291]\tvalidation_0-auc:0.85705\n",
      "[292]\tvalidation_0-auc:0.85706\n",
      "[293]\tvalidation_0-auc:0.85706\n",
      "[294]\tvalidation_0-auc:0.85708\n",
      "[295]\tvalidation_0-auc:0.85708\n",
      "[296]\tvalidation_0-auc:0.85708\n",
      "[297]\tvalidation_0-auc:0.85710\n",
      "[298]\tvalidation_0-auc:0.85712\n",
      "[299]\tvalidation_0-auc:0.85714\n",
      "[300]\tvalidation_0-auc:0.85714\n",
      "[301]\tvalidation_0-auc:0.85715\n",
      "[302]\tvalidation_0-auc:0.85714\n",
      "[303]\tvalidation_0-auc:0.85716\n",
      "[304]\tvalidation_0-auc:0.85717\n",
      "[305]\tvalidation_0-auc:0.85719\n",
      "[306]\tvalidation_0-auc:0.85719\n",
      "[307]\tvalidation_0-auc:0.85719\n",
      "[308]\tvalidation_0-auc:0.85720\n",
      "[309]\tvalidation_0-auc:0.85722\n",
      "[310]\tvalidation_0-auc:0.85723\n",
      "[311]\tvalidation_0-auc:0.85723\n",
      "[312]\tvalidation_0-auc:0.85726\n",
      "[313]\tvalidation_0-auc:0.85725\n",
      "[314]\tvalidation_0-auc:0.85725\n",
      "[315]\tvalidation_0-auc:0.85726\n",
      "[316]\tvalidation_0-auc:0.85728\n",
      "[317]\tvalidation_0-auc:0.85729\n",
      "[318]\tvalidation_0-auc:0.85729\n",
      "[319]\tvalidation_0-auc:0.85729\n",
      "[320]\tvalidation_0-auc:0.85729\n",
      "[321]\tvalidation_0-auc:0.85728\n",
      "[322]\tvalidation_0-auc:0.85728\n",
      "[323]\tvalidation_0-auc:0.85728\n",
      "[324]\tvalidation_0-auc:0.85730\n",
      "[325]\tvalidation_0-auc:0.85733\n",
      "[326]\tvalidation_0-auc:0.85732\n",
      "[327]\tvalidation_0-auc:0.85733\n",
      "[328]\tvalidation_0-auc:0.85734\n",
      "[329]\tvalidation_0-auc:0.85734\n",
      "[330]\tvalidation_0-auc:0.85733\n",
      "[331]\tvalidation_0-auc:0.85735\n",
      "[332]\tvalidation_0-auc:0.85736\n",
      "[333]\tvalidation_0-auc:0.85736\n",
      "[334]\tvalidation_0-auc:0.85739\n",
      "[335]\tvalidation_0-auc:0.85739\n",
      "[336]\tvalidation_0-auc:0.85739\n",
      "[337]\tvalidation_0-auc:0.85740\n",
      "[338]\tvalidation_0-auc:0.85740\n",
      "[339]\tvalidation_0-auc:0.85741\n",
      "[340]\tvalidation_0-auc:0.85743\n",
      "[341]\tvalidation_0-auc:0.85744\n",
      "[342]\tvalidation_0-auc:0.85746\n",
      "[343]\tvalidation_0-auc:0.85747\n",
      "[344]\tvalidation_0-auc:0.85746\n",
      "[345]\tvalidation_0-auc:0.85745\n",
      "[346]\tvalidation_0-auc:0.85746\n",
      "[347]\tvalidation_0-auc:0.85746\n",
      "[348]\tvalidation_0-auc:0.85745\n",
      "[349]\tvalidation_0-auc:0.85745\n",
      "[350]\tvalidation_0-auc:0.85746\n",
      "[351]\tvalidation_0-auc:0.85746\n",
      "[352]\tvalidation_0-auc:0.85746\n",
      "[353]\tvalidation_0-auc:0.85746\n",
      "[354]\tvalidation_0-auc:0.85749\n",
      "[355]\tvalidation_0-auc:0.85749\n",
      "[356]\tvalidation_0-auc:0.85751\n",
      "[357]\tvalidation_0-auc:0.85752\n",
      "[358]\tvalidation_0-auc:0.85753\n",
      "[359]\tvalidation_0-auc:0.85754\n",
      "[360]\tvalidation_0-auc:0.85757\n",
      "[361]\tvalidation_0-auc:0.85757\n",
      "[362]\tvalidation_0-auc:0.85758\n",
      "[363]\tvalidation_0-auc:0.85759\n",
      "[364]\tvalidation_0-auc:0.85759\n",
      "[365]\tvalidation_0-auc:0.85759\n",
      "[366]\tvalidation_0-auc:0.85759\n",
      "[367]\tvalidation_0-auc:0.85759\n",
      "[368]\tvalidation_0-auc:0.85759\n",
      "[369]\tvalidation_0-auc:0.85759\n",
      "[370]\tvalidation_0-auc:0.85760\n",
      "[371]\tvalidation_0-auc:0.85760\n",
      "[372]\tvalidation_0-auc:0.85762\n",
      "[373]\tvalidation_0-auc:0.85764\n",
      "[374]\tvalidation_0-auc:0.85764\n",
      "[375]\tvalidation_0-auc:0.85766\n",
      "[376]\tvalidation_0-auc:0.85765\n",
      "[377]\tvalidation_0-auc:0.85767\n",
      "[378]\tvalidation_0-auc:0.85767\n",
      "[379]\tvalidation_0-auc:0.85767\n",
      "[380]\tvalidation_0-auc:0.85768\n",
      "[381]\tvalidation_0-auc:0.85769\n",
      "[382]\tvalidation_0-auc:0.85770\n",
      "[383]\tvalidation_0-auc:0.85772\n",
      "[384]\tvalidation_0-auc:0.85772\n",
      "[385]\tvalidation_0-auc:0.85773\n",
      "[386]\tvalidation_0-auc:0.85773\n",
      "[387]\tvalidation_0-auc:0.85774\n",
      "[388]\tvalidation_0-auc:0.85774\n",
      "[389]\tvalidation_0-auc:0.85774\n",
      "[390]\tvalidation_0-auc:0.85776\n",
      "[391]\tvalidation_0-auc:0.85778\n",
      "[392]\tvalidation_0-auc:0.85779\n",
      "[393]\tvalidation_0-auc:0.85780\n",
      "[394]\tvalidation_0-auc:0.85780\n",
      "[395]\tvalidation_0-auc:0.85781\n",
      "[396]\tvalidation_0-auc:0.85784\n",
      "[397]\tvalidation_0-auc:0.85786\n",
      "[398]\tvalidation_0-auc:0.85786\n",
      "[399]\tvalidation_0-auc:0.85786\n",
      "[400]\tvalidation_0-auc:0.85785\n",
      "[401]\tvalidation_0-auc:0.85785\n",
      "[402]\tvalidation_0-auc:0.85785\n",
      "[403]\tvalidation_0-auc:0.85785\n",
      "[404]\tvalidation_0-auc:0.85786\n",
      "[405]\tvalidation_0-auc:0.85785\n",
      "[406]\tvalidation_0-auc:0.85787\n",
      "[407]\tvalidation_0-auc:0.85786\n",
      "[408]\tvalidation_0-auc:0.85786\n",
      "[409]\tvalidation_0-auc:0.85787\n",
      "[410]\tvalidation_0-auc:0.85787\n",
      "[411]\tvalidation_0-auc:0.85787\n",
      "[412]\tvalidation_0-auc:0.85787\n",
      "[413]\tvalidation_0-auc:0.85786\n",
      "[414]\tvalidation_0-auc:0.85786\n",
      "[415]\tvalidation_0-auc:0.85786\n",
      "[416]\tvalidation_0-auc:0.85786\n",
      "[417]\tvalidation_0-auc:0.85785\n",
      "[418]\tvalidation_0-auc:0.85786\n",
      "[419]\tvalidation_0-auc:0.85787\n",
      "[420]\tvalidation_0-auc:0.85788\n",
      "[421]\tvalidation_0-auc:0.85790\n",
      "[422]\tvalidation_0-auc:0.85791\n",
      "[423]\tvalidation_0-auc:0.85791\n",
      "[424]\tvalidation_0-auc:0.85791\n",
      "[425]\tvalidation_0-auc:0.85792\n",
      "[426]\tvalidation_0-auc:0.85791\n",
      "[427]\tvalidation_0-auc:0.85791\n",
      "[428]\tvalidation_0-auc:0.85792\n",
      "[429]\tvalidation_0-auc:0.85793\n",
      "[430]\tvalidation_0-auc:0.85794\n",
      "[431]\tvalidation_0-auc:0.85795\n",
      "[432]\tvalidation_0-auc:0.85796\n",
      "[433]\tvalidation_0-auc:0.85797\n",
      "[434]\tvalidation_0-auc:0.85797\n",
      "[435]\tvalidation_0-auc:0.85796\n",
      "[436]\tvalidation_0-auc:0.85797\n",
      "[437]\tvalidation_0-auc:0.85797\n",
      "[438]\tvalidation_0-auc:0.85798\n",
      "[439]\tvalidation_0-auc:0.85799\n",
      "[440]\tvalidation_0-auc:0.85798\n",
      "[441]\tvalidation_0-auc:0.85799\n",
      "[442]\tvalidation_0-auc:0.85799\n",
      "[443]\tvalidation_0-auc:0.85798\n",
      "[444]\tvalidation_0-auc:0.85799\n",
      "[445]\tvalidation_0-auc:0.85798\n",
      "[446]\tvalidation_0-auc:0.85799\n",
      "[447]\tvalidation_0-auc:0.85800\n",
      "[448]\tvalidation_0-auc:0.85801\n",
      "[449]\tvalidation_0-auc:0.85804\n",
      "[450]\tvalidation_0-auc:0.85804\n",
      "[451]\tvalidation_0-auc:0.85805\n",
      "[452]\tvalidation_0-auc:0.85804\n",
      "[453]\tvalidation_0-auc:0.85804\n",
      "[454]\tvalidation_0-auc:0.85804\n",
      "[455]\tvalidation_0-auc:0.85804\n",
      "[456]\tvalidation_0-auc:0.85804\n",
      "[457]\tvalidation_0-auc:0.85804\n",
      "[458]\tvalidation_0-auc:0.85806\n",
      "[459]\tvalidation_0-auc:0.85806\n",
      "[460]\tvalidation_0-auc:0.85805\n",
      "[461]\tvalidation_0-auc:0.85805\n",
      "[462]\tvalidation_0-auc:0.85805\n",
      "[463]\tvalidation_0-auc:0.85806\n",
      "[464]\tvalidation_0-auc:0.85805\n",
      "[465]\tvalidation_0-auc:0.85805\n",
      "[466]\tvalidation_0-auc:0.85804\n",
      "[467]\tvalidation_0-auc:0.85804\n",
      "[468]\tvalidation_0-auc:0.85805\n",
      "[469]\tvalidation_0-auc:0.85805\n",
      "[470]\tvalidation_0-auc:0.85804\n",
      "[471]\tvalidation_0-auc:0.85803\n",
      "[472]\tvalidation_0-auc:0.85803\n",
      "[473]\tvalidation_0-auc:0.85803\n",
      "[474]\tvalidation_0-auc:0.85803\n",
      "[475]\tvalidation_0-auc:0.85805\n",
      "[476]\tvalidation_0-auc:0.85804\n",
      "[477]\tvalidation_0-auc:0.85805\n",
      "[478]\tvalidation_0-auc:0.85805\n",
      "[479]\tvalidation_0-auc:0.85806\n",
      "[480]\tvalidation_0-auc:0.85806\n",
      "[481]\tvalidation_0-auc:0.85806\n",
      "[482]\tvalidation_0-auc:0.85806\n",
      "[483]\tvalidation_0-auc:0.85806\n",
      "[484]\tvalidation_0-auc:0.85806\n",
      "[485]\tvalidation_0-auc:0.85805\n",
      "[486]\tvalidation_0-auc:0.85805\n",
      "[487]\tvalidation_0-auc:0.85804\n",
      "[488]\tvalidation_0-auc:0.85804\n",
      "[489]\tvalidation_0-auc:0.85804\n",
      "[490]\tvalidation_0-auc:0.85803\n",
      "[491]\tvalidation_0-auc:0.85804\n",
      "[492]\tvalidation_0-auc:0.85805\n",
      "[493]\tvalidation_0-auc:0.85804\n",
      "[494]\tvalidation_0-auc:0.85804\n",
      "[495]\tvalidation_0-auc:0.85805\n",
      "[496]\tvalidation_0-auc:0.85805\n",
      "[497]\tvalidation_0-auc:0.85805\n",
      "[498]\tvalidation_0-auc:0.85805\n",
      "[499]\tvalidation_0-auc:0.85805\n",
      "[500]\tvalidation_0-auc:0.85804\n",
      "[501]\tvalidation_0-auc:0.85803\n",
      "[502]\tvalidation_0-auc:0.85803\n",
      "[503]\tvalidation_0-auc:0.85802\n",
      "[504]\tvalidation_0-auc:0.85802\n",
      "[505]\tvalidation_0-auc:0.85803\n",
      "[506]\tvalidation_0-auc:0.85803\n",
      "[507]\tvalidation_0-auc:0.85802\n",
      "[508]\tvalidation_0-auc:0.85803\n",
      "[509]\tvalidation_0-auc:0.85803\n",
      "[510]\tvalidation_0-auc:0.85804\n",
      "[511]\tvalidation_0-auc:0.85805\n",
      "[512]\tvalidation_0-auc:0.85805\n",
      "[513]\tvalidation_0-auc:0.85806\n",
      "[514]\tvalidation_0-auc:0.85806\n",
      "[515]\tvalidation_0-auc:0.85807\n",
      "[516]\tvalidation_0-auc:0.85807\n",
      "[517]\tvalidation_0-auc:0.85806\n",
      "[518]\tvalidation_0-auc:0.85807\n",
      "[519]\tvalidation_0-auc:0.85807\n",
      "[520]\tvalidation_0-auc:0.85807\n",
      "[521]\tvalidation_0-auc:0.85808\n",
      "[522]\tvalidation_0-auc:0.85808\n",
      "[523]\tvalidation_0-auc:0.85807\n",
      "[524]\tvalidation_0-auc:0.85808\n",
      "[525]\tvalidation_0-auc:0.85808\n",
      "[526]\tvalidation_0-auc:0.85807\n",
      "[527]\tvalidation_0-auc:0.85807\n",
      "[528]\tvalidation_0-auc:0.85808\n",
      "[529]\tvalidation_0-auc:0.85807\n",
      "[530]\tvalidation_0-auc:0.85806\n",
      "[531]\tvalidation_0-auc:0.85807\n",
      "[532]\tvalidation_0-auc:0.85808\n",
      "[533]\tvalidation_0-auc:0.85809\n",
      "[534]\tvalidation_0-auc:0.85808\n",
      "[535]\tvalidation_0-auc:0.85807\n",
      "[536]\tvalidation_0-auc:0.85807\n",
      "[537]\tvalidation_0-auc:0.85807\n",
      "[538]\tvalidation_0-auc:0.85807\n",
      "[539]\tvalidation_0-auc:0.85806\n",
      "[540]\tvalidation_0-auc:0.85806\n",
      "[541]\tvalidation_0-auc:0.85806\n",
      "[542]\tvalidation_0-auc:0.85806\n",
      "[543]\tvalidation_0-auc:0.85806\n",
      "[544]\tvalidation_0-auc:0.85806\n",
      "[545]\tvalidation_0-auc:0.85806\n",
      "[546]\tvalidation_0-auc:0.85806\n",
      "[547]\tvalidation_0-auc:0.85806\n",
      "[548]\tvalidation_0-auc:0.85806\n",
      "[549]\tvalidation_0-auc:0.85806\n",
      "[550]\tvalidation_0-auc:0.85805\n",
      "[551]\tvalidation_0-auc:0.85805\n",
      "[552]\tvalidation_0-auc:0.85805\n",
      "[553]\tvalidation_0-auc:0.85805\n",
      "[554]\tvalidation_0-auc:0.85805\n",
      "[555]\tvalidation_0-auc:0.85805\n",
      "[556]\tvalidation_0-auc:0.85805\n",
      "[557]\tvalidation_0-auc:0.85805\n",
      "[558]\tvalidation_0-auc:0.85806\n",
      "[559]\tvalidation_0-auc:0.85808\n",
      "[560]\tvalidation_0-auc:0.85807\n",
      "[561]\tvalidation_0-auc:0.85806\n",
      "[562]\tvalidation_0-auc:0.85805\n",
      "[563]\tvalidation_0-auc:0.85805\n",
      "[564]\tvalidation_0-auc:0.85806\n",
      "[565]\tvalidation_0-auc:0.85805\n",
      "[566]\tvalidation_0-auc:0.85803\n",
      "[567]\tvalidation_0-auc:0.85803\n",
      "[568]\tvalidation_0-auc:0.85802\n",
      "[569]\tvalidation_0-auc:0.85803\n",
      "[570]\tvalidation_0-auc:0.85802\n",
      "[571]\tvalidation_0-auc:0.85802\n",
      "[572]\tvalidation_0-auc:0.85800\n",
      "[573]\tvalidation_0-auc:0.85799\n",
      "[574]\tvalidation_0-auc:0.85800\n",
      "[575]\tvalidation_0-auc:0.85801\n",
      "[576]\tvalidation_0-auc:0.85800\n",
      "[577]\tvalidation_0-auc:0.85800\n",
      "[578]\tvalidation_0-auc:0.85801\n",
      "[579]\tvalidation_0-auc:0.85801\n",
      "[580]\tvalidation_0-auc:0.85801\n",
      "[581]\tvalidation_0-auc:0.85800\n",
      "[582]\tvalidation_0-auc:0.85800\n",
      "[583]\tvalidation_0-auc:0.85800\n",
      "[584]\tvalidation_0-auc:0.85798\n",
      "[585]\tvalidation_0-auc:0.85799\n",
      "[586]\tvalidation_0-auc:0.85799\n",
      "[587]\tvalidation_0-auc:0.85799\n",
      "[588]\tvalidation_0-auc:0.85801\n",
      "[589]\tvalidation_0-auc:0.85801\n",
      "[590]\tvalidation_0-auc:0.85799\n",
      "[591]\tvalidation_0-auc:0.85799\n",
      "[592]\tvalidation_0-auc:0.85801\n",
      "[593]\tvalidation_0-auc:0.85801\n",
      "[594]\tvalidation_0-auc:0.85800\n",
      "[595]\tvalidation_0-auc:0.85800\n",
      "[596]\tvalidation_0-auc:0.85802\n",
      "[597]\tvalidation_0-auc:0.85802\n",
      "[598]\tvalidation_0-auc:0.85803\n",
      "[599]\tvalidation_0-auc:0.85803\n",
      "[600]\tvalidation_0-auc:0.85804\n",
      "[601]\tvalidation_0-auc:0.85804\n",
      "[602]\tvalidation_0-auc:0.85804\n",
      "[603]\tvalidation_0-auc:0.85801\n",
      "[604]\tvalidation_0-auc:0.85800\n",
      "[605]\tvalidation_0-auc:0.85801\n",
      "[606]\tvalidation_0-auc:0.85801\n",
      "[607]\tvalidation_0-auc:0.85801\n",
      "[608]\tvalidation_0-auc:0.85801\n",
      "[609]\tvalidation_0-auc:0.85801\n",
      "[610]\tvalidation_0-auc:0.85800\n",
      "[611]\tvalidation_0-auc:0.85800\n",
      "[612]\tvalidation_0-auc:0.85801\n",
      "[613]\tvalidation_0-auc:0.85800\n",
      "[614]\tvalidation_0-auc:0.85801\n",
      "[615]\tvalidation_0-auc:0.85802\n",
      "[616]\tvalidation_0-auc:0.85801\n",
      "[617]\tvalidation_0-auc:0.85800\n",
      "[618]\tvalidation_0-auc:0.85800\n",
      "[619]\tvalidation_0-auc:0.85800\n",
      "[620]\tvalidation_0-auc:0.85800\n",
      "[621]\tvalidation_0-auc:0.85800\n",
      "[622]\tvalidation_0-auc:0.85798\n",
      "[623]\tvalidation_0-auc:0.85798\n",
      "[624]\tvalidation_0-auc:0.85798\n",
      "[625]\tvalidation_0-auc:0.85798\n",
      "[626]\tvalidation_0-auc:0.85797\n",
      "[627]\tvalidation_0-auc:0.85795\n",
      "[628]\tvalidation_0-auc:0.85795\n",
      "[629]\tvalidation_0-auc:0.85794\n",
      "[630]\tvalidation_0-auc:0.85793\n",
      "[631]\tvalidation_0-auc:0.85791\n",
      "[632]\tvalidation_0-auc:0.85792\n",
      "[633]\tvalidation_0-auc:0.85792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(14.078000325679856)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.5388617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.83      0.90     27868\n",
      "   Defaulted       0.23      0.73      0.35      1978\n",
      "\n",
      "    accuracy                           0.82     29846\n",
      "   macro avg       0.60      0.78      0.62     29846\n",
      "weighted avg       0.93      0.82      0.86     29846\n",
      "\n",
      "Accuracy: 81.94%\n",
      "ROC AUC: 0.858\n",
      "TP=1445, FP=4858, TN=23010, FN=533\n",
      "Accuracy for class 'Repaid': 82.57%\n",
      "Accuracy for class 'Defaulted': 73.05%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_test, y_probs, thresholds, beta=2.4)\n",
    "best_thresh_b = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Feature   Importance\n",
      "0                         HasAnyDelinquency  5539.897461\n",
      "1                         DelinquencyBucket  2455.662109\n",
      "2                          DelinquencyScore  1347.828125\n",
      "3                         UtilizationPerAge   280.559479\n",
      "4               UtilizationBucketLateBucket   255.373718\n",
      "5               UtilizationTimesDelinquency   150.437683\n",
      "6             RevolvingUtilizationCappedLog   125.578217\n",
      "7                       HasMajorDelinquency    66.369560\n",
      "8                       DebtToIncomeAgeRisk    63.590588\n",
      "9                       IncomePerCreditLine    46.932198\n",
      "10                          HighAgeRiskFlag    41.908051\n",
      "11                 UtilizationPerCreditLine    38.102615\n",
      "12                LatePaymentsPerCreditLine    35.787468\n",
      "13              WasUtilizationPerAgeImputed    32.946724\n",
      "14    WasUtilizationTimesDelinquencyImputed    28.533401\n",
      "15      WasLatePaymentsPerCreditLineImputed     9.517992\n",
      "16            WasIncomePerCreditLineImputed     7.383667\n",
      "17  WasRevolvingUtilizationCappedLogImputed     0.000000\n",
      "18       WasUtilizationPerCreditLineImputed     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1474e78c323e43bf85d6a3bcb4f69264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    feature  mean_abs_shap\n",
      "5                         UtilizationPerAge       0.023608\n",
      "6             RevolvingUtilizationCappedLog       0.016251\n",
      "8                       IncomePerCreditLine       0.011071\n",
      "7                       DebtToIncomeAgeRisk       0.009894\n",
      "2                         HasAnyDelinquency       0.009226\n",
      "0                       HasMajorDelinquency       0.008760\n",
      "18       WasUtilizationPerCreditLineImputed       0.008653\n",
      "1                          DelinquencyScore       0.007464\n",
      "3               UtilizationTimesDelinquency       0.003712\n",
      "9                  UtilizationPerCreditLine       0.003701\n",
      "4                 LatePaymentsPerCreditLine       0.003126\n",
      "10                          HighAgeRiskFlag       0.002262\n",
      "17            WasIncomePerCreditLineImputed       0.001958\n",
      "15              WasUtilizationPerAgeImputed       0.000660\n",
      "13    WasUtilizationTimesDelinquencyImputed       0.000092\n",
      "14      WasLatePaymentsPerCreditLineImputed       0.000091\n",
      "12              UtilizationBucketLateBucket       0.000048\n",
      "16  WasRevolvingUtilizationCappedLogImputed       0.000026\n",
      "11                        DelinquencyBucket       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance NN\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "model_cpu.eval()\n",
    "\n",
    "def shap_cpu(X):\n",
    "    n_num = X_train_num_tensor.shape[1]\n",
    "    n_cat = X_train_cat_tensor.shape[1]\n",
    "\n",
    "    X_num = X[:, :n_num].astype(np.float32)\n",
    "    X_cat = X[:, n_num:n_num + n_cat].astype(np.int64)\n",
    "\n",
    "    X_num_tensor = torch.tensor(X_num, dtype=torch.float32)\n",
    "    X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_num_tensor, X_cat_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "X_train_combined = np.hstack([\n",
    "    X_train_num_tensor.numpy(),\n",
    "    X_train_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "X_val_combined = np.hstack([\n",
    "    X_val_num_tensor.numpy(),\n",
    "    X_val_cat_tensor.numpy()\n",
    "])\n",
    "\n",
    "background = shap.sample(X_train_combined, 100, random_state=42)\n",
    "X_val_sample = X_val_combined[:500]\n",
    "\n",
    "explainer = shap.KernelExplainer(shap_cpu, background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "\n",
    "feature_names = (\n",
    "    list(num_col_order) +\n",
    "    list(cat_col_order) +\n",
    "    list(X_train_flags)\n",
    ")\n",
    "\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
