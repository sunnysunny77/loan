{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 2\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "        \n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    imputed_flags = [col for col in numeric_cols if col.startswith(\"Was\") or col.endswith(\"Imputed\")]\n",
    "    regular_numeric_cols = [col for col in numeric_cols if col not in imputed_flags]\n",
    "\n",
    "    df_num = df_copy[regular_numeric_cols].copy()\n",
    "    \n",
    "    df_num.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    print(f\"Dataset shape: {df_num.shape}\")\n",
    "    print(f\"Total rows: {len(df_num)}\")\n",
    "    print(f\"Total duplicate rows: {df_num.duplicated().sum()}\")\n",
    "\n",
    "    desc = df_num.describe().T\n",
    "    desc[\"skew\"] = df_num.skew()\n",
    "    \n",
    "    desc[\"dtype\"] = df_copy[desc.index].dtypes\n",
    "    desc[\"non_null\"] = df_copy[desc.index].notna().sum()\n",
    "    desc[\"missing\"] = df_copy[desc.index].isna().sum()\n",
    "    desc[\"missing_%\"] = (df_copy[desc.index].isna().mean() * 100).round(2)\n",
    "    desc[\"unique\"] = df_copy[desc.index].nunique()\n",
    "    \n",
    "    if y is not None:\n",
    "        df_num['target'] = y\n",
    "        desc[\"corr_with_target\"] = df_num.corr()['target'].drop('target')\n",
    "    \n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "       \n",
    "    corr_pairs = (\n",
    "        corr_matrix\n",
    "        .where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "      \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "     \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    high_corr_flags = []\n",
    "    high_corr_with = []\n",
    "    \n",
    "    for col in desc.index:\n",
    "        if col in corr_map:\n",
    "            high_corr_flags.append(True)\n",
    "            high_corr_with.append(\", \".join(corr_map[col]))\n",
    "        else:\n",
    "            high_corr_flags.append(False)\n",
    "            high_corr_with.append(\"\")\n",
    "    \n",
    "    desc[\"high_corr_flag\"] = high_corr_flags\n",
    "    desc[\"high_corr_with\"] = high_corr_with\n",
    "    \n",
    "    return desc.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(X, y, n_high=100, n_low=10):\n",
    "    \n",
    "    X_copy = X.copy()\n",
    "    y_copy = y.copy()\n",
    "    \n",
    "    numeric_cols = X_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    X_copy[numeric_cols] = X_copy[numeric_cols].fillna(0)\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X_copy, y_copy)\n",
    "    y_pred_proba = hgb.predict_proba(X_copy)[:, 1]\n",
    "\n",
    "    df_combined = X_copy.copy()\n",
    "    df_combined[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_combined[\"__target__\"] = y_copy.values\n",
    "\n",
    "    df_sorted = df_combined.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    X_filtered = df_filtered.drop(columns=[\"__pred_proba__\", \"__target__\"])\n",
    "    y_filtered = df_filtered[\"__target__\"]\n",
    "\n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    \n",
    "    TotalPastDueLog = np.log1p(TotalPastDue)\n",
    "    \n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationFilled = RevolvingUtilizationCapped.fillna(0)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationFilled)\n",
    "    RevolvingUtilizationCappedLogSafe = RevolvingUtilizationCappedLog.replace(0, np.nan)\n",
    "        \n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].fillna(0).clip(upper=10000.0)\n",
    "        \n",
    "    DebtRatioCappedLog = np.log1p(DebtRatioCapped)\n",
    "    \n",
    "    DebtRatioSafe =  DebtRatioCappedLog.replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeLog = np.log1p(df_e[\"MonthlyIncome\"].fillna(0))\n",
    "\n",
    "    MonthlyIncomeSafe = MonthlyIncomeLog.replace(0, np.nan)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    NumberRealEstateLoansOrLinesfilled = df_e[\"NumberRealEstateLoansOrLines\"].fillna(0)\n",
    "\n",
    "    DebtToIncome = DebtRatioSafe * MonthlyIncomeSafe\n",
    "    \n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "    \n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLogSafe / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDueLog > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilization\"] = RevolvingUtilizationCappedLogSafe\n",
    "    df_e[\"TotalPastDue\"] = TotalPastDueLog\n",
    "\n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationPerCreditLine\"] =  RevolvingUtilizationCappedLogSafe / CreditLinesSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDueLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"RealEstateLeverage\"] = NumberRealEstateLoansOrLinesfilled * RevolvingUtilizationCappedLogSafe\n",
    "    \n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationFilled, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDueLog, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"RevolvingUtilization\",\n",
    "        \"TotalPastDue\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"RealEstateLeverage\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_df)} features\")\n",
    "    print(f\"Engineered cols: {list(engineered_df.columns)}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "\n",
    "    best_param = {\n",
    "        \"learning_rate\": 0.01,              \n",
    "        \"max_depth\": 6,              \n",
    "        'min_child_weight': 6,\n",
    "        \"gamma\": 1.0,                 \n",
    "        'subsample': 0.85,            \n",
    "        \"colsample_bytree\": 0.9,     \n",
    "        'reg_alpha': 1,            \n",
    "        'reg_lambda': 4                       \n",
    "    }\n",
    " \n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_param,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),\n",
    "        n_estimators=800,\n",
    "        max_bin=1024,\n",
    "        booster=\"gbtree\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": X_train.columns,\n",
    "        \"Importance\": mean_abs_shap\n",
    "    }).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    top_features = importance_df[\"Feature\"].head(n_to_keep).tolist()\n",
    "\n",
    "    final_features = list(set(top_features + cat_cols))\n",
    "\n",
    "    dropped_features = [f for f in df_temp.columns if f not in final_features]\n",
    "\n",
    "    print(f\"Kept {len(final_features)} features (including categorical columns)\")\n",
    "    print(f\"Dropped {len(dropped_features)} features\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols: {dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[final_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None):\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    count = df.duplicated().sum()\n",
    "\n",
    "    if target is None:\n",
    "        print(f\"Dropped: {count} duplicates\")\n",
    "        return df_cleaned\n",
    "\n",
    "    target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "    mask = target_cleaned.notna()\n",
    "    df_cleaned = df_cleaned[mask].reset_index(drop=True)\n",
    "    target_cleaned = target_cleaned[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Dropped: {count} duplicates\")\n",
    "    \n",
    "    return df_cleaned, target_cleaned\n",
    "\n",
    "def threshold_by_target_recall(y_true, y_probs, thresholds, target_recall):\n",
    "    \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_probs = np.asarray(y_probs).astype(float)\n",
    "    thresholds = np.asarray(thresholds).astype(float)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :]\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    closest_idx = np.argmin(np.abs(recall - target_recall))\n",
    "    \n",
    "    return thresholds[closest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>120269.0</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>146076.0</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         count         mean           std  \\\n",
       "MonthlyIncome                         120269.0  6670.221237  14384.674215   \n",
       "NumberOfDependents                    146076.0     0.757222      1.115086   \n",
       "age                                   150000.0    52.295207     14.771866   \n",
       "RevolvingUtilizationOfUnsecuredLines  150000.0     6.048438    249.755371   \n",
       "DebtRatio                             150000.0   353.005076   2037.818523   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  150000.0     0.421033      4.192781   \n",
       "NumberOfOpenCreditLinesAndLoans       150000.0     8.452760      5.145951   \n",
       "NumberOfTimes90DaysLate               150000.0     0.265973      4.169304   \n",
       "NumberRealEstateLoansOrLines          150000.0     1.018240      1.129771   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  150000.0     0.240387      4.155179   \n",
       "\n",
       "                                      min          25%          50%  \\\n",
       "MonthlyIncome                         0.0  3400.000000  5400.000000   \n",
       "NumberOfDependents                    0.0     0.000000     0.000000   \n",
       "age                                   0.0    41.000000    52.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines  0.0     0.029867     0.154181   \n",
       "DebtRatio                             0.0     0.175074     0.366508   \n",
       "NumberOfTime30-59DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans       0.0     5.000000     8.000000   \n",
       "NumberOfTimes90DaysLate               0.0     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines          0.0     0.000000     1.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse  0.0     0.000000     0.000000   \n",
       "\n",
       "                                              75%        max        skew  \\\n",
       "MonthlyIncome                         8249.000000  3008750.0  114.040318   \n",
       "NumberOfDependents                       1.000000       20.0    1.588242   \n",
       "age                                     63.000000      109.0    0.188995   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.559046    50708.0   97.631574   \n",
       "DebtRatio                                0.868254   329664.0   95.157793   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000       98.0   22.597108   \n",
       "NumberOfOpenCreditLinesAndLoans         11.000000       58.0    1.215314   \n",
       "NumberOfTimes90DaysLate                  0.000000       98.0   23.087345   \n",
       "NumberRealEstateLoansOrLines             2.000000       54.0    3.482484   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000       98.0   23.331743   \n",
       "\n",
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique  corr_with_target  \\\n",
       "MonthlyIncome                          13594         -0.019746   \n",
       "NumberOfDependents                        13          0.046048   \n",
       "age                                       86         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728         -0.001802   \n",
       "DebtRatio                             114194         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans           58         -0.029669   \n",
       "NumberOfTimes90DaysLate                   19          0.117175   \n",
       "NumberRealEstateLoansOrLines              28         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>1.202670e+05</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>149998.000000</td>\n",
       "      <td>146074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066841</td>\n",
       "      <td>6.048512</td>\n",
       "      <td>52.295557</td>\n",
       "      <td>0.421032</td>\n",
       "      <td>353.009780</td>\n",
       "      <td>6.645265e+03</td>\n",
       "      <td>8.452766</td>\n",
       "      <td>0.265977</td>\n",
       "      <td>1.018234</td>\n",
       "      <td>0.240390</td>\n",
       "      <td>0.757198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249747</td>\n",
       "      <td>249.757035</td>\n",
       "      <td>14.771347</td>\n",
       "      <td>4.192809</td>\n",
       "      <td>2037.831702</td>\n",
       "      <td>1.148842e+04</td>\n",
       "      <td>5.145980</td>\n",
       "      <td>4.169331</td>\n",
       "      <td>1.129776</td>\n",
       "      <td>4.155207</td>\n",
       "      <td>1.115074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029869</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>3.400000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>5.400000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559044</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868260</td>\n",
       "      <td>8.249000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149998.000000                         149998.000000  149998.000000   \n",
       "mean           0.066841                              6.048512      52.295557   \n",
       "std            0.249747                            249.757035      14.771347   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.029869      41.000000   \n",
       "50%            0.000000                              0.154181      52.000000   \n",
       "75%            0.000000                              0.559044      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                         149998.000000  149998.000000   1.202670e+05   \n",
       "mean                               0.421032     353.009780   6.645265e+03   \n",
       "std                                4.192809    2037.831702   1.148842e+04   \n",
       "min                                0.000000       0.000000   0.000000e+00   \n",
       "25%                                0.000000       0.175074   3.400000e+03   \n",
       "50%                                0.000000       0.366508   5.400000e+03   \n",
       "75%                                0.000000       0.868260   8.249000e+03   \n",
       "max                               98.000000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149998.000000            149998.000000   \n",
       "mean                          8.452766                 0.265977   \n",
       "std                           5.145980                 4.169331   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149998.000000                         149998.000000   \n",
       "mean                       1.018234                              0.240390   \n",
       "std                        1.129776                              4.155207   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       146074.000000  \n",
       "mean             0.757198  \n",
       "std              1.115074  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling Manual\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139972\n",
      "1     10026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_train)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 160 outlier rows (lowest 30, highest 130)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Outlier Handling \n",
    "X_train_cut, y_train_cut = outlier_handling(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    n_high=130, \n",
    "    n_low=30\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_cut, y_train_cut, test_size=0.2, stratify=y_train_cut, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026bc2c6-c772-4a73-9cbf-5e29c2b410e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 451 duplicates\n",
      "Dropped: 45 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)\n",
    "X_val, y_val = check_and_drop_duplicates(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 95419 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bd0425-dbbf-491a-aee0-b602edf86033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 2694 duplicates\n"
     ]
    }
   ],
   "source": [
    "df_e, y_train = check_and_drop_duplicates(df_e, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             MissingCount  MissingPercent\n",
      "DebtToIncomeAgeRisk                 18348           19.79\n",
      "DelinquencyScore                        0            0.00\n",
      "HighAgeRiskFlag                         0            0.00\n",
      "IncomePerCreditLine                 17631           19.01\n",
      "LatePaymentsPerCreditLine             537            0.58\n",
      "RealEstateLeverage                   4927            5.31\n",
      "RevolvingUtilization                 4927            5.31\n",
      "TotalPastDue                            0            0.00\n",
      "UtilizationBucketLateBucket             0            0.00\n",
      "UtilizationPerAge                    4927            5.31\n",
      "UtilizationPerCreditLine             5464            5.89\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           19           0.02\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'UtilizationBucketLateBucket': collapsed 14 rare categories: ['Very High_ModerateLate', 'Very Low_FewLate', 'Very High_FewLate', 'Low_FewLate', 'Moderate_FewLate', 'High_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'Very Low_ModerateLate', 'Low_ModerateLate', 'Extreme_NoLate', 'Extreme_ModerateLate', 'Very High_FrequentLate', 'Extreme_FewLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da8189b-60a9-4cc7-a082-1a56c327dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 11 features (including categorical columns)\n",
      "Dropped 0 features\n",
      "                        Feature  Importance\n",
      "0     LatePaymentsPerCreditLine    0.501053\n",
      "1             UtilizationPerAge    0.496926\n",
      "2              DelinquencyScore    0.392548\n",
      "3          RevolvingUtilization    0.295521\n",
      "4           DebtToIncomeAgeRisk    0.173187\n",
      "5           IncomePerCreditLine    0.143487\n",
      "6                  TotalPastDue    0.136281\n",
      "7      UtilizationPerCreditLine    0.113165\n",
      "8            RealEstateLeverage    0.088474\n",
      "9               HighAgeRiskFlag    0.027349\n",
      "10  UtilizationBucketLateBucket    0.018062\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n",
      "['UtilizationPerAge', 'RealEstateLeverage', 'LatePaymentsPerCreditLine', 'IncomePerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationPerCreditLine', 'HighAgeRiskFlag', 'DelinquencyScore', 'TotalPastDue', 'RevolvingUtilization']\n",
      "['UtilizationBucketLateBucket']\n",
      "{'UtilizationBucketLateBucket': {'Very Low_NoLate': 0, 'Low_NoLate': 1, 'Moderate_NoLate': 2, 'High_NoLate': 3, 'Other': 4, 'Very High_NoLate': 5}}\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")\n",
    "print(num_col_order)\n",
    "print(cat_col_order)\n",
    "print(cat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 23923 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 30000 features\n",
      "Engineered cols: ['RevolvingUtilization', 'TotalPastDue', 'DelinquencyScore', 'RealEstateLeverage', 'UtilizationPerAge', 'IncomePerCreditLine', 'LatePaymentsPerCreditLine', 'DebtToIncomeAgeRisk', 'UtilizationBucketLateBucket', 'UtilizationPerCreditLine', 'HighAgeRiskFlag']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (92725, 11)\n",
      "Total rows: 92725\n",
      "Total duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.911665e-01</td>\n",
       "      <td>0.772839</td>\n",
       "      <td>-0.409007</td>\n",
       "      <td>-0.305323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694677</td>\n",
       "      <td>8.239514</td>\n",
       "      <td>1.675551</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82266</td>\n",
       "      <td>0.261912</td>\n",
       "      <td>True</td>\n",
       "      <td>RevolvingUtilization (0.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealEstateLeverage</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>5.928118e-01</td>\n",
       "      <td>1.345818</td>\n",
       "      <td>-0.151205</td>\n",
       "      <td>-0.151205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848795</td>\n",
       "      <td>51.397576</td>\n",
       "      <td>5.030255</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53518</td>\n",
       "      <td>0.113533</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>3.844893e-02</td>\n",
       "      <td>0.125785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>6.581883</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "      <td>0.305015</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>4.839945e-01</td>\n",
       "      <td>1.877196</td>\n",
       "      <td>-1.682442</td>\n",
       "      <td>-0.404051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.595949</td>\n",
       "      <td>17.366549</td>\n",
       "      <td>3.841591</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34404</td>\n",
       "      <td>0.044586</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>1.719824e-01</td>\n",
       "      <td>1.138875</td>\n",
       "      <td>-1.367330</td>\n",
       "      <td>-0.457108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542892</td>\n",
       "      <td>29.104658</td>\n",
       "      <td>2.807291</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73017</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerCreditLine</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>7.191053e-01</td>\n",
       "      <td>2.270139</td>\n",
       "      <td>-0.426381</td>\n",
       "      <td>-0.299496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700504</td>\n",
       "      <td>38.250113</td>\n",
       "      <td>4.565031</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82002</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighAgeRiskFlag</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>4.597742e-17</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-1.119283</td>\n",
       "      <td>-1.119283</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>-0.225857</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.091812</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>3.163926e+00</td>\n",
       "      <td>1.717489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.331477</td>\n",
       "      <td>int8</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.054811</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyScore</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>6.774980e-01</td>\n",
       "      <td>2.453629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.162218</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.352806</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDue</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.048315e-01</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.354847</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.387168</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyScore (0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilization</th>\n",
       "      <td>92725.0</td>\n",
       "      <td>2.277991e-01</td>\n",
       "      <td>0.634013</td>\n",
       "      <td>-0.431953</td>\n",
       "      <td>-0.310826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689174</td>\n",
       "      <td>4.146705</td>\n",
       "      <td>1.099702</td>\n",
       "      <td>float64</td>\n",
       "      <td>92725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80873</td>\n",
       "      <td>0.265002</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.92)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean       std       min  \\\n",
       "UtilizationPerAge            92725.0  2.911665e-01  0.772839 -0.409007   \n",
       "RealEstateLeverage           92725.0  5.928118e-01  1.345818 -0.151205   \n",
       "LatePaymentsPerCreditLine    92725.0  3.844893e-02  0.125785  0.000000   \n",
       "IncomePerCreditLine          92725.0  4.839945e-01  1.877196 -1.682442   \n",
       "DebtToIncomeAgeRisk          92725.0  1.719824e-01  1.138875 -1.367330   \n",
       "UtilizationPerCreditLine     92725.0  7.191053e-01  2.270139 -0.426381   \n",
       "HighAgeRiskFlag              92725.0  4.597742e-17  1.000005 -1.119283   \n",
       "UtilizationBucketLateBucket  92725.0  3.163926e+00  1.717489  0.000000   \n",
       "DelinquencyScore             92725.0  6.774980e-01  2.453629  0.000000   \n",
       "TotalPastDue                 92725.0  2.048315e-01  0.446746  0.000000   \n",
       "RevolvingUtilization         92725.0  2.277991e-01  0.634013 -0.431953   \n",
       "\n",
       "                                  25%       50%       75%        max  \\\n",
       "UtilizationPerAge           -0.305323  0.000000  0.694677   8.239514   \n",
       "RealEstateLeverage          -0.151205  0.000000  0.848795  51.397576   \n",
       "LatePaymentsPerCreditLine    0.000000  0.000000  0.000000   3.433987   \n",
       "IncomePerCreditLine         -0.404051  0.000000  0.595949  17.366549   \n",
       "DebtToIncomeAgeRisk         -0.457108  0.000000  0.542892  29.104658   \n",
       "UtilizationPerCreditLine    -0.299496  0.000000  0.700504  38.250113   \n",
       "HighAgeRiskFlag             -1.119283  0.893429  0.893429   0.893429   \n",
       "UtilizationBucketLateBucket  2.000000  3.000000  5.000000   5.000000   \n",
       "DelinquencyScore             0.000000  0.000000  0.000000  60.000000   \n",
       "TotalPastDue                 0.000000  0.000000  0.000000   3.433987   \n",
       "RevolvingUtilization        -0.310826  0.000000  0.689174   4.146705   \n",
       "\n",
       "                                  skew    dtype  non_null  missing  missing_%  \\\n",
       "UtilizationPerAge             1.675551  float64     92725        0        0.0   \n",
       "RealEstateLeverage            5.030255  float64     92725        0        0.0   \n",
       "LatePaymentsPerCreditLine     6.581883  float64     92725        0        0.0   \n",
       "IncomePerCreditLine           3.841591  float64     92725        0        0.0   \n",
       "DebtToIncomeAgeRisk           2.807291  float64     92725        0        0.0   \n",
       "UtilizationPerCreditLine      4.565031  float64     92725        0        0.0   \n",
       "HighAgeRiskFlag              -0.225857  float64     92725        0        0.0   \n",
       "UtilizationBucketLateBucket  -0.331477     int8     92725        0        0.0   \n",
       "DelinquencyScore             11.162218  float64     92725        0        0.0   \n",
       "TotalPastDue                  2.354847  float64     92725        0        0.0   \n",
       "RevolvingUtilization          1.099702  float64     92725        0        0.0   \n",
       "\n",
       "                             unique  corr_with_target  high_corr_flag  \\\n",
       "UtilizationPerAge             82266          0.261912            True   \n",
       "RealEstateLeverage            53518          0.113533           False   \n",
       "LatePaymentsPerCreditLine       278          0.305015           False   \n",
       "IncomePerCreditLine           34404          0.044586           False   \n",
       "DebtToIncomeAgeRisk           73017          0.074956           False   \n",
       "UtilizationPerCreditLine      82002          0.167203           False   \n",
       "HighAgeRiskFlag                   2         -0.091812           False   \n",
       "UtilizationBucketLateBucket       6         -0.054811           False   \n",
       "DelinquencyScore                 37          0.352806            True   \n",
       "TotalPastDue                     18          0.387168            True   \n",
       "RevolvingUtilization          80873          0.265002            True   \n",
       "\n",
       "                                          high_corr_with  \n",
       "UtilizationPerAge            RevolvingUtilization (0.92)  \n",
       "RealEstateLeverage                                        \n",
       "LatePaymentsPerCreditLine                                 \n",
       "IncomePerCreditLine                                       \n",
       "DebtToIncomeAgeRisk                                       \n",
       "UtilizationPerCreditLine                                  \n",
       "HighAgeRiskFlag                                           \n",
       "UtilizationBucketLateBucket                               \n",
       "DelinquencyScore                     TotalPastDue (0.78)  \n",
       "TotalPastDue                     DelinquencyScore (0.78)  \n",
       "RevolvingUtilization            UtilizationPerAge (0.92)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WasRealEstateLeverageImputed', 'WasLatePaymentsPerCreditLineImputed', 'WasUtilizationPerCreditLineImputed', 'WasRevolvingUtilizationImputed']\n"
     ]
    }
   ],
   "source": [
    "# Zero importance cols entered after running\n",
    "zero_importance_cols = [\n",
    "    \"WasDebtToIncomeAgeRiskImputed\",\n",
    "    \"WasUtilizationBucketLateBucketImputed\",\n",
    "    \"WasIncomePerCreditLineImputed\",\n",
    "    \"WasHighAgeRiskFlagImputed\",         \n",
    "    \"WasDelinquencyScoreImputed\",\n",
    "    \"WasUtilizationPerAgeImputed\",\n",
    "    \"WasTotalPastDueImputed\",\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val = X_val.drop(columns=zero_importance_cols)\n",
    "X_test = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags = flags_to_keep\n",
    "X_test_flags = flags_to_keep\n",
    "print(X_train_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Flags\n",
    "X_train_flags = X_train[X_train_flags]\n",
    "X_val_flags = X_val[X_val_flags]\n",
    "X_test_flags = X_test[X_test_flags]\n",
    "\n",
    "# NN\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_col_order])\n",
    "X_val_cat = encoder.transform(X_val[cat_col_order])\n",
    "X_test_cat = encoder.transform(X_test[cat_col_order])\n",
    "\n",
    "cat_feature_names = encoder.get_feature_names_out(cat_col_order)\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "X_val_cat_df = pd.DataFrame(X_val_cat, columns=cat_feature_names, index=X_val.index)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat, columns=cat_feature_names, index=X_test.index)\n",
    "\n",
    "X_train_nn_full = pd.concat([X_train_cat_df, X_train[num_col_order], X_train_flags], axis=1)\n",
    "X_val_nn_full = pd.concat([X_val_cat_df, X_val[num_col_order], X_val_flags], axis=1)\n",
    "X_test_nn_full = pd.concat([X_test_cat_df, X_test[num_col_order], X_test_flags], axis=1)\n",
    "\n",
    "# xgb\n",
    "X_train_xgb = X_train\n",
    "X_val_xgb = X_val\n",
    "X_test_xgb = X_test\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train_xgb[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val_xgb[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test_xgb[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast\n",
    "# NN\n",
    "X_train_nn_final = X_train_nn_full.astype('float32').values\n",
    "X_val_nn_final = X_val_nn_full.astype('float32').values\n",
    "X_test_nn_final = X_test_nn_full.astype('float32').values\n",
    "\n",
    "# XGB\n",
    "X_train_xgb = X_train_xgb.astype(np.float32)\n",
    "X_val_xgb = X_val_xgb.astype(np.float32)\n",
    "X_test_xgb = X_test_xgb.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([92725, 20])\n",
      "Class weights: {np.int64(0): np.float64(0.5353822880700255), np.int64(1): np.float64(7.565682114882507)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_nn_final)\n",
    "X_val_tensor = torch.tensor(X_val_nn_final)\n",
    "X_test_tensor = torch.tensor(X_test_nn_final)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32) \n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Input shape:\", X_train_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 92725, Val: 23923, Test: 30000\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (bn_all): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 48873\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Union\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "    \n",
    "    TotalPastDueLog = np.log1p(TotalPastDue)\n",
    "    \n",
    "    RevolvingUtilizationCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationFilled = RevolvingUtilizationCapped.fillna(0)\n",
    "    RevolvingUtilizationCappedLog = np.log1p(RevolvingUtilizationFilled)\n",
    "    RevolvingUtilizationCappedLogSafe = RevolvingUtilizationCappedLog.replace(0, np.nan)\n",
    "        \n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].fillna(0).clip(upper=10000.0)\n",
    "        \n",
    "    DebtRatioCappedLog = np.log1p(DebtRatioCapped)\n",
    "    \n",
    "    DebtRatioSafe =  DebtRatioCappedLog.replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeLog = np.log1p(df_e[\"MonthlyIncome\"].fillna(0))\n",
    "\n",
    "    MonthlyIncomeSafe = MonthlyIncomeLog.replace(0, np.nan)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    NumberRealEstateLoansOrLinesfilled = df_e[\"NumberRealEstateLoansOrLines\"].fillna(0)\n",
    "\n",
    "    DebtToIncome = DebtRatioSafe * MonthlyIncomeSafe\n",
    "    \n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "    \n",
    "    UtilizationPerAge = RevolvingUtilizationCappedLogSafe / AgeSafe\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDueLog > 0).astype(int)\n",
    "\n",
    "    df_e[\"RevolvingUtilization\"] = RevolvingUtilizationCappedLogSafe\n",
    "    df_e[\"TotalPastDue\"] = TotalPastDueLog\n",
    "\n",
    "    df_e[\"DelinquencyScore\"] = DelinquencyScore\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = UtilizationPerAge\n",
    "    df_e[\"UtilizationPerCreditLine\"] =  RevolvingUtilizationCappedLogSafe / CreditLinesSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDueLog / CreditLinesSafe\n",
    "\n",
    "    df_e[\"RealEstateLeverage\"] = NumberRealEstateLoansOrLinesfilled * RevolvingUtilizationCappedLogSafe\n",
    "    \n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    df_e[\"HighAgeRiskFlag\"] = (AgeRisk <= 0.4).astype(int)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    UtilizationBucket = pd.cut(RevolvingUtilizationFilled, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    LatePaymentBucket = pd.cut(TotalPastDueLog, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        UtilizationBucket.astype(str) + \"_\" + LatePaymentBucket.astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"RevolvingUtilization\",\n",
    "        \"TotalPastDue\",\n",
    "        \"DelinquencyScore\",\n",
    "        \"RealEstateLeverage\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"UtilizationBucketLateBucket\",\n",
    "        \"UtilizationPerCreditLine\",\n",
    "        \"HighAgeRiskFlag\",\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim): \n",
    "        super().__init__()\n",
    "        self.bn_all = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_all): \n",
    "    \n",
    "        x = self.bn_all(x_all) \n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "model_b = xgb.XGBClassifier()\n",
    "model_b.load_model(\"cr_b.json\")\n",
    "xgb_col_order = joblib.load(\"xgb_col_order.pkl\")\n",
    "nn_col_order = joblib.load(\"nn_col_order.pkl\")\n",
    "num_imputer = joblib.load(\"num_imputer.pkl\")\n",
    "cat_imputer = joblib.load(\"cat_imputer.pkl\")\n",
    "robust_scaler = joblib.load(\"robust_scaler.pkl\")\n",
    "std_scaler = joblib.load(\"std_scaler.pkl\")\n",
    "cat_maps = joblib.load(\"cat_maps.pkl\")\n",
    "cat_col_order = joblib.load(\"cat_col_order.pkl\")\n",
    "num_col_order = joblib.load(\"num_col_order.pkl\")\n",
    "skewed_col_order = joblib.load(\"skewed_col_order.pkl\")\n",
    "threshold_a = joblib.load(\"threshold_a.pkl\")\n",
    "threshold_b = joblib.load(\"threshold_b.pkl\")\n",
    "rare_maps = joblib.load(\"rare_maps.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NN(input_dim=len(nn_col_order))\n",
    "weights_path = \"cr_weights.pth\"\n",
    "loaded_weights = torch.load(weights_path, map_location=device) \n",
    "model.load_state_dict(loaded_weights)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "app = FastAPI(title=\"Credit Risk Prediction API\")\n",
    "\n",
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    data: Dict[str, Union[str, float, int, None]]\n",
    "\n",
    "def preprocess(df: pd.DataFrame, for_xgb: bool = False):\n",
    "    df_copy = engineer_features(df)\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_col_order or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "\n",
    "    if for_xgb:\n",
    "        for col in cat_col_order:\n",
    "            df_copy[col] = (\n",
    "                df_copy[col].astype(str)\n",
    "                .map(cat_maps.get(col, {}))\n",
    "                .fillna(0)\n",
    "                .astype(int)\n",
    "            )\n",
    "        df_final = df_copy.reindex(columns=xgb_col_order, fill_value=0.0).astype(np.float32)\n",
    "        return df_final\n",
    "    else: \n",
    "        df_copy = df_copy.reindex(columns=nn_col_order, fill_value=0.0)\n",
    "        x_tensor = torch.tensor(df_copy.astype(\"float32\").values, dtype=torch.float32).to(device)\n",
    "        return x_tensor\n",
    "\n",
    "def predict_nn(df: pd.DataFrame, threshold=threshold_a):\n",
    "    x_all = preprocess(df, for_xgb=False)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_all)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_nn\")\n",
    "def predict_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_nn(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}\n",
    "\n",
    "def predict_xgb(df: pd.DataFrame, threshold=threshold_b):\n",
    "    df = preprocess(df, for_xgb=True)\n",
    "    probs = model_b.predict_proba(df)[:, 1]\n",
    "    preds = (probs > threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "@app.post(\"/predict_xgb\")\n",
    "def predict_xgb_endpoint(input_data: InputData):\n",
    "    df = pd.DataFrame([input_data.data]).replace(\"\", np.nan)\n",
    "    probs, preds = predict_xgb(df)\n",
    "    return {\"probabilities\": probs.tolist(), \"predictions\": preds.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run 1/2 ===\n",
      "Epoch 1/75 | Train loss: 0.029275 | Train AUC: 0.8011 | Val loss: 0.024965 | Val AUC: 0.8480\n",
      "Epoch 2/75 | Train loss: 0.025314 | Train AUC: 0.8402 | Val loss: 0.025175 | Val AUC: 0.8525\n",
      "Epoch 3/75 | Train loss: 0.024891 | Train AUC: 0.8463 | Val loss: 0.024861 | Val AUC: 0.8529\n",
      "Epoch 4/75 | Train loss: 0.024847 | Train AUC: 0.8470 | Val loss: 0.024950 | Val AUC: 0.8502\n",
      "Epoch 5/75 | Train loss: 0.024663 | Train AUC: 0.8498 | Val loss: 0.025000 | Val AUC: 0.8554\n",
      "Epoch 6/75 | Train loss: 0.024634 | Train AUC: 0.8506 | Val loss: 0.024820 | Val AUC: 0.8529\n",
      "Epoch 7/75 | Train loss: 0.024661 | Train AUC: 0.8502 | Val loss: 0.024778 | Val AUC: 0.8518\n",
      "Epoch 8/75 | Train loss: 0.024507 | Train AUC: 0.8524 | Val loss: 0.024665 | Val AUC: 0.8531\n",
      "Epoch 9/75 | Train loss: 0.024590 | Train AUC: 0.8510 | Val loss: 0.025084 | Val AUC: 0.8528\n",
      "Epoch 10/75 | Train loss: 0.024549 | Train AUC: 0.8520 | Val loss: 0.024763 | Val AUC: 0.8538\n",
      "Epoch 11/75 | Train loss: 0.024512 | Train AUC: 0.8528 | Val loss: 0.025057 | Val AUC: 0.8544\n",
      "Epoch 12/75 | Train loss: 0.024399 | Train AUC: 0.8545 | Val loss: 0.024776 | Val AUC: 0.8551\n",
      "Epoch 13/75 | Train loss: 0.024333 | Train AUC: 0.8557 | Val loss: 0.024548 | Val AUC: 0.8541\n",
      "Epoch 14/75 | Train loss: 0.024366 | Train AUC: 0.8555 | Val loss: 0.024423 | Val AUC: 0.8553\n",
      "Epoch 15/75 | Train loss: 0.024341 | Train AUC: 0.8554 | Val loss: 0.024540 | Val AUC: 0.8555\n",
      "Epoch 16/75 | Train loss: 0.024329 | Train AUC: 0.8556 | Val loss: 0.024593 | Val AUC: 0.8545\n",
      "Epoch 17/75 | Train loss: 0.024352 | Train AUC: 0.8554 | Val loss: 0.024545 | Val AUC: 0.8542\n",
      "Epoch 18/75 | Train loss: 0.024246 | Train AUC: 0.8570 | Val loss: 0.024455 | Val AUC: 0.8558\n",
      "Epoch 19/75 | Train loss: 0.024273 | Train AUC: 0.8569 | Val loss: 0.024503 | Val AUC: 0.8560\n",
      "Epoch 20/75 | Train loss: 0.024234 | Train AUC: 0.8567 | Val loss: 0.024495 | Val AUC: 0.8553\n",
      "Epoch 21/75 | Train loss: 0.024271 | Train AUC: 0.8567 | Val loss: 0.024480 | Val AUC: 0.8547\n",
      "Epoch 22/75 | Train loss: 0.024271 | Train AUC: 0.8567 | Val loss: 0.024421 | Val AUC: 0.8559\n",
      "Epoch 23/75 | Train loss: 0.024236 | Train AUC: 0.8576 | Val loss: 0.024444 | Val AUC: 0.8559\n",
      "Epoch 24/75 | Train loss: 0.024184 | Train AUC: 0.8579 | Val loss: 0.024472 | Val AUC: 0.8557\n",
      "Epoch 25/75 | Train loss: 0.024212 | Train AUC: 0.8573 | Val loss: 0.024456 | Val AUC: 0.8554\n",
      "Epoch 26/75 | Train loss: 0.024225 | Train AUC: 0.8575 | Val loss: 0.024407 | Val AUC: 0.8561\n",
      "Epoch 27/75 | Train loss: 0.024187 | Train AUC: 0.8582 | Val loss: 0.024383 | Val AUC: 0.8566\n",
      "Epoch 28/75 | Train loss: 0.024210 | Train AUC: 0.8578 | Val loss: 0.024394 | Val AUC: 0.8567\n",
      "Epoch 29/75 | Train loss: 0.024136 | Train AUC: 0.8586 | Val loss: 0.024423 | Val AUC: 0.8562\n",
      "Epoch 30/75 | Train loss: 0.024184 | Train AUC: 0.8583 | Val loss: 0.024463 | Val AUC: 0.8554\n",
      "Epoch 31/75 | Train loss: 0.024115 | Train AUC: 0.8593 | Val loss: 0.024399 | Val AUC: 0.8561\n",
      "Epoch 32/75 | Train loss: 0.024221 | Train AUC: 0.8576 | Val loss: 0.024516 | Val AUC: 0.8554\n",
      "Epoch 33/75 | Train loss: 0.024136 | Train AUC: 0.8586 | Val loss: 0.024456 | Val AUC: 0.8555\n",
      "Epoch 34/75 | Train loss: 0.024130 | Train AUC: 0.8588 | Val loss: 0.024400 | Val AUC: 0.8559\n",
      "Epoch 35/75 | Train loss: 0.024161 | Train AUC: 0.8583 | Val loss: 0.024411 | Val AUC: 0.8563\n",
      "Epoch 36/75 | Train loss: 0.024135 | Train AUC: 0.8591 | Val loss: 0.024392 | Val AUC: 0.8556\n",
      "Epoch 37/75 | Train loss: 0.024188 | Train AUC: 0.8579 | Val loss: 0.024436 | Val AUC: 0.8564\n",
      "Epoch 38/75 | Train loss: 0.024127 | Train AUC: 0.8589 | Val loss: 0.024517 | Val AUC: 0.8548\n",
      "Epoch 39/75 | Train loss: 0.024103 | Train AUC: 0.8595 | Val loss: 0.024420 | Val AUC: 0.8561\n",
      "Epoch 40/75 | Train loss: 0.024120 | Train AUC: 0.8591 | Val loss: 0.024424 | Val AUC: 0.8561\n",
      "Early stopping at epoch 41\n",
      "Run 1 best Val AUC: 0.8567\n",
      "=== Run 2/2 ===\n",
      "Epoch 1/75 | Train loss: 0.024370 | Train AUC: 0.8550 | Val loss: 0.025046 | Val AUC: 0.8552\n",
      "Epoch 2/75 | Train loss: 0.024415 | Train AUC: 0.8544 | Val loss: 0.024508 | Val AUC: 0.8553\n",
      "Epoch 3/75 | Train loss: 0.024356 | Train AUC: 0.8559 | Val loss: 0.024509 | Val AUC: 0.8538\n",
      "Epoch 4/75 | Train loss: 0.024400 | Train AUC: 0.8547 | Val loss: 0.024499 | Val AUC: 0.8541\n",
      "Epoch 5/75 | Train loss: 0.024398 | Train AUC: 0.8543 | Val loss: 0.024796 | Val AUC: 0.8539\n",
      "Epoch 6/75 | Train loss: 0.024358 | Train AUC: 0.8558 | Val loss: 0.024636 | Val AUC: 0.8539\n",
      "Epoch 7/75 | Train loss: 0.024295 | Train AUC: 0.8560 | Val loss: 0.024549 | Val AUC: 0.8531\n",
      "Epoch 8/75 | Train loss: 0.024321 | Train AUC: 0.8558 | Val loss: 0.024851 | Val AUC: 0.8556\n",
      "Epoch 9/75 | Train loss: 0.024312 | Train AUC: 0.8560 | Val loss: 0.024809 | Val AUC: 0.8548\n",
      "Epoch 10/75 | Train loss: 0.024275 | Train AUC: 0.8567 | Val loss: 0.024748 | Val AUC: 0.8524\n",
      "Epoch 11/75 | Train loss: 0.024358 | Train AUC: 0.8551 | Val loss: 0.024606 | Val AUC: 0.8550\n",
      "Epoch 12/75 | Train loss: 0.024311 | Train AUC: 0.8559 | Val loss: 0.024769 | Val AUC: 0.8545\n",
      "Epoch 13/75 | Train loss: 0.024306 | Train AUC: 0.8564 | Val loss: 0.024853 | Val AUC: 0.8550\n",
      "Epoch 14/75 | Train loss: 0.024328 | Train AUC: 0.8558 | Val loss: 0.024616 | Val AUC: 0.8550\n",
      "Epoch 15/75 | Train loss: 0.024197 | Train AUC: 0.8582 | Val loss: 0.024594 | Val AUC: 0.8553\n",
      "Epoch 16/75 | Train loss: 0.024148 | Train AUC: 0.8586 | Val loss: 0.024635 | Val AUC: 0.8539\n",
      "Epoch 17/75 | Train loss: 0.024215 | Train AUC: 0.8575 | Val loss: 0.024469 | Val AUC: 0.8556\n",
      "Epoch 18/75 | Train loss: 0.024211 | Train AUC: 0.8575 | Val loss: 0.024391 | Val AUC: 0.8558\n",
      "Epoch 19/75 | Train loss: 0.024149 | Train AUC: 0.8584 | Val loss: 0.024580 | Val AUC: 0.8560\n",
      "Epoch 20/75 | Train loss: 0.024092 | Train AUC: 0.8598 | Val loss: 0.024501 | Val AUC: 0.8556\n",
      "Epoch 21/75 | Train loss: 0.024129 | Train AUC: 0.8592 | Val loss: 0.024414 | Val AUC: 0.8563\n",
      "Epoch 22/75 | Train loss: 0.024203 | Train AUC: 0.8578 | Val loss: 0.024444 | Val AUC: 0.8551\n",
      "Epoch 23/75 | Train loss: 0.024043 | Train AUC: 0.8609 | Val loss: 0.024455 | Val AUC: 0.8551\n",
      "Epoch 24/75 | Train loss: 0.024223 | Train AUC: 0.8574 | Val loss: 0.024349 | Val AUC: 0.8559\n",
      "Epoch 25/75 | Train loss: 0.024108 | Train AUC: 0.8593 | Val loss: 0.024336 | Val AUC: 0.8559\n",
      "Epoch 26/75 | Train loss: 0.024098 | Train AUC: 0.8595 | Val loss: 0.024573 | Val AUC: 0.8543\n",
      "Epoch 27/75 | Train loss: 0.024173 | Train AUC: 0.8582 | Val loss: 0.024454 | Val AUC: 0.8546\n",
      "Epoch 28/75 | Train loss: 0.024000 | Train AUC: 0.8612 | Val loss: 0.024354 | Val AUC: 0.8563\n",
      "Epoch 29/75 | Train loss: 0.024059 | Train AUC: 0.8599 | Val loss: 0.024295 | Val AUC: 0.8564\n",
      "Epoch 30/75 | Train loss: 0.024105 | Train AUC: 0.8592 | Val loss: 0.024373 | Val AUC: 0.8561\n",
      "Epoch 31/75 | Train loss: 0.024026 | Train AUC: 0.8608 | Val loss: 0.024338 | Val AUC: 0.8562\n",
      "Epoch 32/75 | Train loss: 0.024051 | Train AUC: 0.8603 | Val loss: 0.024347 | Val AUC: 0.8556\n",
      "Epoch 33/75 | Train loss: 0.024059 | Train AUC: 0.8602 | Val loss: 0.024435 | Val AUC: 0.8541\n",
      "Epoch 34/75 | Train loss: 0.024116 | Train AUC: 0.8595 | Val loss: 0.024412 | Val AUC: 0.8553\n",
      "Epoch 35/75 | Train loss: 0.024148 | Train AUC: 0.8589 | Val loss: 0.024293 | Val AUC: 0.8562\n",
      "Epoch 36/75 | Train loss: 0.023994 | Train AUC: 0.8612 | Val loss: 0.024314 | Val AUC: 0.8562\n",
      "Epoch 37/75 | Train loss: 0.023997 | Train AUC: 0.8613 | Val loss: 0.024313 | Val AUC: 0.8554\n",
      "Epoch 38/75 | Train loss: 0.024003 | Train AUC: 0.8612 | Val loss: 0.024286 | Val AUC: 0.8567\n",
      "Epoch 39/75 | Train loss: 0.024054 | Train AUC: 0.8605 | Val loss: 0.024327 | Val AUC: 0.8562\n",
      "Epoch 40/75 | Train loss: 0.024034 | Train AUC: 0.8608 | Val loss: 0.024274 | Val AUC: 0.8563\n",
      "Epoch 41/75 | Train loss: 0.024022 | Train AUC: 0.8609 | Val loss: 0.024316 | Val AUC: 0.8558\n",
      "Epoch 42/75 | Train loss: 0.024059 | Train AUC: 0.8600 | Val loss: 0.024377 | Val AUC: 0.8552\n",
      "Epoch 43/75 | Train loss: 0.024053 | Train AUC: 0.8600 | Val loss: 0.024364 | Val AUC: 0.8552\n",
      "Epoch 44/75 | Train loss: 0.024004 | Train AUC: 0.8612 | Val loss: 0.024290 | Val AUC: 0.8564\n",
      "Epoch 45/75 | Train loss: 0.023986 | Train AUC: 0.8613 | Val loss: 0.024321 | Val AUC: 0.8561\n",
      "Epoch 46/75 | Train loss: 0.023953 | Train AUC: 0.8616 | Val loss: 0.024309 | Val AUC: 0.8560\n",
      "Epoch 47/75 | Train loss: 0.023987 | Train AUC: 0.8613 | Val loss: 0.024317 | Val AUC: 0.8561\n",
      "Epoch 48/75 | Train loss: 0.023962 | Train AUC: 0.8616 | Val loss: 0.024350 | Val AUC: 0.8555\n",
      "Epoch 49/75 | Train loss: 0.023966 | Train AUC: 0.8616 | Val loss: 0.024364 | Val AUC: 0.8554\n",
      "Epoch 50/75 | Train loss: 0.023978 | Train AUC: 0.8617 | Val loss: 0.024308 | Val AUC: 0.8556\n",
      "Early stopping at epoch 51\n",
      "Run 2 best Val AUC: 0.8567\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8567)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "for run in range(num_runs):\n",
    "    print(f\"=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_all, yb in train_loader:\n",
    "            x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_all)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_all.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_all, yb in val_loader:\n",
    "                x_all, yb = x_all.to(device), yb.to(device).float()\n",
    "                logits = model(x_all)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_all.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "        \n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.3403570353984833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.85      0.91     27995\n",
      "   Defaulted       0.26      0.71      0.38      2005\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.85      0.88     30000\n",
      "\n",
      "Accuracy: 84.54%\n",
      "ROC AUC: 0.869\n",
      "TP=1427, FP=4060, TN=23935, FN=578\n",
      "Accuracy for class 'Repaid': 85.50%\n",
      "Accuracy for class 'Defaulted': 71.17%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in val_loader:  \n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "best_thresh_a = threshold_by_target_recall(y_val, y_val_probs, thresholds, 0.69)\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_all, _ in test_loader:\n",
    "        x_all = x_all.to(device)\n",
    "        outputs = model(x_all)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running model 1/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.012, 'gamma': 0.0, 'colsample_bytree': 0.75, 'booster': 'dart'}\n",
      "[INFO] Running model 2/10 with params: {'subsample': 0.9, 'reg_lambda': 6, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.75, 'booster': 'gbtree'}\n",
      "[INFO] Running model 3/10 with params: {'subsample': 0.9, 'reg_lambda': 8, 'reg_alpha': 3, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 4/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.008, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 5/10 with params: {'subsample': 0.75, 'reg_lambda': 6, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'dart'}\n",
      "[INFO] Running model 6/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 5, 'min_child_weight': 4, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.9, 'booster': 'dart'}\n",
      "[INFO] Running model 7/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 3, 'min_child_weight': 8, 'max_depth': 5, 'learning_rate': 0.012, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 8/10 with params: {'subsample': 0.85, 'reg_lambda': 4, 'reg_alpha': 1, 'min_child_weight': 6, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 1.0, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "[INFO] Running model 9/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0.0, 'colsample_bytree': 0.75, 'booster': 'gbtree'}\n",
      "[INFO] Running model 10/10 with params: {'subsample': 0.85, 'reg_lambda': 8, 'reg_alpha': 5, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.008, 'gamma': 0.0, 'colsample_bytree': 0.9, 'booster': 'gbtree'}\n",
      "Best AUC: 0.8568399714757331\n",
      "Best params: {'subsample': 0.75, 'reg_lambda': 6, 'reg_alpha': 1, 'min_child_weight': 8, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 0.9, 'booster': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"booster\": [\"gbtree\", \"dart\"],\n",
    "    \"learning_rate\": [0.008, 0.01, 0.012],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"min_child_weight\": [4, 6, 8],\n",
    "    \"gamma\": [0.0, 0.5, 1.0],\n",
    "    \"subsample\": [0.75, 0.85, 0.9],\n",
    "    \"colsample_bytree\": [0.75, 0.85, 0.9],\n",
    "    \"reg_alpha\": [1, 3, 5],\n",
    "    \"reg_lambda\": [4, 6, 8],\n",
    "}\n",
    "\n",
    "n_iter = 10  \n",
    "sampler = ParameterSampler(param_dist, n_iter=n_iter, random_state=42)\n",
    "\n",
    "best_auc, best_params = 0.0, None\n",
    "\n",
    "for i, params in enumerate(sampler, start=1):\n",
    "    print(f\"[INFO] Running model {i}/{len(sampler)} with params: {params}\")\n",
    "\n",
    "    model_b = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),\n",
    "        n_estimators=800,\n",
    "        max_bin=1024,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        early_stopping_rounds=100,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    model_b.fit(\n",
    "        X_train_xgb, y_train,\n",
    "        eval_set=[(X_val_xgb, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if model_b.best_score > best_auc:\n",
    "        best_auc, best_params = model_b.best_score, params\n",
    "\n",
    "print(\"Best AUC:\", best_auc)\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5737686157226562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.86      0.91     27995\n",
      "   Defaulted       0.26      0.71      0.38      2005\n",
      "\n",
      "    accuracy                           0.85     30000\n",
      "   macro avg       0.62      0.78      0.65     30000\n",
      "weighted avg       0.93      0.85      0.88     30000\n",
      "\n",
      "Accuracy: 84.75%\n",
      "ROC AUC: 0.869\n",
      "TP=1424, FP=3993, TN=24002, FN=581\n",
      "Accuracy for class 'Repaid': 85.74%\n",
      "Accuracy for class 'Defaulted': 71.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "dtest = xgb.DMatrix(X_test_xgb)\n",
    "y_probs = model_b.get_booster().predict(dtest) \n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "best_thresh_b = threshold_by_target_recall(y_test, y_probs, thresholds, 0.71)\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                Feature  Importance\n",
      "0           UtilizationBucketLateBucket    0.624497\n",
      "1                      DelinquencyScore    0.479263\n",
      "2                     UtilizationPerAge    0.440597\n",
      "3                   IncomePerCreditLine    0.152624\n",
      "4                   DebtToIncomeAgeRisk    0.143426\n",
      "5                  RevolvingUtilization    0.117847\n",
      "6                    RealEstateLeverage    0.066517\n",
      "7                          TotalPastDue    0.059496\n",
      "8              UtilizationPerCreditLine    0.059246\n",
      "9             LatePaymentsPerCreditLine    0.032767\n",
      "10                      HighAgeRiskFlag    0.020053\n",
      "11         WasRealEstateLeverageImputed    0.000652\n",
      "12   WasUtilizationPerCreditLineImputed    0.000104\n",
      "13  WasLatePaymentsPerCreditLineImputed    0.000000\n",
      "14       WasRevolvingUtilizationImputed    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Shap xgb\n",
    "explainer = shap.TreeExplainer(model_b)\n",
    "shap_values = explainer.shap_values(X_train_xgb)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_xgb.columns,\n",
    "    \"Importance\": mean_abs_shap\n",
    "}).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05121e0dff54e1babbc7de984f036ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Importance:\n",
      "                                         feature  mean_abs_shap\n",
      "0                              UtilizationPerAge       0.020243\n",
      "1                               DelinquencyScore       0.016573\n",
      "2                           RevolvingUtilization       0.012795\n",
      "3                                   TotalPastDue       0.009775\n",
      "4                            DebtToIncomeAgeRisk       0.007841\n",
      "5                            IncomePerCreditLine       0.006562\n",
      "6    UtilizationBucketLateBucket_Very Low_NoLate       0.004916\n",
      "7                             RealEstateLeverage       0.004763\n",
      "8         UtilizationBucketLateBucket_Low_NoLate       0.003920\n",
      "9              UtilizationBucketLateBucket_Other       0.003404\n",
      "10                               HighAgeRiskFlag       0.003304\n",
      "11   UtilizationBucketLateBucket_Moderate_NoLate       0.001966\n",
      "12                      UtilizationPerCreditLine       0.001429\n",
      "13                     LatePaymentsPerCreditLine       0.001157\n",
      "14  UtilizationBucketLateBucket_Very High_NoLate       0.000989\n",
      "15       UtilizationBucketLateBucket_High_NoLate       0.000597\n",
      "16                WasRevolvingUtilizationImputed       0.000184\n",
      "17           WasLatePaymentsPerCreditLineImputed       0.000153\n",
      "18            WasUtilizationPerCreditLineImputed       0.000129\n",
      "19                  WasRealEstateLeverageImputed       0.000084\n"
     ]
    }
   ],
   "source": [
    "# Shap NN\n",
    "model_gpu = copy.deepcopy(model).to(device)\n",
    "model_gpu.eval()\n",
    "\n",
    "def shap_ohe_gpu(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        logits = model_gpu(X_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "feature_names = list(X_train_nn_full.columns)\n",
    "background = shap.sample(X_train_tensor.cpu().numpy(), 100)\n",
    "explainer = shap.KernelExplainer(shap_ohe_gpu, background)\n",
    "shap_values = explainer.shap_values(X_val_tensor[:500].cpu().numpy())\n",
    "shap_values_array = np.array(shap_values)\n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(by=\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"SHAP Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(X_train_xgb.columns.tolist(), \"xgb_col_order.pkl\")\n",
    "joblib.dump(X_train_nn_full.columns.tolist(), \"nn_col_order.pkl\")\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfb507-cce9-4894-b873-e5e1f5d657ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
