{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcb91c9-3314-445a-94a9-1099b7814f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "import joblib\n",
    "import shap\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score,  make_scorer, fbeta_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Constants\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "num_epochs = 75\n",
    "num_runs = 5\n",
    "max_patience = 13\n",
    "\n",
    "# pd \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dfa21f-9d7d-4dd1-8931-c6e79c04f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(base_path=\"./\"):\n",
    "    \n",
    "    files = {\"train\": \"cs-training.csv\"}\n",
    "    dfs = {}\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        print(f\"Loading {filename}...\")\n",
    "        dfs[key] = pd.read_csv(base_path + filename, index_col=0)\n",
    "        print(f\"Loaded {filename} with {len(dfs[key].columns)} columns\")\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "def dataset_summary(df, y=None, threshold=0.7):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if y is not None and y.name in df_copy.columns:\n",
    "        df_copy = df_copy.drop(columns=[y.name])\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df_copy[col] = df_copy[col].astype(\"category\").cat.codes\n",
    "    \n",
    "    print(f\"Dataset shape: {df_copy.shape}\")\n",
    "    print(f\"Total rows: {len(df_copy)}\")\n",
    "    print(f\"Total duplicate rows: {df_copy.duplicated().sum()}\")\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"dtype\": df_copy.dtypes,\n",
    "        \"non_null\": df_copy.notna().sum(),\n",
    "        \"missing\": df_copy.isna().sum(),\n",
    "        \"missing_%\": (df_copy.isna().mean() * 100).round(2),\n",
    "        \"unique\": df_copy.nunique()\n",
    "    })\n",
    "\n",
    "    numeric_cols = df_copy.select_dtypes(include=\"number\").columns\n",
    "    feature_cols = df_copy.columns.tolist()\n",
    "    desc = df_copy[numeric_cols].describe().T\n",
    "    desc[\"skew\"] = df_copy[numeric_cols].skew()\n",
    "    summary = summary.join(desc[[\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"skew\"]])\n",
    "\n",
    "    if y is not None:\n",
    "        df_copy['target'] = y\n",
    "        summary[\"corr_with_target\"] =  df_copy.corr()['target'].drop('target')\n",
    "\n",
    "    corr_matrix = df_copy.corr(numeric_only=True)\n",
    "    corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        .stack()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    \n",
    "    high_corr = corr_pairs[abs(corr_pairs) > threshold]\n",
    "    \n",
    "    corr_map = {}\n",
    "    for (f1, f2), val in high_corr.items():\n",
    "        corr_map.setdefault(f1, []).append(f\"{f2} ({val:.2f})\")\n",
    "        corr_map.setdefault(f2, []).append(f\"{f1} ({val:.2f})\")\n",
    "    \n",
    "    summary[\"high_corr_flag\"] = summary.index.map(lambda col: col in corr_map)\n",
    "    summary[\"high_corr_with\"] = summary.index.map(\n",
    "        lambda col: \", \".join(corr_map[col]) if col in corr_map else \"\"\n",
    "    )\n",
    "\n",
    "    return summary.sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "def outlier_handling(df, target_col, n_high=100, n_low=10):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    numeric_cols = df_copy.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(0)\n",
    "    \n",
    "    X = df_copy.drop(columns=[target_col])\n",
    "    y = df_copy[target_col]\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        min_samples_leaf=20\n",
    "    )\n",
    "    hgb.fit(X, y)\n",
    "\n",
    "    y_pred_proba = hgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    df_copy[\"__pred_proba__\"] = y_pred_proba\n",
    "    df_sorted = df_copy.sort_values(\"__pred_proba__\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    total_rows = len(df_sorted)\n",
    "    start_idx = n_low\n",
    "    end_idx = max(0, total_rows - n_high)\n",
    "    df_filtered = df_sorted.iloc[start_idx:end_idx].drop(columns=\"__pred_proba__\").reset_index(drop=True)\n",
    "\n",
    "    dropped = total_rows - len(df_filtered)\n",
    "    \n",
    "    print(f\"Dropped {dropped} outlier rows (lowest {n_low}, highest {n_high})\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def drop_target_and_ids(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    feature_cols_to_drop = [\"SeriousDlqin2yrs\"]\n",
    "    target = df_copy[\"SeriousDlqin2yrs\"]\n",
    "    df_raw_features = df_copy.drop(columns=feature_cols_to_drop)\n",
    "    \n",
    "    print(f\"Dropped cols: {feature_cols_to_drop}\")\n",
    "    \n",
    "    return df_raw_features, target, feature_cols_to_drop\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df_e = df.copy()\n",
    "\n",
    "    NumberOfTime3059DaysPastDueNotWorse = df_e[\"NumberOfTime30-59DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTimes90DaysLate = df_e[\"NumberOfTimes90DaysLate\"].fillna(0).clip(upper=10)\n",
    "    NumberOfTime6089DaysPastDueNotWorse = df_e[\"NumberOfTime60-89DaysPastDueNotWorse\"].fillna(0).clip(upper=10)\n",
    "\n",
    "    TotalPastDue = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse\n",
    "        + NumberOfTimes90DaysLate\n",
    "        + NumberOfTime6089DaysPastDueNotWorse\n",
    "    )\n",
    "\n",
    "    RevolvingUtilizationOfUnsecuredLinesCapped = df_e[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper=5.0)\n",
    "    RevolvingUtilizationOfUnsecuredLines = np.log1p(RevolvingUtilizationOfUnsecuredLinesCapped)\n",
    "    RevolvingUtilizationOfUnsecuredLines = RevolvingUtilizationOfUnsecuredLines.replace(0, np.nan)\n",
    "\n",
    "    AgeSafe = df_e[\"age\"].replace(0, np.nan)\n",
    "\n",
    "    MonthlyIncomeSafe = df_e[\"MonthlyIncome\"]\n",
    "\n",
    "    DebtRatioCapped = df_e[\"DebtRatio\"].clip(upper=10000.0)\n",
    "\n",
    "    CreditLinesSafe = df_e[\"NumberOfOpenCreditLinesAndLoans\"].replace(0, np.nan)\n",
    "\n",
    "    DebtToIncome = DebtRatioCapped * MonthlyIncomeSafe\n",
    "    IncomePerCreditLine = MonthlyIncomeSafe / CreditLinesSafe\n",
    "\n",
    "    AgeRisk = np.where(AgeSafe < 25, 1.0,\n",
    "                 np.where(AgeSafe < 35, 0.8,\n",
    "                 np.where(AgeSafe < 50, 0.6, 0.4)))\n",
    "\n",
    "    DelinquencyScore = (\n",
    "        NumberOfTime3059DaysPastDueNotWorse +\n",
    "        NumberOfTime6089DaysPastDueNotWorse * 2 +\n",
    "        NumberOfTimes90DaysLate * 3\n",
    "    )\n",
    "\n",
    "    HasAnyDelinquency = (TotalPastDue > 0).astype(int)\n",
    "\n",
    "    df_e[\"TotalPastDue_Squared\"] = TotalPastDue ** 2\n",
    "    df_e[\"NormalizedUtilization\"] = np.sqrt(RevolvingUtilizationOfUnsecuredLines)\n",
    "    df_e[\"HasAnyDelinquency\"] = HasAnyDelinquency\n",
    "    df_e[\"HasMajorDelinquency\"] = (\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0) |\n",
    "        (NumberOfTimes90DaysLate > 0)\n",
    "    ).astype(int)\n",
    "    df_e[\"SevereDelinquency\"] = (\n",
    "        (NumberOfTimes90DaysLate > 0) &\n",
    "        (NumberOfTime6089DaysPastDueNotWorse > 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    df_e[\"UtilizationPerAge\"] = RevolvingUtilizationOfUnsecuredLines / AgeSafe\n",
    "    df_e[\"LatePaymentsPerAge\"] = TotalPastDue / AgeSafe\n",
    "    df_e[\"LatePaymentsPerCreditLine\"] = TotalPastDue / CreditLinesSafe\n",
    "\n",
    "    df_e[\"90DaysLate_Squared\"] = NumberOfTimes90DaysLate ** 2\n",
    "    df_e[\"IncomePerCreditLine\"] = IncomePerCreditLine\n",
    "    df_e[\"IncomePerCreditLineHasDelinquencies\"] = IncomePerCreditLine * HasAnyDelinquency\n",
    "    df_e[\"DebtToIncome\"] = DebtToIncome\n",
    "    df_e[\"DebtToIncomeAgeRisk\"] = DebtToIncome * AgeRisk\n",
    "\n",
    "    Age_bins = [0, 25, 50, 120]\n",
    "    Age_labels = [\"Young\", \"Mid\", \"Senior\"]\n",
    "    df_e[\"AgeBucket\"] = pd.cut(AgeSafe, bins=Age_bins, labels=Age_labels)\n",
    "\n",
    "    DelinquencyScore_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    DelinquencyScore_labels = [\"None\", \"Few\", \"Moderate\", \"Frequent\", \"Chronic\"]\n",
    "    df_e[\"DelinquencyBucket\"] = pd.cut(DelinquencyScore, bins=DelinquencyScore_bins, labels=DelinquencyScore_labels)\n",
    "\n",
    "    Utilization_bins = [-0.01, 0.1, 0.3, 0.6, 0.9, 1.5, 10]\n",
    "    Utilization_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\", \"Extreme\"]\n",
    "    df_e[\"UtilizationBucket\"] = pd.cut(RevolvingUtilizationOfUnsecuredLines, bins=Utilization_bins, labels=Utilization_labels)\n",
    "\n",
    "    Late_bins = [-1, 0, 1, 3, 6, np.inf]\n",
    "    Late_labels = [\"NoLate\", \"FewLate\", \"ModerateLate\", \"FrequentLate\", \"ChronicLate\"]\n",
    "    df_e[\"LatePaymentBucket\"] = pd.cut(TotalPastDue, bins=Late_bins, labels=Late_labels)\n",
    "\n",
    "    df_e[\"UtilizationBucketLateBucket\"] = (\n",
    "        df_e[\"UtilizationBucket\"].astype(str) + \"_\" + df_e[\"LatePaymentBucket\"].astype(str)\n",
    "    )\n",
    "\n",
    "    engineered_cols = [\n",
    "        \"TotalPastDue_Squared\",\n",
    "        \"NormalizedUtilization\",\n",
    "        \"HasAnyDelinquency\",\n",
    "        \"HasMajorDelinquency\",\n",
    "        \"SevereDelinquency\",\n",
    "        \"UtilizationPerAge\",\n",
    "        \"LatePaymentsPerAge\",\n",
    "        \"LatePaymentsPerCreditLine\",\n",
    "        \"90DaysLate_Squared\",\n",
    "        \"IncomePerCreditLineHasDelinquencies\",\n",
    "        \"IncomePerCreditLine\",\n",
    "        \"DebtToIncome\",\n",
    "        \"DebtToIncomeAgeRisk\",\n",
    "        \"AgeBucket\",\n",
    "        \"DelinquencyBucket\",\n",
    "        \"UtilizationBucket\",\n",
    "        \"LatePaymentBucket\",\n",
    "        \"UtilizationBucketLateBucket\"\n",
    "    ]\n",
    "\n",
    "    engineered_df = df_e[engineered_cols]\n",
    "\n",
    "    print(f\"Engineered {len(engineered_cols)} features\")\n",
    "    print(f\"Engineered cols: {engineered_cols}\")\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "def drop_high_missing_cols(df, threshold=0.3):\n",
    "\n",
    "    missing_frac = df.isna().mean().sort_values(ascending=False)\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'MissingCount': df.isna().sum(),\n",
    "        'MissingPercent': (missing_frac * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(missing_summary.to_string())\n",
    "    \n",
    "    hm_cols_to_drop = missing_frac[missing_frac > threshold].index.tolist()\n",
    "    \n",
    "    if hm_cols_to_drop:\n",
    "        df_drop = df.drop(columns=hm_cols_to_drop)\n",
    "        print(f\"Dropped: {len(hm_cols_to_drop)} high missing cols\")\n",
    "        print(f\"Dropped cols: {hm_cols_to_drop}\")\n",
    "    else:\n",
    "        df_drop = df.copy()\n",
    "        print(\"No high missing cols dropped\")\n",
    "        \n",
    "    return df_drop, hm_cols_to_drop\n",
    "\n",
    "def drop_high_card_cols(df, threshold=50):\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    unique_counts = df[cat_cols].nunique().sort_values(ascending=False)\n",
    "    unique_summary = pd.DataFrame({\n",
    "        'UniqueCount': unique_counts,\n",
    "        'UniquePercent': (unique_counts / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "    if cat_cols:\n",
    "        print(unique_summary.to_string())\n",
    "\n",
    "    hc_cols_to_drop = unique_counts[unique_counts > threshold].index.tolist()\n",
    "\n",
    "    if hc_cols_to_drop:\n",
    "        df_high = df.drop(columns=hc_cols_to_drop, errors='ignore')\n",
    "        print(f\"Dropped: {len(hc_cols_to_drop)} high cardinality cols\")\n",
    "        print(f\"Dropped cols: {hc_cols_to_drop}\")\n",
    "    else:\n",
    "        df_high = df.copy()\n",
    "        print(\"No high cardinality cols dropped\")\n",
    "\n",
    "    return df_high, hc_cols_to_drop\n",
    "\n",
    "def collapse_rare_categories(df, threshold=0.005):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    rare_maps = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        freqs = df_copy[col].value_counts(normalize=True, dropna=True)\n",
    "        rare_cats = [c for c in freqs[freqs < threshold].index]\n",
    "        if rare_cats:\n",
    "            df_copy[col] = df_copy[col].astype('object').replace(rare_cats, 'Other')\n",
    "            rare_maps[col] = set(rare_cats)\n",
    "            print(f\"Column '{col}': collapsed {len(rare_cats)} rare categories: {rare_cats}\")\n",
    "        else:\n",
    "            print(f\"Column '{col}': no rare categories to collapse\")\n",
    "\n",
    "    return df_copy, rare_maps\n",
    "\n",
    "def select_features(df, target, n_to_keep=10, random_state=42, bias_mode=None):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    cat_cols = df_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    df_model = df_temp.copy()\n",
    "    for col in cat_cols:\n",
    "        df_model[col] = df_model[col].astype(\"category\").cat.codes\n",
    "\n",
    "    feature_cols = df_model.columns.tolist()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_model[feature_cols],\n",
    "        target,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=target,\n",
    "    )\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "\n",
    "    neg_count = (y_train == 0).sum()\n",
    "    pos_count = (y_train == 1).sum()\n",
    "    \n",
    "    minority_class = 1 if pos_count < neg_count else 0\n",
    "    majority_class = 0 if minority_class == 1 else 1\n",
    "\n",
    "    if bias_mode is False:\n",
    "        scale_pos_weight = neg_count / max(1, pos_count)\n",
    "        print(\"Biasing toward minority class\")\n",
    "    elif bias_mode is True:\n",
    "        scale_pos_weight = pos_count / max(1, neg_count)\n",
    "        print(\"Biasing toward majority class\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Using normal class weights\")\n",
    "        \n",
    "    tuned_params = {\n",
    "        'subsample': 0.9, \n",
    "        'reg_lambda': 0.5, \n",
    "        'reg_alpha': 0.1, \n",
    "        'min_child_weight': 7, \n",
    "        'max_depth': 5, \n",
    "        'learning_rate': 0.01, \n",
    "        'gamma': 0.2, \n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=800,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        **tuned_params\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    all_features = model.get_booster().feature_names\n",
    "    importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "    full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "    \n",
    "    importance_df = (\n",
    "        pd.DataFrame({\n",
    "            \"Feature\": list(full_importance.keys()),\n",
    "            \"Importance\": list(full_importance.values())\n",
    "        })\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    numeric_feats = [f for f in feature_cols if f not in cat_cols]\n",
    "    top_numeric = importance_df[importance_df[\"Feature\"].isin(numeric_feats)][\"Feature\"].head(n_to_keep).tolist()\n",
    "    kept_features = top_numeric + cat_cols\n",
    "    dropped_features = [f for f in numeric_feats if f not in top_numeric]\n",
    "\n",
    "    print(f\"Kept {len(kept_features)} select features (including all {len(cat_cols)} categorical)\")\n",
    "    print(f\"Dropped:{len(dropped_features)} numeric select features cols\")\n",
    "    if dropped_features:\n",
    "        print(f\"Dropped cols:{dropped_features}\")\n",
    "    print(importance_df)\n",
    "\n",
    "    return df_temp[kept_features].copy(), dropped_features\n",
    "\n",
    "def impute_and_scale(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    num_imputer = None\n",
    "    robust_scaler = None\n",
    "    std_scaler = None\n",
    "    cat_imputer=None\n",
    "    cat_maps = {}\n",
    "    skewed_cols = []\n",
    "\n",
    "    num_col_order = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_col_order = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if num_col_order:\n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_copy[num_col_order] = num_imputer.fit_transform(df_copy[num_col_order])\n",
    "        skewness = df_copy[num_col_order].skew().sort_values(ascending=False)\n",
    "        skewed_cols = skewness[abs(skewness) > 1.0].index.tolist()\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols:\n",
    "            robust_scaler = RobustScaler()\n",
    "            df_copy[skewed_cols] = robust_scaler.fit_transform(df_copy[skewed_cols])\n",
    "        if normal_cols:\n",
    "            std_scaler = StandardScaler()\n",
    "            df_copy[normal_cols] = std_scaler.fit_transform(df_copy[normal_cols])\n",
    "\n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object') \n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_copy[cat_col_order] = cat_imputer.fit_transform(df_copy[cat_col_order]) \n",
    "        for col in cat_col_order:\n",
    "            unique_cats = df_copy[col].astype(str).unique()\n",
    "            cat_maps[col] = {cat: idx for idx, cat in enumerate(unique_cats)}\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_cols, cat_col_order, cat_maps, imputed_flags\n",
    "\n",
    "def transform_val_test(\n",
    "    df, \n",
    "    cols_to_drop=None, \n",
    "    num_imputer=None,\n",
    "    cat_imputer=None,\n",
    "    robust_scaler=None, \n",
    "    std_scaler=None,\n",
    "    num_col_order=None, \n",
    "    skewed_cols=None,\n",
    "    cat_col_order=None,\n",
    "    rare_maps=None,\n",
    "    train_columns=None\n",
    "):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_copy = df_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    if num_col_order:     \n",
    "        df_copy[num_col_order] = df_copy[num_col_order].replace([np.inf, -np.inf], np.nan)\n",
    "        for col in num_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        df_copy[num_col_order] = num_imputer.transform(df_copy[num_col_order])\n",
    "        skewed_cols = skewed_cols or []\n",
    "        normal_cols = [c for c in num_col_order if c not in skewed_cols]\n",
    "        if skewed_cols and robust_scaler:\n",
    "            df_copy[skewed_cols] = robust_scaler.transform(df_copy[skewed_cols])\n",
    "        if normal_cols and std_scaler:\n",
    "            df_copy[normal_cols] = std_scaler.transform(df_copy[normal_cols])\n",
    "            \n",
    "    if cat_col_order:\n",
    "        df_copy[cat_col_order] = df_copy[cat_col_order].astype('object')\n",
    "        for col in cat_col_order:\n",
    "            df_copy[f'Was{col}Imputed'] = df_copy[col].isna().astype(int)\n",
    "        for col in cat_col_order:\n",
    "            if rare_maps and col in rare_maps:\n",
    "                rare_categories = list(rare_maps[col])\n",
    "                df_copy[col] = df_copy[col].replace(rare_categories, 'Other')\n",
    "        df_copy[cat_col_order] = cat_imputer.transform(df_copy[cat_col_order])\n",
    "   \n",
    "    if train_columns is not None:\n",
    "        df_copy = df_copy.reindex(columns=train_columns, fill_value=0)\n",
    "\n",
    "    imputed_flags = [col for col in df_copy.columns if col.startswith(\"Was\") and col.endswith(\"Imputed\")]\n",
    "\n",
    "    print(\"Imputed, flagged, and scaled features\")\n",
    "    \n",
    "    return df_copy, imputed_flags\n",
    "\n",
    "def check_and_drop_duplicates(df, target=None, drop_target_na=False, show_info=True):\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    target_cleaned = None\n",
    "    \n",
    "    total_duplicates = df_cleaned.duplicated().sum()\n",
    "    if total_duplicates > 0:\n",
    "        df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "        if show_info:\n",
    "            print(f\"Dropped {total_duplicates} duplicate rows. Remaining: {len(df_cleaned)}\")\n",
    "    \n",
    "    if target is not None:\n",
    "        target_cleaned = pd.Series(target).reindex(df_cleaned.index)\n",
    "        if drop_target_na:\n",
    "            mask = target_cleaned.notna()\n",
    "            dropped = len(target_cleaned) - mask.sum()\n",
    "            if dropped > 0 and show_info:\n",
    "                print(f\"Dropped {dropped} rows with missing target values\")\n",
    "            df_cleaned = df_cleaned.loc[mask].reset_index(drop=True)\n",
    "            target_cleaned = target_cleaned.loc[mask].reset_index(drop=True)\n",
    "        else:\n",
    "            target_cleaned = target_cleaned.reset_index(drop=True)\n",
    "        return df_cleaned, target_cleaned\n",
    "    else:\n",
    "        return df_cleaned\n",
    "\n",
    "def find_best_param(X_train, y_train):\n",
    "    \n",
    "    neg_count = sum(y_train == 0)\n",
    "    pos_count = sum(y_train == 1)\n",
    "    \n",
    "    base_scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    param_grid = {\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0, 0.2, 0.5, 1.0],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.05, 0.1, 0.3],\n",
    "        \"reg_lambda\": [0.5, 0.8, 1.0, 1.2],\n",
    "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"scale_pos_weight\": [base_scale_pos_weight * m for m in [1.0, 1.5, 2.0, 2.5, 3.0]]\n",
    "    }\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        n_estimators=800,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_clf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=30,  \n",
    "        scoring=f2_scorer,\n",
    "        cv=3,      \n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params:\", search.best_params_)\n",
    "\n",
    "    return search.best_params_\n",
    "\n",
    "def fast_fbeta_scores(y_true, y_probs, thresholds, beta=2):\n",
    "    \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_probs = np.asarray(y_probs)\n",
    "    thresholds = np.asarray(thresholds)\n",
    "\n",
    "    preds = y_probs[:, None] > thresholds[None, :] \n",
    "\n",
    "    TP = (preds & (y_true[:, None] == 1)).sum(axis=0)\n",
    "    FP = (preds & (y_true[:, None] == 0)).sum(axis=0)\n",
    "    FN = ((~preds) & (y_true[:, None] == 1)).sum(axis=0)\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "    f_beta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall + 1e-8)\n",
    "\n",
    "    return f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f30cd2e-7db6-495e-b168-c692582de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cs-training.csv...\n",
      "Loaded cs-training.csv with 11 columns\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "dfs = load_datasets()\n",
    "df_train = dfs[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e40abd-50a9-4e61-99d0-02376a16434f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150000, 10)\n",
      "Total rows: 150000\n",
      "Total duplicate rows: 646\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>120269</td>\n",
       "      <td>29731</td>\n",
       "      <td>19.82</td>\n",
       "      <td>13594</td>\n",
       "      <td>6670.221237</td>\n",
       "      <td>14384.674215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>8249.000000</td>\n",
       "      <td>3008750.0</td>\n",
       "      <td>114.040318</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <td>float64</td>\n",
       "      <td>146076</td>\n",
       "      <td>3924</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>1.115086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.588242</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>52.295207</td>\n",
       "      <td>14.771866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>-0.115386</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125728</td>\n",
       "      <td>6.048438</td>\n",
       "      <td>249.755371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>0.154181</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>50708.0</td>\n",
       "      <td>97.631574</td>\n",
       "      <td>-0.001802</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtRatio</th>\n",
       "      <td>float64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114194</td>\n",
       "      <td>353.005076</td>\n",
       "      <td>2037.818523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175074</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>329664.0</td>\n",
       "      <td>95.157793</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>0.421033</td>\n",
       "      <td>4.192781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.597108</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>8.452760</td>\n",
       "      <td>5.145951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.215314</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>0.265973</td>\n",
       "      <td>4.169304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.087345</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1.018240</td>\n",
       "      <td>1.129771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.482484</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <td>int64</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240387</td>\n",
       "      <td>4.155179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>23.331743</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>True</td>\n",
       "      <td>NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dtype  non_null  missing  missing_%  \\\n",
       "MonthlyIncome                         float64    120269    29731      19.82   \n",
       "NumberOfDependents                    float64    146076     3924       2.62   \n",
       "age                                     int64    150000        0       0.00   \n",
       "RevolvingUtilizationOfUnsecuredLines  float64    150000        0       0.00   \n",
       "DebtRatio                             float64    150000        0       0.00   \n",
       "NumberOfTime30-59DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "NumberOfOpenCreditLinesAndLoans         int64    150000        0       0.00   \n",
       "NumberOfTimes90DaysLate                 int64    150000        0       0.00   \n",
       "NumberRealEstateLoansOrLines            int64    150000        0       0.00   \n",
       "NumberOfTime60-89DaysPastDueNotWorse    int64    150000        0       0.00   \n",
       "\n",
       "                                      unique         mean           std  min  \\\n",
       "MonthlyIncome                          13594  6670.221237  14384.674215  0.0   \n",
       "NumberOfDependents                        13     0.757222      1.115086  0.0   \n",
       "age                                       86    52.295207     14.771866  0.0   \n",
       "RevolvingUtilizationOfUnsecuredLines  125728     6.048438    249.755371  0.0   \n",
       "DebtRatio                             114194   353.005076   2037.818523  0.0   \n",
       "NumberOfTime30-59DaysPastDueNotWorse      16     0.421033      4.192781  0.0   \n",
       "NumberOfOpenCreditLinesAndLoans           58     8.452760      5.145951  0.0   \n",
       "NumberOfTimes90DaysLate                   19     0.265973      4.169304  0.0   \n",
       "NumberRealEstateLoansOrLines              28     1.018240      1.129771  0.0   \n",
       "NumberOfTime60-89DaysPastDueNotWorse      13     0.240387      4.155179  0.0   \n",
       "\n",
       "                                              25%          50%          75%  \\\n",
       "MonthlyIncome                         3400.000000  5400.000000  8249.000000   \n",
       "NumberOfDependents                       0.000000     0.000000     1.000000   \n",
       "age                                     41.000000    52.000000    63.000000   \n",
       "RevolvingUtilizationOfUnsecuredLines     0.029867     0.154181     0.559046   \n",
       "DebtRatio                                0.175074     0.366508     0.868254   \n",
       "NumberOfTime30-59DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "NumberOfOpenCreditLinesAndLoans          5.000000     8.000000    11.000000   \n",
       "NumberOfTimes90DaysLate                  0.000000     0.000000     0.000000   \n",
       "NumberRealEstateLoansOrLines             0.000000     1.000000     2.000000   \n",
       "NumberOfTime60-89DaysPastDueNotWorse     0.000000     0.000000     0.000000   \n",
       "\n",
       "                                            max        skew  corr_with_target  \\\n",
       "MonthlyIncome                         3008750.0  114.040318         -0.019746   \n",
       "NumberOfDependents                         20.0    1.588242          0.046048   \n",
       "age                                       109.0    0.188995         -0.115386   \n",
       "RevolvingUtilizationOfUnsecuredLines    50708.0   97.631574         -0.001802   \n",
       "DebtRatio                              329664.0   95.157793         -0.007602   \n",
       "NumberOfTime30-59DaysPastDueNotWorse       98.0   22.597108          0.125587   \n",
       "NumberOfOpenCreditLinesAndLoans            58.0    1.215314         -0.029669   \n",
       "NumberOfTimes90DaysLate                    98.0   23.087345          0.117175   \n",
       "NumberRealEstateLoansOrLines               54.0    3.482484         -0.007038   \n",
       "NumberOfTime60-89DaysPastDueNotWorse       98.0   23.331743          0.102261   \n",
       "\n",
       "                                      high_corr_flag  \\\n",
       "MonthlyIncome                                  False   \n",
       "NumberOfDependents                             False   \n",
       "age                                            False   \n",
       "RevolvingUtilizationOfUnsecuredLines           False   \n",
       "DebtRatio                                      False   \n",
       "NumberOfTime30-59DaysPastDueNotWorse            True   \n",
       "NumberOfOpenCreditLinesAndLoans                False   \n",
       "NumberOfTimes90DaysLate                         True   \n",
       "NumberRealEstateLoansOrLines                   False   \n",
       "NumberOfTime60-89DaysPastDueNotWorse            True   \n",
       "\n",
       "                                                                                                                high_corr_with  \n",
       "MonthlyIncome                                                                                                                   \n",
       "NumberOfDependents                                                                                                              \n",
       "age                                                                                                                             \n",
       "RevolvingUtilizationOfUnsecuredLines                                                                                            \n",
       "DebtRatio                                                                                                                       \n",
       "NumberOfTime30-59DaysPastDueNotWorse               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTimes90DaysLate (0.98)  \n",
       "NumberOfOpenCreditLinesAndLoans                                                                                                 \n",
       "NumberOfTimes90DaysLate               NumberOfTime60-89DaysPastDueNotWorse (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.98)  \n",
       "NumberRealEstateLoansOrLines                                                                                                    \n",
       "NumberOfTime60-89DaysPastDueNotWorse               NumberOfTimes90DaysLate (0.99), NumberOfTime30-59DaysPastDueNotWorse (0.99)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "dataset_summary(df_train, df_train[\"SeriousDlqin2yrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218bc133-d2ae-4339-a66f-b3ed301bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 31 outlier rows (lowest 9, highest 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>1.499670e+05</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "      <td>149967.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066708</td>\n",
       "      <td>6.049597</td>\n",
       "      <td>52.294758</td>\n",
       "      <td>0.420613</td>\n",
       "      <td>353.040256</td>\n",
       "      <td>5.328656e+03</td>\n",
       "      <td>8.452626</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>1.018231</td>\n",
       "      <td>0.240046</td>\n",
       "      <td>0.737296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.249516</td>\n",
       "      <td>249.782836</td>\n",
       "      <td>14.768636</td>\n",
       "      <td>4.193017</td>\n",
       "      <td>2038.016310</td>\n",
       "      <td>1.062365e+04</td>\n",
       "      <td>5.145867</td>\n",
       "      <td>4.169401</td>\n",
       "      <td>1.129606</td>\n",
       "      <td>4.155487</td>\n",
       "      <td>1.106890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029873</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175076</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154136</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366502</td>\n",
       "      <td>4.358000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558876</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.868153</td>\n",
       "      <td>7.400000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>329664.000000</td>\n",
       "      <td>1.794060e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines            age  \\\n",
       "count     149967.000000                         149967.000000  149967.000000   \n",
       "mean           0.066708                              6.049597      52.294758   \n",
       "std            0.249516                            249.782836      14.768636   \n",
       "min            0.000000                              0.000000      21.000000   \n",
       "25%            0.000000                              0.029873      41.000000   \n",
       "50%            0.000000                              0.154136      52.000000   \n",
       "75%            0.000000                              0.558876      63.000000   \n",
       "max            1.000000                          50708.000000     109.000000   \n",
       "\n",
       "       NumberOfTime30-59DaysPastDueNotWorse      DebtRatio  MonthlyIncome  \\\n",
       "count                         149967.000000  149967.000000   1.499670e+05   \n",
       "mean                               0.420613     353.040256   5.328656e+03   \n",
       "std                                4.193017    2038.016310   1.062365e+04   \n",
       "min                                0.000000       0.000000   0.000000e+00   \n",
       "25%                                0.000000       0.175076   1.550000e+03   \n",
       "50%                                0.000000       0.366502   4.358000e+03   \n",
       "75%                                0.000000       0.868153   7.400000e+03   \n",
       "max                               98.000000  329664.000000   1.794060e+06   \n",
       "\n",
       "       NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "count                    149967.000000            149967.000000   \n",
       "mean                          8.452626                 0.265465   \n",
       "std                           5.145867                 4.169401   \n",
       "min                           0.000000                 0.000000   \n",
       "25%                           5.000000                 0.000000   \n",
       "50%                           8.000000                 0.000000   \n",
       "75%                          11.000000                 0.000000   \n",
       "max                          58.000000                98.000000   \n",
       "\n",
       "       NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "count                 149967.000000                         149967.000000   \n",
       "mean                       1.018231                              0.240046   \n",
       "std                        1.129606                              4.155487   \n",
       "min                        0.000000                              0.000000   \n",
       "25%                        0.000000                              0.000000   \n",
       "50%                        1.000000                              0.000000   \n",
       "75%                        2.000000                              0.000000   \n",
       "max                       54.000000                             98.000000   \n",
       "\n",
       "       NumberOfDependents  \n",
       "count       149967.000000  \n",
       "mean             0.737296  \n",
       "std              1.106890  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              1.000000  \n",
       "max             20.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outlier Handling\n",
    "numeric_df = df_train.select_dtypes(include=['number'])\n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train.sort_values(by=\"MonthlyIncome\", ascending=False).iloc[1:].reset_index(drop=True) \n",
    "\n",
    "df_train = df_train[df_train['age'] > 0].reset_index(drop=True)\n",
    "\n",
    "df_filtered = outlier_handling(\n",
    "    df_train,\n",
    "    target_col=\"SeriousDlqin2yrs\",\n",
    "    n_high=22, \n",
    "    n_low=9\n",
    ")\n",
    "\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21bdd49-f76b-4a6b-a0e1-0cdb1926c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped cols: ['SeriousDlqin2yrs']\n",
      "SeriousDlqin2yrs\n",
      "0    139963\n",
      "1     10004\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select targets\n",
    "df_features, target, feature_cols_to_drop = drop_target_and_ids(df_filtered)\n",
    "print(target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3fc22e-3673-4d21-be4d-f6a8fcc4d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n"
     ]
    }
   ],
   "source": [
    "original_cols = df_features.select_dtypes(include=['number']).columns.tolist()\n",
    "print(original_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6819479e-6ddc-413c-a81b-89c02af1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    df_features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3904c1-ebcb-4128-9bbe-27b52a4dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 454 duplicate rows. Remaining: 95524\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "X_train, y_train = check_and_drop_duplicates(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d728e5-2494-4fb4-a941-37f50bcbfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 18 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n"
     ]
    }
   ],
   "source": [
    "# Engineer_features\n",
    "df_e = engineer_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b93580-1ceb-4f5a-819a-caed5251f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     MissingCount  MissingPercent\n",
      "90DaysLate_Squared                              0            0.00\n",
      "AgeBucket                                       0            0.00\n",
      "DebtToIncome                                    0            0.00\n",
      "DebtToIncomeAgeRisk                             0            0.00\n",
      "DelinquencyBucket                               0            0.00\n",
      "HasAnyDelinquency                               0            0.00\n",
      "HasMajorDelinquency                             0            0.00\n",
      "IncomePerCreditLine                          1038            1.09\n",
      "IncomePerCreditLineHasDelinquencies          1038            1.09\n",
      "LatePaymentBucket                               0            0.00\n",
      "LatePaymentsPerAge                              0            0.00\n",
      "LatePaymentsPerCreditLine                    1038            1.09\n",
      "NormalizedUtilization                        6825            7.14\n",
      "SevereDelinquency                               0            0.00\n",
      "TotalPastDue_Squared                            0            0.00\n",
      "UtilizationBucket                            6825            7.14\n",
      "UtilizationBucketLateBucket                     0            0.00\n",
      "UtilizationPerAge                            6825            7.14\n",
      "No high missing cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with missing\n",
    "df_drop, hm_cols_to_drop = drop_high_missing_cols(df_e, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b809c-09e4-4d23-be60-368a6459cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             UniqueCount  UniquePercent\n",
      "UtilizationBucketLateBucket           35           0.04\n",
      "UtilizationBucket                      6           0.01\n",
      "DelinquencyBucket                      5           0.01\n",
      "LatePaymentBucket                      5           0.01\n",
      "AgeBucket                              3           0.00\n",
      "No high cardinality cols dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop high card\n",
    "df_high, hc_cols_to_drop = drop_high_card_cols(df_drop, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e5881e-dbf5-467b-8290-3f7d9c48e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'AgeBucket': collapsed 1 rare categories: ['Young']\n",
      "Column 'DelinquencyBucket': collapsed 2 rare categories: ['Frequent', 'Chronic']\n",
      "Column 'UtilizationBucket': collapsed 2 rare categories: ['Very High', 'Extreme']\n",
      "Column 'LatePaymentBucket': collapsed 2 rare categories: ['FrequentLate', 'ChronicLate']\n",
      "Column 'UtilizationBucketLateBucket': collapsed 30 rare categories: ['Moderate_FewLate', 'High_FewLate', 'Very Low_FewLate', 'Low_FewLate', 'High_ModerateLate', 'Moderate_ModerateLate', 'High_FrequentLate', 'Low_ModerateLate', 'Very Low_ModerateLate', 'nan_FewLate', 'Moderate_FrequentLate', 'High_ChronicLate', 'nan_ModerateLate', 'Low_FrequentLate', 'Extreme_NoLate', 'Moderate_ChronicLate', 'Very Low_FrequentLate', 'Very High_ModerateLate', 'nan_FrequentLate', 'Very High_NoLate', 'Very High_FrequentLate', 'Very High_FewLate', 'Low_ChronicLate', 'Very Low_ChronicLate', 'Very High_ChronicLate', 'nan_ChronicLate', 'Extreme_FewLate', 'Extreme_ModerateLate', 'Extreme_FrequentLate', 'Extreme_ChronicLate']\n"
     ]
    }
   ],
   "source": [
    "# Collapse rare categories\n",
    "df_collapsed, rare_maps = collapse_rare_categories(df_high, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766dd072-a1e8-409e-b3b6-3756eeff4c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using normal class weights\n",
      "Kept 18 select features (including all 5 categorical)\n",
      "Dropped:0 numeric select features cols\n",
      "                                Feature  Importance\n",
      "0                   HasMajorDelinquency  246.256332\n",
      "1                     DelinquencyBucket  158.668198\n",
      "2                    LatePaymentsPerAge  121.691521\n",
      "3             LatePaymentsPerCreditLine   87.825424\n",
      "4                     HasAnyDelinquency   62.219894\n",
      "5           UtilizationBucketLateBucket   54.305931\n",
      "6                  TotalPastDue_Squared   27.006380\n",
      "7                    90DaysLate_Squared   19.578167\n",
      "8                     UtilizationPerAge   19.372267\n",
      "9                 NormalizedUtilization   17.343699\n",
      "10                    UtilizationBucket   14.779331\n",
      "11                    SevereDelinquency   10.342652\n",
      "12                  DebtToIncomeAgeRisk    6.780648\n",
      "13                  IncomePerCreditLine    5.912997\n",
      "14                         DebtToIncome    5.878598\n",
      "15  IncomePerCreditLineHasDelinquencies    5.634151\n",
      "16                            AgeBucket    5.088704\n",
      "17                    LatePaymentBucket    3.724816\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "df_selected, fs_cols_to_drop = select_features(df_collapsed, y_train, n_to_keep=14, bias_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf996eee-3c94-4dc1-9aeb-65c9b43e1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Impute and scale\n",
    "X_train, num_imputer, cat_imputer, robust_scaler, std_scaler, num_col_order, skewed_col_order, cat_col_order, cat_maps, X_train_flags = impute_and_scale(\n",
    "    df_selected\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7c210-987d-4713-9a63-8e76e6033b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered 18 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n",
      "Engineered 18 features\n",
      "Engineered cols: ['TotalPastDue_Squared', 'NormalizedUtilization', 'HasAnyDelinquency', 'HasMajorDelinquency', 'SevereDelinquency', 'UtilizationPerAge', 'LatePaymentsPerAge', 'LatePaymentsPerCreditLine', '90DaysLate_Squared', 'IncomePerCreditLineHasDelinquencies', 'IncomePerCreditLine', 'DebtToIncome', 'DebtToIncomeAgeRisk', 'AgeBucket', 'DelinquencyBucket', 'UtilizationBucket', 'LatePaymentBucket', 'UtilizationBucketLateBucket']\n",
      "Imputed, flagged, and scaled features\n"
     ]
    }
   ],
   "source": [
    "# Process\n",
    "all_cols_to_drop = feature_cols_to_drop + hm_cols_to_drop + hc_cols_to_drop + fs_cols_to_drop\n",
    "\n",
    "X_val = engineer_features(X_val)\n",
    "X_val, X_val_flags = transform_val_test(    \n",
    "    X_val,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")\n",
    "\n",
    "X_test = engineer_features(X_test)\n",
    "X_test, X_test_flags = transform_val_test(\n",
    "    X_test,\n",
    "    all_cols_to_drop,\n",
    "    num_imputer,\n",
    "    cat_imputer,\n",
    "    robust_scaler,\n",
    "    std_scaler,\n",
    "    num_col_order,\n",
    "    skewed_col_order,\n",
    "    cat_col_order,\n",
    "    rare_maps,\n",
    "    train_columns=X_train.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c565e000-f300-47e3-93f2-5205fd8e4e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (95524, 36)\n",
      "Total rows: 95524\n",
      "Total duplicate rows: 3087\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>unique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>skew</th>\n",
       "      <th>corr_with_target</th>\n",
       "      <th>high_corr_flag</th>\n",
       "      <th>high_corr_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HasMajorDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.647042e-02</td>\n",
       "      <td>0.281059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.942716</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478</td>\n",
       "      <td>1.018601e-02</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>17.296362</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue_Squared (0.85), 90DaysLate_Squared (0.81)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentsPerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212</td>\n",
       "      <td>7.454323e-02</td>\n",
       "      <td>0.293928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.089494</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasAnyDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.024936e-01</td>\n",
       "      <td>0.401860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.480677</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>True</td>\n",
       "      <td>LatePaymentBucket (-0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalPastDue_Squared</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.566015e+00</td>\n",
       "      <td>33.787640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>25.435881</td>\n",
       "      <td>-0.004106</td>\n",
       "      <td>True</td>\n",
       "      <td>90DaysLate_Squared (0.90), LatePaymentsPerAge (0.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90DaysLate_Squared</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.635526e-01</td>\n",
       "      <td>4.339215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.113720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>TotalPastDue_Squared (0.90), LatePaymentsPerAge (0.81)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationPerAge</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82368</td>\n",
       "      <td>2.925370e-01</td>\n",
       "      <td>0.781513</td>\n",
       "      <td>-0.416042</td>\n",
       "      <td>-0.308325</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.691675</td>\n",
       "      <td>8.246064</td>\n",
       "      <td>1.658453</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>True</td>\n",
       "      <td>NormalizedUtilization (0.88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalizedUtilization</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80889</td>\n",
       "      <td>-2.291018e-16</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-1.731366</td>\n",
       "      <td>-0.872380</td>\n",
       "      <td>-1.078416e-01</td>\n",
       "      <td>0.872116</td>\n",
       "      <td>3.537338</td>\n",
       "      <td>0.243326</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationPerAge (0.88), UtilizationBucket (-0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SevereDelinquency</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.786985e-02</td>\n",
       "      <td>0.132479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.278738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncomeAgeRisk</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72740</td>\n",
       "      <td>2.509285e-01</td>\n",
       "      <td>1.563415</td>\n",
       "      <td>-0.442589</td>\n",
       "      <td>-0.433568</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.566432</td>\n",
       "      <td>230.825366</td>\n",
       "      <td>66.170613</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>True</td>\n",
       "      <td>DebtToIncome (0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLine</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26023</td>\n",
       "      <td>3.032750e-01</td>\n",
       "      <td>2.273496</td>\n",
       "      <td>-0.712978</td>\n",
       "      <td>-0.439803</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.560197</td>\n",
       "      <td>279.385693</td>\n",
       "      <td>55.237007</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DebtToIncome</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71509</td>\n",
       "      <td>2.384872e-01</td>\n",
       "      <td>1.467045</td>\n",
       "      <td>-0.445663</td>\n",
       "      <td>-0.436030</td>\n",
       "      <td>-4.565381e-17</td>\n",
       "      <td>0.563970</td>\n",
       "      <td>191.688757</td>\n",
       "      <td>52.945438</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>True</td>\n",
       "      <td>DebtToIncomeAgeRisk (0.97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IncomePerCreditLineHasDelinquencies</th>\n",
       "      <td>float64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7927</td>\n",
       "      <td>1.638939e+02</td>\n",
       "      <td>1079.311557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000.000000</td>\n",
       "      <td>113.484513</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.079645e+00</td>\n",
       "      <td>0.987109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.159777</td>\n",
       "      <td>-0.003607</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DelinquencyBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.820066e+00</td>\n",
       "      <td>0.653684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.639075</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>True</td>\n",
       "      <td>LatePaymentBucket (0.86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.362516e+00</td>\n",
       "      <td>1.566912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.167411</td>\n",
       "      <td>-0.004813</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationBucketLateBucket (0.83), NormalizedUtilization (-0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LatePaymentBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.738600e+00</td>\n",
       "      <td>0.692577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.680888</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>True</td>\n",
       "      <td>DelinquencyBucket (0.86), HasAnyDelinquency (-0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilizationBucketLateBucket</th>\n",
       "      <td>int8</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.710523e+00</td>\n",
       "      <td>1.451552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.379053</td>\n",
       "      <td>-0.005779</td>\n",
       "      <td>True</td>\n",
       "      <td>UtilizationBucket (0.83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasMajorDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentsPerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.086638e-02</td>\n",
       "      <td>0.103675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.436141</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineHasDelinquenciesImputed (1.00), WasIncomePerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasHasAnyDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasTotalPastDue_SquaredImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Was90DaysLate_SquaredImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationPerAgeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.144801e-02</td>\n",
       "      <td>0.257573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.327684</td>\n",
       "      <td>-0.005356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationBucketImputed (1.00), WasNormalizedUtilizationImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasNormalizedUtilizationImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.144801e-02</td>\n",
       "      <td>0.257573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.327684</td>\n",
       "      <td>-0.005356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasUtilizationBucketImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasSevereDelinquencyImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeAgeRiskImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.086638e-02</td>\n",
       "      <td>0.103675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.436141</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineHasDelinquenciesImputed (1.00), WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDebtToIncomeImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasIncomePerCreditLineHasDelinquenciesImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.086638e-02</td>\n",
       "      <td>0.103675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.436141</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasIncomePerCreditLineImputed (1.00), WasLatePaymentsPerCreditLineImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasAgeBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasDelinquencyBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.144801e-02</td>\n",
       "      <td>0.257573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.327684</td>\n",
       "      <td>-0.005356</td>\n",
       "      <td>True</td>\n",
       "      <td>WasUtilizationPerAgeImputed (1.00), WasNormalizedUtilizationImputed (1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasLatePaymentBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WasUtilizationBucketLateBucketImputed</th>\n",
       "      <td>int64</td>\n",
       "      <td>95524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dtype  non_null  missing  \\\n",
       "HasMajorDelinquency                            float64     95524        0   \n",
       "LatePaymentsPerAge                             float64     95524        0   \n",
       "LatePaymentsPerCreditLine                      float64     95524        0   \n",
       "HasAnyDelinquency                              float64     95524        0   \n",
       "TotalPastDue_Squared                           float64     95524        0   \n",
       "90DaysLate_Squared                             float64     95524        0   \n",
       "UtilizationPerAge                              float64     95524        0   \n",
       "NormalizedUtilization                          float64     95524        0   \n",
       "SevereDelinquency                              float64     95524        0   \n",
       "DebtToIncomeAgeRisk                            float64     95524        0   \n",
       "IncomePerCreditLine                            float64     95524        0   \n",
       "DebtToIncome                                   float64     95524        0   \n",
       "IncomePerCreditLineHasDelinquencies            float64     95524        0   \n",
       "AgeBucket                                         int8     95524        0   \n",
       "DelinquencyBucket                                 int8     95524        0   \n",
       "UtilizationBucket                                 int8     95524        0   \n",
       "LatePaymentBucket                                 int8     95524        0   \n",
       "UtilizationBucketLateBucket                       int8     95524        0   \n",
       "WasHasMajorDelinquencyImputed                    int64     95524        0   \n",
       "WasLatePaymentsPerAgeImputed                     int64     95524        0   \n",
       "WasLatePaymentsPerCreditLineImputed              int64     95524        0   \n",
       "WasHasAnyDelinquencyImputed                      int64     95524        0   \n",
       "WasTotalPastDue_SquaredImputed                   int64     95524        0   \n",
       "Was90DaysLate_SquaredImputed                     int64     95524        0   \n",
       "WasUtilizationPerAgeImputed                      int64     95524        0   \n",
       "WasNormalizedUtilizationImputed                  int64     95524        0   \n",
       "WasSevereDelinquencyImputed                      int64     95524        0   \n",
       "WasDebtToIncomeAgeRiskImputed                    int64     95524        0   \n",
       "WasIncomePerCreditLineImputed                    int64     95524        0   \n",
       "WasDebtToIncomeImputed                           int64     95524        0   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed    int64     95524        0   \n",
       "WasAgeBucketImputed                              int64     95524        0   \n",
       "WasDelinquencyBucketImputed                      int64     95524        0   \n",
       "WasUtilizationBucketImputed                      int64     95524        0   \n",
       "WasLatePaymentBucketImputed                      int64     95524        0   \n",
       "WasUtilizationBucketLateBucketImputed            int64     95524        0   \n",
       "\n",
       "                                               missing_%  unique  \\\n",
       "HasMajorDelinquency                                  0.0       2   \n",
       "LatePaymentsPerAge                                   0.0     478   \n",
       "LatePaymentsPerCreditLine                            0.0     212   \n",
       "HasAnyDelinquency                                    0.0       2   \n",
       "TotalPastDue_Squared                                 0.0      20   \n",
       "90DaysLate_Squared                                   0.0      11   \n",
       "UtilizationPerAge                                    0.0   82368   \n",
       "NormalizedUtilization                                0.0   80889   \n",
       "SevereDelinquency                                    0.0       2   \n",
       "DebtToIncomeAgeRisk                                  0.0   72740   \n",
       "IncomePerCreditLine                                  0.0   26023   \n",
       "DebtToIncome                                         0.0   71509   \n",
       "IncomePerCreditLineHasDelinquencies                  0.0    7927   \n",
       "AgeBucket                                            0.0       3   \n",
       "DelinquencyBucket                                    0.0       4   \n",
       "UtilizationBucket                                    0.0       5   \n",
       "LatePaymentBucket                                    0.0       4   \n",
       "UtilizationBucketLateBucket                          0.0       6   \n",
       "WasHasMajorDelinquencyImputed                        0.0       1   \n",
       "WasLatePaymentsPerAgeImputed                         0.0       1   \n",
       "WasLatePaymentsPerCreditLineImputed                  0.0       2   \n",
       "WasHasAnyDelinquencyImputed                          0.0       1   \n",
       "WasTotalPastDue_SquaredImputed                       0.0       1   \n",
       "Was90DaysLate_SquaredImputed                         0.0       1   \n",
       "WasUtilizationPerAgeImputed                          0.0       2   \n",
       "WasNormalizedUtilizationImputed                      0.0       2   \n",
       "WasSevereDelinquencyImputed                          0.0       1   \n",
       "WasDebtToIncomeAgeRiskImputed                        0.0       1   \n",
       "WasIncomePerCreditLineImputed                        0.0       2   \n",
       "WasDebtToIncomeImputed                               0.0       1   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed        0.0       2   \n",
       "WasAgeBucketImputed                                  0.0       1   \n",
       "WasDelinquencyBucketImputed                          0.0       1   \n",
       "WasUtilizationBucketImputed                          0.0       2   \n",
       "WasLatePaymentBucketImputed                          0.0       1   \n",
       "WasUtilizationBucketLateBucketImputed                0.0       1   \n",
       "\n",
       "                                                       mean          std  \\\n",
       "HasMajorDelinquency                            8.647042e-02     0.281059   \n",
       "LatePaymentsPerAge                             1.018601e-02     0.043347   \n",
       "LatePaymentsPerCreditLine                      7.454323e-02     0.293928   \n",
       "HasAnyDelinquency                              2.024936e-01     0.401860   \n",
       "TotalPastDue_Squared                           2.566015e+00    33.787640   \n",
       "90DaysLate_Squared                             3.635526e-01     4.339215   \n",
       "UtilizationPerAge                              2.925370e-01     0.781513   \n",
       "NormalizedUtilization                         -2.291018e-16     1.000005   \n",
       "SevereDelinquency                              1.786985e-02     0.132479   \n",
       "DebtToIncomeAgeRisk                            2.509285e-01     1.563415   \n",
       "IncomePerCreditLine                            3.032750e-01     2.273496   \n",
       "DebtToIncome                                   2.384872e-01     1.467045   \n",
       "IncomePerCreditLineHasDelinquencies            1.638939e+02  1079.311557   \n",
       "AgeBucket                                      1.079645e+00     0.987109   \n",
       "DelinquencyBucket                              1.820066e+00     0.653684   \n",
       "UtilizationBucket                              2.362516e+00     1.566912   \n",
       "LatePaymentBucket                              1.738600e+00     0.692577   \n",
       "UtilizationBucketLateBucket                    2.710523e+00     1.451552   \n",
       "WasHasMajorDelinquencyImputed                  0.000000e+00     0.000000   \n",
       "WasLatePaymentsPerAgeImputed                   0.000000e+00     0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed            1.086638e-02     0.103675   \n",
       "WasHasAnyDelinquencyImputed                    0.000000e+00     0.000000   \n",
       "WasTotalPastDue_SquaredImputed                 0.000000e+00     0.000000   \n",
       "Was90DaysLate_SquaredImputed                   0.000000e+00     0.000000   \n",
       "WasUtilizationPerAgeImputed                    7.144801e-02     0.257573   \n",
       "WasNormalizedUtilizationImputed                7.144801e-02     0.257573   \n",
       "WasSevereDelinquencyImputed                    0.000000e+00     0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.000000e+00     0.000000   \n",
       "WasIncomePerCreditLineImputed                  1.086638e-02     0.103675   \n",
       "WasDebtToIncomeImputed                         0.000000e+00     0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed  1.086638e-02     0.103675   \n",
       "WasAgeBucketImputed                            0.000000e+00     0.000000   \n",
       "WasDelinquencyBucketImputed                    0.000000e+00     0.000000   \n",
       "WasUtilizationBucketImputed                    7.144801e-02     0.257573   \n",
       "WasLatePaymentBucketImputed                    0.000000e+00     0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.000000e+00     0.000000   \n",
       "\n",
       "                                                    min       25%  \\\n",
       "HasMajorDelinquency                            0.000000  0.000000   \n",
       "LatePaymentsPerAge                             0.000000  0.000000   \n",
       "LatePaymentsPerCreditLine                      0.000000  0.000000   \n",
       "HasAnyDelinquency                              0.000000  0.000000   \n",
       "TotalPastDue_Squared                           0.000000  0.000000   \n",
       "90DaysLate_Squared                             0.000000  0.000000   \n",
       "UtilizationPerAge                             -0.416042 -0.308325   \n",
       "NormalizedUtilization                         -1.731366 -0.872380   \n",
       "SevereDelinquency                              0.000000  0.000000   \n",
       "DebtToIncomeAgeRisk                           -0.442589 -0.433568   \n",
       "IncomePerCreditLine                           -0.712978 -0.439803   \n",
       "DebtToIncome                                  -0.445663 -0.436030   \n",
       "IncomePerCreditLineHasDelinquencies            0.000000  0.000000   \n",
       "AgeBucket                                      0.000000  0.000000   \n",
       "DelinquencyBucket                              0.000000  2.000000   \n",
       "UtilizationBucket                              0.000000  1.000000   \n",
       "LatePaymentBucket                              0.000000  2.000000   \n",
       "UtilizationBucketLateBucket                    0.000000  1.000000   \n",
       "WasHasMajorDelinquencyImputed                  0.000000  0.000000   \n",
       "WasLatePaymentsPerAgeImputed                   0.000000  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed            0.000000  0.000000   \n",
       "WasHasAnyDelinquencyImputed                    0.000000  0.000000   \n",
       "WasTotalPastDue_SquaredImputed                 0.000000  0.000000   \n",
       "Was90DaysLate_SquaredImputed                   0.000000  0.000000   \n",
       "WasUtilizationPerAgeImputed                    0.000000  0.000000   \n",
       "WasNormalizedUtilizationImputed                0.000000  0.000000   \n",
       "WasSevereDelinquencyImputed                    0.000000  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.000000  0.000000   \n",
       "WasIncomePerCreditLineImputed                  0.000000  0.000000   \n",
       "WasDebtToIncomeImputed                         0.000000  0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed  0.000000  0.000000   \n",
       "WasAgeBucketImputed                            0.000000  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.000000  0.000000   \n",
       "WasUtilizationBucketImputed                    0.000000  0.000000   \n",
       "WasLatePaymentBucketImputed                    0.000000  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.000000  0.000000   \n",
       "\n",
       "                                                        50%       75%  \\\n",
       "HasMajorDelinquency                            0.000000e+00  0.000000   \n",
       "LatePaymentsPerAge                             0.000000e+00  0.000000   \n",
       "LatePaymentsPerCreditLine                      0.000000e+00  0.000000   \n",
       "HasAnyDelinquency                              0.000000e+00  0.000000   \n",
       "TotalPastDue_Squared                           0.000000e+00  0.000000   \n",
       "90DaysLate_Squared                             0.000000e+00  0.000000   \n",
       "UtilizationPerAge                              0.000000e+00  0.691675   \n",
       "NormalizedUtilization                         -1.078416e-01  0.872116   \n",
       "SevereDelinquency                              0.000000e+00  0.000000   \n",
       "DebtToIncomeAgeRisk                            0.000000e+00  0.566432   \n",
       "IncomePerCreditLine                            0.000000e+00  0.560197   \n",
       "DebtToIncome                                  -4.565381e-17  0.563970   \n",
       "IncomePerCreditLineHasDelinquencies            0.000000e+00  0.000000   \n",
       "AgeBucket                                      2.000000e+00  2.000000   \n",
       "DelinquencyBucket                              2.000000e+00  2.000000   \n",
       "UtilizationBucket                              2.000000e+00  4.000000   \n",
       "LatePaymentBucket                              2.000000e+00  2.000000   \n",
       "UtilizationBucketLateBucket                    3.000000e+00  4.000000   \n",
       "WasHasMajorDelinquencyImputed                  0.000000e+00  0.000000   \n",
       "WasLatePaymentsPerAgeImputed                   0.000000e+00  0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed            0.000000e+00  0.000000   \n",
       "WasHasAnyDelinquencyImputed                    0.000000e+00  0.000000   \n",
       "WasTotalPastDue_SquaredImputed                 0.000000e+00  0.000000   \n",
       "Was90DaysLate_SquaredImputed                   0.000000e+00  0.000000   \n",
       "WasUtilizationPerAgeImputed                    0.000000e+00  0.000000   \n",
       "WasNormalizedUtilizationImputed                0.000000e+00  0.000000   \n",
       "WasSevereDelinquencyImputed                    0.000000e+00  0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                  0.000000e+00  0.000000   \n",
       "WasIncomePerCreditLineImputed                  0.000000e+00  0.000000   \n",
       "WasDebtToIncomeImputed                         0.000000e+00  0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed  0.000000e+00  0.000000   \n",
       "WasAgeBucketImputed                            0.000000e+00  0.000000   \n",
       "WasDelinquencyBucketImputed                    0.000000e+00  0.000000   \n",
       "WasUtilizationBucketImputed                    0.000000e+00  0.000000   \n",
       "WasLatePaymentBucketImputed                    0.000000e+00  0.000000   \n",
       "WasUtilizationBucketLateBucketImputed          0.000000e+00  0.000000   \n",
       "\n",
       "                                                         max        skew  \\\n",
       "HasMajorDelinquency                                 1.000000    2.942716   \n",
       "LatePaymentsPerAge                                  1.428571   17.296362   \n",
       "LatePaymentsPerCreditLine                          30.000000   18.089494   \n",
       "HasAnyDelinquency                                   1.000000    1.480677   \n",
       "TotalPastDue_Squared                              900.000000   25.435881   \n",
       "90DaysLate_Squared                                100.000000   20.113720   \n",
       "UtilizationPerAge                                   8.246064    1.658453   \n",
       "NormalizedUtilization                               3.537338    0.243326   \n",
       "SevereDelinquency                                   1.000000    7.278738   \n",
       "DebtToIncomeAgeRisk                               230.825366   66.170613   \n",
       "IncomePerCreditLine                               279.385693   55.237007   \n",
       "DebtToIncome                                      191.688757   52.945438   \n",
       "IncomePerCreditLineHasDelinquencies            220000.000000  113.484513   \n",
       "AgeBucket                                           2.000000   -0.159777   \n",
       "DelinquencyBucket                                   3.000000   -1.639075   \n",
       "UtilizationBucket                                   4.000000   -0.167411   \n",
       "LatePaymentBucket                                   3.000000   -1.680888   \n",
       "UtilizationBucketLateBucket                         5.000000   -0.379053   \n",
       "WasHasMajorDelinquencyImputed                       0.000000    0.000000   \n",
       "WasLatePaymentsPerAgeImputed                        0.000000    0.000000   \n",
       "WasLatePaymentsPerCreditLineImputed                 1.000000    9.436141   \n",
       "WasHasAnyDelinquencyImputed                         0.000000    0.000000   \n",
       "WasTotalPastDue_SquaredImputed                      0.000000    0.000000   \n",
       "Was90DaysLate_SquaredImputed                        0.000000    0.000000   \n",
       "WasUtilizationPerAgeImputed                         1.000000    3.327684   \n",
       "WasNormalizedUtilizationImputed                     1.000000    3.327684   \n",
       "WasSevereDelinquencyImputed                         0.000000    0.000000   \n",
       "WasDebtToIncomeAgeRiskImputed                       0.000000    0.000000   \n",
       "WasIncomePerCreditLineImputed                       1.000000    9.436141   \n",
       "WasDebtToIncomeImputed                              0.000000    0.000000   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed       1.000000    9.436141   \n",
       "WasAgeBucketImputed                                 0.000000    0.000000   \n",
       "WasDelinquencyBucketImputed                         0.000000    0.000000   \n",
       "WasUtilizationBucketImputed                         1.000000    3.327684   \n",
       "WasLatePaymentBucketImputed                         0.000000    0.000000   \n",
       "WasUtilizationBucketLateBucketImputed               0.000000    0.000000   \n",
       "\n",
       "                                               corr_with_target  \\\n",
       "HasMajorDelinquency                                   -0.002191   \n",
       "LatePaymentsPerAge                                    -0.002560   \n",
       "LatePaymentsPerCreditLine                             -0.003729   \n",
       "HasAnyDelinquency                                     -0.004043   \n",
       "TotalPastDue_Squared                                  -0.004106   \n",
       "90DaysLate_Squared                                          NaN   \n",
       "UtilizationPerAge                                      0.002014   \n",
       "NormalizedUtilization                                  0.000649   \n",
       "SevereDelinquency                                           NaN   \n",
       "DebtToIncomeAgeRisk                                    0.001065   \n",
       "IncomePerCreditLine                                   -0.005894   \n",
       "DebtToIncome                                           0.000439   \n",
       "IncomePerCreditLineHasDelinquencies                    0.004686   \n",
       "AgeBucket                                             -0.003607   \n",
       "DelinquencyBucket                                      0.003980   \n",
       "UtilizationBucket                                     -0.004813   \n",
       "LatePaymentBucket                                      0.004031   \n",
       "UtilizationBucketLateBucket                           -0.005779   \n",
       "WasHasMajorDelinquencyImputed                               NaN   \n",
       "WasLatePaymentsPerAgeImputed                                NaN   \n",
       "WasLatePaymentsPerCreditLineImputed                   -0.001356   \n",
       "WasHasAnyDelinquencyImputed                                 NaN   \n",
       "WasTotalPastDue_SquaredImputed                              NaN   \n",
       "Was90DaysLate_SquaredImputed                                NaN   \n",
       "WasUtilizationPerAgeImputed                           -0.005356   \n",
       "WasNormalizedUtilizationImputed                       -0.005356   \n",
       "WasSevereDelinquencyImputed                                 NaN   \n",
       "WasDebtToIncomeAgeRiskImputed                               NaN   \n",
       "WasIncomePerCreditLineImputed                         -0.001356   \n",
       "WasDebtToIncomeImputed                                      NaN   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed         -0.001356   \n",
       "WasAgeBucketImputed                                         NaN   \n",
       "WasDelinquencyBucketImputed                                 NaN   \n",
       "WasUtilizationBucketImputed                           -0.005356   \n",
       "WasLatePaymentBucketImputed                                 NaN   \n",
       "WasUtilizationBucketLateBucketImputed                       NaN   \n",
       "\n",
       "                                               high_corr_flag  \\\n",
       "HasMajorDelinquency                                     False   \n",
       "LatePaymentsPerAge                                       True   \n",
       "LatePaymentsPerCreditLine                               False   \n",
       "HasAnyDelinquency                                        True   \n",
       "TotalPastDue_Squared                                     True   \n",
       "90DaysLate_Squared                                       True   \n",
       "UtilizationPerAge                                        True   \n",
       "NormalizedUtilization                                    True   \n",
       "SevereDelinquency                                       False   \n",
       "DebtToIncomeAgeRisk                                      True   \n",
       "IncomePerCreditLine                                     False   \n",
       "DebtToIncome                                             True   \n",
       "IncomePerCreditLineHasDelinquencies                     False   \n",
       "AgeBucket                                               False   \n",
       "DelinquencyBucket                                        True   \n",
       "UtilizationBucket                                        True   \n",
       "LatePaymentBucket                                        True   \n",
       "UtilizationBucketLateBucket                              True   \n",
       "WasHasMajorDelinquencyImputed                           False   \n",
       "WasLatePaymentsPerAgeImputed                            False   \n",
       "WasLatePaymentsPerCreditLineImputed                      True   \n",
       "WasHasAnyDelinquencyImputed                             False   \n",
       "WasTotalPastDue_SquaredImputed                          False   \n",
       "Was90DaysLate_SquaredImputed                            False   \n",
       "WasUtilizationPerAgeImputed                              True   \n",
       "WasNormalizedUtilizationImputed                          True   \n",
       "WasSevereDelinquencyImputed                             False   \n",
       "WasDebtToIncomeAgeRiskImputed                           False   \n",
       "WasIncomePerCreditLineImputed                            True   \n",
       "WasDebtToIncomeImputed                                  False   \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed            True   \n",
       "WasAgeBucketImputed                                     False   \n",
       "WasDelinquencyBucketImputed                             False   \n",
       "WasUtilizationBucketImputed                              True   \n",
       "WasLatePaymentBucketImputed                             False   \n",
       "WasUtilizationBucketLateBucketImputed                   False   \n",
       "\n",
       "                                                                                                                                 high_corr_with  \n",
       "HasMajorDelinquency                                                                                                                              \n",
       "LatePaymentsPerAge                                                                       TotalPastDue_Squared (0.85), 90DaysLate_Squared (0.81)  \n",
       "LatePaymentsPerCreditLine                                                                                                                        \n",
       "HasAnyDelinquency                                                                                                     LatePaymentBucket (-0.75)  \n",
       "TotalPastDue_Squared                                                                       90DaysLate_Squared (0.90), LatePaymentsPerAge (0.85)  \n",
       "90DaysLate_Squared                                                                       TotalPastDue_Squared (0.90), LatePaymentsPerAge (0.81)  \n",
       "UtilizationPerAge                                                                                                  NormalizedUtilization (0.88)  \n",
       "NormalizedUtilization                                                                       UtilizationPerAge (0.88), UtilizationBucket (-0.78)  \n",
       "SevereDelinquency                                                                                                                                \n",
       "DebtToIncomeAgeRisk                                                                                                         DebtToIncome (0.97)  \n",
       "IncomePerCreditLine                                                                                                                              \n",
       "DebtToIncome                                                                                                         DebtToIncomeAgeRisk (0.97)  \n",
       "IncomePerCreditLineHasDelinquencies                                                                                                              \n",
       "AgeBucket                                                                                                                                        \n",
       "DelinquencyBucket                                                                                                      LatePaymentBucket (0.86)  \n",
       "UtilizationBucket                                                             UtilizationBucketLateBucket (0.83), NormalizedUtilization (-0.78)  \n",
       "LatePaymentBucket                                                                           DelinquencyBucket (0.86), HasAnyDelinquency (-0.75)  \n",
       "UtilizationBucketLateBucket                                                                                            UtilizationBucket (0.83)  \n",
       "WasHasMajorDelinquencyImputed                                                                                                                    \n",
       "WasLatePaymentsPerAgeImputed                                                                                                                     \n",
       "WasLatePaymentsPerCreditLineImputed                  WasIncomePerCreditLineHasDelinquenciesImputed (1.00), WasIncomePerCreditLineImputed (1.00)  \n",
       "WasHasAnyDelinquencyImputed                                                                                                                      \n",
       "WasTotalPastDue_SquaredImputed                                                                                                                   \n",
       "Was90DaysLate_SquaredImputed                                                                                                                     \n",
       "WasUtilizationPerAgeImputed                                          WasUtilizationBucketImputed (1.00), WasNormalizedUtilizationImputed (1.00)  \n",
       "WasNormalizedUtilizationImputed                                          WasUtilizationPerAgeImputed (1.00), WasUtilizationBucketImputed (1.00)  \n",
       "WasSevereDelinquencyImputed                                                                                                                      \n",
       "WasDebtToIncomeAgeRiskImputed                                                                                                                    \n",
       "WasIncomePerCreditLineImputed                  WasIncomePerCreditLineHasDelinquenciesImputed (1.00), WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasDebtToIncomeImputed                                                                                                                           \n",
       "WasIncomePerCreditLineHasDelinquenciesImputed                  WasIncomePerCreditLineImputed (1.00), WasLatePaymentsPerCreditLineImputed (1.00)  \n",
       "WasAgeBucketImputed                                                                                                                              \n",
       "WasDelinquencyBucketImputed                                                                                                                      \n",
       "WasUtilizationBucketImputed                                          WasUtilizationPerAgeImputed (1.00), WasNormalizedUtilizationImputed (1.00)  \n",
       "WasLatePaymentBucketImputed                                                                                                                      \n",
       "WasUtilizationBucketLateBucketImputed                                                                                                            "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary\n",
    "dataset_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8685269e-518c-4174-81a2-e425a3d117b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero importance cols \n",
    "zero_importance_cols = [\n",
    "    \"WasHasAnyDelinquencyImputed\", \n",
    "    \"WasLatePaymentsPerAgeImputed\", \n",
    "    \"WasTotalPastDue_SquaredImputed\", \n",
    "    \"WasNormalizedUtilizationImputed\", \n",
    "    \"Was90DaysLate_SquaredImputed\", \n",
    "    \"WasUtilizationPerAgeImputed\", \n",
    "    \"WasHasMajorDelinquencyImputed\", \n",
    "    \"WasSevereDelinquencyImputed\", \n",
    "    \"WasDebtToIncomeAgeRiskImputed\", \n",
    "    \"WasDebtToIncomeImputed\", \n",
    "    \"WasAgeBucketImputed\", \n",
    "    \"WasDelinquencyBucketImputed\", \n",
    "    \"WasUtilizationBucketImputed\", \n",
    "    \"WasLatePaymentBucketImputed\", \n",
    "    \"WasUtilizationBucketLateBucketImputed\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns=zero_importance_cols)\n",
    "X_val   = X_val.drop(columns=zero_importance_cols)\n",
    "X_test  = X_test.drop(columns=zero_importance_cols)\n",
    "\n",
    "flags_to_keep = [f for f in X_train_flags if f not in zero_importance_cols]\n",
    "\n",
    "X_train_flags = flags_to_keep\n",
    "X_val_flags   = flags_to_keep\n",
    "X_test_flags  = flags_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5ccf26-70f7-4e16-8ecb-0d1ad9d87920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "for col in cat_col_order:\n",
    "    X_train[col] = X_train[col].astype(str).map(cat_maps[col]).astype(int)\n",
    "    X_val[col] = X_val[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)\n",
    "    X_test[col] = X_test[col].astype(str).map(cat_maps[col]).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98be230c-b9da-4bd8-9acf-cf3e640509aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 and int64\n",
    "X_train_num = X_train[num_col_order + X_train_flags].astype('float32').values\n",
    "X_val_num   = X_val[num_col_order + X_val_flags].astype('float32').values\n",
    "X_test_num  = X_test[num_col_order + X_test_flags].astype('float32').values\n",
    "\n",
    "X_train_cat = X_train[cat_col_order].astype('int64').values\n",
    "X_val_cat   = X_val[cat_col_order].astype('int64').values\n",
    "X_test_cat  = X_test[cat_col_order].astype('int64').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff7a704-29e1-4006-b277-89ed436db0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric input shape: torch.Size([95524, 16])\n",
      "Categorical input shape: torch.Size([95524, 5])\n",
      "Class weights: {np.int64(0): np.float64(0.5357908080275512), np.int64(1): np.float64(7.485033693778405)}\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_train_num_tensor = torch.tensor(X_train_num)\n",
    "X_val_num_tensor = torch.tensor(X_val_num)\n",
    "X_test_num_tensor = torch.tensor(X_test_num)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat)\n",
    "X_val_cat_tensor = torch.tensor(X_val_cat)\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights, strict=True))\n",
    "weights_tensor = torch.tensor([class_weight_dict[int(c)] for c in y_train], dtype=torch.float32)\n",
    "\n",
    "print(\"Numeric input shape:\", X_train_num_tensor.shape)\n",
    "print(\"Categorical input shape:\", X_train_cat_tensor.shape)\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "746b3142-5266-4267-a2ee-9787e0cc7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 95524, Val: 23995, Test: 29994\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num, x_cat, y):\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_num[idx], self.x_cat[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabularDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor)\n",
    "val_ds = TabularDataset(X_val_num_tensor, X_val_cat_tensor, y_val_tensor)\n",
    "test_ds = TabularDataset(X_test_num_tensor, X_test_cat_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505d1520-2bbf-4c7f-bf60-f3b7415e1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(3, 2)\n",
      "    (1): Embedding(4, 2)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(4, 2)\n",
      "    (4): Embedding(6, 3)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bn_num): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (skip_proj_main): Sequential(\n",
      "    (0): Linear(in_features=28, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (cat_skip): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 52440\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_numeric, cat_dims, emb_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim)\n",
    "            for cat_dim, emb_dim in zip(cat_dims, emb_dims, strict=True)\n",
    "        ])\n",
    "        self.emb_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn_num = nn.BatchNorm1d(num_numeric)\n",
    "\n",
    "        total_emb_dim = sum(emb_dims)\n",
    "        self.input_dim = num_numeric + total_emb_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        self.skip_proj_main = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 64),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.cat_skip = nn.Sequential(\n",
    "            nn.Linear(total_emb_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "    \n",
    "        x_cat_emb = torch.cat([\n",
    "            emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)\n",
    "        ], dim=1)\n",
    "        x_cat_emb = self.emb_dropout(x_cat_emb)\n",
    "\n",
    "        x_num = self.bn_num(x_num)\n",
    "\n",
    "        x = torch.cat([x_num, x_cat_emb], dim=1)\n",
    "\n",
    "        x_main = self.main(x)\n",
    "\n",
    "        x_skip = self.skip_proj_main(x) + self.cat_skip(x_cat_emb)\n",
    "\n",
    "        x_combined = x_main + x_skip\n",
    "        \n",
    "        return self.out(x_combined).squeeze(1)\n",
    "\n",
    "cat_dims = [len(cat_maps[col]) for col in cat_col_order]\n",
    "emb_dims = [min(50, (cat_dim + 1) // 2) for cat_dim in cat_dims]\n",
    "\n",
    "model = NN(X_train_num.shape[1], cat_dims, emb_dims).to(device)\n",
    "print(model)\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1994e184-b5b9-4010-8de3-931c94d652c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits,\n",
    "            targets,\n",
    "            reduction='none',\n",
    "            pos_weight=torch.tensor(self.pos_weight, device=logits.device)\n",
    "            if self.pos_weight else None\n",
    "        )\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "alpha = class_weights[1] / (class_weights[0] + class_weights[1])\n",
    "loss_fn = FocalLoss(alpha=alpha, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "023f7588-ec2a-4a40-863e-ef86a056b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/5 ===\n",
      "Epoch 1/75 | Train loss: 0.029913 | Train AUC: 0.7992 | Val loss: 0.025073 | Val AUC: 0.8562\n",
      "Epoch 2/75 | Train loss: 0.025194 | Train AUC: 0.8438 | Val loss: 0.024696 | Val AUC: 0.8560\n",
      "Epoch 3/75 | Train loss: 0.025042 | Train AUC: 0.8465 | Val loss: 0.024907 | Val AUC: 0.8581\n",
      "Epoch 4/75 | Train loss: 0.024988 | Train AUC: 0.8470 | Val loss: 0.024789 | Val AUC: 0.8534\n",
      "Epoch 5/75 | Train loss: 0.024944 | Train AUC: 0.8465 | Val loss: 0.024699 | Val AUC: 0.8561\n",
      "Epoch 6/75 | Train loss: 0.024843 | Train AUC: 0.8490 | Val loss: 0.024561 | Val AUC: 0.8562\n",
      "Epoch 7/75 | Train loss: 0.024771 | Train AUC: 0.8502 | Val loss: 0.024841 | Val AUC: 0.8554\n",
      "Epoch 8/75 | Train loss: 0.024725 | Train AUC: 0.8507 | Val loss: 0.025153 | Val AUC: 0.8549\n",
      "Epoch 9/75 | Train loss: 0.024651 | Train AUC: 0.8518 | Val loss: 0.024720 | Val AUC: 0.8570\n",
      "Epoch 10/75 | Train loss: 0.024516 | Train AUC: 0.8540 | Val loss: 0.024622 | Val AUC: 0.8584\n",
      "Epoch 11/75 | Train loss: 0.024486 | Train AUC: 0.8545 | Val loss: 0.024642 | Val AUC: 0.8582\n",
      "Epoch 12/75 | Train loss: 0.024509 | Train AUC: 0.8540 | Val loss: 0.024469 | Val AUC: 0.8586\n",
      "Epoch 13/75 | Train loss: 0.024463 | Train AUC: 0.8546 | Val loss: 0.024534 | Val AUC: 0.8589\n",
      "Epoch 14/75 | Train loss: 0.024435 | Train AUC: 0.8556 | Val loss: 0.024533 | Val AUC: 0.8583\n",
      "Epoch 15/75 | Train loss: 0.024455 | Train AUC: 0.8552 | Val loss: 0.024652 | Val AUC: 0.8585\n",
      "Epoch 16/75 | Train loss: 0.024356 | Train AUC: 0.8563 | Val loss: 0.024375 | Val AUC: 0.8589\n",
      "Epoch 17/75 | Train loss: 0.024404 | Train AUC: 0.8557 | Val loss: 0.024668 | Val AUC: 0.8582\n",
      "Epoch 18/75 | Train loss: 0.024425 | Train AUC: 0.8553 | Val loss: 0.024607 | Val AUC: 0.8601\n",
      "Epoch 19/75 | Train loss: 0.024402 | Train AUC: 0.8563 | Val loss: 0.024635 | Val AUC: 0.8532\n",
      "Epoch 20/75 | Train loss: 0.024464 | Train AUC: 0.8551 | Val loss: 0.024510 | Val AUC: 0.8588\n",
      "Epoch 21/75 | Train loss: 0.024393 | Train AUC: 0.8560 | Val loss: 0.024300 | Val AUC: 0.8592\n",
      "Epoch 22/75 | Train loss: 0.024388 | Train AUC: 0.8559 | Val loss: 0.024398 | Val AUC: 0.8593\n",
      "Epoch 23/75 | Train loss: 0.024348 | Train AUC: 0.8565 | Val loss: 0.024746 | Val AUC: 0.8593\n",
      "Epoch 24/75 | Train loss: 0.024364 | Train AUC: 0.8564 | Val loss: 0.024361 | Val AUC: 0.8573\n",
      "Epoch 25/75 | Train loss: 0.024192 | Train AUC: 0.8592 | Val loss: 0.024282 | Val AUC: 0.8583\n",
      "Epoch 26/75 | Train loss: 0.024266 | Train AUC: 0.8580 | Val loss: 0.024278 | Val AUC: 0.8597\n",
      "Epoch 27/75 | Train loss: 0.024240 | Train AUC: 0.8582 | Val loss: 0.024363 | Val AUC: 0.8588\n",
      "Epoch 28/75 | Train loss: 0.024239 | Train AUC: 0.8581 | Val loss: 0.024503 | Val AUC: 0.8549\n",
      "Epoch 29/75 | Train loss: 0.024265 | Train AUC: 0.8582 | Val loss: 0.024251 | Val AUC: 0.8595\n",
      "Epoch 30/75 | Train loss: 0.024219 | Train AUC: 0.8586 | Val loss: 0.024401 | Val AUC: 0.8589\n",
      "Early stopping at epoch 31\n",
      "Run 1 best Val AUC: 0.8601\n",
      "\n",
      "=== Run 2/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024496 | Train AUC: 0.8547 | Val loss: 0.024659 | Val AUC: 0.8562\n",
      "Epoch 2/75 | Train loss: 0.024455 | Train AUC: 0.8554 | Val loss: 0.024210 | Val AUC: 0.8598\n",
      "Epoch 3/75 | Train loss: 0.024442 | Train AUC: 0.8554 | Val loss: 0.024275 | Val AUC: 0.8593\n",
      "Epoch 4/75 | Train loss: 0.024432 | Train AUC: 0.8556 | Val loss: 0.024479 | Val AUC: 0.8572\n",
      "Epoch 5/75 | Train loss: 0.024500 | Train AUC: 0.8547 | Val loss: 0.024368 | Val AUC: 0.8595\n",
      "Epoch 6/75 | Train loss: 0.024479 | Train AUC: 0.8550 | Val loss: 0.024631 | Val AUC: 0.8554\n",
      "Epoch 7/75 | Train loss: 0.024379 | Train AUC: 0.8567 | Val loss: 0.024631 | Val AUC: 0.8543\n",
      "Epoch 8/75 | Train loss: 0.024425 | Train AUC: 0.8554 | Val loss: 0.024527 | Val AUC: 0.8558\n",
      "Epoch 9/75 | Train loss: 0.024297 | Train AUC: 0.8576 | Val loss: 0.024277 | Val AUC: 0.8602\n",
      "Epoch 10/75 | Train loss: 0.024280 | Train AUC: 0.8582 | Val loss: 0.024364 | Val AUC: 0.8605\n",
      "Epoch 11/75 | Train loss: 0.024271 | Train AUC: 0.8577 | Val loss: 0.024335 | Val AUC: 0.8596\n",
      "Epoch 12/75 | Train loss: 0.024249 | Train AUC: 0.8584 | Val loss: 0.024310 | Val AUC: 0.8600\n",
      "Epoch 13/75 | Train loss: 0.024315 | Train AUC: 0.8572 | Val loss: 0.024281 | Val AUC: 0.8598\n",
      "Epoch 14/75 | Train loss: 0.024303 | Train AUC: 0.8573 | Val loss: 0.024352 | Val AUC: 0.8605\n",
      "Epoch 15/75 | Train loss: 0.024278 | Train AUC: 0.8582 | Val loss: 0.024529 | Val AUC: 0.8581\n",
      "Epoch 16/75 | Train loss: 0.024249 | Train AUC: 0.8585 | Val loss: 0.024907 | Val AUC: 0.8562\n",
      "Epoch 17/75 | Train loss: 0.024246 | Train AUC: 0.8581 | Val loss: 0.024184 | Val AUC: 0.8600\n",
      "Epoch 18/75 | Train loss: 0.024151 | Train AUC: 0.8597 | Val loss: 0.024587 | Val AUC: 0.8550\n",
      "Epoch 19/75 | Train loss: 0.024154 | Train AUC: 0.8597 | Val loss: 0.024253 | Val AUC: 0.8605\n",
      "Epoch 20/75 | Train loss: 0.024139 | Train AUC: 0.8596 | Val loss: 0.024231 | Val AUC: 0.8596\n",
      "Epoch 21/75 | Train loss: 0.024169 | Train AUC: 0.8596 | Val loss: 0.024311 | Val AUC: 0.8577\n",
      "Epoch 22/75 | Train loss: 0.024198 | Train AUC: 0.8587 | Val loss: 0.024315 | Val AUC: 0.8586\n",
      "Epoch 23/75 | Train loss: 0.024147 | Train AUC: 0.8599 | Val loss: 0.024315 | Val AUC: 0.8584\n",
      "Epoch 24/75 | Train loss: 0.024148 | Train AUC: 0.8599 | Val loss: 0.024296 | Val AUC: 0.8585\n",
      "Epoch 25/75 | Train loss: 0.024059 | Train AUC: 0.8611 | Val loss: 0.024325 | Val AUC: 0.8594\n",
      "Epoch 26/75 | Train loss: 0.024107 | Train AUC: 0.8605 | Val loss: 0.024168 | Val AUC: 0.8607\n",
      "Epoch 27/75 | Train loss: 0.024163 | Train AUC: 0.8594 | Val loss: 0.024364 | Val AUC: 0.8578\n",
      "Epoch 28/75 | Train loss: 0.024100 | Train AUC: 0.8604 | Val loss: 0.024233 | Val AUC: 0.8601\n",
      "Epoch 29/75 | Train loss: 0.024103 | Train AUC: 0.8606 | Val loss: 0.024269 | Val AUC: 0.8593\n",
      "Epoch 30/75 | Train loss: 0.024090 | Train AUC: 0.8603 | Val loss: 0.024450 | Val AUC: 0.8601\n",
      "Epoch 31/75 | Train loss: 0.024113 | Train AUC: 0.8601 | Val loss: 0.024443 | Val AUC: 0.8599\n",
      "Epoch 32/75 | Train loss: 0.024073 | Train AUC: 0.8607 | Val loss: 0.024263 | Val AUC: 0.8600\n",
      "Epoch 33/75 | Train loss: 0.024095 | Train AUC: 0.8607 | Val loss: 0.024438 | Val AUC: 0.8566\n",
      "Epoch 34/75 | Train loss: 0.024061 | Train AUC: 0.8611 | Val loss: 0.024418 | Val AUC: 0.8559\n",
      "Epoch 35/75 | Train loss: 0.024067 | Train AUC: 0.8611 | Val loss: 0.024285 | Val AUC: 0.8597\n",
      "Epoch 36/75 | Train loss: 0.024051 | Train AUC: 0.8611 | Val loss: 0.024460 | Val AUC: 0.8607\n",
      "Epoch 37/75 | Train loss: 0.024097 | Train AUC: 0.8604 | Val loss: 0.024354 | Val AUC: 0.8576\n",
      "Epoch 38/75 | Train loss: 0.024044 | Train AUC: 0.8612 | Val loss: 0.024842 | Val AUC: 0.8534\n",
      "Epoch 39/75 | Train loss: 0.024052 | Train AUC: 0.8611 | Val loss: 0.024229 | Val AUC: 0.8601\n",
      "Epoch 40/75 | Train loss: 0.024042 | Train AUC: 0.8613 | Val loss: 0.024522 | Val AUC: 0.8570\n",
      "Epoch 41/75 | Train loss: 0.024066 | Train AUC: 0.8609 | Val loss: 0.024506 | Val AUC: 0.8582\n",
      "Epoch 42/75 | Train loss: 0.024068 | Train AUC: 0.8606 | Val loss: 0.024203 | Val AUC: 0.8603\n",
      "Epoch 43/75 | Train loss: 0.024046 | Train AUC: 0.8613 | Val loss: 0.024452 | Val AUC: 0.8558\n",
      "Epoch 44/75 | Train loss: 0.024070 | Train AUC: 0.8611 | Val loss: 0.024283 | Val AUC: 0.8580\n",
      "Epoch 45/75 | Train loss: 0.024039 | Train AUC: 0.8615 | Val loss: 0.024249 | Val AUC: 0.8583\n",
      "Epoch 46/75 | Train loss: 0.024058 | Train AUC: 0.8608 | Val loss: 0.024373 | Val AUC: 0.8573\n",
      "Epoch 47/75 | Train loss: 0.024042 | Train AUC: 0.8612 | Val loss: 0.024293 | Val AUC: 0.8586\n",
      "Epoch 48/75 | Train loss: 0.024063 | Train AUC: 0.8609 | Val loss: 0.024162 | Val AUC: 0.8603\n",
      "Early stopping at epoch 49\n",
      "Run 2 best Val AUC: 0.8607\n",
      "\n",
      "=== Run 3/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024376 | Train AUC: 0.8563 | Val loss: 0.024635 | Val AUC: 0.8588\n",
      "Epoch 2/75 | Train loss: 0.024294 | Train AUC: 0.8580 | Val loss: 0.024641 | Val AUC: 0.8578\n",
      "Epoch 3/75 | Train loss: 0.024355 | Train AUC: 0.8561 | Val loss: 0.024228 | Val AUC: 0.8601\n",
      "Epoch 4/75 | Train loss: 0.024361 | Train AUC: 0.8568 | Val loss: 0.024338 | Val AUC: 0.8608\n",
      "Epoch 5/75 | Train loss: 0.024331 | Train AUC: 0.8571 | Val loss: 0.024492 | Val AUC: 0.8555\n",
      "Epoch 6/75 | Train loss: 0.024249 | Train AUC: 0.8586 | Val loss: 0.024276 | Val AUC: 0.8603\n",
      "Epoch 7/75 | Train loss: 0.024320 | Train AUC: 0.8573 | Val loss: 0.024462 | Val AUC: 0.8582\n",
      "Epoch 8/75 | Train loss: 0.024345 | Train AUC: 0.8568 | Val loss: 0.024630 | Val AUC: 0.8513\n",
      "Epoch 9/75 | Train loss: 0.024280 | Train AUC: 0.8579 | Val loss: 0.024304 | Val AUC: 0.8596\n",
      "Epoch 10/75 | Train loss: 0.024282 | Train AUC: 0.8578 | Val loss: 0.024412 | Val AUC: 0.8573\n",
      "Epoch 11/75 | Train loss: 0.024197 | Train AUC: 0.8591 | Val loss: 0.024437 | Val AUC: 0.8599\n",
      "Epoch 12/75 | Train loss: 0.024187 | Train AUC: 0.8592 | Val loss: 0.024333 | Val AUC: 0.8586\n",
      "Epoch 13/75 | Train loss: 0.024199 | Train AUC: 0.8589 | Val loss: 0.024221 | Val AUC: 0.8605\n",
      "Epoch 14/75 | Train loss: 0.024155 | Train AUC: 0.8597 | Val loss: 0.024244 | Val AUC: 0.8596\n",
      "Epoch 15/75 | Train loss: 0.024155 | Train AUC: 0.8594 | Val loss: 0.024361 | Val AUC: 0.8580\n",
      "Epoch 16/75 | Train loss: 0.024128 | Train AUC: 0.8601 | Val loss: 0.024238 | Val AUC: 0.8598\n",
      "Early stopping at epoch 17\n",
      "Run 3 best Val AUC: 0.8608\n",
      "\n",
      "=== Run 4/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024257 | Train AUC: 0.8579 | Val loss: 0.024288 | Val AUC: 0.8593\n",
      "Epoch 2/75 | Train loss: 0.024260 | Train AUC: 0.8582 | Val loss: 0.024324 | Val AUC: 0.8575\n",
      "Epoch 3/75 | Train loss: 0.024278 | Train AUC: 0.8582 | Val loss: 0.024404 | Val AUC: 0.8596\n",
      "Epoch 4/75 | Train loss: 0.024194 | Train AUC: 0.8591 | Val loss: 0.024478 | Val AUC: 0.8590\n",
      "Epoch 5/75 | Train loss: 0.024248 | Train AUC: 0.8582 | Val loss: 0.024528 | Val AUC: 0.8543\n",
      "Epoch 6/75 | Train loss: 0.024317 | Train AUC: 0.8571 | Val loss: 0.024363 | Val AUC: 0.8592\n",
      "Epoch 7/75 | Train loss: 0.024245 | Train AUC: 0.8581 | Val loss: 0.024351 | Val AUC: 0.8594\n",
      "Epoch 8/75 | Train loss: 0.024216 | Train AUC: 0.8589 | Val loss: 0.024341 | Val AUC: 0.8593\n",
      "Epoch 9/75 | Train loss: 0.024272 | Train AUC: 0.8583 | Val loss: 0.024433 | Val AUC: 0.8570\n",
      "Epoch 10/75 | Train loss: 0.024211 | Train AUC: 0.8585 | Val loss: 0.024471 | Val AUC: 0.8555\n",
      "Epoch 11/75 | Train loss: 0.024161 | Train AUC: 0.8594 | Val loss: 0.024683 | Val AUC: 0.8519\n",
      "Epoch 12/75 | Train loss: 0.024125 | Train AUC: 0.8599 | Val loss: 0.024340 | Val AUC: 0.8604\n",
      "Epoch 13/75 | Train loss: 0.024132 | Train AUC: 0.8601 | Val loss: 0.024348 | Val AUC: 0.8600\n",
      "Epoch 14/75 | Train loss: 0.024122 | Train AUC: 0.8597 | Val loss: 0.024526 | Val AUC: 0.8601\n",
      "Epoch 15/75 | Train loss: 0.024151 | Train AUC: 0.8597 | Val loss: 0.024322 | Val AUC: 0.8585\n",
      "Epoch 16/75 | Train loss: 0.024131 | Train AUC: 0.8600 | Val loss: 0.024316 | Val AUC: 0.8599\n",
      "Epoch 17/75 | Train loss: 0.024084 | Train AUC: 0.8606 | Val loss: 0.024348 | Val AUC: 0.8579\n",
      "Epoch 18/75 | Train loss: 0.024109 | Train AUC: 0.8599 | Val loss: 0.024480 | Val AUC: 0.8553\n",
      "Epoch 19/75 | Train loss: 0.024039 | Train AUC: 0.8614 | Val loss: 0.024428 | Val AUC: 0.8567\n",
      "Epoch 20/75 | Train loss: 0.024024 | Train AUC: 0.8615 | Val loss: 0.024341 | Val AUC: 0.8586\n",
      "Epoch 21/75 | Train loss: 0.024050 | Train AUC: 0.8614 | Val loss: 0.024327 | Val AUC: 0.8600\n",
      "Epoch 22/75 | Train loss: 0.024037 | Train AUC: 0.8614 | Val loss: 0.024582 | Val AUC: 0.8538\n",
      "Epoch 23/75 | Train loss: 0.024048 | Train AUC: 0.8612 | Val loss: 0.024276 | Val AUC: 0.8602\n",
      "Epoch 24/75 | Train loss: 0.024059 | Train AUC: 0.8608 | Val loss: 0.024177 | Val AUC: 0.8607\n",
      "Epoch 25/75 | Train loss: 0.024037 | Train AUC: 0.8615 | Val loss: 0.024646 | Val AUC: 0.8534\n",
      "Epoch 26/75 | Train loss: 0.024021 | Train AUC: 0.8615 | Val loss: 0.024335 | Val AUC: 0.8606\n",
      "Epoch 27/75 | Train loss: 0.023996 | Train AUC: 0.8621 | Val loss: 0.024677 | Val AUC: 0.8538\n",
      "Epoch 28/75 | Train loss: 0.024037 | Train AUC: 0.8613 | Val loss: 0.024405 | Val AUC: 0.8566\n",
      "Epoch 29/75 | Train loss: 0.024009 | Train AUC: 0.8617 | Val loss: 0.024241 | Val AUC: 0.8607\n",
      "Epoch 30/75 | Train loss: 0.024009 | Train AUC: 0.8618 | Val loss: 0.024472 | Val AUC: 0.8565\n",
      "Epoch 31/75 | Train loss: 0.023968 | Train AUC: 0.8626 | Val loss: 0.024293 | Val AUC: 0.8595\n",
      "Epoch 32/75 | Train loss: 0.023981 | Train AUC: 0.8623 | Val loss: 0.024590 | Val AUC: 0.8537\n",
      "Epoch 33/75 | Train loss: 0.023981 | Train AUC: 0.8624 | Val loss: 0.024215 | Val AUC: 0.8607\n",
      "Epoch 34/75 | Train loss: 0.023965 | Train AUC: 0.8623 | Val loss: 0.024335 | Val AUC: 0.8599\n",
      "Epoch 35/75 | Train loss: 0.023982 | Train AUC: 0.8620 | Val loss: 0.024645 | Val AUC: 0.8514\n",
      "Epoch 36/75 | Train loss: 0.023989 | Train AUC: 0.8619 | Val loss: 0.024168 | Val AUC: 0.8606\n",
      "Early stopping at epoch 37\n",
      "Run 4 best Val AUC: 0.8607\n",
      "\n",
      "=== Run 5/5 ===\n",
      "Epoch 1/75 | Train loss: 0.024165 | Train AUC: 0.8596 | Val loss: 0.024678 | Val AUC: 0.8559\n",
      "Epoch 2/75 | Train loss: 0.024184 | Train AUC: 0.8595 | Val loss: 0.024481 | Val AUC: 0.8589\n",
      "Epoch 3/75 | Train loss: 0.024220 | Train AUC: 0.8588 | Val loss: 0.024225 | Val AUC: 0.8593\n",
      "Epoch 4/75 | Train loss: 0.024197 | Train AUC: 0.8584 | Val loss: 0.024271 | Val AUC: 0.8591\n",
      "Epoch 5/75 | Train loss: 0.024210 | Train AUC: 0.8587 | Val loss: 0.024332 | Val AUC: 0.8592\n",
      "Epoch 6/75 | Train loss: 0.024214 | Train AUC: 0.8588 | Val loss: 0.024554 | Val AUC: 0.8563\n",
      "Epoch 7/75 | Train loss: 0.024234 | Train AUC: 0.8585 | Val loss: 0.024567 | Val AUC: 0.8541\n",
      "Epoch 8/75 | Train loss: 0.024200 | Train AUC: 0.8590 | Val loss: 0.024441 | Val AUC: 0.8554\n",
      "Epoch 9/75 | Train loss: 0.024167 | Train AUC: 0.8594 | Val loss: 0.024644 | Val AUC: 0.8581\n",
      "Epoch 10/75 | Train loss: 0.024101 | Train AUC: 0.8610 | Val loss: 0.024558 | Val AUC: 0.8535\n",
      "Epoch 11/75 | Train loss: 0.024085 | Train AUC: 0.8604 | Val loss: 0.024263 | Val AUC: 0.8593\n",
      "Epoch 12/75 | Train loss: 0.024130 | Train AUC: 0.8599 | Val loss: 0.024265 | Val AUC: 0.8596\n",
      "Epoch 13/75 | Train loss: 0.024097 | Train AUC: 0.8605 | Val loss: 0.024322 | Val AUC: 0.8584\n",
      "Epoch 14/75 | Train loss: 0.024066 | Train AUC: 0.8612 | Val loss: 0.024397 | Val AUC: 0.8559\n",
      "Epoch 15/75 | Train loss: 0.024088 | Train AUC: 0.8606 | Val loss: 0.024671 | Val AUC: 0.8522\n",
      "Epoch 16/75 | Train loss: 0.024128 | Train AUC: 0.8599 | Val loss: 0.024282 | Val AUC: 0.8598\n",
      "Epoch 17/75 | Train loss: 0.024043 | Train AUC: 0.8615 | Val loss: 0.024385 | Val AUC: 0.8577\n",
      "Epoch 18/75 | Train loss: 0.024034 | Train AUC: 0.8613 | Val loss: 0.024341 | Val AUC: 0.8585\n",
      "Epoch 19/75 | Train loss: 0.024046 | Train AUC: 0.8612 | Val loss: 0.024492 | Val AUC: 0.8560\n",
      "Epoch 20/75 | Train loss: 0.024012 | Train AUC: 0.8616 | Val loss: 0.024429 | Val AUC: 0.8559\n",
      "Epoch 21/75 | Train loss: 0.024034 | Train AUC: 0.8615 | Val loss: 0.024501 | Val AUC: 0.8552\n",
      "Epoch 22/75 | Train loss: 0.024019 | Train AUC: 0.8616 | Val loss: 0.024307 | Val AUC: 0.8582\n",
      "Epoch 23/75 | Train loss: 0.024031 | Train AUC: 0.8614 | Val loss: 0.024333 | Val AUC: 0.8567\n",
      "Epoch 24/75 | Train loss: 0.023955 | Train AUC: 0.8627 | Val loss: 0.024266 | Val AUC: 0.8594\n",
      "Epoch 25/75 | Train loss: 0.023950 | Train AUC: 0.8627 | Val loss: 0.024365 | Val AUC: 0.8587\n",
      "Epoch 26/75 | Train loss: 0.023976 | Train AUC: 0.8623 | Val loss: 0.024300 | Val AUC: 0.8597\n",
      "Epoch 27/75 | Train loss: 0.023966 | Train AUC: 0.8625 | Val loss: 0.024353 | Val AUC: 0.8573\n",
      "Epoch 28/75 | Train loss: 0.023922 | Train AUC: 0.8632 | Val loss: 0.024534 | Val AUC: 0.8561\n",
      "Early stopping at epoch 29\n",
      "Run 5 best Val AUC: 0.8598\n",
      "\n",
      "Best model across all runs restored (Val AUC = 0.8608)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "overall_best_val_auc = 0.0\n",
    "overall_best_model_state = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n=== Run {run + 1}/{num_runs} ===\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', patience=5, factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_auc_this_run = 0.0\n",
    "    best_model_state_this_run = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_logits, train_labels = [], []\n",
    "\n",
    "        for x_num, x_cat, yb in train_loader:\n",
    "            x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_num, x_cat)  \n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * x_num.size(0)\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_labels.append(yb.cpu())\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_logits = torch.cat(train_logits)\n",
    "        train_labels = torch.cat(train_labels)\n",
    "        train_probs = torch.sigmoid(train_logits).numpy()\n",
    "        train_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_logits, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_num, x_cat, yb in val_loader:\n",
    "                x_num, x_cat, yb = x_num.to(device), x_cat.to(device), yb.to(device).float()\n",
    "                logits = model(x_num, x_cat)\n",
    "            \n",
    "                loss = loss_fn(logits, yb)\n",
    "                total_val_loss += loss.item() * x_num.size(0)\n",
    "                val_logits.append(logits.cpu())\n",
    "                val_labels.append(yb.cpu())\n",
    "\n",
    "        val_loss = total_val_loss / len(val_loader.dataset)\n",
    "        val_logits = torch.cat(val_logits)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        val_probs = torch.sigmoid(val_logits).numpy()\n",
    "        val_auc = roc_auc_score(val_labels.numpy(), val_probs)\n",
    "\n",
    "        if val_auc > best_val_auc_this_run:\n",
    "            best_val_auc_this_run = val_auc\n",
    "            best_model_state_this_run = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "              f\"Train loss: {train_loss:.6f} | Train AUC: {train_auc:.4f} | \"\n",
    "              f\"Val loss: {val_loss:.6f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    print(f\"Run {run + 1} best Val AUC: {best_val_auc_this_run:.4f}\")\n",
    "\n",
    "    if best_val_auc_this_run > overall_best_val_auc:\n",
    "        overall_best_val_auc = best_val_auc_this_run\n",
    "        overall_best_model_state = copy.deepcopy(best_model_state_this_run)\n",
    "\n",
    "model.load_state_dict(overall_best_model_state)\n",
    "print(f\"\\nBest model across all runs restored (Val AUC = {overall_best_val_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56e8e152-c918-4152-a390-4a626dbb0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.33994782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.85      0.91     27993\n",
      "   Defaulted       0.25      0.71      0.37      2001\n",
      "\n",
      "    accuracy                           0.84     29994\n",
      "   macro avg       0.62      0.78      0.64     29994\n",
      "weighted avg       0.93      0.84      0.87     29994\n",
      "\n",
      "Accuracy: 84.08%\n",
      "ROC AUC: 0.867\n",
      "TP=1430, FP=4205, TN=23788, FN=571\n",
      "Accuracy for class 'Repaid': 84.98%\n",
      "Accuracy for class 'Defaulted': 71.46%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_val_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in val_loader:  \n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_val_probs = np.array(y_val_probs)\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_val_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_val, y_val_probs, thresholds, beta=2)\n",
    "best_thresh_a = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_test_probs = []\n",
    "with torch.no_grad():\n",
    "    for x_num, x_cat, _ in test_loader:\n",
    "        x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "        outputs = model(x_num, x_cat)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        y_test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "y_test_probs = np.array(y_test_probs)\n",
    "y_test_pred_opt = (y_test_probs > best_thresh_a).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_test_pred_opt, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_test_pred_opt)\n",
    "roc_auc = roc_auc_score(y_test, y_test_probs)\n",
    "cm = confusion_matrix(y_test, y_test_pred_opt)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_a)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_a:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdba09d8-8307-4ade-b197-9eb639de9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d148b146-0750-409b-ae90-c33a80b4862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=3, reg_alpha=0, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.03, max_depth=8, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=7, min_child_weight=1, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=27.94013477511362, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=27.94013477511362, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.05, max_depth=5, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=27.94013477511362, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=6, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.03, max_depth=7, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=7, reg_alpha=0.1, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.03, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=13.97006738755681, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=13.97006738755681, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=1.0, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=13.97006738755681, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=34.925168468892025, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=34.925168468892025, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=34.925168468892025, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=5, reg_alpha=0.05, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=27.94013477511362, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=27.94013477511362, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=27.94013477511362, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=13.97006738755681, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, min_child_weight=7, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.03, max_depth=4, min_child_weight=5, reg_alpha=0.3, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=1, reg_alpha=0.3, reg_lambda=0.8, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=1.0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.05, reg_lambda=0.5, scale_pos_weight=41.91020216267043, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.03, max_depth=8, min_child_weight=3, reg_alpha=0.05, reg_lambda=1.0, scale_pos_weight=41.91020216267043, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.03, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=1.2, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=3, reg_alpha=0.3, reg_lambda=0.5, scale_pos_weight=27.94013477511362, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=1.0, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=1.2, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=7, reg_alpha=0.3, reg_lambda=1.0, scale_pos_weight=13.97006738755681, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=1, reg_alpha=0.1, reg_lambda=0.8, scale_pos_weight=20.955101081335215, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.03, max_depth=5, min_child_weight=7, reg_alpha=0, reg_lambda=0.5, scale_pos_weight=34.925168468892025, subsample=0.9; total time=   0.7s\n",
      "Best params: {'subsample': 0.9, 'scale_pos_weight': np.float64(13.97006738755681), 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_param = find_best_param(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a22f3a-9ecb-47c1-aaa5-d4b706c9d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_b = xgb.XGBClassifier(\n",
    "    **best_param,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=[\"auc\"],\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2953291-5c20-4a1f-851f-bf0453fa7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84969\n",
      "[1]\tvalidation_0-auc:0.85249\n",
      "[2]\tvalidation_0-auc:0.85382\n",
      "[3]\tvalidation_0-auc:0.85448\n",
      "[4]\tvalidation_0-auc:0.85440\n",
      "[5]\tvalidation_0-auc:0.85554\n",
      "[6]\tvalidation_0-auc:0.85626\n",
      "[7]\tvalidation_0-auc:0.85650\n",
      "[8]\tvalidation_0-auc:0.85667\n",
      "[9]\tvalidation_0-auc:0.85688\n",
      "[10]\tvalidation_0-auc:0.85688\n",
      "[11]\tvalidation_0-auc:0.85684\n",
      "[12]\tvalidation_0-auc:0.85687\n",
      "[13]\tvalidation_0-auc:0.85679\n",
      "[14]\tvalidation_0-auc:0.85715\n",
      "[15]\tvalidation_0-auc:0.85719\n",
      "[16]\tvalidation_0-auc:0.85711\n",
      "[17]\tvalidation_0-auc:0.85717\n",
      "[18]\tvalidation_0-auc:0.85717\n",
      "[19]\tvalidation_0-auc:0.85712\n",
      "[20]\tvalidation_0-auc:0.85712\n",
      "[21]\tvalidation_0-auc:0.85712\n",
      "[22]\tvalidation_0-auc:0.85707\n",
      "[23]\tvalidation_0-auc:0.85716\n",
      "[24]\tvalidation_0-auc:0.85715\n",
      "[25]\tvalidation_0-auc:0.85742\n",
      "[26]\tvalidation_0-auc:0.85735\n",
      "[27]\tvalidation_0-auc:0.85741\n",
      "[28]\tvalidation_0-auc:0.85742\n",
      "[29]\tvalidation_0-auc:0.85757\n",
      "[30]\tvalidation_0-auc:0.85760\n",
      "[31]\tvalidation_0-auc:0.85769\n",
      "[32]\tvalidation_0-auc:0.85771\n",
      "[33]\tvalidation_0-auc:0.85760\n",
      "[34]\tvalidation_0-auc:0.85761\n",
      "[35]\tvalidation_0-auc:0.85764\n",
      "[36]\tvalidation_0-auc:0.85762\n",
      "[37]\tvalidation_0-auc:0.85760\n",
      "[38]\tvalidation_0-auc:0.85761\n",
      "[39]\tvalidation_0-auc:0.85776\n",
      "[40]\tvalidation_0-auc:0.85772\n",
      "[41]\tvalidation_0-auc:0.85771\n",
      "[42]\tvalidation_0-auc:0.85774\n",
      "[43]\tvalidation_0-auc:0.85785\n",
      "[44]\tvalidation_0-auc:0.85781\n",
      "[45]\tvalidation_0-auc:0.85785\n",
      "[46]\tvalidation_0-auc:0.85791\n",
      "[47]\tvalidation_0-auc:0.85788\n",
      "[48]\tvalidation_0-auc:0.85796\n",
      "[49]\tvalidation_0-auc:0.85801\n",
      "[50]\tvalidation_0-auc:0.85809\n",
      "[51]\tvalidation_0-auc:0.85813\n",
      "[52]\tvalidation_0-auc:0.85828\n",
      "[53]\tvalidation_0-auc:0.85831\n",
      "[54]\tvalidation_0-auc:0.85829\n",
      "[55]\tvalidation_0-auc:0.85829\n",
      "[56]\tvalidation_0-auc:0.85833\n",
      "[57]\tvalidation_0-auc:0.85837\n",
      "[58]\tvalidation_0-auc:0.85843\n",
      "[59]\tvalidation_0-auc:0.85849\n",
      "[60]\tvalidation_0-auc:0.85849\n",
      "[61]\tvalidation_0-auc:0.85849\n",
      "[62]\tvalidation_0-auc:0.85851\n",
      "[63]\tvalidation_0-auc:0.85848\n",
      "[64]\tvalidation_0-auc:0.85850\n",
      "[65]\tvalidation_0-auc:0.85844\n",
      "[66]\tvalidation_0-auc:0.85847\n",
      "[67]\tvalidation_0-auc:0.85849\n",
      "[68]\tvalidation_0-auc:0.85851\n",
      "[69]\tvalidation_0-auc:0.85855\n",
      "[70]\tvalidation_0-auc:0.85858\n",
      "[71]\tvalidation_0-auc:0.85860\n",
      "[72]\tvalidation_0-auc:0.85862\n",
      "[73]\tvalidation_0-auc:0.85860\n",
      "[74]\tvalidation_0-auc:0.85859\n",
      "[75]\tvalidation_0-auc:0.85857\n",
      "[76]\tvalidation_0-auc:0.85854\n",
      "[77]\tvalidation_0-auc:0.85858\n",
      "[78]\tvalidation_0-auc:0.85857\n",
      "[79]\tvalidation_0-auc:0.85853\n",
      "[80]\tvalidation_0-auc:0.85851\n",
      "[81]\tvalidation_0-auc:0.85852\n",
      "[82]\tvalidation_0-auc:0.85852\n",
      "[83]\tvalidation_0-auc:0.85851\n",
      "[84]\tvalidation_0-auc:0.85850\n",
      "[85]\tvalidation_0-auc:0.85851\n",
      "[86]\tvalidation_0-auc:0.85848\n",
      "[87]\tvalidation_0-auc:0.85848\n",
      "[88]\tvalidation_0-auc:0.85847\n",
      "[89]\tvalidation_0-auc:0.85848\n",
      "[90]\tvalidation_0-auc:0.85850\n",
      "[91]\tvalidation_0-auc:0.85850\n",
      "[92]\tvalidation_0-auc:0.85850\n",
      "[93]\tvalidation_0-auc:0.85851\n",
      "[94]\tvalidation_0-auc:0.85853\n",
      "[95]\tvalidation_0-auc:0.85851\n",
      "[96]\tvalidation_0-auc:0.85852\n",
      "[97]\tvalidation_0-auc:0.85853\n",
      "[98]\tvalidation_0-auc:0.85855\n",
      "[99]\tvalidation_0-auc:0.85861\n",
      "[100]\tvalidation_0-auc:0.85866\n",
      "[101]\tvalidation_0-auc:0.85866\n",
      "[102]\tvalidation_0-auc:0.85868\n",
      "[103]\tvalidation_0-auc:0.85873\n",
      "[104]\tvalidation_0-auc:0.85873\n",
      "[105]\tvalidation_0-auc:0.85876\n",
      "[106]\tvalidation_0-auc:0.85876\n",
      "[107]\tvalidation_0-auc:0.85879\n",
      "[108]\tvalidation_0-auc:0.85879\n",
      "[109]\tvalidation_0-auc:0.85887\n",
      "[110]\tvalidation_0-auc:0.85892\n",
      "[111]\tvalidation_0-auc:0.85896\n",
      "[112]\tvalidation_0-auc:0.85895\n",
      "[113]\tvalidation_0-auc:0.85899\n",
      "[114]\tvalidation_0-auc:0.85900\n",
      "[115]\tvalidation_0-auc:0.85904\n",
      "[116]\tvalidation_0-auc:0.85904\n",
      "[117]\tvalidation_0-auc:0.85906\n",
      "[118]\tvalidation_0-auc:0.85906\n",
      "[119]\tvalidation_0-auc:0.85905\n",
      "[120]\tvalidation_0-auc:0.85911\n",
      "[121]\tvalidation_0-auc:0.85915\n",
      "[122]\tvalidation_0-auc:0.85913\n",
      "[123]\tvalidation_0-auc:0.85917\n",
      "[124]\tvalidation_0-auc:0.85922\n",
      "[125]\tvalidation_0-auc:0.85927\n",
      "[126]\tvalidation_0-auc:0.85931\n",
      "[127]\tvalidation_0-auc:0.85932\n",
      "[128]\tvalidation_0-auc:0.85934\n",
      "[129]\tvalidation_0-auc:0.85933\n",
      "[130]\tvalidation_0-auc:0.85934\n",
      "[131]\tvalidation_0-auc:0.85935\n",
      "[132]\tvalidation_0-auc:0.85941\n",
      "[133]\tvalidation_0-auc:0.85941\n",
      "[134]\tvalidation_0-auc:0.85944\n",
      "[135]\tvalidation_0-auc:0.85948\n",
      "[136]\tvalidation_0-auc:0.85948\n",
      "[137]\tvalidation_0-auc:0.85948\n",
      "[138]\tvalidation_0-auc:0.85948\n",
      "[139]\tvalidation_0-auc:0.85950\n",
      "[140]\tvalidation_0-auc:0.85949\n",
      "[141]\tvalidation_0-auc:0.85949\n",
      "[142]\tvalidation_0-auc:0.85951\n",
      "[143]\tvalidation_0-auc:0.85958\n",
      "[144]\tvalidation_0-auc:0.85957\n",
      "[145]\tvalidation_0-auc:0.85958\n",
      "[146]\tvalidation_0-auc:0.85959\n",
      "[147]\tvalidation_0-auc:0.85959\n",
      "[148]\tvalidation_0-auc:0.85960\n",
      "[149]\tvalidation_0-auc:0.85964\n",
      "[150]\tvalidation_0-auc:0.85968\n",
      "[151]\tvalidation_0-auc:0.85970\n",
      "[152]\tvalidation_0-auc:0.85970\n",
      "[153]\tvalidation_0-auc:0.85973\n",
      "[154]\tvalidation_0-auc:0.85975\n",
      "[155]\tvalidation_0-auc:0.85976\n",
      "[156]\tvalidation_0-auc:0.85979\n",
      "[157]\tvalidation_0-auc:0.85979\n",
      "[158]\tvalidation_0-auc:0.85976\n",
      "[159]\tvalidation_0-auc:0.85975\n",
      "[160]\tvalidation_0-auc:0.85978\n",
      "[161]\tvalidation_0-auc:0.85980\n",
      "[162]\tvalidation_0-auc:0.85981\n",
      "[163]\tvalidation_0-auc:0.85985\n",
      "[164]\tvalidation_0-auc:0.85983\n",
      "[165]\tvalidation_0-auc:0.85981\n",
      "[166]\tvalidation_0-auc:0.85982\n",
      "[167]\tvalidation_0-auc:0.85982\n",
      "[168]\tvalidation_0-auc:0.85985\n",
      "[169]\tvalidation_0-auc:0.85986\n",
      "[170]\tvalidation_0-auc:0.85987\n",
      "[171]\tvalidation_0-auc:0.85988\n",
      "[172]\tvalidation_0-auc:0.85989\n",
      "[173]\tvalidation_0-auc:0.85992\n",
      "[174]\tvalidation_0-auc:0.85994\n",
      "[175]\tvalidation_0-auc:0.85996\n",
      "[176]\tvalidation_0-auc:0.86000\n",
      "[177]\tvalidation_0-auc:0.86003\n",
      "[178]\tvalidation_0-auc:0.86005\n",
      "[179]\tvalidation_0-auc:0.86005\n",
      "[180]\tvalidation_0-auc:0.86005\n",
      "[181]\tvalidation_0-auc:0.86005\n",
      "[182]\tvalidation_0-auc:0.86006\n",
      "[183]\tvalidation_0-auc:0.86006\n",
      "[184]\tvalidation_0-auc:0.86009\n",
      "[185]\tvalidation_0-auc:0.86016\n",
      "[186]\tvalidation_0-auc:0.86018\n",
      "[187]\tvalidation_0-auc:0.86017\n",
      "[188]\tvalidation_0-auc:0.86017\n",
      "[189]\tvalidation_0-auc:0.86019\n",
      "[190]\tvalidation_0-auc:0.86023\n",
      "[191]\tvalidation_0-auc:0.86024\n",
      "[192]\tvalidation_0-auc:0.86025\n",
      "[193]\tvalidation_0-auc:0.86024\n",
      "[194]\tvalidation_0-auc:0.86025\n",
      "[195]\tvalidation_0-auc:0.86027\n",
      "[196]\tvalidation_0-auc:0.86026\n",
      "[197]\tvalidation_0-auc:0.86026\n",
      "[198]\tvalidation_0-auc:0.86028\n",
      "[199]\tvalidation_0-auc:0.86031\n",
      "[200]\tvalidation_0-auc:0.86033\n",
      "[201]\tvalidation_0-auc:0.86032\n",
      "[202]\tvalidation_0-auc:0.86033\n",
      "[203]\tvalidation_0-auc:0.86035\n",
      "[204]\tvalidation_0-auc:0.86037\n",
      "[205]\tvalidation_0-auc:0.86037\n",
      "[206]\tvalidation_0-auc:0.86037\n",
      "[207]\tvalidation_0-auc:0.86037\n",
      "[208]\tvalidation_0-auc:0.86036\n",
      "[209]\tvalidation_0-auc:0.86038\n",
      "[210]\tvalidation_0-auc:0.86036\n",
      "[211]\tvalidation_0-auc:0.86039\n",
      "[212]\tvalidation_0-auc:0.86041\n",
      "[213]\tvalidation_0-auc:0.86042\n",
      "[214]\tvalidation_0-auc:0.86040\n",
      "[215]\tvalidation_0-auc:0.86041\n",
      "[216]\tvalidation_0-auc:0.86044\n",
      "[217]\tvalidation_0-auc:0.86044\n",
      "[218]\tvalidation_0-auc:0.86043\n",
      "[219]\tvalidation_0-auc:0.86042\n",
      "[220]\tvalidation_0-auc:0.86042\n",
      "[221]\tvalidation_0-auc:0.86042\n",
      "[222]\tvalidation_0-auc:0.86043\n",
      "[223]\tvalidation_0-auc:0.86044\n",
      "[224]\tvalidation_0-auc:0.86046\n",
      "[225]\tvalidation_0-auc:0.86046\n",
      "[226]\tvalidation_0-auc:0.86045\n",
      "[227]\tvalidation_0-auc:0.86047\n",
      "[228]\tvalidation_0-auc:0.86045\n",
      "[229]\tvalidation_0-auc:0.86049\n",
      "[230]\tvalidation_0-auc:0.86051\n",
      "[231]\tvalidation_0-auc:0.86051\n",
      "[232]\tvalidation_0-auc:0.86053\n",
      "[233]\tvalidation_0-auc:0.86056\n",
      "[234]\tvalidation_0-auc:0.86055\n",
      "[235]\tvalidation_0-auc:0.86055\n",
      "[236]\tvalidation_0-auc:0.86059\n",
      "[237]\tvalidation_0-auc:0.86059\n",
      "[238]\tvalidation_0-auc:0.86058\n",
      "[239]\tvalidation_0-auc:0.86059\n",
      "[240]\tvalidation_0-auc:0.86060\n",
      "[241]\tvalidation_0-auc:0.86061\n",
      "[242]\tvalidation_0-auc:0.86063\n",
      "[243]\tvalidation_0-auc:0.86065\n",
      "[244]\tvalidation_0-auc:0.86065\n",
      "[245]\tvalidation_0-auc:0.86067\n",
      "[246]\tvalidation_0-auc:0.86065\n",
      "[247]\tvalidation_0-auc:0.86067\n",
      "[248]\tvalidation_0-auc:0.86068\n",
      "[249]\tvalidation_0-auc:0.86066\n",
      "[250]\tvalidation_0-auc:0.86066\n",
      "[251]\tvalidation_0-auc:0.86065\n",
      "[252]\tvalidation_0-auc:0.86069\n",
      "[253]\tvalidation_0-auc:0.86072\n",
      "[254]\tvalidation_0-auc:0.86072\n",
      "[255]\tvalidation_0-auc:0.86070\n",
      "[256]\tvalidation_0-auc:0.86069\n",
      "[257]\tvalidation_0-auc:0.86071\n",
      "[258]\tvalidation_0-auc:0.86072\n",
      "[259]\tvalidation_0-auc:0.86073\n",
      "[260]\tvalidation_0-auc:0.86075\n",
      "[261]\tvalidation_0-auc:0.86076\n",
      "[262]\tvalidation_0-auc:0.86078\n",
      "[263]\tvalidation_0-auc:0.86078\n",
      "[264]\tvalidation_0-auc:0.86079\n",
      "[265]\tvalidation_0-auc:0.86081\n",
      "[266]\tvalidation_0-auc:0.86083\n",
      "[267]\tvalidation_0-auc:0.86082\n",
      "[268]\tvalidation_0-auc:0.86082\n",
      "[269]\tvalidation_0-auc:0.86084\n",
      "[270]\tvalidation_0-auc:0.86084\n",
      "[271]\tvalidation_0-auc:0.86084\n",
      "[272]\tvalidation_0-auc:0.86085\n",
      "[273]\tvalidation_0-auc:0.86085\n",
      "[274]\tvalidation_0-auc:0.86085\n",
      "[275]\tvalidation_0-auc:0.86086\n",
      "[276]\tvalidation_0-auc:0.86088\n",
      "[277]\tvalidation_0-auc:0.86090\n",
      "[278]\tvalidation_0-auc:0.86090\n",
      "[279]\tvalidation_0-auc:0.86093\n",
      "[280]\tvalidation_0-auc:0.86091\n",
      "[281]\tvalidation_0-auc:0.86093\n",
      "[282]\tvalidation_0-auc:0.86092\n",
      "[283]\tvalidation_0-auc:0.86092\n",
      "[284]\tvalidation_0-auc:0.86094\n",
      "[285]\tvalidation_0-auc:0.86094\n",
      "[286]\tvalidation_0-auc:0.86093\n",
      "[287]\tvalidation_0-auc:0.86094\n",
      "[288]\tvalidation_0-auc:0.86092\n",
      "[289]\tvalidation_0-auc:0.86093\n",
      "[290]\tvalidation_0-auc:0.86093\n",
      "[291]\tvalidation_0-auc:0.86095\n",
      "[292]\tvalidation_0-auc:0.86096\n",
      "[293]\tvalidation_0-auc:0.86096\n",
      "[294]\tvalidation_0-auc:0.86096\n",
      "[295]\tvalidation_0-auc:0.86095\n",
      "[296]\tvalidation_0-auc:0.86093\n",
      "[297]\tvalidation_0-auc:0.86093\n",
      "[298]\tvalidation_0-auc:0.86094\n",
      "[299]\tvalidation_0-auc:0.86094\n",
      "[300]\tvalidation_0-auc:0.86095\n",
      "[301]\tvalidation_0-auc:0.86095\n",
      "[302]\tvalidation_0-auc:0.86095\n",
      "[303]\tvalidation_0-auc:0.86095\n",
      "[304]\tvalidation_0-auc:0.86096\n",
      "[305]\tvalidation_0-auc:0.86095\n",
      "[306]\tvalidation_0-auc:0.86094\n",
      "[307]\tvalidation_0-auc:0.86096\n",
      "[308]\tvalidation_0-auc:0.86095\n",
      "[309]\tvalidation_0-auc:0.86097\n",
      "[310]\tvalidation_0-auc:0.86097\n",
      "[311]\tvalidation_0-auc:0.86099\n",
      "[312]\tvalidation_0-auc:0.86098\n",
      "[313]\tvalidation_0-auc:0.86098\n",
      "[314]\tvalidation_0-auc:0.86099\n",
      "[315]\tvalidation_0-auc:0.86099\n",
      "[316]\tvalidation_0-auc:0.86099\n",
      "[317]\tvalidation_0-auc:0.86099\n",
      "[318]\tvalidation_0-auc:0.86099\n",
      "[319]\tvalidation_0-auc:0.86098\n",
      "[320]\tvalidation_0-auc:0.86099\n",
      "[321]\tvalidation_0-auc:0.86099\n",
      "[322]\tvalidation_0-auc:0.86099\n",
      "[323]\tvalidation_0-auc:0.86100\n",
      "[324]\tvalidation_0-auc:0.86100\n",
      "[325]\tvalidation_0-auc:0.86099\n",
      "[326]\tvalidation_0-auc:0.86101\n",
      "[327]\tvalidation_0-auc:0.86101\n",
      "[328]\tvalidation_0-auc:0.86103\n",
      "[329]\tvalidation_0-auc:0.86103\n",
      "[330]\tvalidation_0-auc:0.86103\n",
      "[331]\tvalidation_0-auc:0.86104\n",
      "[332]\tvalidation_0-auc:0.86103\n",
      "[333]\tvalidation_0-auc:0.86103\n",
      "[334]\tvalidation_0-auc:0.86102\n",
      "[335]\tvalidation_0-auc:0.86104\n",
      "[336]\tvalidation_0-auc:0.86105\n",
      "[337]\tvalidation_0-auc:0.86104\n",
      "[338]\tvalidation_0-auc:0.86103\n",
      "[339]\tvalidation_0-auc:0.86102\n",
      "[340]\tvalidation_0-auc:0.86103\n",
      "[341]\tvalidation_0-auc:0.86104\n",
      "[342]\tvalidation_0-auc:0.86104\n",
      "[343]\tvalidation_0-auc:0.86104\n",
      "[344]\tvalidation_0-auc:0.86103\n",
      "[345]\tvalidation_0-auc:0.86104\n",
      "[346]\tvalidation_0-auc:0.86105\n",
      "[347]\tvalidation_0-auc:0.86106\n",
      "[348]\tvalidation_0-auc:0.86106\n",
      "[349]\tvalidation_0-auc:0.86106\n",
      "[350]\tvalidation_0-auc:0.86106\n",
      "[351]\tvalidation_0-auc:0.86106\n",
      "[352]\tvalidation_0-auc:0.86107\n",
      "[353]\tvalidation_0-auc:0.86108\n",
      "[354]\tvalidation_0-auc:0.86109\n",
      "[355]\tvalidation_0-auc:0.86110\n",
      "[356]\tvalidation_0-auc:0.86111\n",
      "[357]\tvalidation_0-auc:0.86111\n",
      "[358]\tvalidation_0-auc:0.86112\n",
      "[359]\tvalidation_0-auc:0.86112\n",
      "[360]\tvalidation_0-auc:0.86112\n",
      "[361]\tvalidation_0-auc:0.86112\n",
      "[362]\tvalidation_0-auc:0.86112\n",
      "[363]\tvalidation_0-auc:0.86111\n",
      "[364]\tvalidation_0-auc:0.86110\n",
      "[365]\tvalidation_0-auc:0.86110\n",
      "[366]\tvalidation_0-auc:0.86110\n",
      "[367]\tvalidation_0-auc:0.86109\n",
      "[368]\tvalidation_0-auc:0.86109\n",
      "[369]\tvalidation_0-auc:0.86109\n",
      "[370]\tvalidation_0-auc:0.86110\n",
      "[371]\tvalidation_0-auc:0.86109\n",
      "[372]\tvalidation_0-auc:0.86110\n",
      "[373]\tvalidation_0-auc:0.86109\n",
      "[374]\tvalidation_0-auc:0.86109\n",
      "[375]\tvalidation_0-auc:0.86109\n",
      "[376]\tvalidation_0-auc:0.86108\n",
      "[377]\tvalidation_0-auc:0.86108\n",
      "[378]\tvalidation_0-auc:0.86107\n",
      "[379]\tvalidation_0-auc:0.86108\n",
      "[380]\tvalidation_0-auc:0.86109\n",
      "[381]\tvalidation_0-auc:0.86110\n",
      "[382]\tvalidation_0-auc:0.86111\n",
      "[383]\tvalidation_0-auc:0.86110\n",
      "[384]\tvalidation_0-auc:0.86111\n",
      "[385]\tvalidation_0-auc:0.86112\n",
      "[386]\tvalidation_0-auc:0.86111\n",
      "[387]\tvalidation_0-auc:0.86110\n",
      "[388]\tvalidation_0-auc:0.86111\n",
      "[389]\tvalidation_0-auc:0.86111\n",
      "[390]\tvalidation_0-auc:0.86111\n",
      "[391]\tvalidation_0-auc:0.86111\n",
      "[392]\tvalidation_0-auc:0.86111\n",
      "[393]\tvalidation_0-auc:0.86111\n",
      "[394]\tvalidation_0-auc:0.86112\n",
      "[395]\tvalidation_0-auc:0.86112\n",
      "[396]\tvalidation_0-auc:0.86113\n",
      "[397]\tvalidation_0-auc:0.86114\n",
      "[398]\tvalidation_0-auc:0.86113\n",
      "[399]\tvalidation_0-auc:0.86113\n",
      "[400]\tvalidation_0-auc:0.86114\n",
      "[401]\tvalidation_0-auc:0.86113\n",
      "[402]\tvalidation_0-auc:0.86114\n",
      "[403]\tvalidation_0-auc:0.86113\n",
      "[404]\tvalidation_0-auc:0.86112\n",
      "[405]\tvalidation_0-auc:0.86112\n",
      "[406]\tvalidation_0-auc:0.86111\n",
      "[407]\tvalidation_0-auc:0.86111\n",
      "[408]\tvalidation_0-auc:0.86112\n",
      "[409]\tvalidation_0-auc:0.86111\n",
      "[410]\tvalidation_0-auc:0.86110\n",
      "[411]\tvalidation_0-auc:0.86110\n",
      "[412]\tvalidation_0-auc:0.86110\n",
      "[413]\tvalidation_0-auc:0.86110\n",
      "[414]\tvalidation_0-auc:0.86111\n",
      "[415]\tvalidation_0-auc:0.86110\n",
      "[416]\tvalidation_0-auc:0.86109\n",
      "[417]\tvalidation_0-auc:0.86108\n",
      "[418]\tvalidation_0-auc:0.86108\n",
      "[419]\tvalidation_0-auc:0.86108\n",
      "[420]\tvalidation_0-auc:0.86108\n",
      "[421]\tvalidation_0-auc:0.86110\n",
      "[422]\tvalidation_0-auc:0.86111\n",
      "[423]\tvalidation_0-auc:0.86111\n",
      "[424]\tvalidation_0-auc:0.86110\n",
      "[425]\tvalidation_0-auc:0.86111\n",
      "[426]\tvalidation_0-auc:0.86111\n",
      "[427]\tvalidation_0-auc:0.86111\n",
      "[428]\tvalidation_0-auc:0.86112\n",
      "[429]\tvalidation_0-auc:0.86111\n",
      "[430]\tvalidation_0-auc:0.86112\n",
      "[431]\tvalidation_0-auc:0.86110\n",
      "[432]\tvalidation_0-auc:0.86110\n",
      "[433]\tvalidation_0-auc:0.86110\n",
      "[434]\tvalidation_0-auc:0.86111\n",
      "[435]\tvalidation_0-auc:0.86111\n",
      "[436]\tvalidation_0-auc:0.86110\n",
      "[437]\tvalidation_0-auc:0.86110\n",
      "[438]\tvalidation_0-auc:0.86110\n",
      "[439]\tvalidation_0-auc:0.86111\n",
      "[440]\tvalidation_0-auc:0.86112\n",
      "[441]\tvalidation_0-auc:0.86112\n",
      "[442]\tvalidation_0-auc:0.86112\n",
      "[443]\tvalidation_0-auc:0.86112\n",
      "[444]\tvalidation_0-auc:0.86113\n",
      "[445]\tvalidation_0-auc:0.86114\n",
      "[446]\tvalidation_0-auc:0.86114\n",
      "[447]\tvalidation_0-auc:0.86114\n",
      "[448]\tvalidation_0-auc:0.86115\n",
      "[449]\tvalidation_0-auc:0.86114\n",
      "[450]\tvalidation_0-auc:0.86114\n",
      "[451]\tvalidation_0-auc:0.86114\n",
      "[452]\tvalidation_0-auc:0.86112\n",
      "[453]\tvalidation_0-auc:0.86113\n",
      "[454]\tvalidation_0-auc:0.86113\n",
      "[455]\tvalidation_0-auc:0.86114\n",
      "[456]\tvalidation_0-auc:0.86114\n",
      "[457]\tvalidation_0-auc:0.86114\n",
      "[458]\tvalidation_0-auc:0.86114\n",
      "[459]\tvalidation_0-auc:0.86114\n",
      "[460]\tvalidation_0-auc:0.86114\n",
      "[461]\tvalidation_0-auc:0.86113\n",
      "[462]\tvalidation_0-auc:0.86111\n",
      "[463]\tvalidation_0-auc:0.86112\n",
      "[464]\tvalidation_0-auc:0.86112\n",
      "[465]\tvalidation_0-auc:0.86113\n",
      "[466]\tvalidation_0-auc:0.86113\n",
      "[467]\tvalidation_0-auc:0.86112\n",
      "[468]\tvalidation_0-auc:0.86112\n",
      "[469]\tvalidation_0-auc:0.86112\n",
      "[470]\tvalidation_0-auc:0.86113\n",
      "[471]\tvalidation_0-auc:0.86113\n",
      "[472]\tvalidation_0-auc:0.86113\n",
      "[473]\tvalidation_0-auc:0.86113\n",
      "[474]\tvalidation_0-auc:0.86113\n",
      "[475]\tvalidation_0-auc:0.86113\n",
      "[476]\tvalidation_0-auc:0.86116\n",
      "[477]\tvalidation_0-auc:0.86114\n",
      "[478]\tvalidation_0-auc:0.86115\n",
      "[479]\tvalidation_0-auc:0.86114\n",
      "[480]\tvalidation_0-auc:0.86116\n",
      "[481]\tvalidation_0-auc:0.86116\n",
      "[482]\tvalidation_0-auc:0.86116\n",
      "[483]\tvalidation_0-auc:0.86117\n",
      "[484]\tvalidation_0-auc:0.86116\n",
      "[485]\tvalidation_0-auc:0.86116\n",
      "[486]\tvalidation_0-auc:0.86116\n",
      "[487]\tvalidation_0-auc:0.86115\n",
      "[488]\tvalidation_0-auc:0.86114\n",
      "[489]\tvalidation_0-auc:0.86115\n",
      "[490]\tvalidation_0-auc:0.86114\n",
      "[491]\tvalidation_0-auc:0.86113\n",
      "[492]\tvalidation_0-auc:0.86112\n",
      "[493]\tvalidation_0-auc:0.86114\n",
      "[494]\tvalidation_0-auc:0.86112\n",
      "[495]\tvalidation_0-auc:0.86113\n",
      "[496]\tvalidation_0-auc:0.86113\n",
      "[497]\tvalidation_0-auc:0.86113\n",
      "[498]\tvalidation_0-auc:0.86114\n",
      "[499]\tvalidation_0-auc:0.86113\n",
      "[500]\tvalidation_0-auc:0.86113\n",
      "[501]\tvalidation_0-auc:0.86114\n",
      "[502]\tvalidation_0-auc:0.86114\n",
      "[503]\tvalidation_0-auc:0.86115\n",
      "[504]\tvalidation_0-auc:0.86114\n",
      "[505]\tvalidation_0-auc:0.86115\n",
      "[506]\tvalidation_0-auc:0.86114\n",
      "[507]\tvalidation_0-auc:0.86114\n",
      "[508]\tvalidation_0-auc:0.86111\n",
      "[509]\tvalidation_0-auc:0.86112\n",
      "[510]\tvalidation_0-auc:0.86113\n",
      "[511]\tvalidation_0-auc:0.86113\n",
      "[512]\tvalidation_0-auc:0.86114\n",
      "[513]\tvalidation_0-auc:0.86112\n",
      "[514]\tvalidation_0-auc:0.86112\n",
      "[515]\tvalidation_0-auc:0.86112\n",
      "[516]\tvalidation_0-auc:0.86110\n",
      "[517]\tvalidation_0-auc:0.86110\n",
      "[518]\tvalidation_0-auc:0.86110\n",
      "[519]\tvalidation_0-auc:0.86110\n",
      "[520]\tvalidation_0-auc:0.86110\n",
      "[521]\tvalidation_0-auc:0.86111\n",
      "[522]\tvalidation_0-auc:0.86111\n",
      "[523]\tvalidation_0-auc:0.86111\n",
      "[524]\tvalidation_0-auc:0.86111\n",
      "[525]\tvalidation_0-auc:0.86110\n",
      "[526]\tvalidation_0-auc:0.86110\n",
      "[527]\tvalidation_0-auc:0.86110\n",
      "[528]\tvalidation_0-auc:0.86110\n",
      "[529]\tvalidation_0-auc:0.86110\n",
      "[530]\tvalidation_0-auc:0.86109\n",
      "[531]\tvalidation_0-auc:0.86109\n",
      "[532]\tvalidation_0-auc:0.86110\n",
      "[533]\tvalidation_0-auc:0.86110\n",
      "[534]\tvalidation_0-auc:0.86110\n",
      "[535]\tvalidation_0-auc:0.86110\n",
      "[536]\tvalidation_0-auc:0.86110\n",
      "[537]\tvalidation_0-auc:0.86109\n",
      "[538]\tvalidation_0-auc:0.86109\n",
      "[539]\tvalidation_0-auc:0.86111\n",
      "[540]\tvalidation_0-auc:0.86110\n",
      "[541]\tvalidation_0-auc:0.86110\n",
      "[542]\tvalidation_0-auc:0.86109\n",
      "[543]\tvalidation_0-auc:0.86108\n",
      "[544]\tvalidation_0-auc:0.86109\n",
      "[545]\tvalidation_0-auc:0.86110\n",
      "[546]\tvalidation_0-auc:0.86109\n",
      "[547]\tvalidation_0-auc:0.86109\n",
      "[548]\tvalidation_0-auc:0.86108\n",
      "[549]\tvalidation_0-auc:0.86107\n",
      "[550]\tvalidation_0-auc:0.86107\n",
      "[551]\tvalidation_0-auc:0.86108\n",
      "[552]\tvalidation_0-auc:0.86108\n",
      "[553]\tvalidation_0-auc:0.86108\n",
      "[554]\tvalidation_0-auc:0.86107\n",
      "[555]\tvalidation_0-auc:0.86106\n",
      "[556]\tvalidation_0-auc:0.86106\n",
      "[557]\tvalidation_0-auc:0.86105\n",
      "[558]\tvalidation_0-auc:0.86106\n",
      "[559]\tvalidation_0-auc:0.86107\n",
      "[560]\tvalidation_0-auc:0.86107\n",
      "[561]\tvalidation_0-auc:0.86107\n",
      "[562]\tvalidation_0-auc:0.86106\n",
      "[563]\tvalidation_0-auc:0.86106\n",
      "[564]\tvalidation_0-auc:0.86106\n",
      "[565]\tvalidation_0-auc:0.86105\n",
      "[566]\tvalidation_0-auc:0.86105\n",
      "[567]\tvalidation_0-auc:0.86104\n",
      "[568]\tvalidation_0-auc:0.86104\n",
      "[569]\tvalidation_0-auc:0.86105\n",
      "[570]\tvalidation_0-auc:0.86105\n",
      "[571]\tvalidation_0-auc:0.86103\n",
      "[572]\tvalidation_0-auc:0.86103\n",
      "[573]\tvalidation_0-auc:0.86103\n",
      "[574]\tvalidation_0-auc:0.86102\n",
      "[575]\tvalidation_0-auc:0.86101\n",
      "[576]\tvalidation_0-auc:0.86101\n",
      "[577]\tvalidation_0-auc:0.86100\n",
      "[578]\tvalidation_0-auc:0.86100\n",
      "[579]\tvalidation_0-auc:0.86101\n",
      "[580]\tvalidation_0-auc:0.86101\n",
      "[581]\tvalidation_0-auc:0.86101\n",
      "[582]\tvalidation_0-auc:0.86102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=[&#x27;auc&#x27;], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;auc&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.01</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">800</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(13.97006738755681)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=100,\n",
       "              enable_categorical=False, eval_metric=['auc'], feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=7, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model_b.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98fe75e1-344d-4237-b4ad-cf0bd41a6ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for F1: 0.588026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Repaid       0.98      0.86      0.91     27993\n",
      "   Defaulted       0.26      0.70      0.38      2001\n",
      "\n",
      "    accuracy                           0.85     29994\n",
      "   macro avg       0.62      0.78      0.65     29994\n",
      "weighted avg       0.93      0.85      0.88     29994\n",
      "\n",
      "Accuracy: 84.81%\n",
      "ROC AUC: 0.867\n",
      "TP=1404, FP=3959, TN=24034, FN=597\n",
      "Accuracy for class 'Repaid': 85.86%\n",
      "Accuracy for class 'Defaulted': 70.16%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_probs = model_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Target defaults recall\n",
    "prec, rec, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f_beta_scores = fast_fbeta_scores(y_test, y_probs, thresholds, beta=2)\n",
    "best_thresh_b = thresholds[np.argmax(f_beta_scores)]\n",
    "\n",
    "y_pred = (y_probs > best_thresh_b).astype(int)\n",
    "\n",
    "target_names = ['Repaid', 'Defaulted']\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "print(\"Best threshold for F1:\", best_thresh_b)\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    print(f\"Accuracy for class '{class_name}': {per_class_acc[i]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {best_thresh_b:.2f})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f59276e5-d6aa-4c33-9e0d-bb69831287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Feature   Importance\n",
      "0                               HasAnyDelinquency  5456.720215\n",
      "1                               DelinquencyBucket  1178.671143\n",
      "2                              LatePaymentsPerAge  1127.926880\n",
      "3                            TotalPastDue_Squared   522.943054\n",
      "4                             HasMajorDelinquency   279.114502\n",
      "5                               UtilizationPerAge   254.710114\n",
      "6                               LatePaymentBucket   155.778030\n",
      "7                     UtilizationBucketLateBucket   151.570526\n",
      "8                               UtilizationBucket   151.192017\n",
      "9                           NormalizedUtilization   128.023941\n",
      "10  WasIncomePerCreditLineHasDelinquenciesImputed    84.666016\n",
      "11                             90DaysLate_Squared    80.314735\n",
      "12            WasLatePaymentsPerCreditLineImputed    60.672470\n",
      "13                            DebtToIncomeAgeRisk    60.429962\n",
      "14                                      AgeBucket    56.049545\n",
      "15                            IncomePerCreditLine    54.887234\n",
      "16                  WasIncomePerCreditLineImputed    50.954777\n",
      "17                      LatePaymentsPerCreditLine    48.167339\n",
      "18                                   DebtToIncome    47.744282\n",
      "19                              SevereDelinquency    27.928686\n",
      "20            IncomePerCreditLineHasDelinquencies    26.887114\n"
     ]
    }
   ],
   "source": [
    "# Importance XGB\n",
    "all_features = model_b.get_booster().feature_names\n",
    "importance_dict = model_b.get_booster().get_score(importance_type=\"gain\")\n",
    "full_importance = {feat: importance_dict.get(feat, 0.0) for feat in all_features}\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": list(full_importance.keys()),\n",
    "        \"Importance\": list(full_importance.values())\n",
    "    })\n",
    "    .sort_values(\"Importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43fa8015-98b5-4417-bee5-5f16321e37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19582dc939984cc49f928616598c4b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  mean_abs_shap\n",
      "3                               HasAnyDelinquency       0.025415\n",
      "6                               UtilizationPerAge       0.020775\n",
      "7                           NormalizedUtilization       0.012422\n",
      "10                            IncomePerCreditLine       0.011295\n",
      "9                             DebtToIncomeAgeRisk       0.010147\n",
      "0                             HasMajorDelinquency       0.007479\n",
      "18            WasLatePaymentsPerCreditLineImputed       0.003566\n",
      "16                              LatePaymentBucket       0.002984\n",
      "19                  WasIncomePerCreditLineImputed       0.002961\n",
      "20  WasIncomePerCreditLineHasDelinquenciesImputed       0.002481\n",
      "2                       LatePaymentsPerCreditLine       0.001800\n",
      "11                                   DebtToIncome       0.001614\n",
      "8                               SevereDelinquency       0.000735\n",
      "17                    UtilizationBucketLateBucket       0.000571\n",
      "1                              LatePaymentsPerAge       0.000530\n",
      "12            IncomePerCreditLineHasDelinquencies       0.000087\n",
      "5                              90DaysLate_Squared       0.000086\n",
      "15                              UtilizationBucket       0.000052\n",
      "14                              DelinquencyBucket       0.000017\n",
      "4                            TotalPastDue_Squared       0.000000\n",
      "13                                      AgeBucket       0.000000\n"
     ]
    }
   ],
   "source": [
    "# Importance NN\n",
    "model_cpu = copy.deepcopy(model).cpu()\n",
    "\n",
    "def shap_cpu(X):\n",
    "    X_num = X[:, :X_train_num_tensor.shape[1]]\n",
    "    X_cat = X[:, X_train_num_tensor.shape[1]:].astype(int)\n",
    "    \n",
    "    X_num_tensor = torch.tensor(X_num, dtype=torch.float32)\n",
    "    X_cat_tensor = torch.tensor(X_cat, dtype=torch.long)\n",
    "    \n",
    "    model_cpu.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model_cpu(X_num_tensor, X_cat_tensor)\n",
    "        probs = torch.sigmoid(logits).numpy()\n",
    "    return probs\n",
    "\n",
    "X_train_combined = np.hstack([X_train_num_tensor.numpy(), X_train_cat_tensor.numpy()])\n",
    "X_val_combined = np.hstack([X_val_num_tensor.numpy(), X_val_cat_tensor.numpy()])\n",
    "background_full = X_train_combined  \n",
    "background = shap.sample(background_full, 100)\n",
    "explainer = shap.KernelExplainer(shap_cpu, background)\n",
    "X_val_sample = X_val_combined[:500]\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "feature_names = list(num_col_order) + list(cat_col_order) + list(X_train_flags)\n",
    "\n",
    "shap_values_array = np.array(shap_values)  \n",
    "mean_abs_shap = np.abs(shap_values_array).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "})\n",
    "\n",
    "shap_importance = shap_importance.sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "print(shap_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f93116c1-306d-4f54-aad3-594620a558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NN model\n",
    "torch.save(model.state_dict(), \"cr_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "253cff4c-fced-4602-9725-51fedb59d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save xgb model\n",
    "model_b.save_model(\"cr_b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9623be2e-8fa4-4389-b656-bb7a9c17740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rare_maps.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save for hosting\n",
    "joblib.dump(best_thresh_a, \"threshold_a.pkl\")\n",
    "joblib.dump(best_thresh_b, \"threshold_b.pkl\")\n",
    "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
    "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
    "joblib.dump(robust_scaler, \"robust_scaler.pkl\")\n",
    "joblib.dump(std_scaler, \"std_scaler.pkl\")\n",
    "joblib.dump(num_col_order, \"num_col_order.pkl\")\n",
    "joblib.dump(cat_maps, \"cat_maps.pkl\")\n",
    "joblib.dump(cat_col_order, \"cat_col_order.pkl\")\n",
    "joblib.dump(X_train_flags, \"X_train_flags.pkl\")\n",
    "joblib.dump(skewed_col_order, \"skewed_col_order.pkl\")\n",
    "joblib.dump(rare_maps, \"rare_maps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeaa347-6df5-43da-96f1-c9965a086d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
